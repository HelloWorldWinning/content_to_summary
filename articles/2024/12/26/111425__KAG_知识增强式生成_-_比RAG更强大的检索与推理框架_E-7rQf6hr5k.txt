Timestamp: 2024-12-26T11:14:25.952524
Title: 【KAG】知识增强式生成 - 比RAG更强大的检索与推理框架 E-7rQf6hr5k
URL: https://youtube.com/watch?v=E-7rQf6hr5k&si=2Y2IQT57ZqVB4rOO
Status: success

Description:
**核心思想概要:**

1.  **背景:** 当前AI问答领域中，检索增强生成（RAG）技术被广泛使用，但存在诸如缺乏关联性、逻辑性以及检索结果不完整和重复等局限性。
2.  **新方案:**  提出一种基于知识图谱 (KG) 的新型信息检索增强技术，以弥补RAG的不足，从而提高AI问答质量。
3.  **KG核心功能:** 
    *   **知识表示:** 将非结构化、结构化数据以及专家经验整合为统一的知识图谱，方便大模型理解。
    *   **推理模式:**  采用逻辑形式引导的混合推理，包含规划、推理和检索等操作，能更好地进行复杂问题的求解。
4.  **KG应用:** 通过一个实际案例演示，对比了KG和RAG在信息检索和问答方面的差异，展示KG在复杂问题回答上的优势。
5.  **总结:**  KG可以弥补 RAG 的局限性，提供更高质量的信息检索，从而提升大模型问答的质量。


Content:
大家好,我是小莫头,欢迎大家来到我的视频频道在追博AI的热潮中,RG是非常热门的一个概念和话题RG也就是减锁增强式的声承这是在AI问答中常见的数据或信息减锁的方式帮助大模型扩展支持领域将私有的或外部的数据应用到AI问答中虽然RG非常流行,但是它也有非常明显的短板今天我就能分享一种新的支持或信息减锁技术KG帮助我们弥补RG的短板,更好的在AI支持问答中实现数据或信息的减锁首先简单回顾一下什么是RG在这里我就利用危机版颗的页面来做一番介绍RG也就是减锁增强式的声承通过这张图片可以看到在一个问答轮次中当用户的提问需要引用到特有领域或私狱的知识是该怎么做呢这就是RG发挥作用的地方大模型会通过一个叫相量数据库的数据存储来减锁相关文档这个相关文档是基于相似度来进行计算或许的相关文档在作为大元模型推理的上下文的文本片段推理并得到结果反会给用户这就是RG的概念以及如何将外部数据或私有的知识引用到AI问答中从现在我所分享的RG的价格可以看到虽然RG解决到大部分由于缺乏特定领域知识和实实更新信息导致到换决问题但是声承的文本也就是相关文档人家存在的局限性首先是缺乏连关性和逻辑性特别是在法律医学科学等需要分析推理的专业领域中无法产生正确而有价值的答案另一方面是减锁机制本身的局限性RG主要依赖文本或相量的相思性来减锁参考信息这可能导致减锁结果不完整和重复这也是在进习为什么会推演出以知识图普数据存储为基础的信息减锁增强现在我们就回到在视频开始时介绍的KG概念我现在分享的是OpenKG的官网来到代码仓库这正是今天我们介绍的主题KG首先我们来简单介绍一下什么是KG这是一个基于OpenSPG引擎和大约模型的逻辑推理和问答框架用于构建垂直领域知识库的逻辑推理和问答解决方案KG基于OpenSPG引擎那什么是OpenSPG呢我们再次来到OpenSPG代码仓库这是马亚集团与OpenKG共同开发的知识图谱引擎OpenSPG又积预了SPG框架现在分享的这样图表呢能够接视OpenSPG KG等等框架与模块的关系在最底层是通过图存储大模型相当存储等等来为上层的OpenSPG提供了数据的存储与减锁支持而最上层的KG则积预了SPG编程框架来实现了垂直领域知识库的构建减锁以及问答今天我们主要介绍的是如何利用KG来构建垂直领域的知识库我们首先快速地来看看KG的核心的功能第一部分是知识的表示在4有数据库的背景下非结构画数据 结构画的数据和业务专家经验往往共存KG是参加了DIKW层次结构将SPG升级为对大约模型友好的版本对于领域特定的知识或信息KG采用版面分析 知识抽取属性规范化和与对其的技术将原始的业务数据和专家贵则整合了统一的知识图谱中这有什么好处呢他使得在同意知识类型上兼容无模式的信息抽取和有模式约束的专业知识构建最终知识图结构与原始文文快之间的交叉所引这种护所引有助于去图结构构建倒派所引促进逻辑形式的同意表示和推理咱们可以持关的认为可以实现在RG应用中常见的向上数据的成处与检俗以及继续图结构的数据存处与检俗接下来介绍KG中的推理模式这是一种逻辑形式引导的混合推理KG支持逻辑形式引导的混合解决方案和推理引擎该引擎它包含了三部分规划推理和检俗三类算字能够将自安语言转换为结合语言和符号的问题求解过程在这个推理过程每一步都可以使用不同的算字比如精确匹配的检俗比如文本的检俗数值计算以及于推理或许这部分介绍听起来有些抽象那么从学习层面来讲分为两部分第一部分是KG的理论基础这部分来自于RKF上的一篇文章在这里我已经打开这篇文章有兴趣同学可以来深入的学习了解一下它的理论基础在今天分享中我们就不在这里深入展开我想大家对于KG技术非常有兴趣是第一时间的运行测试看看在知识库构建上究竟信息减所 问答体验有什么不同现在我就在本地运行KG跟大家一起来构建一个知识库看看在问答上究竟它能产生什么不一样的效果从使用身边来讲分为了两种模式第一种是直接以产品性式来使用我们可以通过到KG的形式来运行这是最方便的另一种是KG模式大家期望通过程序化的方式来使用那么可以参考目前文档中第二部分即于工具包的形式在这种模式下我们可以利用Person变成语言来使用KG以产品的形式使用非常简单通过下载一份到KG的Pose文件本地运行就好在这里有两行命令通过Curl下载到KG的Pose文件并且利用到KG的Pose文件运行这样我们会得到三个容器我们马上会来运行在分享演示前在这里同样介绍一下KG的拥护手册目前我所分享的就是KG的拥护手册我会将相关链接都放在视频描述中有讯确的同学就在描述中取用在文档中对软硬件的要求都做了介绍在KG使用中会用到深圳模型还可以根据自己偏好来选择我在演示中会用到OpenEI的GPT4O同样在KG中会用到文本签入模型也就表示模型大家可以按照自己的偏好来设置现在我们就通过在文档中介绍的命令来将它下载运行我在本地已经下载了这份Docke Compose文件同时已经预拉取了Docke倾向这样也能帮助我们的演示能够更加的顺利快速我再次将其启动大家可以看到在这个环境当中一共有三个容器一个是MySQL一个是Nale4G一个就是OpenSPG的福气Nale4G正式帮助我们进行图数据的存储现在已经启动完毕我们就可以来到本地的8887专口大家在我现在本地这个环境这里应该能够看到一个WTF的Langin即简入门的支持库这是我在演示前已经创建好的因为支持库的创建已经任务执行需要一些时间因此我已经提前准备好那么我同样会通过创建支持库的步骤来演示该如何配置点击创建支持库接参数大家可能暂时不知道该怎么填不过不要紧我们可以参考文档文档对于每个字段该怎么填有非常明确的介绍我们可以主意的来填写支持库有两个名字一个是中文名一个是英文名中文名主要用于业面上这是库名字的展示英文名用于Skima的秘名因此中文名我们在这里可以任意填写而英文名则不能带控格我们可以按照这种形式来设置中文名和英文名接下来是纯组的配置这个纯组是图数据库的纯组在本地运行了一个Nale4界的容器因此我们可以参考这个配置直接将其负责占贴进去就好接下来我们进行模型的配置这里提到的模型是深层式模型可以继织支持OpenEA肩容的一批比如像OpenEA的官方的模型或DipSync千万二等等模型大家可以通过本地化比如通过VALM或Olamac模式在本地运行目前文囊中给到的实力是DipSync所提供的模型同样负质这部分配置将其沾贴到模型配置这里作为的是在配置完成点击OK确定的时候会对模型的配置作验证如果是无下的AppiK或者UARL配置不正确这里会创建失败比如我们在这里如果需要将模型修改为OpenEA的GPTSO我们可以这样做BaseUARL自然是OpenEA要注意的是OpenEA这里需要V1加上Appi的后锥来给它提供一个AppiK我在后台负质了一个OpenEA的AppiK沾贴过来我会在视频分享后将其回滚接下来是相量的配置什么是相量配置呢我们来看看相量的配置其实也就是Inbending Model文本签入模型的配置大家同样可以使用OpenEA的文本签入模型也可以使用像规矩流动等服务工业上提供的只要按照相应的参数来进行配置就好比如我们在这里将这段配置复制沾贴到这里同样我们也是使用OpenEA的文本签入模型复制沾贴过来对应的Face U2AO就要做修改OpenEA到Con slash V1比如咱们使用老的Inbending A的Deling2模型这就完成了文本签入模型的配置最后有一项是提示词来看看文档虽然在页面上并没有标记为B甜但是在文档中还是提到了这是一个B甜项用于模型调用是判断是否使用中文还是使用英文我们也同样将其复制现在点击OK现在呢知识固创建完毕我们要做的还需要将咱们的知识上传完成数据的处理和锁影那么点击knowledge management就进入了知识固的管理界面通过创建一个任务来上传文件处理文件并完成所有的点击可以task目前已经能够支持多种文件类型像文本CSVJSON XMLMD PDF等等我交易WTFLunchen急证入门课程系列的第一课来做演示这就是一个点形的MD文件现在呢我选择已经下载好的这一份MD文件给它一个名字比如课程E在这里默认的分段长度或分块长度呢是2000我在这里呢将其设的相对小一些目的在于通过将文囊分成叫小的快从而在后续的KG和RG的问答质量的对比上体现出一些效果这个呢我们在后续的分享中马上会介绍下一步抽取模型我们选择默认在这里允许我们提供一些提示词这个提示词是什么呢我们回到文囊接和文囊介绍一下点击Finish就完成了任务的创建接下来呢会花一些时间进行任务的执行我们在这里点击Log可以看到目前它的处理进程我在这里呢就不等待它完成了我先将这个任务就删除那回到在视频分享前我已经创建好的知识库通过日质大家来看看它的处理过程是什么接过程大约花了8分钟这是一个大约5K的文囊花了大约8分钟因此呢这个过程可能会有些长特别是针对一些叫大的文件它完成了几大任务第一呢读取文囊然后对文囊做切分这个切分是按照我们刚才设置的Second Lands来做的切分在相当数据深圳前首先会做知识的抽取针对每一块数据块进行知识抽取这是为了后续的图数据做准备在相当深圳这里会利用咱们已经配置好的文本签入模型进行相当数据的深圳最后进行图数据的存储完成整个任务的知识现在我们就有了一个KG支持下的知识库我们现在来到知识库问哪这里创建一个新的会话在右边就可以如日常咱们使用两天机器的那样进行问答首先我想问一个最简单的问题什么是WTF LANCHAN它会进行一个叫TITLE的过程REASONING PROCESS我们稍时等待这个回答是一个非常标准的回答因为这段内容也完完全全来自于即将入门课程系列因为这个问题答案就在文档的开头部分大概率它能够包含在一个完整的RG的文稳分块中为了更好的演示KG和RG的不同我在D5的云端也够建了同样的知识库这就是一个典型的GRG的知识库我们来通过同样的问答看看它有什么区别在NOLIT这里我提前够建好的一个知识库使用了同样的MD文件可以来看一下它的配置在分块场路上我同样使用了200这样的方便咱们来比对在问答中对数据减硕方面会产生什么不一样的效果这就是一个典型的RG的知识库在STUDE这里我也创建了一个聊天机器人这个聊天机器人呢咱们将WTFLANCHAN1这个知识库关键进来通过使用GPT4O模型吧来看看它的问答质量有何差异同样我们来问问什么是WTFLANCHAN这个问答都没有问题在分块上大家可以看到问题的答案就分布在了文档的最开头的文档分块中因此呢它是能够很好的进行回答的现在我先建一个会话尝试来减所更多的信息那首先来到课程E这里现在呢我想问一个问题来涵盖更多的信息或知识点比如我想了解什么是LANCHAN什么是OpenEI他们之间的关系并且呢看一看一个最简单的LANCHAN拍成应用程序的代码是什么样的最后来了解这门课程的总结这些信息基本上就涵盖了冲突到尾整个文档我们来看看在问答上KG和传统RG知识库有什么不同我觉得这样这个问题交给KG知识库同时呢我将这个问题也到D5这里作为一番询问来看看效果吧在KG这里的回答上可能显示或月图上并不是那么的直观不过我们可以通过点击这个推理过程的问题答案来看更加友好的一个显示在这里呢对LANCHAN OpenEI都做了介绍并且介绍他们的关系还基于课程的内容给到了最简单的一个LANCHAN应用的实力代码最后是一番总结非常的友好大家注意在回答中LANCHAN OpenEI他们的关系实力代码以及最后的总结都很好的通过信息减硕不获到了必要的信息来回答问题那么回到RG知识库这里我们来看看他的回答对LANCHAN做了介绍可以通过文档分块这里看到通这种方式的减锁呢确实是能够得到绝大告诉我们想要的信息但受制于RG的局限性导致在信息减锁是有限的文档片段并不能够足以复材所以我们可以通过文档分块这里看到通这种方式的减锁呢确实是能够得到绝大告诉我们想要的信息但受制于RG的局限性导致在信息减锁是有限的文档片段能够足以复材在提问中所有必要的文档分块在这个提问的回答中他就确实了文档EI的介绍因此大家可以通过这个对比看到在KG和RG的对比中KG能够迷补掉在RG应用场景中的局限性帮助我们更好的完成信息的所以从而在大约模型问答中数据或信息减锁中提供更高质量的减锁那视频分享时间有限我们无法覆盖到KG的方方面面我会将今天分享中用的的文档KG的代码倡库的链接都放在视频描述中有兴趣同学就在描述中取用在KG的使用中大家如果有任何问题也欢迎在频中去一个我们交流希望通过咱们的技术分享能够帮助在基于大约模型的知识减锁和问答中提高问答质量帮助大家更好的构建更优秀的到模型应用好吧今天的分享就到这里感谢大家收看那我们就下期视频分享再见同学们 拜拜
