Timestamp: 2024-12-22T14:51:00.721054
Title: Gemini 2.0 Flash Thinking
URL: https://youtu.be/podMF0FNJac?si=Lb_8cWXFwWnzMFPg
Status: success

Description:
Okay, here's a structured summary of the core ideas:

**I. Introduction of Gemini 2.0 Flash "Thinking" Model:**

*   Google has released an experimental version of Gemini 2.0 Flash model, called "Thinking" that utilizes "Chain of Thought" reasoning.
*   This model appears to be a response to similar developments at OpenAI, focusing on improved reasoning through internal thought processes.
*   The release was done without much fanfare, mostly through Twitter posts from the Gemini team.

**II. Key Features and Characteristics:**

*   **Chain of Thought (CoT) Reasoning:** The model is trained to utilize its "thoughts" to enhance its reasoning capabilities, showing intermediate steps.
*   **No Sub-Diffusion:** The model is increasing inference time computation, unlike some other approaches.
*   **Full Output of Thoughts:** Users can access the complete "Chain of Thought" output, unlike the abbreviated outputs of some models like 01 preview.
*   **Free Access:** The experimental model is available for free through AI Studio, both for direct use and via API.
*   **Token Limit:**  Currently limited to a 32,000 token context window but this should be increased in the future.
*   **Multi-modal reasoning:** can understand and reason about both images and text.

**III. Performance and Examples:**

*   **Improved Reasoning:** The model demonstrates the ability to analyze inputs carefully, detect misinterpretations, and correct itself.
*   **Self-Correction:** It engages in a self-correcting and double-checking process.
*   **Internal Questioning:** It asks itself questions to validate its thinking before providing answers.
*   **Contextual Awareness:** The model can understand relationships in complex questions, even when modified.
*   **Scenario Generation:** It can consider different possible future scenarios beyond what's explicitly presented in the input and shows deeper planning capabilities for agent tasks.
*   **Multi-modal reasoning:** Can reason about images and text.

**IV. API Usage and System Prompt Influence:**

*   **API Access:** The model is accessible via a Gen Unified SDK for both AI Studio and Vertex AI.
*   **System Prompts Impact:**  System prompts can influence both the final output and the "Chain of Thought" reasoning process; for example, prompting it to "think carefully" increases thought output.
*   **Thinking vs. Final Answer Extraction:** The API allows for the separation of the "Chain of Thought" from the final answer.

**V. Conclusion:**

*   The Gemini 2.0 Flash "Thinking" model provides free access to a model with enhanced reasoning through visible internal thought processes, opening up possibilities for more complex AI applications.


Content:
Okay so yesterday Google shipped their even newer version of Gemini 2.0 flash that contains reasoning traces or Chain of Thought traces uh in here so they're calling this Gemini 2.0 flash thinking it's an experimental model that's just been dropped now one may think that it's been dropped quite deliberately to preempt a big announcement from open AI anyway as I'm recording this there is no fancy blog post about this or really many even details about this it's kind of released on Twitter by a number of people on the Gemini team starting with Logan kill Patrick who introduced the model and has got a nice little video example of it now not long after Logan's post we saw a whole bunch of posts from people working on the Gemini team people like Jeff Dean who's one of the two leaders of the Gemini team talking about this model talking about that like their first foray into this idea of building something where it's been train to use its thoughts to strengthen reasoning in here and it's kind of interesting to see that there is no sort of sub diffusion here that they quite openly talk about that this is basically where they're increasing inference time computation and that it's the first model that they're releasing like this really this is not surprising for people who follow the research deep mine has had a number of papers around these ideas over the past couple of years including this one which was scaling llm test time compute and there' have been others along similar lines to what open AI has been working on another thing if you didn't know some of the key people behind 01 at open aai are ex Google brain researchers so it's really just a matter of time until when Google is going to release a model like this one of the tweets I found really interesting was Nome Shazia for those of you who don't know Nome Shazia is the guy that Google paid a fortune to bring back from character AI he and his co-founder both were researchers at Google brain in the past they've come back now to Google Deep Mind he's also the key author I would say on the original Transformer paper as well as many of the papers around mixture of experts and scaling to large models you know inside Google Now very interestingly not long after the Google tweets came out we saw a tweet from from El Marina which is the place I've talked about many times where people go to test out their models companies upload their models Etc and we can see here that they're basically ranking this Gemini 2.0 flash thinking as tied for the number one overall model with another experimental model which no one has publicly confirmed exactly what it is and I think we'll have to wait another month or so before we actually see that so it is very interesting looking at the chatbot Arena results that they're ranking this flash reasoning or Flash thinking model above both 01 preview and 01 mini which is interesting because don't forget this is you know built on flash this is the sort of much smaller faster more agile model and it does really open the door for okay where do things go from here with the Gemini 2.0 models as they bring out Pro are we going to see Ultra come back for public use Etc and most of all the probably biggest and coolest thing about this announcement today is that you can go and use this right now and it's not going to cost you a penny you don't have to pay $200 a month you don't even have to pay to use it as an API you can literally come into AI Studio scroll down to the preview models and access this flash thinking experimental so the 129 date there currently you can use this for free currently the version that they've released only goes up to 32,000 tokens for the context window I think we'll see that change early next year but anyway let's jump in here and have a look and play with just using this model and let's see what it can do both in AI Studio we also have a play with it of how you can use it on collab via the API directly okay so let's jump in and look at the first example so I've got no system instructions in here so I guess we're just going with whatever the default they had in there and so obviously the first thing to ask is about the strawberry question but if you've seen me do this in some of the other like re reasoning models and stuff like that nowadays what I ask is I spell strawberries wrong so it's got four RS and then I ask it so how many RS in Strawberry with uh spelled wrong should be four it actually gives us three in here and we can see that it rephrases that okay I want to know just strawberry now the thing that I thought was interesting was not that it gets it wrong but I thought that when I ask it okay that is not what I asked read my first statement carefully and this is the bit that I find really interesting in here is that in its sort of chain of thoughts it now breaks down that okay identify the ques the user pointed out my mistake and specifically referenced their first statement this tells me problem isn't with the counting itself but with understanding the input this I think is really powerful right that it's having the ability to distinguish that okay it wasn't that the counting it got wrong it was that it misinterpreted what I asked asked and then now it looks at it and it noticed the misspelling of strawberry right that actually I spelled it wrong and that was quite deliberate so now it says okay let's go and sort of count you know that and so it now works out that okay there are four hours so then constructs a clear and concise answer acknowledge the error expecially State the correct word I should have been analyzing provide the accurate response refine the answer and then it gives us the the answer back right you are absolutely right my my apologies I miss you read your original statement counting the RS in Strawberry there are four RS so whether this got this right or wrong is not the bit that I'm most interested in I'm interested in these internal chains of thought now by the way check this out if we were doing this with 01 we wouldn't have access to any of these in this model from Google we're getting the full output that it's basically doing its chains of thought in here we're not getting some kind of abbreviated thing the 01 preview Etc had this is the full output for each of these statements I do find it very kind of funny or ironic that when we ask the exact same model from the non-thinking thing and I spell it wrong it straight away just says there are four RS in this so it's almost like this thinking one is trying to understand your input more and think that okay you probably didn't mean to spell it wrong but is then able to correct when it sees this issue so for me this one is really fascinating looking at this part in here all right let's look at another one okay so this is a pretty simple sort of question my mother was 24 when I was born how old was she when I was 13 her age half her age and 3/4 her age all right so you can see that it gives us an answer back this answer back has got explanations in it so actually got quite a lot lot in the answer back here that sort of explains the thinking down to when we get the summary but this is not the Chain of Thought thinking right so when we click this we see the raw chains of thought that are going on in here so we can see that here it's gone for understand core relationships the fact is the age difference between mother and child remains a constant Define variables so these kinds of chains of thought actually uh a lot of them come out of some of the ideas around papers that came out of Deep Mind for things like self-discover and prompt breeder and stuff like that where they were trying to encourage models to come up with better and more useful chains of thought as they go through so we can see with each of these we're getting like what the Chain of Thought is and then the actual thinking you know behind it as we go through so we can see that it comes through this it does like a self-correcting or double checking process and here I find it very interesting how it actually asks itself questions about its own thinking here does the H difference remain constant so it's looking at this do the answers make sense in the context of the problem read the question carefully so it really is like it's double cheing its thought processes before it goes on to solve this then it goes on to show us the sort of answer or the proof of what it's actually done here okay so the next one is like a variation on one I've done before I do think it's really important that when you do these kind of things in this case I'm getting it testing okay does it understand the relationships between number of sisters and brothers but we don't want to always go with s or the standard sort of uh way that these questions are formatted because everyone's training on the internet those questions get out there it's very easy for these models even ones with no sort of self- reasoning to be able to get good at memorizing answers so here I've changed it to FR has Five Sisters each sister has four brothers how many brothers does Freddy all right so we can see that this is going off we can see the amount of seconds it's taking to do the thinking right as it's going through we can see clearly this time it's taking more seconds than the last one all right it's come back it's given us its breakdown focus on and this is like the summary this is what we would get from the output of the 01 model so it's like a summary of it thinking okay focus on the sister's perspective the key piece of information is that each sister has four brothers shared brothers and sure enough it's worked out that okay Freddy's Brothers since Freddy is one of the brothers he has four minus one which Equals Three Brothers now if we look at that Chain of Thought we've got quite a lot of Chain of Thought going on there so this is very interesting to actually be able to access this raw sort of stuff again I point out that all of this is free right you can use this now already in AI Studio AI studio is definitely aimed at developers but I know a lot of you who are watching a perhaps not developers you can come along and just use this for free it's not hard to use remember you can just always come up here make an API key get your 1500 free calls a day or whatever it is that you've got access to in there looking at this again we can see that okay we need to identify the key individuals focus on the sisters perspective consider the shared Brothers connect Freddy to the brothers there's a lot of nice chains of thought here that have come out of sort of stepbystep thinking of how to make this work and even reread and confirm so you can see that as it's going through this it's putting it together to come up with the final answer all right let's look at one more before we have a quick look at looking at code for this okay so the next one up is one that I've used before also in the videos explain the consequences of what would have happened in to if the nuclear weapon wasn't used so really this is testing it on how can it think of different sorts of possible Futures Etc now one of the issues that we've gotten here is that this may have been affected by this sort of content filter and even though I've got all of these turned off it flagged it in here all right so we can see here that we got some of the thinking that was very similar to some of the nice thinking from both o1 and r one was like that okay that perhaps Russia would have got involved more and different things that could have possibly happened in here so we definitely got a nice detailed out if we look at the expanded chains of thought we can see that okay what's the core question again this is a very common pattern that these things do is that they establish they really have their first chains of thought that are all about trying to understand the question better what did the person really mean behind this and this is why I thought it was interesting when it got the strawberry wrong the first time that it just presumed that okay that's a typo he doesn't mean that as it tries to understand the question but was then able to correct that when I established no that go and read that cuz I didn't have a typo go and read it carefully we can see that then we've got different sorts of things about brainstorming so this is idea generation rather than just analysis of these things this is now starting to have to think about okay coming up with ideas and then focus on most likely or discussed scenarios now remember this has been trained on a lot of the content on the web so it's probably looking around at things in its training data right not literally looking up things but through its weights it's going back to so what scenarios were proposed that it's read on the internet before and then we can see it does some really interesting thing then it goes into sort of like analyze mode of where it analyzes each scenario in detail and it asks itself specific questions about each scenario that how would it unfold consequences evidence and arguments supporting the scenario potential counterarguments and limitations so there's some really nice sort of logical thinking going on in how it's doing these things and then finally structuring its explanation out refining elaborate I'm guessing at the end it's going to check did it get it right yes sure enough we've got our self-correction example and then notices okay initial thought was focused solely on Invasion correction realized that Soviet entry was a significant factor and go through this now obviously if we're going to ask it something that Google's going to block heavily we're probably not going to see that in the chains of thought coming through here and it seems like this is just a warning it hasn't actually taken anything out of the Chain of Thought from what I can see and the answer seems very thorough as well going through this okay so the next thing that wanted to point out is that because Flash can take multimodal inputs in we can do things like have it reason on images so here you can see I've basically given it a puzzle where it's got a sort of unfolded die that can be assembled and when it's assembled it's going to be one of these now notice that here I've put think carefully and hard then I'm just asking it which of these die can be made with the layout in the pick so so it goes on to get the correct answer if you look at this you're going to basically end up having the square next to the three in this these two can never be next to each other so that eliminates these two and then these two can never be next to each other because they're on opposite sides so the only correct answer here is D if we look at the answer out here is that it gives us the correct answer but more than this when we're looking at the Chain of Thought it's really got an interesting way of getting this that it thinks about okay how these would go and then it does a nice re-evaluation putting these you know together it talks about visualizing the folding so where each piece is going to be on the folding and stuff like that as it goes through finally it's able to come up with its final answer for doing this so the whole idea of multimodal reasoning is really interesting as well and that's one that's only just come to the 01 models with their release that can basically take images in you could imagine that we could also get this to do reasoning on other multimodal things like audio like video that kind of thing going forward okay let's just jump in and have a look at how you can do this directly via the API and how you can set it up for both text and for image input I'm just going to quickly go through this and show you how to basically get started so you're going to be using the Gen unified SDK so this will work for both AI Studio or for vertex AI if you're using vertex AI you basically just don't pass in this you will pass in a project you pass in some I am some other stuff going on in there first off just calling a simple prompt you'll see that okay the system prompt does actually have quite a bit of effect I noticed I'll talk about that a little bit more as we go through but I've just started off with a simple system prompt be a thorough and helpful assistant explain the concepts of World War II so I did that already in AI studio and you see that if you just take the response. text you get everything out here right the full sort of long thing but if you take different parts you can get the thinking and then you can get the you know final answer or separate parts out now interestingly they have a DOT thought thing in there so I'm not sure if later on that's going to become the thinking part will go in there so that we can get the thought out at the moment it doesn't seem to be being used in here the next thing is just putting it together in a function and in this case I'm going to basically return back the full response The Chain of Thought thinking the final answer and you can see now we can take the Jenny has five brothers they each have three sisters how many sisters does Jenny have I run it through with a system prompt of nothing and you'll find that okay it gives me this is a classic riddle the answer is two it gives me the the Chain of Thought thinking of why it came to that answer and then we can get the full response now interestingly playing around with it if I use this keep your final answer succinct and very brief that does seem to sort of limit both the final output but also the actual quality of the Chain of Thought in just a few couple tests so it could be coincidental put it in there and try it out I definitely notice another one I'll show you in a bit is that if you say hey take your time and think carefully about this it will really use the Chain of Thought more in that way so the system prompt definitely seems to influence both the Chain of Thought and the final output that you get there the other cool thing is you can do this with images so this is just bringing in the standard image that they've got but you can bring in any image that you want this is the jetpack backpack it's a picture that's been used for Gemini for a while and here I've just made a version of the get thinking with image and we're just passing in the image as well into the prompt and now I can ask it things like how much weight do you think Jetpack like this could carry think extensively so this one I found it to be quite good comparing this to not passing in or passing in an empty system prompt it got much better results and you can see here we've got the final answer back there and then we've got the Chain of Thought showing this in-depth thinking that it's gone to and then obviously the full response putting it all together so have a play with this I definitely found this really interesting to try out I've Tred on a few different agent tasks that I've been using and it's quite nice for doing the planning and stuff and being able to abstract out getting the Chain of Thought thinking for a plan and the final plan can be really useful to separate those out anyway I will certainly be playing with this a lot more I'll probably make some more videos with it over the next few weeks or when the ga version comes out so that we can look at that as always if you've got any questions or comments I'd love to hear how you're using it what you're finding it to be good at I think the Gemini team would also love to hear where it's not doing well so that if you can give feedback about that that's also really interesting to see and as always if you found the video useful please click and subscribe and I will see you in the next video bye for now
