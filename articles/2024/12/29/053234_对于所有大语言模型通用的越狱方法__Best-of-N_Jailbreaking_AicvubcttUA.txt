Timestamp: 2024-12-29T05:32:34.309355
Title: 对于所有大语言模型通用的越狱方法  Best-of-N Jailbreaking AicvubcttUA
URL: https://youtu.be/AicvubcttUA?si=l_85ggAoZXiZWGxD
Status: success

Description:
*   **核心观点：** 一种新的大语言模型越狱方法通过微调输入提示词，在多次尝试后可绕过模型安全限制，实现越狱攻击。

*   **要点：**
    1.  **方法原理：** 通过对问题中的词语进行微小变换，多次尝试直到模型给出危险或不应回答的答案。
    2.  **实验验证：** 该方法对多种前沿大模型（文本、视觉、音频模型）均有效，攻击成功率在多次尝试后趋于稳定，文本攻击在1万次尝试后达到较高成功率。
    3.  **实际应用：** 研究提供的例子部分有效，但部分因模型更新失效；个人测试显示，该方法在本地模型上亦可实现越狱。
    4.  **辅助工具：** OpenAI的Model Ration API可用于检测越狱后模型输出的有害内容。

*   **总结：** 通过暴力破解式的微调提示词，一种越狱方法被验证可行，并可通过检测有害内容来判断是否成功。


Content:
今天我们来介绍一种大元模型的越于方法基本上这种方法对于现在所有的前颜大元模型都是有效的无论你是避缘还是开缘这个方法是Unserpec的研究人员研究出来的现在屏幕上展现的就是他们的方法的一个呆要一个总结屏幕上方的这张图是插的越于方法一个工作原理的解释基本上你输入一个问题比如说去怎么去构建一个炸弹如果你把这个问题扔给大元模型大元模型肯定是拒绝回答的因为这样的问题是危险的具有危险的倾向所以大元说我不能回答你但是你把里面的这些单词里面的字我进行微小的一些变换再为给大元模型大元模型很有可能再说我还是不能回答你自类的但是你不断的事不断的事中有一天在某种组合下面大元模型说好我可以提供你这个答案那么在这种组合下面大元模型说OK的时候那么你的越于就成功了这个相当于是一个同举的一个暴力的破解的一个方法这就有点像一个左降啊他去开一把不是自己的没有钥匙的一个署他拿了一把万能钥匙不是说把万能钥匙放进去立刻就能开而是不断的在里面不断的事是在着眼的某一个合适的位置那么一牛正好把所有的位置都对上了把这个说打开了这个他的一个越于的方法的工作原理的一个非常简单的一个解释那我们看一下下面这张图是这个研究人员对于现在的一些前约的大元模型所进行的一个测试的一个结果我们可以看到有Klaude3三点五三耐的EPT4GPD4mmGeminaeDama他都进行一些测试除了这个文本提示词的攻击也包括视觉模型的攻击还有音频模型的于营模型的攻击那么一看到他的最后的效果是怎么样呢我们可以看到这个NN的Douart次常试常试的次数我们可以看到基本上到了一万次的时候他的诊本提示词的攻击的效果都出来的都有一定的攻击效果也就是他的攻击成功率基本上去平稳了比如说我们可以看到在调限是大概90%多的左右一样子这个就是他的攻击的成功率那也就是说到了一万次左右的时候攻击的成功率就达到了90%左右的样子对于这条线来说的这个线能到位一点这条线我看好是GeminaeGeminae的话一万次左右是40%多了还不到50%的样子这个是文本提示词的攻击可以看到在格式决模型他基本上到了6000次的时候这个攻击基本上是去于平稳他的攻击率就基本上搜脸了音频是在6000以上大概的78000的样子好像也就开始去搜脸了一个状态了那么在这篇需要的他的Link里面他还提供了一些样丽这样丽是包括了文本提示词的攻击也包括了决模型的攻击拭决模型的攻击只用图片来进行攻击也包括了于模型的攻击于模型的攻击只用音频文件来作为塑入的提示词那么这些例子到底有效没效呢我也进行了一些测试发现有些例子是有效的那有些例子已经是不起作用了那为什么不起作用呢我估计是由于有些模型他不断的在进行更新所以当时这些研究人员说测试出来有效的例子呢再搞大元的模型更新之后呢他就变得不起作用了那有些第一词还是有效的比如说这句题词是用于plow3OPS这个模型上的我就尝试了一下这是他的Input这下面就是他的Output这 Output不得的内容看起来是他的攻击是有效果的如果大家有兴趣的也可以直接使用他们的代码来自己也去体验一把但是说老实话我觉得他们这个代码安装起来实在是太麻烦了而且我自己尝试了一下最后还是放弃了主要是这个环境的一个安装就本能就非常复杂看起来还有一大堆的这个K你需要设置什么OpenIA的呀谷歌的呀什么You can't live的呀这些K呀他都要设置我觉得太麻烦了那最后呢我就自己写了那么一个拍摄了一个脚本参考了他的一些元代码进行的一些测试我测试的对象的是Ola马上面的Lama 3.2这么一个大元模型从我的测试的一个结果来看这个方法确实是有效的我大概经过了一万到两万次左右的一个测试就出现了那么几条看起来是越于成功了的这个响应结果最后的响应结果我都放到了这个Kandy Data的这个Tax的文件里头大家有兴趣的可以参考一下中间有些是属于假扬性也就是说它看起来是成功了其实没有成功但是看起来有些是确实越于成功了这个link我会放到视频的描述栏里面供大家参考最后有一点我想分享一下在这测试里面我使用到了一个OpenAI的API它叫Model Ration这个API是用来干什么能不能使用来去检测你的内容里面是不是有有害内容比如说什么总组歧视仇恨言论之类的那我为什么需要这样的一个API这就是因为我在测试的时候要判断它是不是越于成功了那么越于成功的这种Response通常有可能是会被OpenAI和定位有害的所以我就使用到了这么一个API感觉听了意思的给大家分享一下
