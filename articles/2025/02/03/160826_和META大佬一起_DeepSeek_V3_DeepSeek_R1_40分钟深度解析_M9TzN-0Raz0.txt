Timestamp: 2025-02-03T16:08:26.200613
Title: 和META大佬一起！DeepSeek V3、DeepSeek R1 40分钟深度解析 M9TzN-0Raz0
URL: https://www.youtube.com/watch?v=M9TzN-0Raz0&ab_channel=Ph.D.Vlog
Status: success
Duration: 39:09

Description:
好的，这是对您提供的文本的总结：

**Outline & Structure Summary:**

1.  **引言:**
    *   PhDV 介绍了自己，并希望大家关注他的频道。
    *   他将尝试一种新的双人模式，与另一位伙伴一起讨论最新技术。
    *   他们可能会互相打断，并从不同的角度提供见解。
    *   如果有论文需求，可以加入Discord群组找PhDHR。他们主要做serve, reveal 和 benchmark相关的论文。
2.  **Discord 和模型介绍:**
    *   最近 Discord 很火，特别是v3模型。
    *   v3 模型下载量很高，可以在Olamar上获取。
    *   如果显卡不足，可以先用1.5B模型测试。
    *   模型经过4比特量化，使得模型体积较小。
    *   视频中采用系统自动减去空白声音，所以有时候会突然关麦克风。
    *   FP16 模型占用大量内存，而4比特量化可以减少内存占用，使苹果电脑也能运行70B模型。
    *   苹果电脑上可以运行70B模型，但数据量不能太大，否则会爆显存。
    *   CPU上可使用1.5B模型，但速度较慢，并且会输出HTML标签和思考过程。
3.  **显卡和训练:**
    *   4090显卡最大可以运行32B模型，4比特量化非常重要。
    *   苹果电脑在内存方面表现突出，但硬件问题可能导致运行错误。
    *   长时间高强度计算时，显卡可能会因为过热而掉线。
4.  **Depthake 模型和对比:**
    *   Depthake R1, R2/3 和 V3模型，V3的下载量远超其他，因为V3是较小的模型，更容易运行。
    *   V3 是一个混合专家模型 (MoE)，虽然参数量大，但每次运行只需37B参数。
    *   R1 是一个Ryzen模型，使用强化学习和COT生成，具有常链思维能力。
    *   R1 的基础是 Llama 模型，采用了模型蒸馏技术。
    *   模型蒸馏过程中可以从中间层多次蒸馏，以获得更好的效果。
    *   Depthake R1 在图表上的表现看起来不错，但实际与其他模型性能相当，主要是视觉效果和颜色调优。
    *   文章通常会自带Benchmark，以便对比和证明自己的优势。
5.  **Dipsy V3 和开源:**
    *   Dipsy V3 虽然性能很强，但只开源了 Infrerence 代码，未开源训练代码，这不算是完全开源。
    *   类似于 OpenAI，只开源了模型和 Inference 代码，未开源训练代码。
    *   二开版本可以通过谷歌翻译直接翻译，需要小心翻译问题造成的误解。
    *   Dipsy V3 的参数量是 671B，但 Token 计算时只需要 37B。
    *   使用了 H800 GPU，速度更快，原因是他们采用了更底层的代码，而不是CUDA。
    *   Dipsy V3 的训练成本约为 600 万美元。
6.  **中国 AI 优势分析:**
    *   中国 AI 的优势在于工程师廉价且能力强，法律约束较少，资源便宜，版权顾虑较少，以及隐私数据收集顾虑少。
    *   AI 的创新通常是将小规模的成功应用扩展到大规模上，例如从小型数据到大型数据。
7.  **Moe 模型和优化:**
    *   Moe模型通过多个专家模块和一个路由模块进行决策，可以减少参数量。
    *   Moe 模型在训练时容易出现两极分化，部分专家独占资源，需要平衡每个专家的使用。
    *   预测多个字的优化方法可以提高效率，同时使用确定度阈值来提高准确性。
    *   工程优化通过错开计算时间来提高GPU利用率，让每个部分都得到充分利用。
    *  GPU 运行方式：CPU 分配任务给 GPU，数据通过 PCIe 总线传输，苹果 M 芯片将 CPU 和 GPU 集成在同一芯片上，共享内存。
8.   **显卡和网络:**
    *   英伟达显卡通过 NVLink 进行多卡互联，苹果芯片上的 CPU 和 GPU 共享内存空间。
    *   显卡之间通过网线连接，越底层的连接速度越快。
    *   训练过程：通过一系列优化，如流线化，把 GPU 的计算时间充分利用。
9.  **混合精度训练:**
    *   使用不同精度的计算方式进行训练，以提高效率。
    *   华为芯片支持混合精度训练。
10. **模型性能和专家分析:**
     *  Dipsync 模型 的 token 长度很长，知识储存量大。
     *  对混合模型做专家使用分析，发现每个专家都有被调用。
11.  **结尾:**
     *  讨论了模型，以及新的二重奏模式，并表示下次会录好另外一位伙伴的声音。

**Core Point:**

Depthake 的 V3 模型是一个强大的混合专家模型，它通过有效的量化和工程优化，在速度和效率上取得了显著的进步。

**Fundamental Point:**

当前 AI 发展的趋势是模型工程化的优化，利用廉价的资源和人才，以及宽松的法律环境，在大规模数据上进行训练和推理。

**Overarching Framework:**

The content is presented as a technical overview and analysis of Depthake's latest models, comparing them against existing industry benchmarks. The presentation method shifts from a technical lecture into a more conversational tone that explores not only the technological advancements but also the operational and strategic environment that enables those developments. It covers various layers, including model structure, training methodology, computational infrastructure, and even global market dynamics that impact AI advancement.

<Mermaid_Diagram>
    graph LR
    subgraph "AI 模型发展"
    A[Introduction] --> B(Discord & Models);
    B --> C(GPU & Training);
    C --> D(Depthake Models);
    D --> E(Dipsy V3 & Open Source);
    E --> F(China AI Advantages);
    F --> G(MoE & Optimizations);
    G --> H(GPU & Network);
    H --> I(Mixed Precision Training);
    I --> J(Model Performance);
    J --> K[Conclusion];
     end
    
    style A fill:#f9f,stroke:#333,stroke-width:2px
    style K fill:#9cf,stroke:#333,stroke-width:2px
    
    style B fill:#ccf,stroke:#333,stroke-width:1px
    style C fill:#ccf,stroke:#333,stroke-width:1px
     style D fill:#ccf,stroke:#333,stroke-width:1px
     style E fill:#ccf,stroke:#333,stroke-width:1px
      style F fill:#ccf,stroke:#333,stroke-width:1px
     style G fill:#ccf,stroke:#333,stroke-width:1px
     style H fill:#ccf,stroke:#333,stroke-width:1px
     style I fill:#ccf,stroke:#333,stroke-width:1px
    style J fill:#ccf,stroke:#333,stroke-width:1px


    subgraph "Model Details"
       D --> DA[R1 Model]
       D --> DB[V3 Model]

       DA --> DA1(Reinforcement Learning & COT)
       DA --> DA2(Model Distillation)
        DB --> DB1(Mixture of Experts)
        DB --> DB2(4-bit Quantization)
        DB --> DB3(H800 GPU & Faster Computation)
         DB --> DB4(Inference code open-sourced)
    end
    
     style DA fill:#bbf,stroke:#333,stroke-width:1px
    style DB fill:#bbf,stroke:#333,stroke-width:1px
   style DA1 fill:#ddf,stroke:#333,stroke-width:1px
     style DA2 fill:#ddf,stroke:#333,stroke-width:1px
   style DB1 fill:#ddf,stroke:#333,stroke-width:1px
     style DB2 fill:#ddf,stroke:#333,stroke-width:1px
    style DB3 fill:#ddf,stroke:#333,stroke-width:1px
     style DB4 fill:#ddf,stroke:#333,stroke-width:1px



    subgraph "Global Dynamics"
     F --> FA[Cheap Engineers & Strong Skill]
       F --> FB[Fewer legal Constraints]
       F --> FC[Cheap Resources]
         F --> FD[Less Privacy Concerns]
    end
        style FA fill:#fbc,stroke:#333,stroke-width:1px
      style FB fill:#fbc,stroke:#333,stroke-width:1px
       style FC fill:#fbc,stroke:#333,stroke-width:1px
         style FD fill:#fbc,stroke:#333,stroke-width:1px

    subgraph "Core Ideas"
       K --> KA[Core Point]
        K --> KB[Fundamental Point]
    end
    
    style KA fill:#9df,stroke:#333,stroke-width:1px
   style KB fill:#9df,stroke:#333,stroke-width:1px


    linkStyle 0,1,2,3,4,5,6,7,8,9,10 stroke:#333,stroke-width:1px
        linkStyle 11,12,13,14,15,16,17,18,19 stroke:#666,stroke-width:1px
         linkStyle 20,21,22,23,24 stroke:#666,stroke-width:1px
         linkStyle 25,26  stroke:#666,stroke-width:1px

</Mermaid_Diagram>


Content:
大家好我是PhDV到然后想一个12粉丝的牌子希望大家能够多多去关注那么今天我们也尝试一个新的模式我们找一个小伙伴然后我们一起来做这个事情就是说我们就变成二人状了我们这是两个人一起去聊一聊这个最新的技术那我们可能会互相打断对方然后也给大家提供一些就是说就是不同的方面上的就是因为我们两个人就是做的东西不一样所以说我们会有一些不同方向上的一些不同的见解吧好的那么那还是这样的就是如果你要想写paper的话呢就去找一下那个加一下群加discord群然后去你们找一下PhDHR然后我们就可以写一些paper了我们现在主要做的paper的就是serve还有就是说做那个revealreveal和serve是一样的嘛然后还有就是做班迟mark这样的话就是我们所有做的这样的一个paper好的那么今天呢就给大家来讲一讲就是最近火的一大糊涂的这个discord然后discord这些东西那我也都看了差不多了r1就没怎么好好看因为就是我不太做reveal some的那种然后呢我主要就是关注它那个v3然后你能看到嘛就是这个模型一上以后就火爆了很厉害它已经有6.6个medium的这样的一个下载了如果你要去上这个Olamar的话呢就可以去拿到这个模型然后呢如果你要是跌打上没有显卡的话呢你可以先弄一个1.5B的这样的一个模型就去试一下就是它那个命令很简单嘛我看看后面有没有截图的就这样Olamar 软discord个r1然后呢如果你要不只能大小的话它应该就是默认是1.5B或者7B这样一个比较小的模型如果你要只能大小的话呢就是这个r1然后是帽号然后后面可以打比如说70B它这样还是一个比较大的这样的一个模型了然后呢它这个模型呢是经过4比特量化的所以说它这个模型呢其实实际上是比较的小的对这为什么现在那么强呢实际上就是说那个我这个视频吃做了一个系统就是它可以自动地把所有的空白的地方的声音减掉就如果一个地方的声音是空的那就可以把减掉所以有时候我会关麦克风你要跳那个康帮那个声音就是关麦克风那个声音然后这样的话就有时候说话成功还气了或者说就是有时候就是反应不过来了就会关掉然后呢那个就说你要想RESPONSE一下话也可以然后不RESPONSE的话这样它直接过去的话它后面会自动把它减掉OK这个明白吧OK所以说呢它就是这样的就是说它呢是4比特量化那比如说一个模型它原来是FP16嘛比如说70比特FP16的话因为它是16个位嘛然后计算机里面这个大B是一个是8位嘛所以说呢相当于一个就是这个这个70比呢对吧相当于它要占两个比特所以说呢70比的话呢就需要占140个Gb的内存才能运行起来你在CPU上的就是Gb的内存在这个显卡上的就是Gb的显存所以说70比呢需要140个Gb的显存才能运行那这个实在是太大了我们现在根本找到这样的显卡那苹果的机器呢最大192个机当然就说它可以运行但是依然会很慢啊所以说呢它这儿有个4比特量化就可以让这个苹果上面呢可以达到就是每秒钟能输出十个头肯这个样子吧所以它的速度还可以就像GbT4那样的一个速度就是我测试了一下因为我有一个苹果嘛然后呢就是这样的感觉所以说呢在苹果上最大你的能运行70比当然70比呢其实只用35G的显存这样苹果可能它还要有一个5G左右的那个系统嘛所以说它可能就是40个G有时候你买一个64G的苹果的M1的LX或者MX就可以运行它但是呢你的数呢不能太大如果你要数一个文章或者数一个PDF进去的话呢它可能会爆因为它它那个占用的显存大小也跟你数的东西的那个Size有关嘛你的数的越多它的那个KVCAS越多所以它也会越来越大这个样子然后呢如果你来CPU的话用1.5B就可以了这个RIDG那儿的模型呢RIDG那种这个模型呢它其实是比较慢的所以说呢1.5B的话呢就是说它会输出一大堆的废话就要在那个就是一个HTML的那个标签就是一个Sync然后呢还有一个反贤浪Sync中间它会有它怎么思考这个问题的那个部分当然我给大家看一下因为我今天不讲R1有讲R1的时候给大家说一下这个RIDG那儿的模式包括什么QWQ啊QQWQ啊这样的模型也都是这个这个SRIDG那种的这样的一个模式好的然后呢如果你的显还要是4090的话呢你最大可以运行到比如说32个比因为32比它用16个级的内存显存然后呢因为Windows大家会占较大一个级所以说它还是17个级所以说Synch0是完全可以寒斗这个东西的所以它比较慢你可以自己去体验一下那要感觉它似比特电话池非常不错的它只要你还知道SRIDG7个级比就可以把它下下来好了看还是我觉得有一个苹果的电脑比较它的能力挺比较高而且是供下内存的对它的CPU和这PU用的是一样的因为答案有一些问题就是它在导强的时候因为它它第一回会讲到它导强的时候它有时候会有些报错什么的然后呢你根本就不知道该怎么去解决它因为它就是那个一些硬件上的问题那些问题都非常的恶心然后呢如果你还是做一些班吃March这样的Work的时候你就会体验到因为当你进行这种长长长时间大规模高强度计算的时候因为它先卡有时候还会报错就是比如说我们那个Live有一个8卡的16000然后呢两个卡之间具体比较小它是那种暴力扇就是那种这种像吹风机一样的这种吹扇吹的然后呢它呢就有的时候就是说你在吹模型的时候如果搞得太热的话还有时候那个显卡会掉它掉了以后呢就是说哎怎么那个机上就变成四张显卡怎么就有四张显卡就不见了它其实就是因为两显卡临进太近的话它就它就它就不工作了然后呢它必须要重起那个机器但那个机器上有一班还有好多人在用所以说呢你重起机器的话你还得给它们发邮件然后就比较麻烦一点好了对人家人家这个算这半天大好我第一厅就可以可以看到了是啊是啊所以这就是问题嗯然后呢我们可以看看就说Depthake发的两个模型应该是 R1嘛然后呢可能它也会有 R2 2 3吧然后呢还有一个就是 V3但它有 V2和 V1了就是 V2 V1的话就是以前不是可以有名嘛所以它就就没有就三到一就是大家没有那么大关注这个模型它的性能非常地好但是你看它这个下来量呢是 151.6K次然后这个模型呢是 6.6M次原因就是因为它就说咱们做一个正常的来讲咱们能运行最大的模型就是 70B即以下的模型这种 671B的模型咱们基本就是很多人都运行不了然后呢它这个模型只有 671B的所以说就说它下来呢非常少就是这个原因然后它呢是一个Mixer of ExpertsMoe的一个模型这个模型就是混合专业模型然后这个模型的大型也对于 671B但是呢就是说它每一次运行的时候它只要 37B的参数就能运行也说它其实有一堆的 37B的这种专家组成的然后它最后有一个平船机制就是选择那个专家到底是最牛逼的那个专家就是打这个问题打你这个问题最牛逼的专家然后把它的结果给你轮退出来所以大概是这样所以说呢它这个模型的快就是因为它虽然是 671B但是呢它实际上每次只有 37B的这个这个部分呢在计算所以说每次你问它问题其实只算 37B的数量它的这个速度呢就大大加快了好的然后呢它这个模型呢它呢就是我们说 R1R1这个模型它是个Ryzen的模型Ryzen的模型呢就是使用强化学习还有就是那个COT就是Cenal Saw就是那个四位电然后呢它呢去生成的一个模型比如说四位电什么意思呢就是说我想让它去解那个比如说我想让你一个模型去解海轮公式吧这海轮公式到底是什么东西呢那这个模型呢正常模型它就解不出来因为就说它不知道这海轮公式怎么去解那Ryzen的模型呢就是说你在训练的时候它就是这样的就说首先呢恰恰问什么是海轮公式然后呢发现查诺公式证明三小时面积的公式然后呢编程的有公式编积的公式好像说我忘掉了然后呢它呢就会去查就说这个小学里面的这些知识怎么回事啊然后为什么这地方加了一起它可以成这样啊然后为什么它做出还要出眼啊然后为什么这个地方它是这个高是这么垂的呀然后呢最后得到就是海轮公式这样一个公式所以它其实是一步一步一步这样去走的所以它这个模型就说它就有一个常链思维的能力它是这个样子这个模型它里面的每一个部分Basic里都是就是说一个就是它是用一些小的模型作为它的那个BikeBall嘛然后呢它呢去做出来的所以它这个是征流的一个Q1.5B然后呢它呢就是Q1.5B然后呢它再继续去锐整然后它就相当于就是一步一步一步的去思考这个样子因为我们去思考也是这样的我们以说我们想说12加8成也3在出一久等于多少我们就会想那我们应该先算哪里呢对不对那肯定是12加8成也3出一久那肯定是就是这个8成也3出一久对完因为它是加8优先顺序然后8成也3出一久应该先算8成也3的还是算3出一久那好像这个关系不大是吧就是我们先算8成也3然后呢等于24在出一久然后呢做的加上12就是我们思维的一个顺序嘛它是这样对它也这样它呢你看它最小的模型呢是Deathdale的是Q1.5B然后这也是一个一个模型吧然后应该是Q1.5的就是2.5它是Q1.5这个版本的1.5B这个模型然后这也是2.5版本的然后这拉骂的应该是3.23.100本的然后这个这个后面这个是3.3.3.100的70B所以它都是就是进用人家模型然后一个一个这样去一跳一跳这样去四伪船好我刚才看一看好像就是说它去中流了这些线模我们说像这些线模型当它的7圈然后它很护原来的胜利这个是这样的就是说R1这个模型它Basic的就是就是用拉骂所以这个模型也没什么说的但是那个这个我们要一会讲到好吧这个一会儿来说然后呢这就是模型争流的这个事这个说我们有一个T-S模的然后还有一个Sdodem模的然后我们的就是一个T-S模的它就有很多支持嘛但这个模型很大它很慢一点然后我们想来把它弄一个小模型来学习它怎么办呢我们就去生成一些数据或者找一些数据库的数据然后呢同时问T-S模的Sdodem然后算他们俩之间这生成出来的差异什么然后就要差异把这个老师的模型支撑给到头到小小随生的模型你们然后呢它这个争流呢不只有就是最后从最后争流它也可以在中间在争流这样的话不争流效果更好一点因为就是说你从最后争流的话它是一个黑盒它也是个黑盒然后你从中间多在几刀的话呢它就相当于把黑盒切开了这样的话这个模型它就会更加的就是说就更Rhythm的一点是知道吧因为如果它是争流最后的结尾的话它就就没有没有什么就是它就它这个争流效果就不好但是我从中间也多争流几次的话就可以去把两个模型它更对齐一点但是这个样子OK那我们一会再讲那个那个那个事情啊然后这边的话就是说这个Depthic R1占营模型它的这个效果这个一看这个图好像很好啊但是呢就不要被图骗了另外就是说你还这个量是好一点那这个量是好一点这个量是差一点这就要差挺多这边好一点这这个量是差一点这这个量是好一点它背随着你和这个OE是一个打平手的关系它只是呢用了这样的一个就是首先它别人的颜色调的二了一点然后呢它自己又给加上一个鞋纹因为你知道吗人穿衣服有的人是让穿那个调温衣服就会显受显高所以它就是利用了一些视觉上的这样的一些方式吧就是让它看起来很好其他也没有那么好就是你去真的去理性的去看它里面的数字的话发现其实它跟别人的模型也没有说说就是牛到哪里去了是吧这基本上跟人家也也差不多然后这个期间也是一种班斯mark的你看就是说它去跟对面对比所以今天其实很多文章它自己会自带色位或者自带班斯mark因为就说就说它要和别人去对比所以它要去自带一个这样的东西它才能够就说去证明我比别人好或者说现在的一个状态是什么样或者说我从别人那里借件的什么东西比如说我做了一个S&D对不对然后呢我把前面的东西讲了讲就证明一下为什么我比双子的网络好我比这个网络好别那个网络好所以大家现在文章都自带一个这样的一个Sexer就说给大家讲讲比如说那个外奥特别闻闻章就VLT的闻闻章讲的是最多的对吧就是说它别的闻章都列了一遍然后给你看就说为什么它的闻章非常地好然后这个图里是这样是Dipsy个V3然后Dipsy个V3的话它也是这样的一个结果但这个图我觉得也不是特别的就说公平了因为Dipsy个V3的它是671个比例的参数然后别人模型了都是什么712B然后4105B这短了那个赛子都没那么大所以说你跟他们去装个比其实也不是特别的特别的对而且有限模型它比比如说Nava 3.33.14105B这个模型其实挺老的然后这个0513的也挺老的它其实这个掉队比的话应该队比现在就是更冒惮的模型对吧对于有那种影响就像每次你盘的苹果的发布会比起来发布会交达有伤你都是在这些MXM的后来的那种处理机上做手奖我觉得方也成为伙合伙伪对还有他这个这个颜色还有他这个调稳他其实都是有些这个视觉错误你知道吧就是比如说一个球他外面有6个小球然后一个球外面有没有6个大球他其实要这中间两个球大小是一样但是就是他有一种视觉骗局这个你也知道所以他这个鞋纹和这个颜色其实也有点这样的嫌疑了当然有这样的感觉好了然后我们去聊一下就说呢第四个威3他有一个开源的这样的一个technique report但是他这个他只开源的E-France的代码他没有开源他的一个春丁的代码我不知道他现在有没有开源所以说呢他其实实际上也不算是就是完全开源吧他算是一个不完全开源他只开放了就是你怎么去用他他没有开放他去年的部分的代码所以这个呢也是挺人丘姐的一件事件然后呢你说但我觉得这些可能也是他的mode top secret我觉得轻易公开除非说我觉得他有一个更好的technique或者更好的这个硬件就很难能公布上一代对我觉得主要就是说晚上很多人吹说你看OpenAI对吧实际上是Klow3第四个威3他开源的代码但其实一样的他也没开完代码他只是开源的模型然后呢但是开模型也是一个很大的进步了就是说他开源的模型然后开源的那个influenced代码就是你可以自己跑但是呢就是说他也不开放他的这个春灵代码的话那就是说就他会产生很多问题是吧然后呢他也不这别人也没发布去复刻他这个结果当然有些能力瞧瞧他也会自己去做一个这东西出来但是呢有可能就是副项目出来他一样的结果那我们之后会讲没什么然后呢他这个这个二开我现在呢他有HTM没有二个版本我觉得这个版本其实非常好因为这个版本就可以那个就是说用谷歌翻译直接翻译他就又见直接翻译就是因为他多暖气里直接翻译就可以了然后呢我们这是就给他翻译成中文比如说我们可以看就是说抽象了就是AppStrike这个还遇到的个笑话就是有一个人那个中国的发了一个文章然后呢发了那个他可能打抽象结果那个翻译器翻译就变成了Punking I的粉然后那个围按就会不会撤掉被撤掉听好笑的然后他这个讲就说没有所以这个I的位去好英文你都要对一定要一定要小心不要搞出什么Punking I的粉腿然后之前之前还搞出什么反正就是搞出一对特别特别抽象的事情就是各种各样的由于翻译还就是复备粘天的时候不要先把那个就说继续生成啊什么呢不要先粘天到自己的Payparty然后导致自己的Payparty那个被下架然后自己上了新闻这种这种停停下人的我觉得我还是得小心一下这种事情我们俩给你想要看这个要看这个那个还一讲最工业务还有什么托卖啊就是托向是啊他就是哎就是说翻译这个事情还要小心吗然后他这边有六百七十一个毕竟的参与所然后他这个托肯几乎三十七毕他就是讲这件事情然后他呢就说他用那个H800的速H800这批用呢其他要打败的那个一十一百就样子其实原因也是来自于一个是他们的位现的问题一会儿会讲还有一个就是来自于他们这个没有用库打因为大家现在都用库打嘛你就是写什么东西用库打他没有用库打他没有用了更底层的那个东西所以这样的话他的那个速度就会变得更快一点然后呢但是他一个工程量可能会变得更大我看过呢好像那所有会编语不一定这个现在一般常评看到我手上是啊就像像那个安斯劳斯干的事一啊因为就说有一个春境的一个工具叫安斯劳斯就是斯劳斯嘛就是数了就是他不是数了他意思就是比较快然后安斯劳斯那工具他就是相当于重写了很多底层的那种东西然后他就让那个春境的部分还有Tice的部分都快了但是Inference其实没什么可优化因为Inference其实他就是他就是就是他就是他就你看那个拉马点CPP他只有Inference本就是他只有这个测试的部分他没有那个训练的部分因为训练他有他有什么Eidermen优化器什么都很难但是测试部分他其实其传说嘛他就是个大举阵我每次问他问题就是从大举阵你要往上抽结果对吧其实就是就是在用一些程法抽结果相当于我们就是从属于废物调库但是他调库他不是一个简单的调库他是利用一些关系的调库所以传说嘛其实背后就是这样他就是一个大的一个卷程法他其实就是一个大的一个单sneye但是这是单sneye他是就是单sneye连接的更好只是这样的一个东西然后呢我们来看他的一个东西就是他他这个他这个使用的这个H800然后他算的时候他所有的这些东西比如说运萱链然后还有什么扩展然后还有就说在训练之后进行微调啊这些东西他都算的是就是H800的那个这笔有小时数所以他算的那个训练成本其实不包含特工程师的成本然后呢他这个加拿一起是大概花了不到600万美元还做出来这样一个东西他就按照没有时就说GPU是两块钱这么来算当然现在这个H100这笔就大概什么样是两块钱吧这个说现在价格其实都很便宜的我觉得大家呢也不用自己去买如果你要想试试的话你就租一个然后呢苹果其实也不用买也可以去租一个当然就是你要算一下嘛就说你是适合买呢还是合租对吧然后呢因为很多人就是想自己想练习一下但是呢说白的就是说买这个设备花呢就有时候就吃灰了你还是去租一个会比较合适的然后呢我觉得中国的AI呢就说比较前途的原因呢就是还能制补个原因吧一个原因就是工商师他很便宜也是能力很强在每个这边照过工商师呢其实挺贵的比如说那个OpenAI的工商师呢他很多工商师呢这个年轻的都大于就百万美元他这个一年的工资就可以训练一个模型出案了所以说呢工商师呢便宜呢能力强呢还有就是他刷地扣多少的很多这也是一个原因还就是法律约束很少就比如说他没有什么那种就说那种很多法律问题他都不存在所以说呢扩很多顾虑呢就就不存在了还是他自然很便宜啊比如说什么土地呀电力呀人力呀都很便宜尤其是人框都把人框很便宜然后呢他那个有时候也不是特别出种版权问题他真有这个事不算是版权问题了我觉得这会像争流这个这个美国公司也在干了所以这也不是什么问题主要是利用什么比如说YouTube上那些视频啊BDB地上那些视频啊还有就是说一些就是便室剧啊电影啊这东西这东西他用的时候还有些书啊这些东西的这些东西明显是更高这样的数据然后他的版权在美国这边可能会有点问题但是在国内呢这个问题就比较清一点避避你把他都打包到了这个模型里面其实实际上大家也都看不出来你的版权问题了这个呢也想打赢官司呢其实很难的然后第五就是我觉得他收集隐私数据的顾虑也很少国内晚隐私他就是不是特别的贴所以说这个隐私数据其实有些时候他训练出来可能效果还是非常不错然后呢我觉得呢其实拿出来跟什么都的本来那他就没什么创新就是他就是一个小的东西做成大规模的就跟所谓的数据和大数据一样大数据其实也没什么创新所谓他就是有一些东西小数据让他没发去work让到大数据上他在小数据上他能work但在大数据上他做可不良了比如说你一个算法是忽音方的在小数据上他可能能够运行跟大数据上他就就说他要天文时间才能运行完他就得想一些别的方法来优化他比如说用那个facebook他开发了一个色迟方法比如说于是你你做相量的这种这种就是我想找因为他有一堆相量嘛我想找这个我现在有一个点对吧那些点因为每个点都是一个相量嘛他就是一个坐标嘛对吧然后我想找哪些点的这个点比较近我以前就是就是用库屋定理嘛全算一遍对不对然后找到小于我那句子就可以了但今天呢肯定算不了了对吧我们叫先弄具类啊具类东西然后呢做一个具类之类的算法因为他当我有比如说十一个点的时候或者一千一个点的时候我就没发去算所以什么FAS是就是Facebook那个Race那个SERC那个方法就就非常不错大家可以自己去研究一下那个在Rack里面用的很多叫FAS这样一个算法OK那所以说就说可以研究研究他们到的是什么去做的好那首先第一个上来就讲这个这个模型这个模型最低一点的就是他的这个Moe的这样的应该加高那什么Moe的这个加高就是说他有一堆的专家对不对我这儿这么多的专家然后呢有一个Router就是我有一个东西来决定到底是给哪个专家去说哪就是哪个专家更合适一点然后呢他呢就是我有一个问题见了之后我先分析这个问题对不对然后他可能他一个结构可能还非常多就是有SERC的Expert他上上Rotie的Expert这Expert可能更大一点这Expert可能更小一点然后这Expert就是说每一个每一次都会用的然后这一次Expert就是有些专业领域的比如说这个可能是说数学这可能做物理的当然了他是不这么分的就是说他都是用训练的时候的一些算法去平衡这些专家然后这么去做的是这样的就是说呢多专家我像其实很简单就是说他有一些专家在这然后有一些专家在这然后我有一个算法决定到底是哪个专家去回答那这样一个算家可能只要30个B定的摩这个参数的话呢我就可以减少整个的这样的一个参数量但多专家目前有一个大的问题就是说我在训练的时候这个新来的这个世界这样两级分化很具体他都是能者越强就弱者越弱所以说呢就是说可能就是第二个专家和第八个专家可能这两专家就把所有的这个东西都独斩熬头了每一次都分了他们两个专家实在专家都没用了那这样相当于就是跟那个我们所说的那个节点就是当时那个REST那一专之后就是有人说REST那一项我不好为什么不好呢因为有些节点他是死掉的就这个节点他就像我就很差他没训练出来对吧大家都不会会用他那你这样的话对吧其实一个BD的参数相当于可能知道那60个BD是有用的那把甚至的BD都没用那这个模型效果就很差了所以他们有开发的一套的算法确确保就说每一个专家他都能够就说比较均衡一点就说这个专家可能是物理更强一点那个专家可能数学更强一点但他们背下的能力都很强大家是做成这样嘿这个就是M1这样一个模型这个模型其实上了十几六十年来就提出来了那个时候可能还没有D不在内了然后有D不在内内很出型的阶段然后他就是这样子你看这个就是这个这个这会儿走这条路这会儿走这条路然后他有一些就是说通过一些概率通过一些东西来做所以这个肉团的其实也是个回归模型他不是一个那么简单的就是一个随机选的东西然后呢比较早期一点的这个专家模型呢他上每一个专家都轮流的输出结果然后做到看那个结果更好一点对吧这是早期一点的现在呢他一个肉团可能做得更好一点所以他呢就可以让只让一个专家去做我记得好Mixed那个模型就是八成二十二并的那种模型对那个模型好像就是每个都算一遍所以他就是会打扰他一个效率特别低嘛他就是一个附层还嘛他的效率很低那这个的话就效率会高很多然后呢还有我们之前讲的那个MTP就是这样的那个当然就是我我看了一个这样的一个东西觉得这个东西形容很贴切要多头美度啥但是只有这么一个地方这就用这个名字别的人都没有任何一个人用这个名字因为他这个图可能版权所以把那个那个整段那个网页都接下来然后呢他什么意思呢就是说我以前预测上还有什么好玩的地方我说上对吧他会说就是我设论上有什么好玩的他说呢有这个比如说有那个外摊呀什么的所以我就问就说我问了这样一个问题进去之后他一次呢不只回答一个字因为他大模型都是笨字嘛一个字就是我比如说我有一个苹果对不对然后呢我把我放进去然后呢他预测下一个字是有对吧然后把我有放进去然后他预测下一个是一个然后把我有一个放进去然后他预测苹果然后我有一个苹果放进去他预测下一个40度号他就这样一个就是一个字一个字一个字一个字一个字这么预测的然后他把前面的这些东西呢根据他之前的那个就是上下文的那个那个长度的比如上下文长度是五个字对吧然后我呢在看到这个字的时候只能看到前面五个字对吧这样前的字就中掉然后他终于进去的然后他一般都比较长一般都是有比如说三十二K或者是什么十六K就是上能看到就是前面好长一半的字这也是这么一个字一个字一个字蹦进去所以他这个玩法就说我不是一丝蹦一个字我一丝往后还蹦两个字蹦三个字我预测为了三个字是说什么东西这样的好处呢就是说他的速度会变很快外出就是他的准确率然后会变得很低因为预测为了一个字还比较简单预测为了三个字就比较难了那我怎么办呢我请预测为了三个字的就说比如说我发现预测很多的时候很多发现他的这个这个模型不是很确定因为他有一个确定度的这样一个输出就是他比如说做SuffMix他会有一个对吧你会有一个概率发现概率不是很高的时候他就会把会从这儿再切一刀然后从这个有这个量再从新预测他那就是把后面的那个多预测传结这样的那个扔掉这样的话能提到他的准确率因为他有一个字不确定了因为你要预测为了三步的话一定是比较难的预测为了一就是预测为了一天天就报特别几十分准预测三天的才就不太准那就把那个不准的一天的扔掉然后我们从今从那个第二天再进去预测这样的话就会更准所以这个被部分被先给你讲是同样的一件事就是我一次多预测几个字第二呢这他们做的很多这种工程上的优化而这个文章其实他也没有提出什么特别创新的创新点做的很多工程上的优化比如说他有computercomputation这样一个东西都给他错开了然后这样的话他就而且他就说你看看把这个时间都填得很满对不对然后他到这个地方这可能是一个一个过程对不对然后到这个地方他给他就说这个地方就像一张他同步一下是不是这个地方就是像一空的可能就空了一点点时间然后这个地方再给他再进行下一个过程所以他就这么一个过程然后就这样一个过程所以你看他这个效率可能就比那个就是比上没踏他们的效率要高很多就是把你们那些所有能见面差真的量全都给差真他就是这样工程师的比较便宜比较工程师的素质比较高这样的一个结果工程师他的一个卷很卷就是卷了以后就是说他不他不把地口都刷完他找不到工作所以这这些算法什么写都得心净手这样然后就说到英伟辆的一个问题就是说我很讨厌伟辆的原因就是英伟辆的东西他还是这样的你知道我电脑师怎么运行的比如说我要想做一个大元模型对吧我想做一个比如说我想去那一个RiseNet去那一个这种狐巷神实别的这样的一个模型模式生对吧这朋友是一个班的小学生比如说我就想让他我想我想解片文章对不对我找了四个博士生来写这个文章那就很慢因为博士生能力很强但是他就说人手比较傻那我怎么办我找上50个班的小学生对我找了一半个小学生那这里的这朋友然后呢小学生比较傻他什么都不会干博士生就给他派任务派活把这个活的给他分的会细会简单随便生的就把这活都会干了那这样的话就这个效率一下就提高了是不是所以那这朋友也是这样去做这我CPU先把任务先给他拆分出来告诉这个这朋友的每个合的干什么然后呢就把数据从CPU上倒通到这朋友上通过PCIe总建那个那个显卡他不是插主板他有一个金手指的就是那个一排金属的东西这个就是PCIe总建通过PCIe总建从CPU把数据到这朋友上这朋友每个合的分配到了以后就算完了以后打出去再传回到CPU上然后CPU类似的博士就分析一下到底他怎么去做的所以这是因为拿这样一个东西所以你也能很清楚看到就是PCIe很容易成为一个平均角并且PCIe很容易崩掉对吧有时候他就会他通信发生错误什么他就可能就崩溃了所以因为拿来做半十八个什么的东西他就要长时间运旋的时候有时候他就虽然算他就崩了对吧你这个东西就白算那苹果的那个东西他是CPU和这一批是做在同一个C片上的然后他呢他也是用同样的内存你说呢CPU的东西可以无放的放到这批有啥你这说呢我们每一个内存空间他比如说我这每一个讲上去看着内存他这个开始不是内存讲上去有这么一个开始CPU和这批是共用这个开始那我这一块呢部分呢他有数据对不对前方还有一个标志位标志位就是说我现在是CPU在用还这批又在用对吧然后CPU在用的时候就CPU在用然后这批又在用的时候这批又在用那应该不是同时用因为就同时用的话他会打架他就不打架就CPU用的时候我标记住这条这批用就别用然后呢这批又用的时候CPU就在标记一下这批用就别用这样的话我就数据就会打架以后这个可能会改改了以后他可能效率会变得更高一点好那这个因为俩这个东西他那比如说你要有八张这个卡的时候他当时这个每两张卡之间也会有连接所以他就那个NV令可嘛但是他起来好像比较NV令可反正是别的东西反正是更能都互相点在一起就说这个系统他就很高然后带官不只是通过那个主板上连接他还有只他自己内部的一些点点快点带官变得很高然后呢做这个东西非常难比如说这是Mata的405B他是怎么去训练的这是安置NVNM这样的一个网站可以自己去搜一下他呢在最下面呢是他的那个节点就是他每一个都是他一个JPO然后他这个JPO上面会有那个板载的那个连接器或者什么东西我也不知道具体这每一层是什么但是大概就这意思他们真结是每一个JPOJPO可能再通过一些什么还没令他这些桥还给他连在一起然后呢这个呢这个1r4这个每一个呢就是一个机会而这个可能是这可能是每一个每一个每一个机器吧这是每一个机器就是一共有八让卡这个样子然后那个记忆之间呢他会有他会有在机内部有机器之间的互联然后呢这当然这就是一个区域就是他的那个工厂厂房的一个区域之间外一个区域在这些区域之间呢他还有会有那个区域之间那个网络的那个互联所以他这个连接器其实是非常负责越底下的连接呢他速跃快越上面连接他的速跃越慢因为他就是说他是要用网线连在一起的吧对吧你网线最大可能就是40G或者是两个40G或者是可能是把多少个40G连在一起那你这个交换速就很棒了所以说呢如果他能够让他在底层之间他的这个交互变得更更多一点上面的交互变得更少一点他会牺牲一定的精度但是呢他会提高整个机程轩速度然后他那个交换机都是这个样子他都是这个黑夜交换机嘛都是这样子他也有那个光线在里面然后呢就是这样去互相连接所以他那个还有就是因为拿这个机会他这后面是一大堆的那个电了是连在一起他那个效率是非常高的然后呢他们做的这个这个work说白了就是把这个流血线的给他都填满这是8个八张显卡这是DBI S0-7是8张显卡8张H800然后呢他的里面会有前像过程反像过程然后反像过程有带这个这个音波的反像过程反像过程还有这个这个最为辞的这样的一个反像传递过程还有就是各种就是反正他有各种各样的操作吧然后他那你看他吧这个做白色的地方这空泡的地方这是他是没有任何的操作的地方你看他跟我一系列整段几八道的优化就把这个中上这个空泡的地方变得非常少他这个已经几半达到的理论极限了就是说那个没看那个东西他能达到就是30%到50%的效率吧估计他们这个也能达到只要90%的80%的效率他们的效率就一下提高了变它还做的一些很多异部啊这样的时间但这个在每个估计是做不了的这个工程师请不起他做的很多异部这样的操作所以他就很多的地方都是异部的然后这些异部的地方就可以把他时间压到最低那个显卡就可以达到最好的利用效率然后他对所以他就讲的他们这个他们这个派不赖他们整个的这个过程是怎么样他在效率是怎么样那八博的这个率就非常非常低所以他就讲就是这么一件事情然后呢他们还做的一个英文人做不出来的事这也当于是空中上的东西我讲这么多也没什么意义就说英文人一直想弄一个巴比特训练就说我们训练的时候现在都是Fp32或者Fp16这样对吧就是半精度去练这应该是半精度吧然后呢这个应该是全精度去练他做不同的去练他花的时间是不一样的吧比如说你要做一个承法运算对不对那你要是两个四位精英运算你要是一个四位精英运算的话他花一辈的时间变成八位的还不像四位的时间而变成十六位还不像十六位的时间因为他就是他那个时间是以平方登长的然后他们怎么做他们就说在不同的地方对吧然后呢他们的计算呢用不同的精度他还低他会有问题你这边这样这边要用他用十六位精度这边用八位行不行呢他的效果可能会变差有的地方他用十六有的地方用八有的地方用十六他有的地方用八变成这个八位精度他的表实方法还不一样我们知道弗洛他能踏守一个地上表示他那个数值多少还有地上表示他是那个二的多少次方还是十二的多少次方反正他他是比说1.372成一十的十五次方这个样子但是他是分配的不同的位给前面这个把连个后面这个部分然后他这个还p8他可以是p8可以是千神四成四和四也可以切完成三和五也可以凄分成二和六这个样他也进行了很多这样的切分对他这个整个就是一个大的工程上的这样的一个模式然后呢这个因为连这个显卡他原生是不支持这个东西的他们自己举写的算法然后他们还用了华为的芯片吧好像华为的芯片这个什么那个叫什么一生开什么东西一生九一零一还什么东西我我忘了那个芯片叫什么名字你有那个那个那个字那个字我也不那个字我都不认的关于这个问题然后呢那个那个叫生什么生我我不让这个字叫什么我不让那个字念什么对对那个芯片听说质量不是特别好就是说的那个经常坏但是呢这个芯片从原生就支持那个混合精度训练他那个混合精度不是那种混16p8p的一种但是8p里面有那种不同的那种位的那种精度反正就是那个芯片很方便听说就说可以做的很多因为他工程是便宜嘛所以他就做了这些东西他就能够在那个就说啊质成没那么前进的情况下这个功耗功耗可能值平或者更高的情况下现在能达到一样的速度大概就是做这么一件事然后呢他这个他这个东西就天花的很贵了这个这个我觉得要不是你是专门搞系统的可能也不太能看得懂然后看懂得也没什么用对吧因为这个东西安平山也不会去不会太太多去那个纠结他但是他还去把这个护大里面的那个剧集的那个过程都给他去操作的一番就像安斯Loss做的那个事儿一样就是他相当于就是把里面那个就是一段期把到的那些通期传统给他优化了一下还有些还有些地方的算字就是他可以通过一些就是降低精度的方法然后呢来提到他的速度就别说像这派个格式就是你那个要像那个GorpeG那一个格式他头有时候压出来发现他精力度会下降他会有些那种水印你能不能感觉但是他的速度他的洗击都比偏这样小他就是通过一些一些他有些量可以就是说这么这么损失一点你损失上去要注意吧就说你哪都损失一点就说可能就损失报所以他损失的时候可能这儿损失一点这个往左边损失一点因为往右边损失一点他跟做的拉回来就是有很多算法这东西都非常难以去部署就是说他其实挺难想的挺麻烦的然后呢他们就是他们的这个偷看的这样一个情况发现了就是说他们那个偷看的跟那个Mata的那个拉马奇差不多就是说他呢到和那个Google那个东西差不多这Gemina也差不多他就是说就是可以他188K的整个长度都能够有效的去给他拿到就都能拿到十分的这样一个词这个还是挺牛逼的一件事然后呢他这个671B也可以装很多的知识进去所以那个Dipsync的模型还是不错的我觉得那个以后可以拿一些论文然后还有一个事呢就是他们这个就说还不同的类似什么他想去看看就说他混合专家模型吗所以说混合专家有很多的专家在上面他想去看一看就说每一个不同的位置上面对吧就说我我我我我我来问他一个问题的时候他到底几乎哪些专家啊对不对他几乎的这专家他在几乎的这专家然后呢还是说他这个他就说他这么弄了以后发现就说Export这样一个Low的呢他没有就说就是他还是挺兵康的你看他没有说就说某一个专家就是这条大头对吧也没有这点说法那他呢在做某些事的时候呢确实又有些专家呢就说他确实就是就很多专家模型他主要就是专家就是说他就是他就是要找出了几个精英嘛对吧他确实有精英他这个教育呢是非常不错的可能和这个呢也是有关系然后呢这个视频那里的大家就能在这里然后当然就是说我们现在可以再再再讨论一下吧对吧因为我们这个现在不只是我一个人讲所以说有一个家冰然后我们来看看就是说有什么问题或者说有什么想想表达了吗或者说有些灵感或者去到一些商法论我想可能轻易带着这个那原模型的定能可能就是大胎了是啊我发现一个问题啊刚才好像那个没有把你的那个声音录进去就是录进去但是它通过卖个风录进去的所以下一次在录的时候我可能把那个卖个风放在哪上面这样的话他们就能听到了可能刚才声音云烂小但是也不至于听不到吧总之这个呢是我们第一次尝试这样去做吧那以后我希望能够把这个越做越好吧那我们今天这个视频呢是不是就到这里了等一段观看我们下期再见
