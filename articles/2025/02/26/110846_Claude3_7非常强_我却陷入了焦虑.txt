Timestamp: 2025-02-26T11:08:46.929252
Title: Claude3.7非常强，我却陷入了焦虑...
URL: https://youtu.be/1-VikuCtmqk?si=wcx-7gnmOTpHCwPu
Status: success
Duration: 9:35

Description:
好的，我将用中文对内容进行总结，并提供大纲、核心观点、总体框架和 Mermaid 概念图。

**总结：**

**I. Cloud 3.7 的主要更新与特性**

   A. **代码能力大幅提升：**
      1.  被认为是目前市面上解决代码问题最强的模型之一。
      2.  通过优化训练集，更多地使用现实生活中的代码问题进行训练。
      3.  在前端代码编写方面表现出色。
   B. **引入 Reasoning 能力：**
      1.  具备类似 Chain of Thought 的推理能力。
      2.  扩展了输出窗口，能够处理更长的文本输出。
   C. **Cloud Code 工具：**
      1.  与 GitHub 联动，方便在控制台中进行代码调整和 AI 操作。
      2.  类似于 Cursor、Windsurf 等工具，官方开始抢占市场。

**II. AI 对程序员的影响与焦虑**

   A. **AI 落地程序开发领域：**
      1.  AI 显著提升了程序开发的生产力。
      2.  Cursor 等工具的成功表明了 AI 在程序开发领域的巨大助力。
   B. **对程序员的潜在威胁：**
      1.  AI 的发展可能导致生产力过剩，部分技术工种被取代。
      2.  一线 AI 工程师也感受到被自己所做的事情取代的焦虑。

**III. Cloud 3.7 的安全担忧**

   A. **System Card 强调 AI 安全：**
      1.  System Card 大部分篇幅都在讨论 AI 安全问题。
      2.  AnswerPic 强调如果不注意 AI 安全，可能会对人类造成危害。
   B. **Release Decision Process 的担忧：**
      1.  担心公开 Chain of Thought 中间步骤可能包含有害内容。
      2.  担心用户可能利用中间步骤对 AI 进行越狱，生成有害内容。
   C. **RSP Evaluation 的实际场景：**
      1.  列出了一些实际的可能威胁人类安全的场景。
      2.  建立了评估体系来判断模型是否会对人类安全造成威胁。
      3.  例如，利用 AI 制造生化武器、AI 自动进化等。

**核心观点：**

Cloud 3.7 在代码能力上取得了显著提升，但同时也引发了关于 AI 安全和对程序员职业影响的担忧，提醒人们在追求技术进步的同时，必须重视潜在的安全风险。

**总体框架：**

本文主要围绕 Cloud 3.7 的发布展开，从其在代码能力上的提升、引入的 Reasoning 能力以及 Cloud Code 工具三个方面介绍了其主要更新；随后，讨论了 AI 对程序员的影响，以及随之而来的焦虑；最后，重点关注了 Cloud 3.7 的安全担忧，通过 System Card 的分析，强调了 AI 安全的重要性。

**<Mermaid_Diagram>**
```mermaid
graph LR
    subgraph Cloud 3.7
        A[代码能力提升]:::code --> B(优化训练集);
        A --> C(前端代码增强);
        B --> D{现实代码问题};
        E[引入Reasoning]:::reasoning --> F(扩展输出窗口);
        G[Cloud Code工具]:::tool --> H(GitHub联动);
        G --> I(AI代码操作);
    end

    subgraph AI的影响
        J[AI落地程序开发]:::dev --> K(生产力提升);
        J --> L(Cursor成功);
        M[对程序员的威胁]:::threat --> N(生产力过剩);
        M --> O(技术取代);
    end

    subgraph Cloud 3.7安全担忧
        P[System Card强调安全]:::security --> Q(AI潜在危害);
        R[Release Decision] --> S(有害内容风险);
        R --> T(AI越狱风险);
        U[RSP Evaluation] --> V(生化武器制造);
        U --> W(AI自动进化);
    end

    Cloud 3.7 --> AI的影响
    Cloud 3.7 --> Cloud 3.7安全担忧

    style A fill:#ADD8E6,stroke:#333,stroke-width:2px
    style E fill:#90EE90,stroke:#333,stroke-width:2px
    style G fill:#FFA07A,stroke:#333,stroke-width:2px
    style J fill:#D3D3D3,stroke:#333,stroke-width:2px
    style M fill:#F08080,stroke:#333,stroke-width:2px
    style P fill:#FFFFE0,stroke:#333,stroke-width:2px

    classDef code fill:#ADD8E6,stroke:#333,stroke-width:2px;
    classDef reasoning fill:#90EE90,stroke:#333,stroke-width:2px;
    classDef tool fill:#FFA07A,stroke:#333,stroke-width:2px;
    classDef dev fill:#D3D3D3,stroke:#333,stroke-width:2px;
    classDef threat fill:#F08080,stroke:#333,stroke-width:2px;
    classDef security fill:#FFFFE0,stroke:#333,stroke-width:2px;
```
</Mermaid_Diagram>

Content:
哈喽大家好啊 cloud 3.7 昨天发布了 整体上来说 大家对于这个新的 3.7 的版本 还是非常认可的 觉得它的功能 尤其是代码的功能非常的强大 在用完并且看完 cloud 3.7 之后呢 我自己却陷入了一种深深的焦虑啊 那今天就带大家看一下 cloud 3.7 到底有什么样的不同 以及这种焦虑从何而来 欢迎大家收看我们今天新一期的视频 首先从社区的反馈上来说啊 大部分人对 cloud 3.7 最大的初印象 其实是它针对于代码的问题 解决的非常的好啊 可以说是市面上 呃那种解决代码问题最强的模型 没有之一啊 呃比如说像 reddit 社区里面 大家都在夸说这个 3.7 版本出来之后 有很多之前的复杂问题 我用 AI 都解决不了 但是现阶段就是可以解决了 所以像大部分的这种代码开发的工具 比如说 cursor 啊 比如说 windsurf 啊 他们都第一时间 接入了这个 cloud 3.7 大家如果之前用 3.5 现在可以直接切换到 3.7 去体验一下它是否直接能够提升 你写代码的这样的一种能力 我自己测试的结果下来 我发现其实 cloud 3.7 在这个前端代码 也就是说呃去写网页这件事情上 变得非常的强大啊 其实呃最核心的原因 你也可以在这找到啊 就是他们其实优化了这样的一个训练器 减少了这个代码的那种竞赛的题目 反而转向用更多的这个现实生活里面的一些 呃代码问题来训练它的模型 从而让人们在真正使用这样的一个模型之中 呃会有更好的体验啊 呃如果你去看它这个代码能力的提升 差这样的一个精准度 或者说是一些这种评价体系 还是基于标准的这个 benchmark 是吧 呃那在同样这个标准的数据下 其实在实际的使用体验上来说 3.7 应该其实是比其他的模型 有着更好的一个使用体验的 那 cloud 3.7 呢 第二个特性就是它引入了这个 reasoning 这 reasoning 其实不能算是一个新的东西是吧 就是你其他的模型已经被讨论很多遍了 不管是这个 o1 呢还是 deepseek 的 r1 呢 是他们都有这样的一种能力啊 然后他这方也引入了这个 chain of sort 的这样的一个显示 呃引入 chain of sort 这样的一个东西核心点 其实是它的输出的这个窗口 相比原来而比是可以变得更长是吧 原来我可能只是一个 4096 的一个 token 现在可能是变成多少多少 k 的一个 这个输出的一个窗口了 所以他不仅仅是有呃这个 reasoning 的能力的 可能对于一些常文本的输出也能够做得很好啊 然后第三个更新的特色呢 是叫这个 cloud code cloud code 你可以理解成是一个更偏向于产品的一个工具啊 它能够和你的 github 进行一个联动 然后可以在它的控制台里面去对代码进行一些调整啊 进行一个 AI 的操作 如果你熟练的掌握 cursor 啊 wingsurf 啊这种软件这样的东西对你来说应该不陌生啊 只不过就是他官方也发布一些工具开始抢占这个赛道 基于以上三点啊 其实 cloud 3.7 最大的更新就是在于代码上面啊 就是我们之前还老聊 AI 到底会落地在哪个地方 现在已经没有人说这个问题了 因为 AI 已经落地了 而且它落地的最大生产力提升的地方就是在于程序开发这一块啊 标志性的事件其实就是像 cursor 这样的一个工具 是最快达到呃年收入一亿的这样的一个公司啊 就是完完全全的凸显了在程序开发这个市场啊 这个 AI 的助力到底有多么的大 那在前几期 deepseek 的视频里我们提到过 就是最近大猿模型提升的方向的确是在网更加智能 更加重推理中代码的方向走啊 原因是在于 reinforced learning 给了人们一条确定的路径 说你往这个方向提升就能够让你的大模型啊 能够回答更有逻辑的问题 呃 那在这个方向上你不需要有那么多的数据 你只需要有一个正确的结果 或者说确定性的结果和一个题目啊 就能做这样一个训练了啊 所以呃 像代码这种比较确定性的比较抽象的啊 训练级啊 的确能够切实的去提升大模型这方面的能力 那的确能够更好的帮助大猿模型在开发上面的落地 如果你两年前问我说这个 AI 会取代程序员吗 我可能觉得不会啊 但如果你现在问我 我可能会打一个问号 因为我现在切实的用 AI 提升了我写代码的效率 那你说随着 AI 继续再往前发展 会不会出现生产力过剩的状况 是吧 会不会出现啊 的确有一些技术工种会被取代掉 或者说我们原来 10 个人干的活 现在只需要两个人干 我觉得可能出现这样的情况 那在这个地方啊 我记得我在朋友圈里面 看到那种一线的大跃远模型的工程师的一句话 就是我现在做的东西好像在取代我自己 但是如果我不做这些东西 我好像更快也都会被取代 那除了这个工作上面的这样一种焦虑 我在看 cloud center 7 system card 的时候 我会有另外一种担心 为什么 因为 cloud center 7 这个 system card 大概有 90%的篇幅都在讲 AI 安全的这样的一个问题 这 cloud 的公司 AnswerPic 其实特别有意思 它每次的模型卡都写的特别的丧 它给人那种感觉就是 我们一定要注意 AI 安全 如果不注意 AI 安全 人们就要毁在我们手里了 那给大家总结一下 我觉得这个 system card 里面 它强调了比较有意思的两点 第一个是它有个章节叫做 release decision process 那这个地方的章节 release decision process 讲的是 他们为什么要把这个 train of thought 中间的每一步 这样的每一步的思考的过程 给到用户 能够让用户去进行一个阅读 这件事情其实对用户来说 有点不可思议 因为大家觉得不管是 DeepSeek 也好 还是 OpenAI 的 O1 也好 这个中间步骤好像我都能看到 为什么 cloud center 7 会犹豫要不要做这件事情 它花了很长的篇幅去解释 首先它如果给大家去看这个思考过程 有可能没有办法保证 这个过程中间是否有有害内容 因为中间的一些中文或者英文的 这种转换 或者说是一些思考的过程 就像我们前面几期视频所说的 它可能不是人能够读懂的语义 是吧 那当把这个语义转换成文字的时候 可能会出现一些偏差 或者说是会有一些有害的信息生成 是吧 他们没有办法 或者说需要有一个方式能够衡量 这中间的信息会不会对人造成危害 那第二点就是 当把中间思考这些信息 给到用户的时候 用户会不会更容易去 针对 AI 进行一个越狱 就是我本来不让 AI 去产生一些有害内容 但是由于中间这样的一些思考过程 是吧 我把它思考过程弄清楚之后 我就能够用依靠更好的方式 或者说是绕过它的一些这种限制 来让 AI 更容易地生成一些有害的内容 那根据这些情况 它把它到底是怎么样做决定 以及怎么样去评估它的危害 写在了这样的一篇文章里面 对大部分用户来说 我知道你这样的一个决策过程 对我来说到底有什么用 好像一点用没有 但是其实它体现的是 这个 Azure Peak 它想说 这个安全对它来说很重要 即使是别家这样做了 但是在我这儿 我一定要告诉你 我为什么这样做 当然也体现了它的一种丧 因为它就会觉得连这样的一种功能 它可能都会觉得有风险不安全 第二个我觉得值得一提的东西就是 它在这方做了一个 RSP evaluation 因为我们老说 AI 安全 其实有很多人就觉得 我天天用 AI 我也没有觉得 AI 不安全 到底 AI 安全是为了什么 那在这个地方 它就列出了一些实际的场景 来告诉大家 到底哪些东西 是的确会威胁到人类的安全的 并且给出了它自己的评估体系 来判断它现在的模型 是否会威胁到人类的安全 举个例子 就比如说它这一方的 7.1 就说的是 如果一个人想要利用大模型 去制作生化武器 并且这个人他有一定的理科背景 那他是否能够通过 AI 把这样的生化武器给制造出来 再比如这一方 7.2 这一方 7.2 讲的是自动演化 就是说它给 AI 这样的一种权限 让它去做 AI 相关的研究 然后让自己进化 它有没有这样的一种能力 能够自动的创造出下一代 更先进的 AI 所以我们可以看出 它这个地方其实设定了一些 真实的会威胁到人类安全的情况 并且设定了一些标准和测量指标 然后每一个模型 都根据这样的指标 去进行一个观测 从而发现 它是否未来真的会威胁到人类 Cloud 7.2 的 System Card 用了这么长的篇幅 去散播焦虑 我觉得它其实还是想提醒大家 要重视 AI 安全这样一件事情 我们在追逐更快更高更强的时候 也要追逐更安全 那这就是今天视频的主要内容 如果你有不明白的 或者想要讨论的事情 欢迎在我们的视频下方留言 如果你觉得我们的视频 做得还不错的话 欢迎点赞收藏转发 订阅评论我们的频道 这对我们来说非常重要 感谢你的收看 祝你学习顺利
