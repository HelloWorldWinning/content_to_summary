Timestamp: 2025-03-28T09:32:15.639744
Title: 图灵奖得主杨立昆：我对大语言模型已经不感兴趣了，还有四个更加有趣的问题 BV1iaoeYuELn
URL: https://b23.tv/NDXGxvz
Status: success
Duration: 0:59

Description:
好的，这是对给定文本的总结，包含大纲、核心观点、总体框架以及 Mermaid 概念图：

**总结：**

**一、 大纲：**

1.  **对 L&M (Large Models) 兴趣降低：** 说话者对传统的大型模型，特别是那些由行业产品人员改进的模型，兴趣正在减退。
2.  **更感兴趣的四个方向：**
    *   机器理解物理世界
    *   机器拥有持久记忆
    *   机器进行推理
    *   机器进行规划
3.  **对 L&M 推理能力的看法：** 认为目前 L&M 的推理方式过于简单。

**二、 核心观点：**

相对于在现有大型模型上进行边际改进，未来人工智能研究更应该关注如何让机器理解物理世界、拥有持久记忆、进行更高级的推理和规划。

**三、 总体框架：**

内容表达了对人工智能研究方向转变的观点，从关注传统的大型模型优化，转向关注更深层次的智能能力，例如理解物理世界、拥有记忆、推理和规划。这可以被认为是一种对人工智能发展路线的重新思考，强调了通用人工智能 (AGI) 的一些关键要素。

**四、Mermaid 概念图：**

<Mermaid_Diagram>
```mermaid
graph LR
    subgraph Large Models (LMs) [fill:#f9f,stroke:#333,stroke-width:2px]
    A[边际改进] --> B(数据获取)
    A --> C(计算资源)
    A --> D(合成数据)
    style A fill:#ccf,stroke:#333,stroke-width:2px
    style B fill:#ccf,stroke:#333,stroke-width:2px
    style C fill:#ccf,stroke:#333,stroke-width:2px
    style D fill:#ccf,stroke:#333,stroke-width:2px
    end

    subgraph More Interesting Directions [fill:#ffc,stroke:#333,stroke-width:2px]
    E[理解物理世界]
    F[持久记忆]
    G[推理 (更高级)]
    H[规划]
    style E fill:#bbf,stroke:#333,stroke-width:2px
    style F fill:#bbf,stroke:#333,stroke-width:2px
    style G fill:#bbf,stroke:#333,stroke-width:2px
    style H fill:#bbf,stroke:#333,stroke-width:2px
    end

    I[传统 L&M 研究] --> A
    I -->|兴趣减退| J(研究方向转变)
    J --> E
    J --> F
    J --> G
    J --> H

    K[L&M 的推理] -- 简单 --> G
    style K fill:#fcc,stroke:#333,stroke-width:2px

    style I fill:#eee,stroke:#333,stroke-width:2px
    style J fill:#eee,stroke:#333,stroke-width:2px
```
</Mermaid_Diagram>


Content:
 But I tell you one thing, which may surprise a few of you. I'm not so interested in L&M's anymore. You know, the kind of, the last thing, there are in the hands of industry product people, kind of, you know, improving at the margin, trying to get, you know, more data, more compute, generating synthetic data. I think there are more interesting questions in, four things. How do you get machines to understand the physical world? And Jensen talked about this this morning in the keynote. How do you get them to have persistent memory, which not too many people talk about? And then the last two are, how do you get them to reason and plan, and there is some effort, of course, to get, you know, L&M's to reason. But in my opinion, it's a very kind of simplistic way of viewing reasoning. I think there are probably kind of more, you know, better way of doing this.
