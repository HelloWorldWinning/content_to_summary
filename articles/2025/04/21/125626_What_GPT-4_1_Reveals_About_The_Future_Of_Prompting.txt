Timestamp: 2025-04-21T12:56:26.392818
Title: What GPT-4.1 Reveals About The Future Of Prompting
URL: https://youtube.com/watch?v=fCDWtqu5wD0&si=AbRdkH6JibUtZJ6q
Status: success
Duration: 18:15

Description:
好的，这是根据您提供的文本生成的总结：

**概要总结**

本文主要讨论了OpenAI新模型GPT-4.1的prompting最佳实践，以及这些实践对旧方法的影响。同时，还对比了GPT-4.1与其他模型（如Gemini 2.5 Pro和Claude 3.7）在特定任务上的表现。

**核心结论：**

尽管GPT-4.1在指令遵循方面有所提升，但Gemini 2.5 Pro在编码和长文本理解方面仍然表现更佳。

**总体框架：**

1.  **指令遵循（Instruction Following）：**

    *   新模型（GPT-4.1等）在指令遵循方面更强大，不再需要复杂的“技巧”。
    *   过去常用的“大写字母吼叫”或“贿赂”等方法不再必要。
2.  **上下文窗口（Context Window）：**

    *   GPT-4.1拥有更大的上下文窗口（1百万token）。
    *   全局规则（Global Rules）与项目规则（Project Rules）
    *   Gemini 2.5 Pro在遵循全局规则方面表现突出，这对于AI开发非常有利。
    *   推荐使用Gemini 2.5 Pro或GPT-4.1来提升规则参照能力。
3.  **否定词（Negating Terms）：**

    *   现在可以使用否定词，模型能更好地理解“不要做什么”。
4.  **分隔符（Delimiters）：**

    *   XML分隔符在系统提示中表现最佳，有助于模型理解不同部分的目的。
    *   OpenAI和Anthropic等公司都在趋同使用XML。
5.  **格式遵循（Format Following）：**

    *   在系统提示中，可以先做X，再做Y，最后做Z。
6.  **内容要求（Content Requirements）：**

    *   可以用正常语气表达要求，不需要使用全部大写。
7.  **过度自信（Overconfidence）：**

    *   对于Retrieval-Augmented Generation(RAG)机器人，如果不知道答案，直接回答不知道，避免幻觉。
8.  **基本系统提示结构（Basic System Prompt Structure）：**

    *   角色（Role）、任务（Task）、指令（Instructions）、推理步骤（Reasoning Steps）、输出格式（Output Format）、示例（Examples）、上下文（Context）。
    *   在提示的顶部和底部重复关键指令，但OpenAI过去的缓存方法与此相悖。

**信息架构Mermaid示意图**
<Mermaid_Diagram>
graph LR
    subgraph Prompting_Evolving [Prompting技术演进]
        style Prompting_Evolving fill:#f9f,stroke:#333,stroke-width:2px
        A[指令遵循改进]:::green_node --> B(不再需要复杂技巧);
        A --> C(可用否定词);
        D[分隔符XML]:::green_node --> E(系统提示更有效);
        F[基本提示结构]:::green_node --> G{角色，任务，指令，推理步骤，输出格式，示例，上下文};
    end
    subgraph 模型对比 [模型性能对比]
        style 模型对比 fill:#ccf,stroke:#333,stroke-width:2px
        H[Gemini 2.5 Pro]:::blue_node --> I(编码和长文本理解);
        J[GPT-4.1]:::blue_node --> K(指令遵循进步);
        L[Cloud 3.7]:::blue_node --> M(策略思考);
        N[Tool calling] -- 比之前差了点 --> J
    end
    subgraph 长期文本分析 [长期文本分析关键]
        style 长期文本分析 fill:#fcc,stroke:#333,stroke-width:2px
        AA[不仅仅是找重点]:::red_node --> AB(需要连贯的逻辑);
        AA --> AC(需要深度的了解);
    end
    Prompting_Evolving --> 模型对比
    长期文本分析 --> 模型对比
    classDef green_node fill:#90EE90,stroke:#333,stroke-width:2px
    classDef blue_node fill:#ADD8E6,stroke:#333,stroke-width:2px
    classDef red_node fill:#ff6961,stroke:#333,stroke-width:2px
</Mermaid_Diagram>


Content:
WEBVTT Kind: captions Language: en hey internet so today i want to talk to hey internet so today i want to talk to hey internet so today i want to talk to you about openai's new model 4. 1 and you about openai's new model 4. 1 and you about openai's new model 4. 1 and what this model reveals about the future what this model reveals about the future what this model reveals about the future of prompting so not just the model was of prompting so not just the model was of prompting so not just the model was released but they also released a guide released but they also released a guide released but they also released a guide and this guide actually talks through and this guide actually talks through and this guide actually talks through best practices for how to prompt this best practices for how to prompt this best practices for how to prompt this specific model and what i want to do in specific model and what i want to do in specific model and what i want to do in this video is i want to talk to you this video is i want to talk to you this video is i want to talk to you about not just the best practices from about not just the best practices from about not just the best practices from this blog post but also what this blog this blog post but also what this blog this blog post but also what this blog post means for old best practices for post means for old best practices for post means for old best practices for prompting and how the prompting as a as prompting and how the prompting as a as prompting and how the prompting as a as a practice in itself a craft is evolving a practice in itself a craft is evolving a practice in itself a craft is evolving over time as the models get better and over time as the models get better and over time as the models get better and uh with that being said let's get into uh with that being said let's get into uh with that being said let's get into it so this is uh our super cool awesome it so this is uh our super cool awesome it so this is uh our super cool awesome anime of the day from openai thank you anime of the day from openai thank you anime of the day from openai thank you gpt i guess 04. 0 or something like that gpt i guess 04. 0 or something like that gpt i guess 04. 0 or something like that so we're going to start with uh these so we're going to start with uh these so we're going to start with uh these items here that i want to walk you items here that i want to walk you items here that i want to walk you through from the blog post and i'll i'll through from the blog post and i'll i'll through from the blog post and i'll i'll share all the resources that i mentioned share all the resources that i mentioned share all the resources that i mentioned here um that i call out both in relation here um that i call out both in relation here um that i call out both in relation to the guide and also other things that to the guide and also other things that to the guide and also other things that i mentioned all right so we'll start i mentioned all right so we'll start i mentioned all right so we'll start here at the top and we'll work our way here at the top and we'll work our way here at the top and we'll work our way down now the first thing here is uh down now the first thing here is uh down now the first thing here is uh instruction following so this is one of instruction following so this is one of instruction following so this is one of the primary things that they talk the primary things that they talk the primary things that they talk through in their post and the importance through in their post and the importance through in their post and the importance of instruction following uh is is of instruction following uh is is of instruction following uh is is critical for all types of things and uh critical for all types of things and uh critical for all types of things and uh the primary thing that i want to call the primary thing that i want to call the primary thing that i want to call out here for instruction uh following is out here for instruction uh following is out here for instruction uh following is that oftentimes in the past when we that oftentimes in the past when we that oftentimes in the past when we would a best practice for getting a would a best practice for getting a would a best practice for getting a model to do what you wanted it to do is model to do what you wanted it to do is model to do what you wanted it to do is you'd kind of pull out all these crazy you'd kind of pull out all these crazy you'd kind of pull out all these crazy tricks to either like do all caps and tricks to either like do all caps and tricks to either like do all caps and yell at it or create some sort of yell at it or create some sort of yell at it or create some sort of convoluted scenario saying if you aren't convoluted scenario saying if you aren't convoluted scenario saying if you aren't able to do this then somebody will die able to do this then somebody will die able to do this then somebody will die or uh bribing it saying you know if if or uh bribing it saying you know if if or uh bribing it saying you know if if you do this i'll give you a million you do this i'll give you a million you do this i'll give you a million dollars or something like that and some dollars or something like that and some dollars or something like that and some of these actually worked there were of these actually worked there were of these actually worked there were studies that were written around these studies that were written around these studies that were written around these types of prompting tactics and how types of prompting tactics and how types of prompting tactics and how models were more effective in following models were more effective in following models were more effective in following certain tasks and doing certain things certain tasks and doing certain things certain tasks and doing certain things but now with 4. 1 and also gemini 2. 5 pro but now with 4. 1 and also gemini 2. 5 pro but now with 4. 1 and also gemini 2. 5 pro and claude 3. 7 these newer models this and claude 3. 7 these newer models this and claude 3. 7 these newer models this newer kind of cohort of models they're a newer kind of cohort of models they're a newer kind of cohort of models they're a lot better at following instructions you lot better at following instructions you lot better at following instructions you don't have to do all these crazy don't have to do all these crazy don't have to do all these crazy convoluted tasks to get them to do convoluted tasks to get them to do convoluted tasks to get them to do something very specific which is which something very specific which is which something very specific which is which is great to see and also amazing to not is great to see and also amazing to not is great to see and also amazing to not have to yell at models uh the next thing have to yell at models uh the next thing have to yell at models uh the next thing here is context window so this is the here is context window so this is the here is context window so this is the first model that openai's released that first model that openai's released that first model that openai's released that has such a big context window which is 1 has such a big context window which is 1 has such a big context window which is 1 million 1 million input i think and the million 1 million input i think and the million 1 million input i think and the really cool thing about this is really cool thing about this is really cool thing about this is specifically for those that are using ai specifically for those that are using ai specifically for those that are using ai to develop uh if you're using cursor so to develop uh if you're using cursor so to develop uh if you're using cursor so we'll do c for cursor and we'll do wf we'll do c for cursor and we'll do wf we'll do c for cursor and we'll do wf for windsurf these two types of ideides for windsurf these two types of ideides for windsurf these two types of ideides that are id ai centric ide they have that are id ai centric ide they have that are id ai centric ide they have these types of rules and let me actually these types of rules and let me actually these types of rules and let me actually walk you through what this is so each walk you through what this is so each walk you through what this is so each one of these boxes these can represent one of these boxes these can represent one of these boxes these can represent applications that we're building so applications that we're building so applications that we're building so these are different projects we're these are different projects we're these are different projects we're working on with these different tools so working on with these different tools so working on with these different tools so our first project here has uh project our first project here has uh project our first project here has uh project rules and i think wind surf has the same rules and i think wind surf has the same rules and i think wind surf has the same thing i use mainly cursor but i'm pretty thing i use mainly cursor but i'm pretty thing i use mainly cursor but i'm pretty sure they're similar so they have sure they're similar so they have sure they're similar so they have project rules and then you have a subset project rules and then you have a subset project rules and then you have a subset of global rules so we'll go above here of global rules so we'll go above here of global rules so we'll go above here and we'll say gr for global rules and and we'll say gr for global rules and and we'll say gr for global rules and global rules are basically rules that global rules are basically rules that global rules are basically rules that the ai should follow um in all the the ai should follow um in all the the ai should follow um in all the projects project rules are very specific projects project rules are very specific projects project rules are very specific to that project so if you're using a to that project so if you're using a to that project so if you're using a specific langu language a certain specific langu language a certain specific langu language a certain framework etc oftentimes from my framework etc oftentimes from my framework etc oftentimes from my experience most models really really experience most models really really experience most models really really suck at following the global rules and suck at following the global rules and suck at following the global rules and the reason they suck at following the the reason they suck at following the the reason they suck at following the global rules is when they're working on global rules is when they're working on global rules is when they're working on a project say project three the context a project say project three the context a project say project three the context is so big that it actually loses the is so big that it actually loses the is so big that it actually loses the thread so it loses the fact that there thread so it loses the fact that there thread so it loses the fact that there are global rules in the first place are global rules in the first place are global rules in the first place because it's its memory and its brain is because it's its memory and its brain is because it's its memory and its brain is so full of everything else that it can't so full of everything else that it can't so full of everything else that it can't reach those global rules so from my reach those global rules so from my reach those global rules so from my experience gemini 2. 5 pro is the first experience gemini 2. 5 pro is the first experience gemini 2. 5 pro is the first model that has consistently referenced model that has consistently referenced model that has consistently referenced the global rules that i've had in my the global rules that i've had in my the global rules that i've had in my cursor subset um period going forward so cursor subset um period going forward so cursor subset um period going forward so this is a really good breakthrough for a this is a really good breakthrough for a this is a really good breakthrough for a lot of us ai ai developers because we lot of us ai ai developers because we lot of us ai ai developers because we can actually have these global rules and can actually have these global rules and can actually have these global rules and they can be referenced and they can they can be referenced and they can they can be referenced and they can improve our ability to oneshot different improve our ability to oneshot different improve our ability to oneshot different parts of an application so it can build parts of an application so it can build parts of an application so it can build it without too many errors so this is a it without too many errors so this is a it without too many errors so this is a big plus so i recommend using gemini 2. 5 big plus so i recommend using gemini 2. 5 big plus so i recommend using gemini 2. 5 pro or even now gbt4. 1 for those pro or even now gbt4. 1 for those pro or even now gbt4. 1 for those improved ability to actually reference improved ability to actually reference improved ability to actually reference those rules so that's the one thing i those rules so that's the one thing i those rules so that's the one thing i wanted to share there for the wanted to share there for the wanted to share there for the context um next is negating terms so context um next is negating terms so context um next is negating terms so when we look at best practices from the when we look at best practices from the when we look at best practices from the past um a lot of people would avoid past um a lot of people would avoid past um a lot of people would avoid using negating terms so a negating term using negating terms so a negating term using negating terms so a negating term is saying do not do this ever or never is saying do not do this ever or never is saying do not do this ever or never do x or not etc so you're basically do x or not etc so you're basically do x or not etc so you're basically saying not to do something and the saying not to do something and the saying not to do something and the reason we wouldn't do that in system reason we wouldn't do that in system reason we wouldn't do that in system prompts is that the uh ai would prompts is that the uh ai would prompts is that the uh ai would accidentally do that thing that you accidentally do that thing that you accidentally do that thing that you didn't want it to do because it was didn't want it to do because it was didn't want it to do because it was inside of the system prompt and when inside of the system prompt and when inside of the system prompt and when that happens um we actually are that happens um we actually are that happens um we actually are obviously doing the exact opposite of obviously doing the exact opposite of obviously doing the exact opposite of what we wanted to do and if you can hear what we wanted to do and if you can hear what we wanted to do and if you can hear construction in the background sorry construction in the background sorry construction in the background sorry about that um anyways so the cool thing about that um anyways so the cool thing about that um anyways so the cool thing now is that it's okay to use these now is that it's okay to use these now is that it's okay to use these negating terms we're allowed to say not negating terms we're allowed to say not negating terms we're allowed to say not to do something or to avoid something or to do something or to avoid something or to do something or to avoid something or to never do something because the ai's to never do something because the ai's to never do something because the ai's ability to follow that instruction has ability to follow that instruction has ability to follow that instruction has improved with models like 4. 1 and 2. 5 improved with models like 4. 1 and 2. 5 improved with models like 4. 1 and 2. 5 pro and then the last thing here is pro and then the last thing here is pro and then the last thing here is delimiters now with a model when you're delimiters now with a model when you're delimiters now with a model when you're writing a prompt we'll do another image writing a prompt we'll do another image writing a prompt we'll do another image here so say this is our prompt and we're here so say this is our prompt and we're here so say this is our prompt and we're writing all this stuff here so in our writing all this stuff here so in our writing all this stuff here so in our prompt we usually want the ai to segment prompt we usually want the ai to segment prompt we usually want the ai to segment the prompt into certain sections because the prompt into certain sections because the prompt into certain sections because certain sections have certain purposes certain sections have certain purposes certain sections have certain purposes so say we have section one two and three so say we have section one two and three so say we have section one two and three and each has its own purpose so the and each has its own purpose so the and each has its own purpose so the model should actually know that section model should actually know that section model should actually know that section one has a different purpose than two and one has a different purpose than two and one has a different purpose than two and three inside of the system prompt and to three inside of the system prompt and to three inside of the system prompt and to do that we would usually use delimiters do that we would usually use delimiters do that we would usually use delimiters so that can be markdown which is usually so that can be markdown which is usually so that can be markdown which is usually hashtags and other things either it hashtags and other things either it hashtags and other things either it could be xml which is little bracket could be xml which is little bracket could be xml which is little bracket thingies like this or different types of thingies like this or different types of thingies like this or different types of things like that things like that things like that and in the blog post for prompting and in the blog post for prompting and in the blog post for prompting opening actually said that xml has opening actually said that xml has opening actually said that xml has actually performed the best when it actually performed the best when it actually performed the best when it comes to system prompts that have a lot comes to system prompts that have a lot comes to system prompts that have a lot of context and are more complicated and of context and are more complicated and of context and are more complicated and this is interesting because claude this is interesting because claude this is interesting because claude anthropic the company that made claude anthropic the company that made claude anthropic the company that made claude they actually used xml for a while so they actually used xml for a while so they actually used xml for a while so their models have always been good at their models have always been good at their models have always been good at xml and there seems to be a convergence xml and there seems to be a convergence xml and there seems to be a convergence happening so if openai anthropic and happening so if openai anthropic and happening so if openai anthropic and probably other model providers that are probably other model providers that are probably other model providers that are building models they're all starting to building models they're all starting to building models they're all starting to converge on the usage of xml and system converge on the usage of xml and system converge on the usage of xml and system prompts because of its effectiveness and prompts because of its effectiveness and prompts because of its effectiveness and having the model follow instructions and having the model follow instructions and having the model follow instructions and segment them effectively so this isn't segment them effectively so this isn't segment them effectively so this isn't necessarily going to be forever but it's necessarily going to be forever but it's necessarily going to be forever but it's interesting how this is happening where interesting how this is happening where interesting how this is happening where people are converging on the usage of a people are converging on the usage of a people are converging on the usage of a certain type of delimter inside of the certain type of delimter inside of the certain type of delimter inside of the system prompt all right so let me system prompt all right so let me system prompt all right so let me quickly look at the in these are some of quickly look at the in these are some of quickly look at the in these are some of my notes for everything i just mentioned my notes for everything i just mentioned my notes for everything i just mentioned above i want to make sure i didn't miss above i want to make sure i didn't miss above i want to make sure i didn't miss anything nope we're good nice all right anything nope we're good nice all right anything nope we're good nice all right so the next thing i want to mention uh so the next thing i want to mention uh so the next thing i want to mention uh so this is actually a snapshot a so this is actually a snapshot a so this is actually a snapshot a screenshot from the i think the main screenshot from the i think the main screenshot from the i think the main blog post they made uh about this new blog post they made uh about this new blog post they made uh about this new model not the guide itself for prompting model not the guide itself for prompting model not the guide itself for prompting but they did call out some interesting but they did call out some interesting but they did call out some interesting bits that i wanted to share with you so bits that i wanted to share with you so bits that i wanted to share with you so the uh format following we've already the uh format following we've already the uh format following we've already talked about the negation we've already talked about the negation we've already talked about the negation we've already talked about order instructions is talked about order instructions is talked about order instructions is interesting and also reranking is interesting and also reranking is interesting and also reranking is interesting so these are kind of similar interesting so these are kind of similar interesting so these are kind of similar where with ordered instructions in the where with ordered instructions in the where with ordered instructions in the system prompt you can say first do x system prompt you can say first do x system prompt you can say first do x then do y then do z this historically then do y then do z this historically then do y then do z this historically has been kind of hard for a model to do has been kind of hard for a model to do has been kind of hard for a model to do effectively in a row so now it's effectively in a row so now it's effectively in a row so now it's actually more effective in its ability actually more effective in its ability actually more effective in its ability to follow instructions which is to follow instructions which is to follow instructions which is important except especially for agents important except especially for agents important except especially for agents um re-ranking is basically sorting um re-ranking is basically sorting um re-ranking is basically sorting something afterwards which is i would something afterwards which is i would something afterwards which is i would say similar to ordering or at least the say similar to ordering or at least the say similar to ordering or at least the the concept behind it uh content the concept behind it uh content the concept behind it uh content requirements so this kind of goes back requirements so this kind of goes back requirements so this kind of goes back to the all cap situation and so instead to the all cap situation and so instead to the all cap situation and so instead of having to say always like uh like of having to say always like uh like of having to say always like uh like freaking out and yelling at it and freaking out and yelling at it and freaking out and yelling at it and saying always do x you don't have to saying always do x you don't have to saying always do x you don't have to have all caps instead you can do it as a have all caps instead you can do it as a have all caps instead you can do it as a normal person would and it'll always normal person would and it'll always normal person would and it'll always reference that specific item inside of reference that specific item inside of reference that specific item inside of the thing you're asking it to do and the thing you're asking it to do and the thing you're asking it to do and then overconfidence this is another then overconfidence this is another then overconfidence this is another really important for agents or really important for agents or really important for agents or specifically rag use cases so oftentimes specifically rag use cases so oftentimes specifically rag use cases so oftentimes you have your uh your robot here so this you have your uh your robot here so this you have your uh your robot here so this is our robot we'll draw some smiley face is our robot we'll draw some smiley face is our robot we'll draw some smiley face and we have our database here and for and we have our database here and for and we have our database here and for rag the ai is asked a question and see rag the ai is asked a question and see rag the ai is asked a question and see we have our human we have our human we have our human here really bad human and they they ask here really bad human and they they ask here really bad human and they they ask a hu the a human asks the robot a a hu the a human asks the robot a a hu the a human asks the robot a question the robot then has to reference question the robot then has to reference question the robot then has to reference the database to get the information so the database to get the information so the database to get the information so often times what we would do is if the often times what we would do is if the often times what we would do is if the robot would accidentally say something robot would accidentally say something robot would accidentally say something that wasn't in the database that would that wasn't in the database that would that wasn't in the database that would be considered a hallucination because be considered a hallucination because be considered a hallucination because it's not referencing the information we it's not referencing the information we it's not referencing the information we asked it for and uh oftentimes in system asked it for and uh oftentimes in system asked it for and uh oftentimes in system prompts for these agent use cases that prompts for these agent use cases that prompts for these agent use cases that are using rag you would ask it to say i are using rag you would ask it to say i are using rag you would ask it to say i don't know if it doesn't know the answer don't know if it doesn't know the answer don't know if it doesn't know the answer and this is a form of grounding and this and this is a form of grounding and this and this is a form of grounding and this is an old uh best practice in prompting is an old uh best practice in prompting is an old uh best practice in prompting where you would actually get the model where you would actually get the model where you would actually get the model to do a grounding technique saying that to do a grounding technique saying that to do a grounding technique saying that if the answer is not in the database if the answer is not in the database if the answer is not in the database then then either give them nothing back then then either give them nothing back then then either give them nothing back or tell them that you don't know but or tell them that you don't know but or tell them that you don't know but never ever go outside of your know go never ever go outside of your know go never ever go outside of your know go outside of the knowledge base that outside of the knowledge base that outside of the knowledge base that you're referencing into your own you're referencing into your own you're referencing into your own knowledge base so it's kind of internal knowledge base so it's kind of internal knowledge base so it's kind of internal versus external knowledge but now with versus external knowledge but now with versus external knowledge but now with instruction following the model is much instruction following the model is much instruction following the model is much more effective at doing this so you can more effective at doing this so you can more effective at doing this so you can simply say just say i don't know and simply say just say i don't know and simply say just say i don't know and there's a high likelihood that the model there's a high likelihood that the model there's a high likelihood that the model will effectively do that instead of will effectively do that instead of will effectively do that instead of loosenate which is yet again another loosenate which is yet again another loosenate which is yet again another plus for rag setups and also overall plus for rag setups and also overall plus for rag setups and also overall kind of system uh a kind of system uh a kind of system uh a agents all right so we've talked about agents all right so we've talked about agents all right so we've talked about this now we're going to go over here this now we're going to go over here this now we're going to go over here really quick so this is also from the really quick so this is also from the really quick so this is also from the prompt guide that openai shared and this prompt guide that openai shared and this prompt guide that openai shared and this is kind of the beginner 101 setup where is kind of the beginner 101 setup where is kind of the beginner 101 setup where if you're not necessarily sure of how to if you're not necessarily sure of how to if you're not necessarily sure of how to start you want to reference this uh start you want to reference this uh start you want to reference this uh structure for a basic system prompt structure for a basic system prompt structure for a basic system prompt structure and this is kind of many many structure and this is kind of many many structure and this is kind of many many people have talked about this before people have talked about this before people have talked about this before it's not anything new but i wanted to it's not anything new but i wanted to it's not anything new but i wanted to just touch on it briefly so everybody just touch on it briefly so everybody just touch on it briefly so everybody kind of knows what it is so at the very kind of knows what it is so at the very kind of knows what it is so at the very top of your prompt you're going to have top of your prompt you're going to have top of your prompt you're going to have the role so this is kind of the persona the role so this is kind of the persona the role so this is kind of the persona you've given it saying you're you're x you've given it saying you're you're x you've given it saying you're you're x you're y so you're a professional writer you're y so you're a professional writer you're y so you're a professional writer you're a coder etc you give it a task or you're a coder etc you give it a task or you're a coder etc you give it a task or they say objective so some people call they say objective so some people call they say objective so some people call this a task some people call it an this a task some people call it an this a task some people call it an objective so this is the thing we want objective so this is the thing we want objective so this is the thing we want you to achieve uh next we have those you to achieve uh next we have those you to achieve uh next we have those instructions that it's so good at instructions that it's so good at instructions that it's so good at following so we can give it instructions following so we can give it instructions following so we can give it instructions and not just instructions of doing x y and not just instructions of doing x y and not just instructions of doing x y and z we can also give it subcategories and z we can also give it subcategories and z we can also give it subcategories so more specific detail below each one so more specific detail below each one so more specific detail below each one of those instructions around the of those instructions around the of those instructions around the specificity of how to execute those specificity of how to execute those specificity of how to execute those instructions over time um also we can instructions over time um also we can instructions over time um also we can give it reasoning steps and it's give it reasoning steps and it's give it reasoning steps and it's important to note that this model gpt4. 1 important to note that this model gpt4. 1 important to note that this model gpt4. 1 is not a reasoning model but it's a is not a reasoning model but it's a is not a reasoning model but it's a generative model so we actually have to generative model so we actually have to generative model so we actually have to bake in the reasoning into the system bake in the reasoning into the system bake in the reasoning into the system prompt so this way we're basically prompt so this way we're basically prompt so this way we're basically saying at the very end of a prompt saying at the very end of a prompt saying at the very end of a prompt saying think step by step and not only saying think step by step and not only saying think step by step and not only do we say think step by step we can do we say think step by step we can do we say think step by step we can actually specify what we mean by think actually specify what we mean by think actually specify what we mean by think step by step what specific things am i step by step what specific things am i step by step what specific things am i going to think about for each one of going to think about for each one of going to think about for each one of those steps in what order so we can those steps in what order so we can those steps in what order so we can actually specify what that reasoning actually specify what that reasoning actually specify what that reasoning looks like uh next we have the output looks like uh next we have the output looks like uh next we have the output format which is the xml thing i format which is the xml thing i format which is the xml thing i mentioned previously and then we have mentioned previously and then we have mentioned previously and then we have the uh examples so this is kind of this the uh examples so this is kind of this the uh examples so this is kind of this is called fshot learning so we're giving is called fshot learning so we're giving is called fshot learning so we're giving it examples of what it should look like it examples of what it should look like it examples of what it should look like when it responds and this increases its when it responds and this increases its when it responds and this increases its likelihood of effectively responding and likelihood of effectively responding and likelihood of effectively responding and then last we have the context and and then last we have the context and and then last we have the context and and actually not last but second to last an actually not last but second to last an actually not last but second to last an important thing to mention here is that important thing to mention here is that important thing to mention here is that the context even though it's just one the context even though it's just one the context even though it's just one line inside of the system prompt uh line inside of the system prompt uh line inside of the system prompt uh proportionally so if we just draw like a proportionally so if we just draw like a proportionally so if we just draw like a big box here at the very top is going to big box here at the very top is going to big box here at the very top is going to be our instructions so our instructions be our instructions so our instructions be our instructions so our instructions are all of this stuff we just mentioned are all of this stuff we just mentioned are all of this stuff we just mentioned examples included it's all going to fit examples included it's all going to fit examples included it's all going to fit in there and then at the very bottom in there and then at the very bottom in there and then at the very bottom we're going to reiterate those we're going to reiterate those we're going to reiterate those instructions but in between we're going instructions but in between we're going instructions but in between we're going to have all this information and all to have all this information and all to have all this information and all this is going to be context depending on this is going to be context depending on this is going to be context depending on your use case you might not have this your use case you might not have this your use case you might not have this much context but some use cases do so we much context but some use cases do so we much context but some use cases do so we can have this huge context section um can have this huge context section um can have this huge context section um inside of our prompt and we're going to inside of our prompt and we're going to inside of our prompt and we're going to have to do two things so we're going to have to do two things so we're going to have to do two things so we're going to have our instructions at the top and have our instructions at the top and have our instructions at the top and also we're going to have them at the also we're going to have them at the also we're going to have them at the bottom and the reason we're going to do bottom and the reason we're going to do bottom and the reason we're going to do top and bottom is actually in the the top and bottom is actually in the the top and bottom is actually in the the prompt guide that they share in best prompt guide that they share in best prompt guide that they share in best practices they say that it's important practices they say that it's important practices they say that it's important to have your instructions and to repeat to have your instructions and to repeat to have your instructions and to repeat them at the top and the bottom and i them at the top and the bottom and i them at the top and the bottom and i probably can't see this because my face probably can't see this because my face probably can't see this because my face is in the way so i'll zoom out a bit and is in the way so i'll zoom out a bit and is in the way so i'll zoom out a bit and do this maybe uh yeah that's a little do this maybe uh yeah that's a little do this maybe uh yeah that's a little better all right so um and the reason better all right so um and the reason better all right so um and the reason we're doing this is that the likelihood we're doing this is that the likelihood we're doing this is that the likelihood of the model understands and remembers of the model understands and remembers of the model understands and remembers the instructions because the context the instructions because the context the instructions because the context window is so big is it's it's a lot window is so big is it's it's a lot window is so big is it's it's a lot higher if you put the instructions at higher if you put the instructions at higher if you put the instructions at the top and not all of them you don't the top and not all of them you don't the top and not all of them you don't have to copy and paste them from the top have to copy and paste them from the top have to copy and paste them from the top and the bottom you just want to kind of and the bottom you just want to kind of and the bottom you just want to kind of re reemphasize the really critical re reemphasize the really critical re reemphasize the really critical instructions and the thinking step by instructions and the thinking step by instructions and the thinking step by step and uh part at the very bottom of step and uh part at the very bottom of step and uh part at the very bottom of the piece um also they state that uh in the piece um also they state that uh in the piece um also they state that uh in their best practices if you don't want their best practices if you don't want their best practices if you don't want to do both top and bottom if you had to to do both top and bottom if you had to to do both top and bottom if you had to choose one they say to actually just go choose one they say to actually just go choose one they say to actually just go with the top and that has performed more with the top and that has performed more with the top and that has performed more effectively than going with the bottom effectively than going with the bottom effectively than going with the bottom versus the top now the interesting thing versus the top now the interesting thing versus the top now the interesting thing about this that i wanted to call out about this that i wanted to call out about this that i wanted to call out which is a bit of a side rant is in the which is a bit of a side rant is in the which is a bit of a side rant is in the past um openai has historically talked past um openai has historically talked past um openai has historically talked about um caching and so has cloud and about um caching and so has cloud and about um caching and so has cloud and other types of providers and this the other types of providers and this the other types of providers and this the reason they do this is because this reason they do this is because this reason they do this is because this saves money for uh people that are saves money for uh people that are saves money for uh people that are building with these tools and the building with these tools and the building with these tools and the caching method that openai has pushed caching method that openai has pushed caching method that openai has pushed for in the past has actually stated that for in the past has actually stated that for in the past has actually stated that you should put all of the uh stuff in you should put all of the uh stuff in you should put all of the uh stuff in your system prompt that is static your system prompt that is static your system prompt that is static something that doesn't change over time something that doesn't change over time something that doesn't change over time so either this is a specific instruction so either this is a specific instruction so either this is a specific instruction that's always the same or it's a piece that's always the same or it's a piece that's always the same or it's a piece of context that's always the same and of context that's always the same and of context that's always the same and you put this at the very top of your you put this at the very top of your you put this at the very top of your prompt you can see by this kind of color prompt you can see by this kind of color prompt you can see by this kind of color coding here is that everything at the coding here is that everything at the coding here is that everything at the top of the prompt here is static it top of the prompt here is static it top of the prompt here is static it doesn't change and by doing this you doesn't change and by doing this you doesn't change and by doing this you cache this information so the model cache this information so the model cache this information so the model doesn't have to rethink about all this doesn't have to rethink about all this doesn't have to rethink about all this stuff every single time so you save stuff every single time so you save stuff every single time so you save yourself a lot of money on inference so yourself a lot of money on inference so yourself a lot of money on inference so this kind of is a way to save money but this kind of is a way to save money but this kind of is a way to save money but still get good quality but the still get good quality but the still get good quality but the interesting thing though is that with interesting thing though is that with interesting thing though is that with this new this uh this new best practice this new this uh this new best practice this new this uh this new best practice that they're referencing over here of that they're referencing over here of that they're referencing over here of putting both your instructions at the putting both your instructions at the putting both your instructions at the top and the bottom it's negating that top and the bottom it's negating that top and the bottom it's negating that caching point so you're not necessarily caching point so you're not necessarily caching point so you're not necessarily saving as much so i don't know if saving as much so i don't know if saving as much so i don't know if they're shifting their tactics or they're shifting their tactics or they're shifting their tactics or shifting their perspectives here um or shifting their perspectives here um or shifting their perspectives here um or maybe it's just one model is different maybe it's just one model is different maybe it's just one model is different than the other but either way it's than the other but either way it's than the other but either way it's interesting to kind of compare what interesting to kind of compare what interesting to kind of compare what they've said in the past to what they're they've said in the past to what they're they've said in the past to what they're saying now for different types of models saying now for different types of models saying now for different types of models so i don't know if this whole caching so i don't know if this whole caching so i don't know if this whole caching thing is going to change or that this is thing is going to change or that this is thing is going to change or that this is just a nuance for gpt4. 1 and the caching just a nuance for gpt4. 1 and the caching just a nuance for gpt4. 1 and the caching thing still applies for all the other thing still applies for all the other thing still applies for all the other models all right so with that being models all right so with that being models all right so with that being said that is mainly what i wanted to said that is mainly what i wanted to said that is mainly what i wanted to talk about for prompting so everything talk about for prompting so everything talk about for prompting so everything we've talked about here these are all we've talked about here these are all we've talked about here these are all the big points when it comes to um how the big points when it comes to um how the big points when it comes to um how prompting is changing and evolving and prompting is changing and evolving and prompting is changing and evolving and how a lot of the things we used to do in how a lot of the things we used to do in how a lot of the things we used to do in the past are becoming somewhat obsolete the past are becoming somewhat obsolete the past are becoming somewhat obsolete with these newer models which is kind of with these newer models which is kind of with these newer models which is kind of cool to see so one quick thing i wanted cool to see so one quick thing i wanted cool to see so one quick thing i wanted to do so this is another side rant is to do so this is another side rant is to do so this is another side rant is actually um talking through some actually um talking through some actually um talking through some benchmarks so oftent times when the benchmarks so oftent times when the benchmarks so oftent times when the these model providers when they talk these model providers when they talk these model providers when they talk about their models they want to make about their models they want to make about their models they want to make them look as good as possible which is them look as good as possible which is them look as good as possible which is which is fair which is fine and what which is fair which is fine and what which is fair which is fine and what they'll do is sometimes they'll compare they'll do is sometimes they'll compare they'll do is sometimes they'll compare themselves to their past self or they'll themselves to their past self or they'll themselves to their past self or they'll compare themselves to other model compare themselves to other model compare themselves to other model providers through a very specific providers through a very specific providers through a very specific benchmark and what i wanted to do is benchmark and what i wanted to do is benchmark and what i wanted to do is show you that if you look at the best show you that if you look at the best show you that if you look at the best models in the market today gemini 2. 5 models in the market today gemini 2. 5 models in the market today gemini 2. 5 pro is still probably by far the best pro is still probably by far the best pro is still probably by far the best when it comes to coding and a variety of when it comes to coding and a variety of when it comes to coding and a variety of other use cases that rely on a lot of other use cases that rely on a lot of other use cases that rely on a lot of long context and i want to give you some long context and i want to give you some long context and i want to give you some use cases and benchmarks uh to kind of use cases and benchmarks uh to kind of use cases and benchmarks uh to kind of show why that's true and also just from show why that's true and also just from show why that's true and also just from my own experience of vibe coding and and my own experience of vibe coding and and my own experience of vibe coding and and working with these models all right so working with these models all right so working with these models all right so we're first going to look at this this we're first going to look at this this we're first going to look at this this um benchmark here that is actually not um benchmark here that is actually not um benchmark here that is actually not talked about often so this is um this is talked about often so this is um this is talked about often so this is um this is called called called fiction. livebench and what this specific fiction. livebench and what this specific fiction. livebench and what this specific benchmark is doing is interesting so benchmark is doing is interesting so benchmark is doing is interesting so it's based off of fictional stories and it's based off of fictional stories and it's based off of fictional stories and the example here is we want the model to the example here is we want the model to the example here is we want the model to be able to shove the entire story in its be able to shove the entire story in its be able to shove the entire story in its head and answer questions not just about head and answer questions not just about head and answer questions not just about specific parts of the story but a lot of specific parts of the story but a lot of specific parts of the story but a lot of interconnected pieces of the story so interconnected pieces of the story so interconnected pieces of the story so our example here is say we've asked the our example here is say we've asked the our example here is say we've asked the model a question about a specific story model a question about a specific story model a question about a specific story and the only way that the model can and the only way that the model can and the only way that the model can effectively answer this question is it effectively answer this question is it effectively answer this question is it has to it has to pull a fact from has to it has to pull a fact from has to it has to pull a fact from chapter 2 it has to pull a reference to chapter 2 it has to pull a reference to chapter 2 it has to pull a reference to that fact in chapter 18 and then it has that fact in chapter 18 and then it has that fact in chapter 18 and then it has to string all of those together together to string all of those together together to string all of those together together in a methodical way to respond to us to in a methodical way to respond to us to in a methodical way to respond to us to get to a good get a good get to a good get a good get to a good get a good answer now this is counter not this this answer now this is counter not this this answer now this is counter not this this is kind of the opposite or different is kind of the opposite or different is kind of the opposite or different from what a lot of these different model from what a lot of these different model from what a lot of these different model providers talk about when they talk providers talk about when they talk providers talk about when they talk about long context windows so this is about long context windows so this is about long context windows so this is something that openai talks a lot about something that openai talks a lot about something that openai talks a lot about on their um video or when they talk on their um video or when they talk on their um video or when they talk through this is uh needle in the hay through this is uh needle in the hay through this is uh needle in the hay stack so this is often what people stack so this is often what people stack so this is often what people reference and this is referring to the reference and this is referring to the reference and this is referring to the model's ability to refer to a specific model's ability to refer to a specific model's ability to refer to a specific fact in a larger pile of data so if i fact in a larger pile of data so if i fact in a larger pile of data so if i have a huge book that talks about baking have a huge book that talks about baking have a huge book that talks about baking and i shove a fact in there about and i shove a fact in there about and i shove a fact in there about quantum physics if the model can pick quantum physics if the model can pick quantum physics if the model can pick that fact out from the entirety of the that fact out from the entirety of the that fact out from the entirety of the book that is considered perfect or good book that is considered perfect or good book that is considered perfect or good and that's what this is showing here is and that's what this is showing here is and that's what this is showing here is basically this entire section is all basically this entire section is all basically this entire section is all blued off because it's showing that blued off because it's showing that blued off because it's showing that irrelevant of the input tokens and irrelevant of the input tokens and irrelevant of the input tokens and irrelevant of the depth of the needle irrelevant of the depth of the needle irrelevant of the depth of the needle it's always going to get it so it's it's always going to get it so it's it's always going to get it so it's basically perfect which is cool but it's basically perfect which is cool but it's basically perfect which is cool but it's not necessarily useful not necessarily useful not necessarily useful and the reason it's not useful is and the reason it's not useful is and the reason it's not useful is oftentimes when you and i are using oftentimes when you and i are using oftentimes when you and i are using these models we have really complex use these models we have really complex use these models we have really complex use cases that have not just finding a cases that have not just finding a cases that have not just finding a specific fact in a in a data set but specific fact in a in a data set but specific fact in a in a data set but it's more about understanding the data it's more about understanding the data it's more about understanding the data set understanding the complexities of set understanding the complexities of set understanding the complexities of the data set and the interconnected the data set and the interconnected the data set and the interconnected pieces for it and then being able to pieces for it and then being able to pieces for it and then being able to cohesively understand that and solve a cohesively understand that and solve a cohesively understand that and solve a problem with that data set in the ai's problem with that data set in the ai's problem with that data set in the ai's head so that's why if we look at this head so that's why if we look at this head so that's why if we look at this benchmark we can see that if we compare benchmark we can see that if we compare benchmark we can see that if we compare all the different models and this was i all the different models and this was i all the different models and this was i think done only a few days ago um we can think done only a few days ago um we can think done only a few days ago um we can see that gemini 2. 5 pro is listed see that gemini 2. 5 pro is listed see that gemini 2. 5 pro is listed here and it has the by far the best here and it has the by far the best here and it has the by far the best score out of all the different models score out of all the different models score out of all the different models and this is only for 120k tokens not the and this is only for 120k tokens not the and this is only for 120k tokens not the larger um spectrum but my guess is that larger um spectrum but my guess is that larger um spectrum but my guess is that since it's at such a high mark it's since it's at such a high mark it's since it's at such a high mark it's probably better than the rest when we probably better than the rest when we probably better than the rest when we extend this out for more tokens and you extend this out for more tokens and you extend this out for more tokens and you can see uh gemini 4. 1 is down here which can see uh gemini 4. 1 is down here which can see uh gemini 4. 1 is down here which is at 62 which is still pretty good um is at 62 which is still pretty good um is at 62 which is still pretty good um but we can see that grock mi mini is but we can see that grock mi mini is but we can see that grock mi mini is better than 62 we can see weirdly that better than 62 we can see weirdly that better than 62 we can see weirdly that gemini 4. 0 is actually uh yeah better gemini 4. 0 is actually uh yeah better gemini 4. 0 is actually uh yeah better than gemini 4. 1 um and we have cloud3. 7 than gemini 4. 1 um and we have cloud3. 7 than gemini 4. 1 um and we have cloud3. 7 which is at 53 so we have different which is at 53 so we have different which is at 53 so we have different scores here but by far gemini 2. 5 pro is scores here but by far gemini 2. 5 pro is scores here but by far gemini 2. 5 pro is still the best um so that's just one still the best um so that's just one still the best um so that's just one interesting thing on that piece that i interesting thing on that piece that i interesting thing on that piece that i wanted to call out when it comes to the wanted to call out when it comes to the wanted to call out when it comes to the context and the ability of using that context and the ability of using that context and the ability of using that context not just finding facts but also context not just finding facts but also context not just finding facts but also uh stringing those facts together to uh stringing those facts together to uh stringing those facts together to answer complex questions and then answer complex questions and then answer complex questions and then another thing i wanted to share here is another thing i wanted to share here is another thing i wanted to share here is i think this is uh for tool calling and i think this is uh for tool calling and i think this is uh for tool calling and for tool calling you can see um that for tool calling you can see um that for tool calling you can see um that gemini 2. 5 pro is again listed as the gemini 2. 5 pro is again listed as the gemini 2. 5 pro is again listed as the best on this benchmark for uh that was best on this benchmark for uh that was best on this benchmark for uh that was referenced inside of the openai referenced inside of the openai referenced inside of the openai announcement you can see 3. 5 sonnet is announcement you can see 3. 5 sonnet is announcement you can see 3. 5 sonnet is actually better than 3. 7 sonnet which is actually better than 3. 7 sonnet which is actually better than 3. 7 sonnet which is interesting when i use cursor sometimes interesting when i use cursor sometimes interesting when i use cursor sometimes i actually reference 3. 5 instead of 3. 7 i actually reference 3. 5 instead of 3. 7 i actually reference 3. 5 instead of 3. 7 for execution and then i use gemini 2. 5 for execution and then i use gemini 2. 5 for execution and then i use gemini 2. 5 pro and cloud3. 7 thinking for the pro and cloud3. 7 thinking for the pro and cloud3. 7 thinking for the strategy so what are we going to do and strategy so what are we going to do and strategy so what are we going to do and then the executor is one of these models then the executor is one of these models then the executor is one of these models down here and you can see uh 4. 1 is down down here and you can see uh 4. 1 is down down here and you can see uh 4. 1 is down here for tool calling which isn't uh here for tool calling which isn't uh here for tool calling which isn't uh comparably isn't as good as the others comparably isn't as good as the others comparably isn't as good as the others so long story short is uh gemini gemini so long story short is uh gemini gemini so long story short is uh gemini gemini no sorry chatbt4. 1 is made made progress no sorry chatbt4. 1 is made made progress no sorry chatbt4. 1 is made made progress really proud of them um but at the same really proud of them um but at the same really proud of them um but at the same time it's also still not the best model time it's also still not the best model time it's also still not the best model so if you have different use cases that so if you have different use cases that so if you have different use cases that you want to code with i still recommend you want to code with i still recommend you want to code with i still recommend using uh cloud 3. 5 or or gemini 2. 5 pro using uh cloud 3. 5 or or gemini 2. 5 pro using uh cloud 3. 5 or or gemini 2. 5 pro or even 3. 7 from cloud for the thinking or even 3. 7 from cloud for the thinking or even 3. 7 from cloud for the thinking side with that being said internet hope side with that being said internet hope side with that being said internet hope you enjoyed this uh please do uh reshare you enjoyed this uh please do uh reshare you enjoyed this uh please do uh reshare this with your friends if you did and if this with your friends if you did and if this with your friends if you did and if you'd like to work with me i have a you'd like to work with me i have a you'd like to work with me i have a company called gradient labs where we company called gradient labs where we company called gradient labs where we help people implement ai internally to help people implement ai internally to help people implement ai internally to increase your productivity so if you're increase your productivity so if you're increase your productivity so if you're interested there's a link below you can interested there's a link below you can interested there's a link below you can book a free 30-minute call to see if book a free 30-minute call to see if book a free 30-minute call to see if there's a good fit between the two of us there's a good fit between the two of us there's a good fit between the two of us and with that being said internet i will and with that being said internet i will and with that being said internet i will see you next
