Timestamp: 2025-04-21T11:08:27.344004
Title: Yann LeCun：我对大语言模型没兴趣，这四个领域更有趣
URL: https://youtube.com/watch?v=PY3p3cMCCHk&si=SdjUiG0n88e0MQSz
Status: success
Duration: 3:25

Description:
好的，我将根据您提供的文本生成一个符合要求的总结，包括结构化的要点、核心结论、总体框架和一个美观的Mermaid概念图。

**总结：**

**一、核心观点：**

*   **对当前大型语言模型（LLM）的兴趣降低：**
    *   认为LLM主要由行业产品人员改进，侧重于边缘优化，如增加数据和算力，生成合成数据。
    *   认为LLM的推理方式过于简单。

*   **更感兴趣的研究方向：**
    *   如何让机器理解物理世界。
    *   如何让机器拥有持久记忆。
    *   如何让机器进行推理和规划（认为LLM在这方面存在局限）。

*   **对通用人工智能（AGI）/高级机器智能（AMI）的看法：**
    *   不认同AGI的提法，认为人类智能过于专业化，"通用"一词不准确。
    *   更喜欢"AMI"（高级机器智能）的说法。
    *   认为在3-5年内，小规模的AMI（能够学习抽象模型并进行推理和规划）可能取得进展。
    *   对“扩展LLM就能实现AGI”的观点持怀疑态度，认为那是过去70年里AI研究领域的重复性错误。
    *   认为当前对AGI的预测（如“数据中心里的天才国度”）是无稽之谈。
    *   承认LLM在特定应用领域会有PhD级别的能力，但在整体智能方面，我们仍然远远落后。

**二、核心结论：**

虽然大型语言模型在某些领域取得了进展，但要实现真正的人工通用智能（AGI）或高级机器智能（AMI），仍然面临诸多挑战，我们需要关注更根本性的问题，例如让机器理解物理世界、拥有持久记忆并进行有效的推理和规划。

**三、总体框架：**

1.  **问题提出：** 对当前LLM的局限性表示不满。
2.  **研究方向：** 提出更值得关注的AI研究方向（理解物理世界、持久记忆、推理规划）。
3.  **概念辨析：** 区分AGI和AMI，更倾向于AMI的提法。
4.  **未来展望：** 对AMI的短期（3-5年）发展持乐观态度，但对AGI的长期实现持谨慎态度，认为不能简单地依赖扩展LLM。
5.  **现状评估：** 承认LLM在某些领域的能力，但强调整体智能方面仍然存在巨大差距。

**四、Mermaid概念图：**

<Mermaid_Diagram>
graph LR
    subgraph 当前LLM (蓝色)
        A[兴趣降低] --> B(边缘优化);
        A --> C(推理方式简单);
        B --> D{更多数据/算力};
        B --> E{生成合成数据};
    end

    subgraph 更感兴趣的研究方向 (绿色)
        F[理解物理世界] --> G(Jensen Keynote);
        H[持久记忆] --> I(关注度低);
        J[推理与规划] --> K(LLM局限);
    end

    subgraph AGI/AMI (红色)
        L[AGI争议] --> M(人类智能专业化);
        M --> N{misnomer};
        L --> O(AMI替代);
        O --> P(抽象模型学习);
        P --> Q(推理与规划);
        Q --> R(小规模3-5年);
        R --> S(扩展问题);
        S --> T(对AGI怀疑);
        T --> U(重复错误);
    end

    subgraph 现状评估 (黄色)
        V[特定领域能力] --> W(PhD级别);
        X[整体智能] --> Y(差距巨大);
    end

    A --> F;
    A --> H;
    A --> J;
    L --> V;
    L --> X;

    style A fill:#f9f,stroke:#333,stroke-width:2px
    style L fill:#f9f,stroke:#333,stroke-width:2px
    style V fill:#f9f,stroke:#333,stroke-width:2px
    style F fill:#ccf,stroke:#333,stroke-width:2px
</Mermaid_Diagram>

**翻译为简体中文：**

好的，我将根据您提供的文本生成一个符合要求的总结，包括结构化的要点、核心结论、总体框架和一个美观的Mermaid概念图。

**总结：**

**一、核心观点：**

*   **对当前大型语言模型（LLM）的兴趣降低：**
    *   认为LLM主要由行业产品人员改进，侧重于边缘优化，例如增加数据和算力，生成合成数据。
    *   认为LLM的推理方式过于简单。

*   **更感兴趣的研究方向：**
    *   如何让机器理解物理世界。
    *   如何让机器拥有持久记忆。
    *   如何让机器进行推理和规划（认为LLM在这方面存在局限）。

*   **对通用人工智能（AGI）/高级机器智能（AMI）的看法：**
    *   不认同AGI的提法，认为人类智能过于专业化，“通用”一词不准确。
    *   更喜欢“AMI”（高级机器智能）的说法。
    *   认为在3-5年内，小规模的AMI（能够学习抽象模型并进行推理和规划）可能取得进展。
    *   对“扩展LLM就能实现AGI”的观点持怀疑态度，认为那是过去70年里AI研究领域的重复性错误。
    *   认为当前对AGI的预测（例如“数据中心里的天才国度”）是无稽之谈。
    *   承认LLM在特定应用领域会有PhD级别的能力，但在整体智能方面，我们仍然远远落后。

**二、核心结论：**

虽然大型语言模型在某些领域取得了进展，但要实现真正的人工通用智能（AGI）或高级机器智能（AMI），仍然面临诸多挑战，我们需要关注更根本性的问题，例如让机器理解物理世界、拥有持久记忆并进行有效的推理和规划。

**三、总体框架：**

1.  **问题提出：** 对当前LLM的局限性表示不满。
2.  **研究方向：** 提出更值得关注的AI研究方向（理解物理世界、持久记忆、推理规划）。
3.  **概念辨析：** 区分AGI和AMI，更倾向于AMI的提法。
4.  **未来展望：** 对AMI的短期（3-5年）发展持乐观态度，但对AGI的长期实现持谨慎态度，认为不能简单地依赖扩展LLM。
5.  **现状评估：** 承认LLM在某些领域的能力，但强调整体智能方面仍然存在巨大差距。

**四、Mermaid概念图：**

<Mermaid_Diagram>
graph LR
    subgraph 当前LLM (蓝色)
        A[兴趣降低] --> B(边缘优化);
        A --> C(推理方式简单);
        B --> D{更多数据/算力};
        B --> E{生成合成数据};
    end

    subgraph 更感兴趣的研究方向 (绿色)
        F[理解物理世界] --> G(Jensen Keynote);
        H[持久记忆] --> I(关注度低);
        J[推理与规划] --> K(LLM局限);
    end

    subgraph AGI/AMI (红色)
        L[AGI争议] --> M(人类智能专业化);
        M --> N{misnomer};
        L --> O(AMI替代);
        O --> P(抽象模型学习);
        P --> Q(推理与规划);
        Q --> R(小规模3-5年);
        R --> S(扩展问题);
        S --> T(对AGI怀疑);
        T --> U(重复错误);
    end

    subgraph 现状评估 (黄色)
        V[特定领域能力] --> W(PhD级别);
        X[整体智能] --> Y(差距巨大);
    end

    A --> F;
    A --> H;
    A --> J;
    L --> V;
    L --> X;

    style A fill:#f9f,stroke:#333,stroke-width:2px
    style L fill:#f9f,stroke:#333,stroke-width:2px
    style V fill:#f9f,stroke:#333,stroke-width:2px
    style F fill:#ccf,stroke:#333,stroke-width:2px
</Mermaid_Diagram>


Content:
WEBVTT Kind: captions Language: en i'm not so interested in LLMs i'm not so interested in LLMs i'm not so interested in LLMs anymore you know they're kind of the anymore you know they're kind of the anymore you know they're kind of the last thing they are in the hands of you last thing they are in the hands of you last thing they are in the hands of you know industry product people kind of you know industry product people kind of you know industry product people kind of you know improving at the margin uh trying know improving at the margin uh trying know improving at the margin uh trying to get you know more data more compute to get you know more data more compute to get you know more data more compute generating synthetic data um I think generating synthetic data um I think generating synthetic data um I think there are more interesting questions in there are more interesting questions in there are more interesting questions in uh four four things how do you get uh four four things how do you get uh four four things how do you get machines to understand the physical machines to understand the physical machines to understand the physical world and Jensen talked about this this world and Jensen talked about this this world and Jensen talked about this this morning in this keynote how do you get morning in this keynote how do you get morning in this keynote how do you get get them to have persistent memory which get them to have persistent memory which get them to have persistent memory which not too many people talk about and then not too many people talk about and then not too many people talk about and then the last two are how do you get them to the last two are how do you get them to the last two are how do you get them to reason and plan and there is some effort reason and plan and there is some effort reason and plan and there is some effort of course to get you know LLM to reason of course to get you know LLM to reason of course to get you know LLM to reason but in my opinion it's a very kind of but in my opinion it's a very kind of but in my opinion it's a very kind of simplistic way of uh viewing um viewing simplistic way of uh viewing um viewing simplistic way of uh viewing um viewing reasoning i think there are probably reasoning i think there are probably reasoning i think there are probably kind of more you know better way of of kind of more you know better way of of kind of more you know better way of of doing this so um so I'm excited about doing this so um so I'm excited about doing this so um so I'm excited about things that a lot of people in this things that a lot of people in this things that a lot of people in this community in the tech community might community in the tech community might community in the tech community might get excited about five years from now um get excited about five years from now um get excited about five years from now um but right now doesn't look so exciting but right now doesn't look so exciting but right now doesn't look so exciting because it's some obscure academic paper because it's some obscure academic paper because it's some obscure academic paper so so many people are saying that um AGI so so many people are saying that um AGI so so many people are saying that um AGI or I guess you would call it AMI is just or I guess you would call it AMI is just or I guess you would call it AMI is just around the corner um what's your what's around the corner um what's your what's around the corner um what's your what's your view um you know when do you think your view um you know when do you think your view um you know when do you think it will be here why what are the gaps it will be here why what are the gaps it will be here why what are the gaps yeah yeah we I I don't like the term AGI yeah yeah we I I don't like the term AGI yeah yeah we I I don't like the term AGI because uh you know people use the term because uh you know people use the term because uh you know people use the term to designate systems that have human to designate systems that have human to designate systems that have human level intelligence and the sad thing is level intelligence and the sad thing is level intelligence and the sad thing is that human intelligence is super that human intelligence is super that human intelligence is super specialized so calling this general I specialized so calling this general I specialized so calling this general I think is a is a misnomer um so I prefer think is a is a misnomer um so I prefer think is a is a misnomer um so I prefer the phrase AMI that we pronounce AMI the phrase AMI that we pronounce AMI the phrase AMI that we pronounce AMI that means advanced machine intelligence that means advanced machine intelligence that means advanced machine intelligence okay it's just vocabulary um I think the okay it's just vocabulary um I think the okay it's just vocabulary um I think the this concept that I'm I'm describing of this concept that I'm I'm describing of this concept that I'm I'm describing of systems that you know can learn uh systems that you know can learn uh systems that you know can learn uh abstract mental models of the world and abstract mental models of the world and abstract mental models of the world and use them for reasoning and planning i use them for reasoning and planning i use them for reasoning and planning i think we're probably going to have a think we're probably going to have a think we're probably going to have a good handle on getting this to work at good handle on getting this to work at good handle on getting this to work at least at a small scale within three least at a small scale within three least at a small scale within three years three to five years and then it's years three to five years and then it's years three to five years and then it's going to be a matter of you know scaling going to be a matter of you know scaling going to be a matter of you know scaling them up etc um until we get to human them up etc um until we get to human them up etc um until we get to human level AI now here's the thing level AI now here's the thing level AI now here's the thing historically in AI historically in AI historically in AI um there's generation after generation um there's generation after generation um there's generation after generation of AI researchers who have discovered a of AI researchers who have discovered a of AI researchers who have discovered a new paradigm and have claimed that's it new paradigm and have claimed that's it new paradigm and have claimed that's it within 10 years we're going to have or within 10 years we're going to have or within 10 years we're going to have or five years or whatever uh we're going to five years or whatever uh we're going to five years or whatever uh we're going to have human level intelligence we're have human level intelligence we're have human level intelligence we're going to have machines that are smarter going to have machines that are smarter going to have machines that are smarter than humans in in all domains and that's than humans in in all domains and that's than humans in in all domains and that's been the case for 70 years um and it's been the case for 70 years um and it's been the case for 70 years um and it's been those you know those waves every 10 been those you know those waves every 10 been those you know those waves every 10 years or so um the current wave is also years or so um the current wave is also years or so um the current wave is also wrong so the idea that you know you just wrong so the idea that you know you just wrong so the idea that you know you just need to scale scale up LLMs or have them need to scale scale up LLMs or have them need to scale scale up LLMs or have them generate you know thousands of sequences generate you know thousands of sequences generate you know thousands of sequences of tokens and select the good ones to of tokens and select the good ones to of tokens and select the good ones to get to human level intelligence and get to human level intelligence and get to human level intelligence and you're going to have you know within a you're going to have you know within a you're going to have you know within a few years two years I think for some few years two years I think for some few years two years I think for some predictions u a country of geniuses in a predictions u a country of geniuses in a predictions u a country of geniuses in a data center to quote uh someone who will data center to quote uh someone who will data center to quote uh someone who will remain nameless I think it's remain nameless I think it's remain nameless I think it's nonsense it's complete nonsense I mean nonsense it's complete nonsense I mean nonsense it's complete nonsense I mean sure there are going to sure there are going to sure there are going to a lot of applications for which you know a lot of applications for which you know a lot of applications for which you know systems in the near future are going to systems in the near future are going to systems in the near future are going to be you know PhD level if you want but in be you know PhD level if you want but in be you know PhD level if you want but in terms of you know overall uh terms of you know overall uh terms of you know overall uh intelligence no we're still very far intelligence no we're still very far intelligence no we're still very far from it I mean you know when I say very from it I mean you know when I say very from it I mean you know when I say very far it might happen within a decade or
