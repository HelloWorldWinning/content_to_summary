Timestamp: 2025-04-12T22:24:17.264934
Title: AI 周报 Llama 4 翻车始末；有人用 GPT 攻破 80000 网站 swPHY-N_PQA
URL: https://youtu.be/swPHY-N_PQA?si=lqazM3ewko7QJ4ie
Status: success
Duration: 11:30

Description:
好的，这是根据您提供的文本生成的摘要：

**核心要点：**

尽管AI在特定任务和效率方面取得了显著进展，但在复杂逻辑推理、长期任务处理以及高风险应用场景中的可靠性方面仍存在挑战，需要进一步提升。

**总体框架：**

本期AI周报主要围绕以下几个方面展开：

1.  **Meta Llama 3 事件：** Llama 3的发布与争议，包括跑分作弊嫌疑、模型性能评估以及开源协议的限制。
2.  **AI 垃圾邮件攻击：** 分析了利用 GPT-4o Mini 大规模发送定制垃圾邮件的案例，强调了信息判断能力的重要性。
3.  **谷歌 Cloud Next 大会：** 介绍了谷歌在 AI 硬件（TPU v7）、软件（Gemini 1.5 Pro）、开放协议（MCP & A2A）等方面的更新。
4.  **斯坦福 AI 指数报告：** 总结了报告中的关键发现，包括 AI 在性能、成本、企业应用等方面的进展，以及在长期任务和复杂推理方面的局限性。

**详细摘要：**

I. **Meta Llama 3 的发布与争议**

*   Meta 发布 Llama 3，包含小号 (SCOD) 和中号 (Maric) 模型，以及正在开发的大号模型。
*   Llama 3 采用混合专家模型架构。
*   发布后不久，Llama 3 被质疑在 LM排行榜上跑分作弊。
*   Meta 紧急回应，否认在测试集上训练，并解释了不同服务商部署可能导致性能差异。
*   LM回应并公开测试数据，指出 Meta 提交的是定制优化版本，并更新排行榜政策以提高透明度。
*   Llama 3 中端模型 Maric 在代码编写准确率方面表现不佳，但在其他基准测试中表现尚可。
*   Llama 3 的开源协议仍然严格，模型参数较大，难以本地部署。

II. **AI 垃圾邮件攻击**

*   安全公司发现 Akerabot 自动化框架利用 GPT-4o Mini 发送定制垃圾邮件。
*   Akerabot 通过 Passen 脚本和 OpenAI API 为每个目标网站生成独特的营销信息。
*   这些消息通过网站联系表单和实时聊天窗口发送，难以被垃圾邮件过滤器拦截。
*   OpenAI 确认此行为违反服务条款并封禁了相关账户。
*   强调了在 AI 时代，信息接收者需要具备足够的判断能力，区分营销信息和事实。

III. **谷歌 Cloud Next 大会**

*   谷歌发布第七代 TPU 处理器 Axion，专为 AI 模型打造，强化了模型推理能力。
*   谷歌支持 MCP 协议，并推出了更大的开源协议 Agent to Agent (A2A)，使不同 AI Agent 能够协同完成复杂任务。
*   谷歌发布 Gemini 1.5 Pro，具备思考能力，更注重速度和性价比。
*   谷歌开放 Wealth 2 视频生成模型的 API。

IV. **斯坦福 AI 指数报告**

*   AI 在性能方面取得了显著进展，但在视频生成等特定领域甚至超越了人类专家。
*   小模型也在飞速进步，成本大幅下降。
*   采用 AI 的企业比例显著增加。
*   AI 在难度高、负责任的长期任务方面仍然存在挑战。
*   AI 的计算能力与逻辑能力之间差距仍然是一个技术瓶颈。

<Mermaid_Diagram>
```mermaid
graph LR
subgraph Meta Llama 3
    A[发布: Llama 3] --> B(争议: 跑分作弊);
    B --> C{Meta 回应};
    C -- 否认测试集训练 --> D(性能差异解释);
    C -- 定制版本 --> E[LM 回应];
    E --> F(排行榜政策更新);
    A --> G(模型评估);
    G --> H{Maric 性能};
    H -- 代码准确率低 --> I(其他测试尚可);
    A --> J(开源协议);
    J --> K{协议严格, 部署难};
    style A fill:#f9f,stroke:#333,stroke-width:2px
    style B fill:#ccf,stroke:#333,stroke-width:2px
    style C fill:#ccf,stroke:#333,stroke-width:2px
    style D fill:#fff,stroke:#333,stroke-width:1px
    style E fill:#fff,stroke:#333,stroke-width:1px
    style F fill:#fff,stroke:#333,stroke-width:1px
    style G fill:#ccf,stroke:#333,stroke-width:2px
    style H fill:#fff,stroke:#333,stroke-width:1px
    style I fill:#fff,stroke:#333,stroke-width:1px
    style J fill:#ccf,stroke:#333,stroke-width:2px
    style K fill:#fff,stroke:#333,stroke-width:1px
end

subgraph AI 垃圾邮件攻击
    L[攻击: Akerabot] --> M(手段: GPT-4o Mini);
    M --> N(定制垃圾邮件);
    N --> O(绕过过滤器);
    L --> P{OpenAI 处理};
    P --> Q(封禁账户);
    L --> R(信息判断重要性);
    style L fill:#f9f,stroke:#333,stroke-width:2px
    style M fill:#ccf,stroke:#333,stroke-width:2px
    style N fill:#fff,stroke:#333,stroke-width:1px
    style O fill:#fff,stroke:#333,stroke-width:1px
     style P fill:#ccf,stroke:#333,stroke-width:2px
    style Q fill:#fff,stroke:#333,stroke-width:1px
    style R fill:#fff,stroke:#333,stroke-width:1px
end

subgraph 谷歌 Cloud Next
    S[大会: Cloud Next] --> T(硬件: TPU v7);
    S --> U(软件: Gemini 1.5 Pro);
    S --> V(协议: MCP & A2A);
        style S fill:#f9f,stroke:#333,stroke-width:2px
    style T fill:#ccf,stroke:#333,stroke-width:2px
    style U fill:#ccf,stroke:#333,stroke-width:2px
    style V fill:#ccf,stroke:#333,stroke-width:2px
end

subgraph 斯坦福 AI 指数报告
    W[报告: AI 指数] --> X(性能提升);
    W --> Y(成本下降);
    W --> Z(企业应用增加);
    W --> AA(长期任务挑战);
    W --> BB(逻辑推理瓶颈);
    style W fill:#f9f,stroke:#333,stroke-width:2px
    style X fill:#ccf,stroke:#333,stroke-width:2px
    style Y fill:#ccf,stroke:#333,stroke-width:2px
    style Z fill:#ccf,stroke:#333,stroke-width:2px
    style AA fill:#ccf,stroke:#333,stroke-width:2px
    style BB fill:#ccf,stroke:#333,stroke-width:2px
end
```
</Mermaid_Diagram>


Content:
欢迎来到第二期的AI周报做这个节目的目的就是为了筛选一些真正有趣或是有意义的AI新闻让大家也让我自己不用每天盯着AI的更新动态也能轻松掌握关键信息本期的AI周报时间范围是4月5号到4月11号我会讲到一下内容Mata从忙发布的LAMA4为什么差点砸了自己的招牌有人利用GPT-CO mini批量发送定制有限攻破了8万个网站谷歌这周举行了Cloud Next大会更新了不少AI相关的产品在研究报告方面斯坦福发布了2025年AI主书报告下面让我们开始今天的内容Mata公司的LAMA4在4月5号周六发布这个系列的模型上线了两款小号产品SCOD中号产品也就是主力模型Maric还有一款最先进的模型号称是2000避练的残数仍然在开发当中LAMA4采用了一前代LAMA2 LAMA3不同的策略转向了更大更稀书的混合专家模型而并不是像以前一样提供多个尺寸的小模型简单介绍下残数LAMA4SCOD17避练的活跃残数109避练的总残数16个专家网络定位类似于JMNetflix这个模型还打出了一个1000万上下软的窗口的血头LAMA4Maric同样是17避练的活跃残数400避练的总残数128个专家网络100万抽坑的上下软作为曾经的开源一颗大家自然很兴奋可兴奋还没超过一天就被发现LAMA4模型在LM而Weena也就是人类晋级场上跑分作弊各种小道消息也开始传播有的说员工部院属名有的说开发团队的领导因故辞职还有消息说LAMA4使用了测试训练级来训练模型总之是各种争议满天飞4月8号官方紧急屁说自己绝不会在测试级上训练同时也解释了一下为什么不同人使用时觉得质量有高有低是因为模型发布的太快了不同服务商的部署硬件不一样软件参数的调整不一样可能产生性能的波动这两点确实是实话这个时间点了没有什么公司再去为了跑分在测试的数据级上训练模型还有就是不同营服务商的部署再初期确实可能产生质量不一致的问题但是引爆大家不满的是Mata为了刷榜LM而Weena用了一个特别的聊天版本但你说它作弊吧在官方的发布业面里它自己写出来了这是个特别的版本所以我真的没搞明白这是图傻这个特定版本的模型回答用户问题是回答内容会特别长而且与其特别激动Mata这样敢直接搞得所有用户连LM而Weena也一同喷击说这个绑胆没啥作用同样是4月8号LM而Weena做出了回应他们公开了2000多份数据包括用户的提示模型的回答以及对应的用户偏好选择来解释为什么Marek可能在排行榜上排到第二我在上视频介绍过LM而Weena也就是人类聊天经济场是一个主观测试平台用户会再不知道模型身份的情况下忙测两个模型的回答从主观感受触发选择自己更喜欢的那一个平台则击于这些投票结果和算法深层最终的排名LM而Weena的这个回应主要是为了自震清版再节尾他们明确指出Mata在提交他们的定制模型参与平测试没有清楚说明这是一个专门优化用户偏好的定制化实验模型因此为了避免类似情况再次发生LM而Weena也会更新绑胆的相关政策进一步提升模型的透明度和公开性其实在LM而Weena的这个官网上有个分格控制的选项点击后排行榜就会指测众模型的回答耻量而不是模型的分格我们会发现指测众耻量是Mata会排名第五我们现在直接看一下LM而Weena放出的测试结果各个语言的都有我们来看看中文里选择Mata的这个结果第一个是对比Lama 3.370B鞋偏8500字座位后者直接拉满了我数了下算上标点是5900了这个确实可以选后者胜处但是如果是创作一首诗就会发现后者不像是一首诗而且它的解释又臭又长如果回答一个简单的数学问题9.1和9.9谁大那就更没法看Mata的直接开始解释小数是什么为什么人类会搞错可以发现和任何模型对比Mata的定制版本确实是回答特别戏特别长但不能说明LM而Weena的这个平台测试没法看首先它有消除分额影响的选项其次它本来就是一个主观测试不是静态测试并不是排名第一模型就是世界最强模型那么Lama4的中端模型Marrake是不是真的很烂了在BAMR测试上有用户在Ider这个击准测试里Marrake修改代码的准确率测出来只有16%远低于DipCQ3的48%但也有用户测试了BacodeBanch在这个击准的两套试题里结果显示Marrake没那么糟糕另一个平台RTF所Nelisys也更新了他们测试团队成功负现了Mata公布的部分测试分数也就是MLU Pro和GPUA的MEN这次测试的是公开版本也就是Hacking Face上的版本并在他们的官网上更新了相关模型的智能指数得分Marrake综合表现微微落后于DipCQ32024微一的亮点是Marrake的结构规模更简洁参数亮约为DipSync的一半总参数亮则为DipSync的60%但是没那么糟糕微微落后对于一个不差钱不差人才不差企皮欧而且是后发布的产品来说就是一场失败开发者期待的是一个更强的小模型能部署到本地上但是喇嘛斯的最小版本SCODE有109B链的参数即使亮化后也没法部署在大多数消费机的GPU上同时它的开源限制没有像DipSync的那样宽松喇嘛斯也用喇嘛系列较为严格的许可协议要求鼠名品牌漏出限制用途相比之下DipSyncV3采用了更宽松的MIT协议总结下Mata这次的发布很仓促实实在LM Reignat上作弊了放出了一个特别的版本去跑分我不明白这是土啥从性能来看Mata的中端模型Marric落后DipSyncV3但是不多Mata的开源协议依旧严格而且模型参数过大很难部署在本地在竞争越发激烈的情况下喇嘛斯不仅没能在开源领域领先含滋坏口味失望过后大家都在期待马上要发布的前文山4月9日安全公司Santhanolabse发布了一篇文章曝光了一个利用ChatGPT生成垃圾油件的活动一个名为Akerabot的自动化框架在短短4个月内利用OpenI的API具体调用了GPT4O Mini这个模型成功的像超过8万个网站发送了垃圾油件而且没有被垃圾油件顾虑器发现它发送这些垃圾油件给网站的负责人或是管理者是为了推广自己的SEO的服务具体是怎么做到的呢报告详细描述了Akerabot的运作机制它通过Passen脚本轮换用于推广SEO服务的遇名并通过调用OpenI的API为每个目标网站深层独特的营销信息这些消息不仅包含网站的名称很减述了其服务看上去就像是良声定制由于内容的独特性这些消息通过网站的联系表单和实施聊天窗口发送传统的过例器难以拦解通过分析Akerabot依留在服务器上的日质文件安全公司Santhanlapse发现了这些活动并将想请报告给了OpenAIOpenAI确认此行为违反了其服务条款直接分了这个账户这个活动进行了四个月才被发现可以想象AI时代骗过各种检测系统骗过人类其实很容易为啥说到这个行为呢因为我发现总有人担心未来会是一个满事AI为我们定制内容的世界其实我并不教训这一点想想看我们早已生活在一个由算法和海量信息构成的警官世界里无论是各种营销化树还是算法推送的广告或者是社交媒体上夸张的内容我们每天都在被动或者主动的接受大量的经过定制和优化的信息垃圾信息的制造者是人还是AI区别不大目的都是为了渗透我们的注意力最终影响我们相信什么不相信什么从而影响我们的决策如果不考虑目的单论内容的深层指量当前的AI水平已经超过许多人类了所以问题的核心不在于AI正在制造更多垃圾而在于我们作为信息的接手端是否具备足够的判断能力我们是没法指望平台把我们过虑信息的最终的评仗始终是我们自己的大脑在AI时代信息红流指挥更加个性化更加有吸引力面对这种情况我们需要问问自己如何判断信息来源的可靠信息如何实际哪些内容是营销哪些是事实如何在海量信息中筛选出真正对自己有价值的内容说到底每天选择看什么就和一日三餐吃什么一样重要Eternation is all you need本周谷歌可谓是干货满满在Cloud Next开幕演讲上谷歌带来了一系列重棒的AI更新首先是硬件方面谷歌发布了第七代TPO处理器案物的这款专门为DM太模型打造的处理器特别强化了模型推理的能力单个泡的集群上集成超过9000颗芯片分支算力高达42.5xfloss在周三DFM的CIO宣布了谷歌将支持MCP协议在支持MCP协议的同时谷歌还顺时推出了更大的开源协议Agent to Agent如果说MCP是解决单个代理如何调用不同工具的表扔那么A2A就更进一步它让不同厂商不同框架开发的AI agent能够互相发现了解对方的能力并邪统完成复杂任务除了协议本身谷歌还配套推出了智能体开发套件模型方面谷歌也没显着DM2.5floss也准备好了继承了Pro的思考能力但更注重速度和性价比谷歌未来的目标是让所有的DM模型都具备思考能力此外谷歌还开放了Wealth 2视频深层模型的API目前它能深层720P分辨率24整最长8秒的视频片段定价为每秒0.35美元可以看到谷歌正在全力投锐A案并且也是能力最全面的一家能造极数设施能研发芯片能研发模型还有众多陈属的应用斯坦福大学人类中心AI研究院发布了2025AI指数报告也是每年必看的一个报告过去一年AI的进步可以说是突飞稳进在MMU,GPQA等标准测试中AI的表现提升最高可以达到67%在视频深层但卖边鞋等特定领域有些AI系统甚至已经超越了人类专家同时小模型也在飞速进步比如微软的Fascade Mini即用3.8B量的残数就达到了当年GPT3.5的水平相比2022年的主流模型小了整整142倍陈敏方面也是飞速下降要知道2022年时达到GPT3.5水平的模型处理百万Tocons要花费月20美元而现在呢只需要0.07美元就够了这样达280倍这样的陈敏下降普及了AI技术目前采用AI的企业比例也从33%门增到71%不过AI现在还有最后一个保联需要功课那就是难度高负责任的长期任务别笨持测试结果显示在短期任务中AI系统的效率能达到人类专家的四倍但一旦遇到长期任务人类就能后来局上在代码边鞋的特定任务中AI虽然能与人类打平甚至更快但要说到任务的持续性和处理复达前景的能力还是明显不足的AI的计算能力与逻辑能力之间差距仍然是一个技术平景大爷模型在处理数学推理规划等需要负杂逻辑的任务时表现还不够理想而在医疗诊断这样高风险的场景中AI的推理能力还需要进一步提升才能让人放心使用好了以上就是本期的AI科技周报了希望能在评论区听到你的建议帮助我不断改进这个节目我们下个星期再见
