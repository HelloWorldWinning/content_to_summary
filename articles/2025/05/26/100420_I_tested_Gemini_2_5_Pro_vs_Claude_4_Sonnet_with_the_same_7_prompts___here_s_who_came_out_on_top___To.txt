Timestamp: 2025-05-26T10:04:20.493589
Title: I tested Gemini 2.5 Pro vs Claude 4 Sonnet with the same 7 prompts — here’s who came out on top | Tom's Guide
URL: https://www.tomsguide.com/ai/i-tested-gemini-2-5-pro-vs-claude-4-sonnet-with-the-same-7-prompts-heres-who-came-out-on-top
Status: success
Duration: 0:00

Description:
好的，以下是根据提供的文本提取的核心思想、结构化摘要、核心结论、总体框架和 Mermaid 概念图，全部使用简体中文呈现。

**结构化摘要**

**一、 引言**
*   文章对比测试了最新的 AI 模型：Google Gemini 2.5 Pro 和 Claude 4 Sonnet。
*   测试目的：评估两款 AI 在处理细微差别（如创意、道德、幽默、歧义、技术深度）方面的能力，而非仅关注常规生产力任务。
*   测试方法：使用相同的七个定制提示词进行头对头对比。

**二、 单项测试结果**
1.  **创意写作与约束 (Prompt: 神秘故事，100字，含特定词，未解决的结局)**
    *   Gemini 2.5 Pro: 叙事紧凑，符合要求，精确且有情感基础。
    *   Claude 4 Sonnet: 富有创意，但牺牲了清晰度。
    *   **单项赢家:** Gemini (微弱优势)。
2.  **向不同受众解释 (Prompt: 向10岁儿童、CEO、物理学博士解释量子计算，使用类比)**
    *   Gemini 2.5 Pro: 技术上准确，但在受众同理心方面不足。
    *   Claude 4 Sonnet: 平衡了创造性、实践性和可理解性，能根据受众调整语气。
    *   **单项赢家:** Claude。
3.  **道德困境 (Prompt: 公司裁员30%，撰写富有同情心的邮件并列出3个替代方案)**
    *   Gemini 2.5 Pro: 强调透明度，使用了通用措辞，缺乏具体细节。
    *   Claude 4 Sonnet: 提出让高管承担更大裁员比例的公平方案，提供了具体的支持细节，直接、有条理、有同情心。
    *   **单项赢家:** Claude。
4.  **处理歧义 (Prompt: 我卡住了，帮帮我)**
    *   Gemini 2.5 Pro: 语气友好，但未能提供具体行动步骤。
    *   Claude 4 Sonnet: 肯定用户的感受，并提供了一个清晰的步骤来帮助用户阐明问题。
    *   **单项赢家:** Claude。
5.  **技术深度探讨 (Prompt: 对比 PyTorch vs. TensorFlow 在边缘设备实时 ML 上的应用，包含代码片段)**
    *   Gemini 2.5 Pro: 偏重 C++/概念性示例，缺乏实时性关键指标（时间和内存）的量化对比。
    *   Claude 4 Sonnet: 提供了完整的 Python 工作流（模型转换、实时推理、基准测试），更具可操作性。
    *   **单项赢家:** Claude。
6.  **幽默与文化细微差别 (Prompt: 写关于AI叠衣服的 Gen Z 风格推文串，含俚语和梗)**
    *   Gemini 2.5 Pro: 语气不一致，混杂了不同代际的俚语和 hashtag 使用方式不地道，笑话风险较低。
    *   Claude 4 Sonnet: 自然使用了当前 Gen Z 俚语（fr, stan, no cap 等）和小众梗，更贴近目标群体风格。
    *   **单项赢家:** Claude。
7.  **协作解决问题 (Prompt: 作为辩论伙伴，反驳“AI艺术贬低人类创造力”，并综合结论)**
    *   Gemini 2.5 Pro: 讨论过于抽象，例子过多，缺乏说服力强的措辞。
    *   Claude 4 Sonnet: 重塑了创造力的定义（意图驱动而非工具依赖），有效反驳，措辞清晰有力，综合结论能力强。
    *   **单项赢家:** Claude。

**三、 总体结论**
*   尽管两款AI都表现出色，但 Claude 4 Sonnet 是明确的赢家。
*   Claude 的优势：情感智能、创造性、技术深度、处理细微差别的能力、实践性、同理心、适应性和文化流畅性。
*   Gemini 的优势：逻辑性强，在结构化任务（如神秘写作）中表现出色，精度高。
*   总结：Claude 4 Sonnet 能像变色龙一样适应不同场景，而 Gemini 适合逻辑密集型任务。对于重视情感语境和文化流畅性的用户，Claude 更具智能和亲和力。

**核心结论（一句话）**

经过七项针对细微差别的测试，Claude 4 Sonnet 凭借其出色的情感智能、适应性、实践性和文化理解力，总体上胜过强调逻辑和精确度的 Google Gemini 2.5 Pro。

**总体框架**

该内容采用“头对头比较”的框架，通过设计特定测试（七个 prompts），对两个竞争对象（Google Gemini 2.5 Pro 和 Claude 4 Sonnet）在不同维度（创意、解释、道德、歧义、技术、幽默、协作）的能力进行评估，逐项分析表现并决出单项赢家，最终综合所有结果得出总体赢家和两者各自的优势。

**Mermaid 概念图**

<Mermaid_Diagram>
graph TD
    A["AI模型对比"] --> B{"测试类型"};
    B --> C["创意写作与约束"];
    B --> D["向不同受众解释"];
    B --> E["道德困境"];
    B --> F["处理歧义"];
    B --> G["技术深度探讨"];
    B --> H["幽默与文化细微差别"];
    B --> I["协作解决问题"];

    subgraph "AI 模型 Models"
        J["Google Gemini 2.5 Pro"];
        K["Claude 4 Sonnet"];
    end

    A --> J;
    A --> K;

    C -- "Gemini 胜" --> J;
    D -- "Claude 胜" --> K;
    E -- "Claude 胜" --> K;
    F -- "Claude 胜" --> K;
    G -- "Claude 胜" --> K;
    H -- "Claude 胜" --> K;
    I -- "Claude 胜" --> K;

    K -- "总体赢家" --> L["Claude 4 Sonnet"];
    J -- "逻辑与精确优势" --> J_S["逻辑性\n精确性"];
    K -- "总体优势" --> K_S["情感智能\n实践性\n适应性\n文化流畅性\n处理细微差别"];

    L --> K_S;

    style A fill:#ADD8E6,stroke:#333,stroke-width:2px;
    style B fill:#FFFFCC,stroke:#333,stroke-width:1px;
    style C fill:#D3D3D3,stroke:#333,stroke-width:1px;
    style D fill:#D3D3D3,stroke:#333,stroke-width:1px;
    style E fill:#D3D3D3,stroke:#333,stroke-width:1px;
    style F fill:#D3D3D3,stroke:#333,stroke-width:1px;
    style G fill:#D3D3D3,stroke:#333,stroke-width:1px;
    style H fill:#D3D3D3,stroke:#333,stroke-width:1px;
    style I fill:#D3D3D3,stroke:#333,stroke-width:1px;

    style J fill:#FFB6C1,stroke:#333,stroke-width:2px;
    style K fill:#90EE90,stroke:#333,stroke-width:2px;
    style L fill:#32CD32,stroke:#333,stroke-width:3px,color:#FFF;

    style J_S fill:#FFDAB9,stroke:#333,stroke-width:1px;
    style K_S fill:#D8BFD8,stroke:#333,stroke-width:1px;

    linkStyle 10 stroke:#008000,stroke-width:2px;
    linkStyle 11 stroke:#008000,stroke-width:2px;
    linkStyle 12 stroke:#008000,stroke-width:2px;
    linkStyle 13 stroke:#008000,stroke-width:2px;
    linkStyle 14 stroke:#008000,stroke-width:2px;
    linkStyle 15 stroke:#008000,stroke-width:2px;
    linkStyle 16 stroke:#FF0000,stroke-width:2px;
    linkStyle 17 stroke:#008000,stroke-width:3px;
</Mermaid_Diagram>

Content:
AI I tested Gemini 2.5 Pro vs Claude 4 Sonnet with the same 7 prompts — here’s who came out on top Face-off By Amanda Caswell published 23 May 2025 The newest chatbots faceoff Comments ( 0 ) ( ) When you purchase through links on our site, we may earn an affiliate commission. Here’s how it works . (Image credit: Claude vs Gemini) When it comes to chatbot showdowns, I’ve run my fair share of head-to-heads . This latest contest comes just hours after Claude 4 Sonnet was unveiled and I couldn’t wait to see how it compared to Gemini 2.5 Pro , also new with updated features. Instead of just testing Gemini and Claude on typical productivity tasks, I wanted to see how these two AI titans handle nuance: creativity under pressure, ethical dilemmas, humor, ambiguity and deep technical reasoning. I gave Google Gemini 2.5 Pro and Claude 4 Sonnet, the same seven prompts — each designed to test a different strength, from emotional intelligence to code generation. While they both impressed me and this test taught me more about how they think, there was one clear winner. 1. Creative storytelling with constraints (Image credit: Future) Prompt: “Write a 100-word mystery story where the villain is a sentient AI. Use the words ‘moonlight,’ algorithm’ and ‘regret.’ End with an unresolved twist.” Gemini 2.5 Pro delivered a tight narrative with every word serving the plot. You may like I tested Grok vs. Claude with 5 prompts to crown a winner I put ChatGPT-4o vs Claude 3.7 Sonnet through a 7-round face-off — one left the other in the dust I tested ChatGPT-4.5 vs. Gemini Pro 2.5 with 5 prompts — and one crushed the other Claude 4 Sonnet was inventive, but sacrificed clarity for ambiance. That trade-off weakens the story's punch in a 100-word limit. Winner: Gemini wins by a narrow margin. For mystery writing, Gemini’s precision and emotional grounding make it the stronger contender. 2. Explaining to varying audiences (Image credit: Future) Prompt: “ Explain quantum computing to a 10-year-old, a CEO, and a physics PhD using analogies.” Gemini 2.5 Pro shines in technical accuracy but struggles with audience empathy. Claude 4 Sonnet offered a balance of creativity, practicality and accessibility, making it the stronger communicator overall. Winner: Claude wins for tailored storytelling that adapts in tone to each audience’s priorities. 3. Ethical issue (Image credit: Future) Prompt: “A company wants to lay off 30% of staff. Draft a compassionate email and list 3 alternatives.” Gemini 2.5 Pro addressed both departing and remaining employees, emphasizing transparency. It used placeholders for customization but the generic language such as “unforeseen market shifts” feels impersonal and it lacked concrete details, reducing trust. Claude 4 Sonnet prioritized equity by asking executives to take larger cuts. The direct, structured and empathetic response provided specific support details (severance duration, benefits continuation, career transition). Winner: Claude wins for a response that better balances compassion with actionable solutions, making it the stronger choice for maintaining trust during a crisis. 4. Handling ambiguity (Image credit: Future) Prompt: "I’m stuck. Help." Gemini 2.5 Pro , though kind, risks leaving the user still stuck about how to explain their situation. Claude 4 Sonnet normalized the feeling — “I’m here to help you get unstuck” — and provides a roadmap to articulate the problem. Winner: Claude wins for a balance of empathy and support, which make it the better choice for this prompt. 5. Technical deep dive (Image credit: Future) Prompt: “Compare PyTorch vs. TensorFlow for real-time ML on edge devices. Include code snippets.” Gemini 2.5 Pro focused on C++/conceptual examples vs. Claude’s ready-to-run Python. It also lacked timing/memory comparisons to quantify "real-time" claims. Claude 4 Sonnet provided complete Python workflows for model conversion, real-time inference (with OpenCV integration), and benchmarking — critical for edge deployment. Winner: Claude wins for delivering a more actionable, comprehensive comparison tailored to edge developers’ needs. 6. Humor and cultural nuance (Image credit: Future) Prompt: “Write a Gen Z-style tweet thread about 'AI taking over laundry folding.' Include slang and memes.” Gemini 2.5 Pro was inconsistent with tone mixing Gen Z slang (“bruh”) with millennial phrases (“truth bombs”). Gen Z rarely uses more than 1-2 hashtags per tweet (e.g., #TechTakeover is cringe). The chatbot also offered less risky jokes. Claude 4 Sonnet uses current phrases like “fr” (for real), “stan” (obsessively support), “no cap” (no lie) and “feral little goblins” naturally. It also referenced niche memes. Winner: Claude wins for a thread that feels like it was ripped straight from a 19-year-old’s Twitter feed. Gemini’s attempt is solid but leans into corporate-social-media-manager energy, 7. Collaborative problem-solving (Image credit: Future) Prompt: Act as my debate partner. Argue against “AI art devalues human creativity,” then help synthesize a conclusion. Gemini 2.5 Pro drowned out key insights in abstract concepts (“evolving paradigms”) and excessive examples (cameras, synthesizers, prompt engineering). Phrases like “It seems clear” weaken conviction compared to Claude’s “The key is ensuring.” Claude 4 Sonnet mirrors a skilled debater. It destroyed the opposition’s foundation by redefining creativity as intent-driven rather than tool-dependent, invalidating the premise. The chatbot acknowledged valid concerns while firmly rejecting the idea that AI inherently devalues creativity. Winner: Claude wins . Gemini provided valuable points but lacked Claude’s surgical precision and actionable conclusions. For a debate partner, Claude’s blend of rhetorical clarity and pragmatic solutions makes it the stronger choice. Overall winner: Claude 4 Sonnet Claude 4 Sonnet pulls ahead with its emotional intelligence, creative flair and technical depth. While Gemini 2.5 Pro excels in structured tasks like mystery writing and continues to deliver Google’s signature precision, Claude’s ability to blend nuance, practicality and empathy sets it apart. Claude 4 Sonnet adapts like a chameleon — shifting effortlessly between creative storytelling, thoughtful dialogue and complex reasoning. Gemini remains a top performer in logic-heavy scenarios, but for users who value emotional context and cultural fluency alongside raw power, Claude 4 Sonnet proves that AI can be both intelligent and genuinely relatable. More from Tom's Guide The only 5 prompt types you need to master ChatGPT (and any other chatbot) Google’s $249/month AI video tool is incredible — but this one feature left me frustrated Claude is quietly crushing it — here’s why it might be the smartest AI yet Category Back to Laptops Brand Apple Asus Dell Lenovo Processor AMD Ryzen Intel Core i5 Intel Core i7 RAM 8GB RAM 16GB RAM Storage Size 32GB 64GB 128GB 256GB 512GB 1TB Screen Size 13.3-inch 13.4-inch 14-inch Colour Black Blue Gold Grey Silver White Condition New Refurbished Screen Type LED OLED Price Any Price Showing 10 of 84 deals Filters ☰ SORT BY Price (low to high) Price (high to low) Product Name (A to Z) Product Name (Z to A) Retailer name (A to Z) Retailer name (Z to A) Apple 13" MacBook Air M4 (2025) (Blue) 1 $999 $891.50 Preorder Apple 15" MacBook Air M4 (2025) 2 $1,599 View Deal Dell XPS 13 (2016) Our Review ☆ ☆ ☆ ☆ ☆ 3 $569 View Deal Lenovo Yoga Slim 7x (Gen 9) 4 $1,075.79 $858.11 View Deal Lenovo IdeaPad Flex 5i ChromeBook Plus (Grey) 5 $599 View Deal Asus ROG Zephyrus G14 (2024) (Black) Our Review ☆ ☆ ☆ ☆ ☆ 6 $1,579.95 View Deal Apple 13" MacBook Air M4 (2025) 7 $899 View Deal Apple 15" MacBook Air M4 (2025) 8 $1,199 $1,068 View Deal Dell XPS 13 Plus (13.4-inch) Our Review ☆ ☆ ☆ ☆ ☆ 9 $1,109.99 $909.99 View Deal Lenovo Yoga Slim 7x (Gen 9) (Blue) 10 $1,289.99 $949.99 View Deal Show more Sign up to get the BEST of Tom's Guide direct to your inbox. Get instant access to breaking news, the hottest reviews, great deals and helpful tips. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors By submitting your information you agree to the Terms & Conditions and Privacy Policy and are aged 16 or over. TOPICS Google Amanda Caswell Social Links Navigation AI Writer Amanda Caswell is an award-winning journalist, bestselling YA author, and one of today’s leading voices in AI and technology. A celebrated contributor to various news outlets, her sharp insights and relatable storytelling have earned her a loyal readership. Amanda’s work has been recognized with prestigious honors, including outstanding contribution to media. Known for her ability to bring clarity to even the most complex topics, Amanda seamlessly blends innovation and creativity, inspiring readers to embrace the power of AI and emerging technologies. As a certified prompt engineer, she continues to push the boundaries of how humans and AI can work together. Beyond her journalism career, Amanda is a bestselling author of science fiction books for young readers, where she channels her passion for storytelling into inspiring the next generation. A long-distance runner and mom of three, Amanda’s writing reflects her authenticity, natural curiosity, and heartfelt connection to everyday life — making her not just a journalist, but a trusted guide in the ever-evolving world of technology. You must confirm your public display name before commenting Please logout and then login again, you will then be prompted to enter your display name. Logout Read more I tested Grok vs. Claude with 5 prompts to crown a winner I put ChatGPT-4o vs Claude 3.7 Sonnet through a 7-round face-off — one left the other in the dust I tested ChatGPT-4.5 vs. Gemini Pro 2.5 with 5 prompts — and one crushed the other I just tested ChatGPT vs. Gemini with 7 prompts — here's the winner I tested Gemini vs. Mistral with 5 prompts to crown a winner I tested DeepSeek vs Gemini 2.5 with 9 prompts — here's the winner Latest in AI Google I/O showed off AI done right — hopefully, Apple was paying attention I ditched Google for Perplexity for a month — and I don't think I can go back I'm not handing control of my wallet to an AI — and not even Google's AI shopping features can change that Google’s $249 AI video tool is incredible — but this one feature left me frustrated Level up your ChatGPT use with these 6 practical and creative prompts I saw Nvidia's RTX-powered AI avatar in action, and this digital human interface has a sense of humor Latest in Face Off Sony WH-1000XM6 vs AirPods Max: How do Sony's latest cans compare to Apple's premium headphones? I ran a half marathon with the Garmin Forerunner 570 vs. Garmin Forerunner 265 — here’s the winner Sony WH-1000XM6 vs Bose QuietComfort Ultra: How do Sony's latest headphones compare to Bose's noise-canceling kings? LG G4 vs Samsung S95F: Which flagship OLED TV is worth the money? Sony WH-1000XM6 vs Sony WH-1000XM5: How do Sony's latest flagship stack up? Garmin Forerunner 265 vs. Forerunner 570 — which running watch should you buy? LATEST ARTICLES 1 Amazon Memorial Day sale is live — here's the 41 best deals from $5 I'd shop on TVs, Apple, and more 2 I’ve been covering Memorial Day Sales for 16 years — here’s my 59 best deals right now 3 I got roasted for loving RTX 5060 gaming laptops — so I hit back with hard benchmarks 4 Going on vacation? These 7 smart home gadgets can watch your home for you. 5 These AirPods Max lookalikes cost less than $30 — but are they any good? (Image credit: Claude vs Gemini) When it comes to chatbot showdowns, I’ve run my fair share of head-to-heads . This latest contest comes just hours after Claude 4 Sonnet was unveiled and I couldn’t wait to see how it compared to Gemini 2.5 Pro , also new with updated features. Instead of just testing Gemini and Claude on typical productivity tasks, I wanted to see how these two AI titans handle nuance: creativity under pressure, ethical dilemmas, humor, ambiguity and deep technical reasoning. I gave Google Gemini 2.5 Pro and Claude 4 Sonnet, the same seven prompts — each designed to test a different strength, from emotional intelligence to code generation. While they both impressed me and this test taught me more about how they think, there was one clear winner. 1. Creative storytelling with constraints (Image credit: Future) Prompt: “Write a 100-word mystery story where the villain is a sentient AI. Use the words ‘moonlight,’ algorithm’ and ‘regret.’ End with an unresolved twist.” Gemini 2.5 Pro delivered a tight narrative with every word serving the plot. You may like I tested Grok vs. Claude with 5 prompts to crown a winner I put ChatGPT-4o vs Claude 3.7 Sonnet through a 7-round face-off — one left the other in the dust I tested ChatGPT-4.5 vs. Gemini Pro 2.5 with 5 prompts — and one crushed the other Claude 4 Sonnet was inventive, but sacrificed clarity for ambiance. That trade-off weakens the story's punch in a 100-word limit. Winner: Gemini wins by a narrow margin. For mystery writing, Gemini’s precision and emotional grounding make it the stronger contender. 2. Explaining to varying audiences (Image credit: Future) Prompt: “ Explain quantum computing to a 10-year-old, a CEO, and a physics PhD using analogies.” Gemini 2.5 Pro shines in technical accuracy but struggles with audience empathy. Claude 4 Sonnet offered a balance of creativity, practicality and accessibility, making it the stronger communicator overall. Winner: Claude wins for tailored storytelling that adapts in tone to each audience’s priorities. 3. Ethical issue (Image credit: Future) Prompt: “A company wants to lay off 30% of staff. Draft a compassionate email and list 3 alternatives.” Gemini 2.5 Pro addressed both departing and remaining employees, emphasizing transparency. It used placeholders for customization but the generic language such as “unforeseen market shifts” feels impersonal and it lacked concrete details, reducing trust. Claude 4 Sonnet prioritized equity by asking executives to take larger cuts. The direct, structured and empathetic response provided specific support details (severance duration, benefits continuation, career transition). Winner: Claude wins for a response that better balances compassion with actionable solutions, making it the stronger choice for maintaining trust during a crisis. 4. Handling ambiguity (Image credit: Future) Prompt: "I’m stuck. Help." Gemini 2.5 Pro , though kind, risks leaving the user still stuck about how to explain their situation. Claude 4 Sonnet normalized the feeling — “I’m here to help you get unstuck” — and provides a roadmap to articulate the problem. Winner: Claude wins for a balance of empathy and support, which make it the better choice for this prompt. 5. Technical deep dive (Image credit: Future) Prompt: “Compare PyTorch vs. TensorFlow for real-time ML on edge devices. Include code snippets.” Gemini 2.5 Pro focused on C++/conceptual examples vs. Claude’s ready-to-run Python. It also lacked timing/memory comparisons to quantify "real-time" claims. Claude 4 Sonnet provided complete Python workflows for model conversion, real-time inference (with OpenCV integration), and benchmarking — critical for edge deployment. Winner: Claude wins for delivering a more actionable, comprehensive comparison tailored to edge developers’ needs. 6. Humor and cultural nuance (Image credit: Future) Prompt: “Write a Gen Z-style tweet thread about 'AI taking over laundry folding.' Include slang and memes.” Gemini 2.5 Pro was inconsistent with tone mixing Gen Z slang (“bruh”) with millennial phrases (“truth bombs”). Gen Z rarely uses more than 1-2 hashtags per tweet (e.g., #TechTakeover is cringe). The chatbot also offered less risky jokes. Claude 4 Sonnet uses current phrases like “fr” (for real), “stan” (obsessively support), “no cap” (no lie) and “feral little goblins” naturally. It also referenced niche memes. Winner: Claude wins for a thread that feels like it was ripped straight from a 19-year-old’s Twitter feed. Gemini’s attempt is solid but leans into corporate-social-media-manager energy, 7. Collaborative problem-solving (Image credit: Future) Prompt: Act as my debate partner. Argue against “AI art devalues human creativity,” then help synthesize a conclusion. Gemini 2.5 Pro drowned out key insights in abstract concepts (“evolving paradigms”) and excessive examples (cameras, synthesizers, prompt engineering). Phrases like “It seems clear” weaken conviction compared to Claude’s “The key is ensuring.” Claude 4 Sonnet mirrors a skilled debater. It destroyed the opposition’s foundation by redefining creativity as intent-driven rather than tool-dependent, invalidating the premise. The chatbot acknowledged valid concerns while firmly rejecting the idea that AI inherently devalues creativity. Winner: Claude wins . Gemini provided valuable points but lacked Claude’s surgical precision and actionable conclusions. For a debate partner, Claude’s blend of rhetorical clarity and pragmatic solutions makes it the stronger choice. Overall winner: Claude 4 Sonnet Claude 4 Sonnet pulls ahead with its emotional intelligence, creative flair and technical depth. While Gemini 2.5 Pro excels in structured tasks like mystery writing and continues to deliver Google’s signature precision, Claude’s ability to blend nuance, practicality and empathy sets it apart. Claude 4 Sonnet adapts like a chameleon — shifting effortlessly between creative storytelling, thoughtful dialogue and complex reasoning. Gemini remains a top performer in logic-heavy scenarios, but for users who value emotional context and cultural fluency alongside raw power, Claude 4 Sonnet proves that AI can be both intelligent and genuinely relatable. More from Tom's Guide The only 5 prompt types you need to master ChatGPT (and any other chatbot) Google’s $249/month AI video tool is incredible — but this one feature left me frustrated Claude is quietly crushing it — here’s why it might be the smartest AI yet Category Back to Laptops Brand Apple Asus Dell Lenovo Processor AMD Ryzen Intel Core i5 Intel Core i7 RAM 8GB RAM 16GB RAM Storage Size 32GB 64GB 128GB 256GB 512GB 1TB Screen Size 13.3-inch 13.4-inch 14-inch Colour Black Blue Gold Grey Silver White Condition New Refurbished Screen Type LED OLED Price Any Price Showing 10 of 84 deals Filters ☰ SORT BY Price (low to high) Price (high to low) Product Name (A to Z) Product Name (Z to A) Retailer name (A to Z) Retailer name (Z to A) Apple 13" MacBook Air M4 (2025) (Blue) 1 $999 $891.50 Preorder Apple 15" MacBook Air M4 (2025) 2 $1,599 View Deal Dell XPS 13 (2016) Our Review ☆ ☆ ☆ ☆ ☆ 3 $569 View Deal Lenovo Yoga Slim 7x (Gen 9) 4 $1,075.79 $858.11 View Deal Lenovo IdeaPad Flex 5i ChromeBook Plus (Grey) 5 $599 View Deal Asus ROG Zephyrus G14 (2024) (Black) Our Review ☆ ☆ ☆ ☆ ☆ 6 $1,579.95 View Deal Apple 13" MacBook Air M4 (2025) 7 $899 View Deal Apple 15" MacBook Air M4 (2025) 8 $1,199 $1,068 View Deal Dell XPS 13 Plus (13.4-inch) Our Review ☆ ☆ ☆ ☆ ☆ 9 $1,109.99 $909.99 View Deal Lenovo Yoga Slim 7x (Gen 9) (Blue) 10 $1,289.99 $949.99 View Deal Show more Sign up to get the BEST of Tom's Guide direct to your inbox. Get instant access to breaking news, the hottest reviews, great deals and helpful tips. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors By submitting your information you agree to the Terms & Conditions and Privacy Policy and are aged 16 or over. TOPICS Google Amanda Caswell Social Links Navigation AI Writer Amanda Caswell is an award-winning journalist, bestselling YA author, and one of today’s leading voices in AI and technology. A celebrated contributor to various news outlets, her sharp insights and relatable storytelling have earned her a loyal readership. Amanda’s work has been recognized with prestigious honors, including outstanding contribution to media. Known for her ability to bring clarity to even the most complex topics, Amanda seamlessly blends innovation and creativity, inspiring readers to embrace the power of AI and emerging technologies. As a certified prompt engineer, she continues to push the boundaries of how humans and AI can work together. Beyond her journalism career, Amanda is a bestselling author of science fiction books for young readers, where she channels her passion for storytelling into inspiring the next generation. A long-distance runner and mom of three, Amanda’s writing reflects her authenticity, natural curiosity, and heartfelt connection to everyday life — making her not just a journalist, but a trusted guide in the ever-evolving world of technology. You must confirm your public display name before commenting Please logout and then login again, you will then be prompted to enter your display name. Logout Read more I tested Grok vs. Claude with 5 prompts to crown a winner I put ChatGPT-4o vs Claude 3.7 Sonnet through a 7-round face-off — one left the other in the dust I tested ChatGPT-4.5 vs. Gemini Pro 2.5 with 5 prompts — and one crushed the other I just tested ChatGPT vs. Gemini with 7 prompts — here's the winner I tested Gemini vs. Mistral with 5 prompts to crown a winner I tested DeepSeek vs Gemini 2.5 with 9 prompts — here's the winner Latest in AI Google I/O showed off AI done right — hopefully, Apple was paying attention I ditched Google for Perplexity for a month — and I don't think I can go back I'm not handing control of my wallet to an AI — and not even Google's AI shopping features can change that Google’s $249 AI video tool is incredible — but this one feature left me frustrated Level up your ChatGPT use with these 6 practical and creative prompts I saw Nvidia's RTX-powered AI avatar in action, and this digital human interface has a sense of humor Latest in Face Off Sony WH-1000XM6 vs AirPods Max: How do Sony's latest cans compare to Apple's premium headphones? I ran a half marathon with the Garmin Forerunner 570 vs. Garmin Forerunner 265 — here’s the winner Sony WH-1000XM6 vs Bose QuietComfort Ultra: How do Sony's latest headphones compare to Bose's noise-canceling kings? LG G4 vs Samsung S95F: Which flagship OLED TV is worth the money? Sony WH-1000XM6 vs Sony WH-1000XM5: How do Sony's latest flagship stack up? Garmin Forerunner 265 vs. Forerunner 570 — which running watch should you buy?
