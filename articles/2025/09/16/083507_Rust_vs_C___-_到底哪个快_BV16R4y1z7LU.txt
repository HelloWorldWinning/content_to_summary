Timestamp: 2025-09-16T08:35:07.795019
Title: Rust vs C++ -_到底哪个快 BV16R4y1z7LU
URL: https://b23.tv/EAFW34F
Status: success
Duration: 21:14

Description:
**总结:**

I. **背景**
    作者在十二月参与了“编程代码降临节”活动，并借此机会用Rust教授编程，撰写了16篇文章。然而，随着问题难度增加，作者开始面临调试和数学上的挑战，于是将重点转向了不同语言间的性能比较和Rust的优势展示。

II. **Rust与Python的性能对比 (Day 17)**
    在第17天，作者将一个Python解决方案移植到Rust。
    *   **结果**: 朴素的Rust一对一翻译比原Python快44倍。通过添加额外数据结构和更快的整数哈希函数，Rust版本最终比原Python快2000多倍，运行时从6秒降至不到3毫秒。
    *   **原因分析**: 这种巨大差异源于语言设计。CPython是解释器，逐行解释字节码；而像PyPy和Node.js（基于V8引擎）这样的实现则拥有JIT（即时编译器），能将字节码编译成机器码直接在CPU上运行。JIT通过运行时类型推断进行优化，但若推断错误则需去优化。
    *   **结论**: Rust与Python之间的性能比较是不公平的，因为它们的底层执行机制截然不同。

III. **Rust与C++的性能对比与开发体验 (Day 18)**
    第18天，作者将一个C++解决方案移植到Rust，结果出乎意料。
    *   **初始阶段**: Rust版本比C++慢。
    *   **问题定位**: 慢的原因并非计算本身，而是Rust在程序开始时进行了大量非缓冲的文件写入，导致频繁的系统调用。C++原方案使用`Fopen`和`FPrintF`等C API，它们默认带有缓冲。
    *   **优化后**: 将Rust的文件写入包装在`BufWriter`中后，第一部分解决方案Rust比C++快1.5倍（从8.9毫秒降至6.1毫秒）。第二部分通过切换数据结构、更改哈希函数和针对现代CPU指令集优化，Rust比C++快3.5倍以上。
    *   **开发体验**: 作者认为Rust在语法简洁性、修改便捷性、诊断信息方面表现更优。C++的挑战包括嵌入输入（原始字符串字面量限制、编译器限制、需要`XXD`）、运算符重载语法记忆困难，以及迭代器处理（如对空`std::set`调用`begin()`后解引用会导致未定义行为，而Rust的`first`方法返回`Option`类型，提供了安全性）。

IV. **Rust与C++的递归性能挑战 (Day 19)**
    作者在第19天再次将C++解决方案移植到Rust，这次Rust版本比C++慢20%（5.4秒 vs 4.5秒），且与系统调用无关，而是大量的函数递归调用（超过十亿次）。
    *   **深层分析**: 通过反汇编和反编译代码，发现关键在于参数传递方式。Rust编译器将大量32位整数参数通过栈传递，而C++编译器（同样基于LLVM）则能将两个32位值打包进一个64位寄存器中，全部通过寄存器传递。这导致了C++版本的更快执行。
    *   **根本原因**: 这是一个复杂的编译器内部调用约定优化问题，涉及到在调用者和被调用者之间权衡寄存器使用。
    *   **临时解决方案**: 在Rust函数上添加`extern "C"`属性，可以强制编译器使用外部C语言的调用约定，从而将参数通过寄存器传递，使Rust版本略快于C++。但这并非通用或可靠的修复方案。
    *   **有趣的发现**: 编译器对结构体字段数量的奇偶性似乎有不同的处理策略，例如，传递两个各含三个字段的结构体（总共6个数据）会使用栈，而传递三个各含两个字段的结构体（同样总共6个数据）则会使用寄存器。

V. **编程语言性能和优化原理**
    文章还介绍了几个核心概念：
    *   **内存层级**: 寄存器（CPU内最快）> 栈（函数调用快）> 堆（大但需分配器，相对慢）。
    *   **调用约定**: 定义了函数参数和返回值如何传递（通常通过寄存器或栈）。
    *   **汇编优化技术**: `LEA`指令（加载有效地址）常用于算术运算，`SIMD`指令（单指令多数据）允许在宽寄存器中并行处理多个数据。
    *   **未定义行为（UB）**: 强调了C++中解引用空迭代器等操作的危险性。

**核心观点**:
在性能优化和开发体验方面，Rust在许多场景下展现出与C++匹敌甚至超越的潜力，但不同语言和编译器在底层优化策略上的细微差异，可能导致出乎意料的性能表现。

**Overarching Framework (核心框架):**
编程语言性能比较、开发体验评估与底层编译器优化原理探究。

<Mermaid_Diagram>
graph TD
    A["Advent of Code活动"] --> B["Rust语言学习与教学"];

    subgraph "I. 性能对比与语言差异"
        B -- "Day 17: Rust vs Python" --> C["性能提升显著"];
        C --> D{"Python (CPython)":::python_node};
        C --> E{"Rust":::rust_node};
        D -- "解释器执行" --> F["字节码"];
        E -- "编译/JIT (如PyPy)" --> G["机器码"];
        G --> H["JIT运行时类型推断优化"];
        H -- "推断错误" --> I["去优化"];
        D -- "Node.js (V8) JIT" -- H;
        C -- "根本差异" --> J["语言执行机制不同"];
    end

    subgraph "II. Rust vs C++: 效率与开发体验"
        B -- "Day 18: Rust vs C++ (文件I/O)" --> K["初始Rust较慢"];
        K --> L["原因: Rust非缓冲文件写入"];
        L --> M["C++: 缓冲C API (Fopen/FPrintF)"];
        M --> K;
        L --> N["优化: Rust添加BufWriter"];
        N --> O["Rust Part 1: 快1.5倍"];
        B -- "Day 18: Rust vs C++ (优化后)" --> P["Rust Part 2: 快3.5倍+"];
        P --> Q["优化因素: 数据结构, 哈希函数, CPU指令集"];

        B -- "开发体验" --> R["Rust语法简洁, 诊断优"];
        R --> S["C++挑战: 嵌入输入, 运算符重载, 迭代器风险"];
        S -- "空Set解引用" --> T["未定义行为 (UB)"];
        R --> T;
    end

    subgraph "III. Rust vs C++: 递归与底层优化"
        B -- "Day 19: Rust vs C++ (递归)" --> U["初始Rust慢20%"];
        U --> V["问题: 大量递归调用"];
        U --> W["深层分析: 汇编/反编译"];
        W --> X["Rust: 32位参数经栈传递"];
        W --> Y["C++: 32位参数打包入64位寄存器 (寄存器传递)"];
        X --> Z["编译器内部调用约定优化差异"];
        Y --> Z;
        Z --> U;
        Z --> AA["临时修复: Rust函数extern 'C'"];
        AA --> BB["Rust略快于C++"];
        Z --> CC["有趣的发现: 结构体字段奇偶性影响参数传递"];
    end

    subgraph "IV. 核心概念与优化原理"
        D_1["内存层级"] --> D_2["寄存器 (最快)"];
        D_1 --> D_3["栈 (快)"];
        D_1 --> D_4["堆 (大但慢)"];
        D_5["调用约定"] --> D_6["参数传递方式 (寄存器/栈)"];
        D_7["汇编优化技术"] --> D_8["LEA (加载有效地址)"];
        D_7 --> D_9["SIMD (单指令多数据)"];
    end

    J --> E_1["核心观点: 语言/编译器底层差异影响性能"];
    T --> E_1;
    Z --> E_1;

    linkStyle 0 stroke:#000000,stroke-width:1px;
    linkStyle 1 stroke:#000000,stroke-width:1px;

    style A fill:#F9F7D8,stroke:#333,stroke-width:2px,color:#333;
    style B fill:#ADD8E6,stroke:#333,stroke-width:1px,color:#333;

    style C fill:#FFFFCC,stroke:#333,stroke-width:1px,color:#333;
    style D fill:#FFB6C1,stroke:#333,stroke-width:1px,color:#333;
    style E fill:#90EE90,stroke:#333,stroke-width:1px,color:#333;
    style F fill:#F0F8FF,stroke:#333,stroke-width:1px,color:#333;
    style G fill:#F0F8FF,stroke:#333,stroke-width:1px,color:#333;
    style H fill:#E6E6FA,stroke:#333,stroke-width:1px,color:#333;
    style I fill:#FFD700,stroke:#333,stroke-width:1px,color:#333;
    style J fill:#FFC0CB,stroke:#333,stroke-width:2px,color:#333;

    style K fill:#FFB6C1,stroke:#333,stroke-width:1px,color:#333;
    style L fill:#F0F8FF,stroke:#333,stroke-width:1px,color:#333;
    style M fill:#ADD8E6,stroke:#333,stroke-width:1px,color:#333;
    style N fill:#90EE90,stroke:#333,stroke-width:1

Content:
 Ever year in December, a bunch of programmers come together online and try to solve the same series of 25 coding exercises in an event called Adgentive Code. Some try to be the first to solve problem-gaining points and shining in the leaderboard, and some are a little more chill about it than use it to learn a new programming language. When I do it, I use it to teach Rust. Last December, I wrote 16 articles going from the basics of error handling to parsing with a dumb crate, doing memory profiling, generators, and even creating graphical interfaces compiling the result of WebAssembly and embedding it on a webpage. But the problems were getting harder and harder, and I wasn't getting any smarter. I was spending more and more time debugging silly off-by-one errors, or having to learn more maths than I'd signed up for, and since the focus of the series was Rust, and not showing off what a clever boy I am, I switched gears. For day 17 live on stream, I ported someone else's solution from Python to Rust. The result was about what you'd expect. At naive 1-1 Rust translation ended up being 44 times faster than the original Python. Adding an extra data structure and switching to a hash function that's faster for integers ended up making it over 2000 times faster than the original, reducing runtime from 6 seconds to under 3 milliseconds. You could make some of the same changes to the Python version, or even switch to a different Python implementation altogether, and that might help narrow the performance gap, but it was never a fair fight to begin with. C Python, the main Python implementation, is just an interpreter. It reads the code, translates it to bytecode, and then at runtime it just steps through the bytecode into preting it as it goes along. PiPy, however, has a JIT, a just-in-time compiler, which is able to translate bytecode to machine code, and the result can be run directly on the CPU with tons of air quotes for the patterns in my comment section. If you look at the computer language benchmarks game, where everyone is trying to prove their language is the fastest, for the n-body program, a math-heavy problem, the fastest solution is currently rust, and then a JavaScript solution running on Node.js is only a time slower. Part of the reason is that the JavaScript engine that powers Node.js has a very good JIT. Even though variables in JavaScript are not statically typed, now it's a number, now it's a string, and now it's an object, the JIT is able to monitor what arguments functions are called with at runtime, and then make guesses. It goes, I'm gonna generate code for this add function as if the arguments were always integers. If that's the case all the time, if the guess was right, then things get really fast, but if the function gets called with an argument that isn't an integer, first you need to do the right thing, you can't add two strings, but you can concatenate them, and that's the same operator in JavaScript, and second, if that happens a lot, then your guess was wrong, and you might need to de-optimize the function and come up with another machine code version of it that branches on the type of the arguments. This is, believe it or not, not what today's video is about, but if I got it all curious about it, you can go read the article's speculation in JavaScript core on the webkit blog which goes into a lot more detail. I felt pretty stupid while reading it, and I wish you the exact same, that just means you found something you can learn about. So, Python v Rust was never a fair fight, because the languages are just too different. C++ however is a language that's strongly typed, despite its C heritage, compiled ahead of time and used in performance-intensive scenarios they used to make game engines and browser engines and databases, it's got to go fast. So, on day 18, when I ported a solution from C++ to Rust, I didn't know what to expect. It could be faster, it could be slower, it was slower. Much slower, in fact, I was a bit sad, until I realized it wasn't slower at doing the heavy computation required by the problem, it was slower because it was doing a bunch of unbeferred writes to a file at the very beginning of the program. In the original solution, just to make sure that the puzzle input was parsed correctly, the author had the program write everything that was parsed back to a file, so that they could look at it and go, yeah, that looks okay. And they used C APIs like Fopen and FPrintF, which are doing buffering. At first, it's writing the text to some buffering memory, and then when the buffer is full, it issues a write Cisco, which is how you politely ask the kernel to perform some IO, and that's a lot more expensive than writing to memory. But in Rust, I was using just a file, so each individual print would issue one write Cisco, and that ended up taking something like 20ms, whereas the C++ version was done in 9ms. Once I wrapped the file in a buff writer, I discovered that the part one solution, there's always two parts, was 1.5 times faster in Rust than in C++, we went from 8.9ms to 6.1ms. For part two of day 18, the story was much the same, the naive 1.1 Rust translation was already 50% faster than the original, and then by switching to a different data structure, changing the hashing function and targeting modern CPU instruction sets, it became more than 3.5 times faster. For it to be really fair, you would need a C++ expert, which I'm not at all, to make similar changes to the C++ version of the code, and the gap would probably narrow significantly. But what's interesting to me is that the Rust version used less syntax, and it was very easy to make those changes, and bring it down from 8.5ms to 3.3ms. I am biased, of course, since I know more Rust than C++, but in C++, I had a hard time even embedding the input into the executable for benchmarking. I discovered that C++ had raw string literal syntax, but that it had parentheses instead of the double quotes, and then in MSVC, Microsoft C++ compiler choked on the literal because it was too large, so I ended up using XXD to generate a header file, and then had to figure out the proper way to include that from C++ sources, running into a bunch of template instantiation errors, which turned out to be a missing cast or a missing include. I've never missed Rust diagnostics as much as I did then. The operator overload syntax in C++ seems hard to remember, and I say that because the original had a link to a stack-of-a-flow answer about how to do operator overloading. And Rust is just implementing a trait like any other, except we didn't even need to do that, because we were able to derive it with a simple attribute. Finally, iterators in C++ are very different from Rust iterators. The pattern they used to iterate over a set, removing some elements but keeping others got me worried, but it turns out that that's just what the retained method does in Rust. Another part of the C++ code calls begin on a set, which gives you an iterator to the beginning of the set, as you cannot really tell from the name, and then it immediately references it. In Rust, I had to call the first function, which gives you a reference to the first element. But in an option, because what if the set is empty? So in Rust, I just used Unwrap so that if the set was empty, it would print an error message and safely exit the app. But in C++, if you dereference the iterator returned by begin on an empty set, that's undefined behavior. You know, nasal demons? The thing that can steal your dog and optimize your whole program away? UB is bad, don't do it. Anyway, the next day I thought, you know what? Maybe Rust being faster than C++ was a fluke. I'd like to try on a different solution just to make sure. And sure enough, on day 19, after porting a solution from that same person in C++ to Rust, it was slower. 20% slower. C++ ran in 4.5 seconds in Rust in 5.4 seconds. And this time around, it wasn't spending any time doing sisk calls, it was just doing a lot of recursion, a function calling itself over and over. And I had no idea where to look. We just call grind, but that just took forever. We used not perf, which is like perf, except not. It's a sampling profiler. And it showed that, yeah, the function calls itself a bunch of times recursively over a billion times, actually. People pointed out that this solution was doing a lot more work than needed. And I could just switch to a better solution. But I decided to focus on figuring out why essentially the same code was slower in Rust than it was in C++. And it took me a hot minute. We disassembled both solutions with Amstrum, looked at them side by side. And it was pretty hard to make sense of it beyond the first few lines. So we used Gidra, which you can decompile to C and start at renaming registers after what they were used for. This all happened live on stream and it lasted over three hours if you want to see the play by play. And finally, I noticed something funny. And we're not going to look at the actual code for day 19, we're going to look at simpler reproduction cases because I want this video to be accessible to people who don't speak x86 assembly fluently. So we need to build this up a little. Let's start simple. Say we are making a function that adds two 64 bit integers. This is what the Rust code for it could look like. When compiling this code, Rust C will generate LLVM IR into media representation. LLVM will generate machine code. And we can translate that back to assembly, which is closest to what the CPU actually does, but still human readable if we try hard enough. We'll be using compiler explorer, a free online service maintained by Matt Godbolt, whom you can support financially on GitHub sponsors, Patreon and PayPal. Let's first look at the disassembly of an unoptimized version of ad numbers with overflow checks disabled. There's three places we can put stuff, the heap, which can grow very large, but it's expensive because we go through an allocator, the stack which is limited in size, but very fast because we're just moving the stack pointer down to grow and up to shrink it, depending on platform, and registers, which are very fast global variables directly in the CPU. There are exceptions, but as a rule, let's assume that if we want our code to go fast, we should try and use registers as much as possible. When we call a function, we are jumping to the start of its code. But before we do, we must put its arguments somewhere. If we can put them in registers, we should do that. And that's what's happening here. In main, we move 1111 to the EDI register and 22222 to the ESI register, then ad numbers gets called, calls almost like jump, except it first pushes the return address on the stack so we know where to continue execution after the function has returned. And in ad numbers, we can see that the valuing RDI, which is another name for EDI, is move to racks, and then the valuing RSI is added to racks. And then we return a calling convention is where and how we pass arguments to a function. What can we say about the calling convention for this function? Well, it follows the standard x8664 sysv API, which says, if the arguments look like numbers, pass the first one in RDI, the second one in RSI, and then Rdx, RcX, R8, R9, and that's it. So argument X is in RDI, argument Y is in RSI, and the return value is in racks. So far so good. Now, let's look at the assembly for the optimized build of the same code. The code for main is the same, but the code for ad numbers has changed. Instead of using a move to copy the first argument to racks, and then an add to add the second, it does both at the same time using lea. What are those square brackets? Well, if you have move racks RDI, it copies the value in the RDI register to the racks register. But if you have move racks, brackets RDI, it treats RDI as an address and copies whatever is at that address to racks. This is useful if RDI is a pointer to the stack, for example. But in those square brackets, we can have more complicated expressions. If we have move racks, brackets RDI plus RSI, it would add RDI and RSI, treat this as an address, and then read whatever is there and then copy it to racks. This would work if RDI was a pointer and RSI was an offset. This happens when a reading struct feels, for example. As for lea, it's a bit like move, except it doesn't read whatever is at that address. It just copies the address itself. Hence, load effective address. So what's happening here is it's using a mechanism meant for computing addresses to do basic arithmetic, which is a very common pattern. Moving on, what happens if we add more parameters, then it uses all six registers we can use for integer arguments, RDI, RSI, RDX, RCX, R8, R9. The unoptimized version moves the first argument to racks and then adds all the other arguments accumulating into racks. And can you guess what the optimized version will do? That's right. Much the same, except it adds the first two arguments into racks with lea. Could we do better than this? Probably, but let's move on. What happens if we add eight numbers together? Then the last two arguments spill onto the stack we can tell because it uses the same square bracket syntax to read from RSP, the stack pointer plus some offset. Let's keep going. What if instead we pass two structs, each having two fields? Even without optimizations we can see from add numbers this assembly that all four numbers are passed through registers main looks inefficient though it's allocating space on the stack moving all our constants there and then moving them back into registers to call add numbers. Turning on optimizations gets rid of that nonsense moving the constants directly into the relevant registers. And now what happens if we have three fields per struct adding six numbers together in total? Stuff gets weird. Real weird. So far we've dealt with 64 bit wide registers RDI our site center, but we have wider registers XMM zero and XMM one are 128 bit wide. And you know what that means we can pack 264 bit integers in there to quad words making a word 16 bits apparently. These are Cindy registers Cindy for single instruction multiple data. And that comes in handy. Let's look at the optimized code and try to go through it. There's a bunch of scary Cindy instructions in there. But the first thing that jumps out is that it's reading memory RSI and RDI points to. I can tell because there's move instructions with the source operand in square brackets. The first move for example moves 64 bits worth of data from wherever RSI points to to the RACs register. The move DQU that follows does the same using RDI as an address and moving 264 bit values to quad words the instructions stands for move double quad word online into the XMM zero register. Let's follow what the function does step by step with diagrams. So originally both structs are somewhere in memory each field 64 bits RDI points to X and RSI points to Y. The first move copies the first field of Y YA to RACs. Then XA and XB are moved in one instruction to XMM zero. Then YB and YCR moved in one instruction to XMM one thanks to that plus eight offset here skipping over the eight bytes or 64 bits of the YA field. P add Q add packed quad word integers as both quad words from XMM zero into XMM one that's two additions with a single instruction single instruction multiple data. P shuff D shuffle packed double words is the most complicated instruction here it has a destination operand a source operand and a third operand that defines the order it's a series of four two bit integers that define which double words to copy from the source to the destination. Here the order operand is decimal 238 which in binary is 1110 1110. If we translate that to four decimal numbers we get three two three two and that corresponds to the higher and lower 32 bits of YB plus XA which is currently in XMM one. So all it's really doing is copying YB plus XA from XMM one to both halves of XMM zero. Then we have another pad Q doing two additions between both pairs of quad words. We only care about one of the results so this could be an add but the other operand is already in XMM one so this saves us a trip. After that we move the result we care about out of XMM zero into RCX and XC at address REI plus 16 to RACS and add RCX the result of all those SIMD additions to RACS which gives us our final sum and return value. Easy am I right aren't you glad you click on this video but let's forget about SIMD stuff for now possibly forever. One thing that's interesting is that this code passes six quad words to a function and it uses six registers to do so but as soon as we switch over to two structs with three fields each it stopped using registers and started passing them on the stack. In some cases that can be slower and that's exactly why the day 19 solution was slower in RUST than in C++. Kind of the day 19 solution was passing more integers but they were 32 bit. The RAS compiler looked at it and went you know what that's too many numbers let's just pass them on the stack whereas the C++ compiler also backed by LVM looked at it and went huh I bet I can pack two 32 bit values in each of those 64 bit registers and so we just use registers for everything. The reason this happened is really complicated and I'm not going to get it to it here. It is the kind of issue where you fix one case and that causes performance progressions in a lot of other cases. It's been an ongoing fight for years according to sources who are very tired. Okay this is not part of the script but I wanted to explain. So for functions that are not exported that are not part of a public interface for a library you can't call them from the outside so you don't have to adhere to a known calling convention right you can do whatever you want and so instead of using registers like RDI through R9 you could use 13 different registers you could use XMM0 as part of your own internal calling convention and that's what LVM is supposed to do but it doesn't for some reason and the problem is if you do that you have fewer registers you can use in the call E in the code that's calling the function. You might already be using those registers to just have local variables instead of allocating them in stack you have them in registers because you have those but if you're calling a function that has an internal specific ABI that uses more registers then you can use fewer in your call E and the function that is calling the other function and so that means that you now need to not use the registers for locals you need to put locals on this tag and that can get slower so the reason is it depends it depends on what the the call E is doing you can't tell just from the function signature and that's why it's about the so hard to fix there's not one good option for like which calling convention to use internally so there you go. Does this story have a happy ending for Rust though for the day 19 problem slapping an X-turn C on the function did make it use registers for argument passing and the compiled Rust code finally became slightly faster than the C++ version but that was a coincidence it's not a real generalized fix it would depend on the target architecture among other things this this works on x86 64 with this version of the compiler anyway before i leave you i want to show you one more thing so we've seen that with the current version of the nightly rust compiler passing two structs with three fields each uses the stack instead of registers and as i was discussing this with a friend a thought occurred three fields is an odd number of fields not just weird also not even so maybe something somewhere in the compiler doesn't like odd numbers what if we passed three structs with two fields each that's still six total would it still use the stack nope it uses registers and i guess this is my long way of saying if you see a compiler engineer in the wild ask if they need a hug so funny story i checked my inbox today and it had a pitch for a sponsored segment for the video i was like heck yeah how all that money and uh the email was from my cat so here you go the video sponsored by cat cat's a very good uh the fluffy that one sleeps a lot so he's a very quiet colleague i don't really i'm in the complaints he's not helping much but i'm a self-driven individual and this in this tech industry climate so that's that's good um cat would like pets um i'm assuming that's cats wave saying he doesn't get enough i don't know i just i'm just reading from the pitch here um cat also wants food uh not cat food cat wants human food the thing that smells delicious in the kitchen and that's that's what cat wants and cat wants if you do know that cat wants that so so yeah um check out cats um this is just half my cats i have double the cats that are shown here on on camera and yeah uh cat's rock you don't i don't think you don't you don't there's no discount code or anything can't use code fast online with cat just just kind of have them and pet them and feed them there's a bunch of clean up you you'll you'll see when you get to it it's nothing
