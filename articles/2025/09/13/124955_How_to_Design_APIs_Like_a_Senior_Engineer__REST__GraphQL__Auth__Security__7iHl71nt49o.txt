Timestamp: 2025-09-13T12:49:55.398353
Title: How to Design APIs Like a Senior Engineer (REST, GraphQL, Auth, Security) 7iHl71nt49o
URL: https://www.youtube.com/watch?v=7iHl71nt49o
Status: success
Duration: 1:23:21

Description:
**核心要点：**
掌握API设计、协议、安全和全生命周期的知识与实践，是开发者从初中级迈向高级岗位的关键。

**总体框架：**
从初级到高级的API设计与开发综合指南

**I. 课程概述**
*   **目标：** 弥合初/中级与高级开发者之间的技能鸿沟。
*   **核心内容：** 超越基础CRUD，深入理解API工作原理、协议选择、设计原则、主流风格（REST/GraphQL/gRPC）和全面的安全实践。
*   **职业发展：** 学习高级工程师在面试中被问及以及在实际项目中应用的关键原则。

**II. API设计基础**
1.  **什么是API？**
    *   **定义：** 应用程序编程接口（Application Programming Interface），定义软件组件间的交互方式。
    *   **作用：** 作为抽象机制（隐藏实现细节）、定义服务边界（允许不同系统/组件通信）。
2.  **主流API风格**
    *   **RESTful (Representational State Transfer):**
        *   特点：资源导向、使用HTTP方法（GET/POST/PUT/PATCH/DELETE）、无状态。
        *   优势：适用于Web和移动应用、标准化。
    *   **GraphQL:**
        *   特点：查询语言、单一端点、客户端请求精确数据、支持订阅。
        *   优势：减少往返次数、避免过度/不足获取数据、适用于复杂UI。
    *   **gRPC (Google Remote Procedure Call):**
        *   特点：高性能RPC框架、使用Protocol Buffers、支持流式和双向通信。
        *   优势：适用于微服务架构和内部系统通信、更高效。
3.  **四大核心设计原则**
    *   **一致性：** 统一命名、大小写和模式。
    *   **简洁性：** 专注于核心用例、直观设计、易于理解和使用。
    *   **安全性：** 实现认证、授权、输入验证、速率限制等。
    *   **性能：** 采用缓存、分页、最小化Payload、减少往返。
4.  **协议选择对API设计的影响：** 协议决定API结构、性能和功能（如HTTP支持RESTful、WebSockets支持实时）。
5.  **API设计流程：**
    *   **阶段：** 需求理解（用例、范围、性能、安全）-> 设计方法 -> 生命周期管理。
    *   **设计方法：** 自上而下（高层需求）、自下而上（现有数据模型）、契约优先（先定义API契约）。
    *   **生命周期：** 设计 -> 开发 -> 部署/监控 -> 维护 -> 弃用/淘汰。

**III. API协议详解**
1.  **应用层协议 (网络栈顶部)**
    *   **HTTP (Hypertext Transfer Protocol):** Web API基础，请求/响应模式、GET/POST等方法、状态码（2xx/3xx/4xx/5xx）、请求头。
    *   **HTTPS:** HTTP + TLS/SSL加密，提供数据传输安全、完整性和身份验证。
    *   **WebSockets:** 适用于实时通信、双向连接、握手后可由服务器主动推送数据、低延迟、减少带宽。
    *   **AMQP (Advanced Message Queuing Protocol):** 企业级消息协议，用于异步通信、消息队列、保证消息交付、生产者/消费者模型。
    *   **gRPC:** 高性能RPC框架，使用HTTP/2作为传输层、Protocol Buffers作为接口定义语言，适用于微服务间通信。
2.  **传输层协议 (网络栈第二层)**
    *   **TCP (Transmission Control Protocol):**
        *   特点：可靠、连接导向、有序交付、三次握手。
        *   用途：支付、认证、用户数据（需要高可靠性）。
    *   **UDP (User Datagram Protocol):**
        *   特点：快速、无连接、不可靠（无交付保证）、低开销。
        *   用途：视频通话、在线游戏、直播（可接受少量数据丢失）。
3.  **协议选择考量：** 交互模式、性能需求、客户端兼容性、Payload大小、安全需求、开发者体验。

**IV. API风格深入实践**
1.  **RESTful API设计**
    *   **资源建模与URL设计：** 使用名词（复数表示集合）、清晰标识资源（如`/products`、`/products/{id}`）、嵌套资源（如`/products/{id}/reviews`）。
    *   **过滤、排序与分页：** 通过查询参数（`category`, `sort`, `page`, `limit`, `offset`, `cursor`）实现，提高性能和灵活性。
    *   **HTTP方法：**
        *   GET: 读取数据 (安全且幂等)。
        *   POST: 创建资源 (不幂等)。
        *   PUT: 完整更新资源 (幂等)。
        *   PATCH: 部分更新资源 (幂等)。
        *   DELETE: 删除资源 (幂等)。
    *   **状态码与错误处理：** 使用标准HTTP状态码 (2xx成功, 3xx重定向, 4xx客户端错误, 5xx服务器错误)。
    *   **最佳实践：** 资源URL使用复数名词、正确使用HTTP方法、支持过滤/排序/分页、API版本控制 (如`/v1/`)、利用HTTP缓存。
2.  **GraphQL API设计**
    *   **存在原因：** 解决RESTful API过度/不足获取数据、需要多次请求的问题。
    *   **Schema设计与类型系统：** 契约定义（类型`type`）、查询`query`（读取数据）、变更`mutation`（修改数据）、订阅`subscription`（实时通信）。
    *   **查询与变更：** 客户端通过查询语言精确指定所需数据结构，通过单一端点进行所有操作。
    *   **错误处理：** 始终返回200 OK状态码，具体错误信息通过响应中的`errors`字段返回。
    *   **最佳实践：** Schema小而模块化、避免深度嵌套查询（设置查询深度限制）、使用有意义的命名、变更使用输入类型。

**V. API安全**
1.  **认证 (Authentication)：**
    *   **定义：** 验证请求者的身份（“你是谁？”）。
    *   **类型：** 基本认证 (Basic Auth)、Bearer Tokens、OAuth 2 + JWT (JSON Web Tokens)、Access & Refresh Tokens、SSO (Single Sign-On，使用SAML或OAuth 2协议)。
    *   **JWT：** 包含用户ID、角色、范围、过期时间等信息，无状态、可扩展。
    *   **Access/Refresh Tokens：** 短期访问令牌用于API调用，长期刷新令牌用于获取新的访问令牌，提升安全性。
2.  **授权 (Authorization)：**
    *   **定义：** 确定已认证用户可以访问哪些资源或执行哪些操作（“你能做什么？”）。
    *   **模型：**
        *   **RBAC (Role-Based Access Control):** 将权限分配给角色，用户被分配角色（如管理员、编辑者、查看者）。
        *   **ABAC (Attribute-Based Access Control):** 基于用户、资源和环境属性动态定义访问策略，更灵活但更复杂。
        *   **ACL (Access Control Lists):** 每个资源拥有自己的权限列表，详细控制单个资源的访问（如Google Docs共享）。
    *   **实施：** OAuth 2 (委派授权)、JWT/Bearer Tokens (携带权限信息，后端检查权限)。
3.  **常见API安全技术：**
    *   **速率限制 (Rate Limiting):** 控制客户端在给定时间内可发起的请求数量，防止DDoS攻击、暴力破解。
    *   **CORS (Cross-Origin Resource Sharing):** 控制哪些域名可以调用API，防止恶意网站通过用户浏览器发起请求。
    *   **SQL/NoSQL注入 (Injection Attacks):** 使用参数化查询或ORM（对象关系映射）防范，避免用户输入直接参与数据库查询。
    *   **防火墙 (WAF - Web Application Firewall):** 过滤恶意流量，识别并阻断已知攻击模式。
    *   **VPN (Virtual Private Networks):** 限制API访问至特定私有网络，适用于内部工具和微服务。
    *   **CSRF (Cross-Site Request Forgery):** 使用CSRF Token与Session Cookie配合，防止已登录用户被诱导发起恶意请求。
    *   **XSS (Cross-Site Scripting):** 对用户输入进行验证和转义，防止攻击者注入恶意脚本。

<Mermaid_Diagram>
graph TD
    subgraph "A[""高级API设计与开发综合指南""]"
        A_INTRO("1. 课程概述") --> A_BASICS("2. API设计基础")
        A_BASICS --> A_PROTOCOLS("3. API协议详解")
        A_PROTOCOLS --> A_STYLES("4. API风格深入实践")
        A_STYLES --> A_SECURITY("5. API安全")
        A_SECURITY --> A_CAREER("6. 职业发展与实践")
    end

    subgraph "API设计基础"
        B1("API定义与作用")
        B2("主流API风格")
        B3("核心设计原则")
        B4("协议选择影响")
        B5("API设计流程")

        B1 --> B2
        B2 --> B3
        B3 --> B4
        B4 --> B5

        B2_REST("RESTful")
        B2_GRAPHQL("GraphQL")
        B2_GRPC("gRPC")
        B2 --> B2_REST
        B2 --> B2_GRAPHQL
        B2 --> B2_GRPC

        B3_CONSISTENCY("一致性")
        B3_SIMPLICITY("简洁性")
        B3_SECURITY("安全性")
        B3_PERFORMANCE("性能")
        B3 --> B3_CONSISTENCY
        B3 --> B3_SIMPLICITY
        B3 --> B3_SECURITY
        B3 --> B3_PERFORMANCE

        B5_REQUIREMENTS("需求理解")
        B5_APPROACHES("设计方法")
        B5_LIFECYCLE("生命周期管理")
        B5 --> B5_REQUIREMENTS
        B5 --> B5_APPROACHES
        B5 --> B5_LIFECYCLE
    end

    subgraph "API协议详解"
        C1("应用层协议")
        C2("传输层协议")
        C3("协议选择考量")

        C1 --> C2
        C2 --> C3

        C1_HTTP("HTTP/HTTPS")
        C1_WEBSOCKETS("WebSockets")
        C1_AMQP("AMQP")
        C1_GRPC("gRPC")
        C1 --> C1_HTTP
        C1 --> C1_WEBSOCKETS
        C1 --> C1_AMQP
        C1 --> C1_GRPC

        C2_TCP("TCP (可靠)")
        C2_UDP("UDP (快速)")
        C2 --> C2_TCP
        C2 --> C2_UDP
    end

    subgraph "API风格深入实践"
        D1("RESTful API最佳实践")
        D2("GraphQL API最佳实践")

        D1 --> D2

        D1_RESOURCE("资源建模与URL设计")
        D1_FILTERS("过滤/排序/分页")
        D1_METHODS("HTTP方法 (CRUD)")
        D1_STATUS("状态码与错误处理")
        D1_VERSIONING("版本控制")
        D1 --> D1_RESOURCE
        D1 --> D1_FILTERS
        D1 --> D1_METHODS
        D1 --> D1_STATUS
        D1 --> D1_VERSIONING

        D2_PROBLEM("解决问题 (过度/不足获取)")
        D2_SCHEMA("Schema设计与类型系统")
        D2_QUERIES("查询与变更")
        D2_ERROR("错误处理 (200 OK & errors)")
        D2_SINGLE_ENDPOINT("单一端点")
        D2 --> D2_PROBLEM
        D2 --> D2_SCHEMA
        D2 --> D2_QUERIES
        D2 --> D2_ERROR
        D2 --> D2_SINGLE_ENDPOINT
    end

    subgraph "API安全"
        E1("认证 (Authentication)")
        E2("授权 (Authorization)")
        E3("常见安全技术")

        E1 --> E2
        E2 --> E3

        E1_BASIC("Basic Auth")
        E1_BEARER("Bearer Tokens")
        E1_OAUTH_JWT("OAuth 2 & JWT")
        E1_ACCESS_REFRESH("Access & Refresh Tokens")
        E1_SSO("SSO与身份协议")
        E1 --> E1_BASIC
        E1 --> E1_BEARER
        E1 --> E1_OAUTH_JWT
        E1 --> E1_ACCESS_REFRESH
        E1 --> E1_SSO

        E2_RBAC("RBAC (角色)")
        E2_ABAC("ABAC (属性)")
        E2_ACL("ACL (列表)")
        E2_ENFORCE("OAuth 2 & JWT实施")
        E2 --> E2_RBAC
        E2 --> E2_ABAC
        E2 --> E2_ACL
        E2 --> E2_ENFORCE

        E3_RATELIMIT("速率限制")
        E3_CORS("CORS (跨域)")
        E3_SQL_INJECTION("SQL/NoSQL注入")
        E3_FIREWALLS("防火墙 (WAF)")
        E3_VPN("VPN (私有网络)")
        E3_CSRF("CSRF (跨站请求伪造)")
        E3_XSS("XSS (跨站脚本攻击)")
        E3 --> E3_RATELIMIT
        E3 --> E3_CORS
        E3 --> E3_SQL_INJECTION
        E3 --> E3_FIREWALLS
        E3 --> E3_VPN
        E3 --> E3_CSRF
        E3 --> E3_XSS
    end

    subgraph "职业发展与实践"
        F1("高级API设计理念")
        F2("实际项目应用")
        F3("一对一指导与进阶")

        F1 --> F2
        F2 --> F3
    end

    A_INTRO -- "引入" --> A_BASICS
    A_BASICS -- "构建" --> A_PROTOCOLS
    A_PROTOCOLS -- "指导" --> A_STYLES
    A_STYLES -- "强化" --> A_SECURITY
    A_SECURITY -- "最终目标" --> A_CAREER

    style A fill:#E0BBE4,stroke:#333,stroke-width:2px,color:#333;
    style A_INTRO fill:#957DAD,stroke:#333,stroke-width:1px,color:#333;
    style A_BASICS fill:#957DAD,stroke:#333,stroke-width:1px,color:#333;
    style A_PROTOCOLS fill:#957DAD,stroke:#333,stroke-width:1px,color:#333;
    style A_STYLES fill:#957DAD,stroke:#333,stroke-width:1px,color:#333;
    style A_SECURITY fill:#957DAD,stroke:#333,stroke-width:1px,color:#333;
    style A_CAREER fill:#F07C6F,stroke:#333,stroke-width:1px,color:#333;

    style B1 fill:#D291BC,stroke:#333,stroke-width:1px,color:#333;
    style B2 fill:#D291BC,stroke:#333,stroke-width:1px,color:#333;
    style B3 fill:#D291BC,stroke:#333,stroke-width:1px,color:#333;
    style B4 fill:#D291BC,stroke:#333,stroke-width:1px,color:#333;
    style B5 fill:#D291BC,stroke:#333,stroke-width:1px,color:#333;
    style B2_REST fill:#FFC72C,stroke:#333,stroke-width:1px,color:#333;
    style B2_GRAPHQL fill:#FFC72C,stroke:#333,stroke-width:1px,color:#333;
    style B2_GRPC fill:#FFC72C,stroke:#333,stroke-width:1px,color:#333;
    style B3_CONSISTENCY fill:#A3D9B1,stroke:#333,stroke-width:1px,color:#333;
    style B3_SIMPLICITY fill:#A3D9B1,stroke:#333,stroke-width:1px,color:#333;
    style B3_SECURITY fill:#A3D9B1,stroke:#333,stroke-width:1px,color:#333;
    style B3_PERFORMANCE fill:#A3D9B1,stroke:#333,stroke-width:1px,color:#333;
    style B5_REQUIREMENTS fill:#FFC72C,stroke:#333,stroke-width:1px,color:#333;
    style B5_APPROACHES fill:#FFC72C,stroke:#333,stroke-width:1px,color:#333;
    style B5_LIFECYCLE fill:#FFC72C,stroke:#333,stroke-width:1px,color:#333;

    style C1 fill:#D291BC,stroke:#333,stroke-width:1px,color:#333;
    style C2 fill:#D291BC,stroke:#333,stroke-width:1px,color:#333;
    style C3 fill:#D291BC,stroke:#333,stroke-width:1px,color:#333;
    style C1_HTTP fill:#FFC72C,stroke:#333,stroke-width:1px,color:#333;
    style C1_WEBSOCKETS fill:#FFC72C,stroke:#333,stroke-width:1px,color:#333;
    style C1_AMQP fill:#FFC72C,stroke:#333,stroke-width:1px,color:#333;
    style C1_GRPC fill:#FFC72C,stroke:#333,stroke-width:1px,color:#333;
    style C2_TCP fill:#FFC72C,stroke:#333,stroke-width:1px,color:#333;
    style C2_UDP fill:#FFC72C,stroke:#333,stroke-width:1px,color:#333;

    style D1 fill:#D291BC,stroke:#333,stroke-width:1px,color:#333;
    style D2 fill:#D291BC,stroke:#333,stroke-width:1px,color:#333;
    style D1_RESOURCE fill:#FFC72C,stroke:#333,stroke-width:1px,color:#333;
    style D1_FILTERS fill:#FFC72C,stroke:#333,stroke-width:1px,color:#333;
    style D1_METHODS fill:#FFC72C,stroke:#333,stroke-width:1px,color:#333;
    style D1_STATUS fill:#FFC72C,stroke:#333,stroke-width:1px,color:#333;
    style D1_VERSIONING fill:#FFC72C,stroke:#333,stroke-width:1px,color:#333;
    style D2_PROBLEM fill:#FFC72C,stroke:#333,stroke-width:1px,color:#333;
    style D2_SCHEMA fill:#FFC72C,stroke:#333,stroke-width:1px,color:#333;
    style D2_QUERIES fill:#FFC72C,stroke:#333,stroke-width:1px,color:#333;
    style D2_ERROR fill:#FFC72C,stroke:#333,stroke-width:1px,color:#333;
    style D2_SINGLE_ENDPOINT fill:#FFC72C,stroke:#333,stroke-width:1px,color:#333;

    style E1 fill:#D291BC,stroke:#333,stroke-width:1px,color:#333;
    style E2 fill:#D291BC,stroke:#333,stroke-width:1px,color:#333;
    style E3 fill:#D291BC,stroke:#333,stroke-width:1px,color:#333;
    style E1_BASIC fill:#FFC72C,stroke:#333,stroke-width:1px,color:#333;
    style E1_BEARER fill:#FFC72C,stroke:#333,stroke-width:1px,color:#333;
    style E1_OAUTH_JWT fill:#FFC72C,stroke:#333,stroke-width:1px,color:#333;
    style E1_ACCESS_REFRESH fill:#FFC72C,stroke:#333,stroke-width:1px,color:#333;
    style E1_SSO fill:#FFC72C,stroke:#333,stroke-width:1px,color:#333;
    style E2_RBAC fill:#FFC72C,stroke:#333,stroke-width:1px,color:#333;
    style E2_ABAC fill:#FFC72C,stroke:#333,stroke-width:1px,color:#333;
    style E2_ACL fill:#FFC72C,stroke:#333,stroke-width:1px,color:#333;
    style E2_ENFORCE fill:#FFC72

Content:
 In this course, you'll learn the API design skills that separate junior developers from seniors. Most developers only know how to build basic CRUD APIs, but they don't really understand how APIs work behind the scenes, like when to choose REST over GraphQL or when to choose rich protocol like HTTP, WebSockets, Messaging Protocols, or how to apply security practices. These are exactly the things that senior engineers get asked in interviews, and the same principles I've applied myself while working on real-world projects. We'll go through the API design principles, protocols, RESTful and GraphQL API design, authentication, authorization, and security practices, so everything you need to know to go beyond the basics and think like a senior engineer. If you're stuck in junior to mid-level roles and want to learn senior salaries, then this is the knowledge that will help you get there. Welcome to this section where you will learn the fundamental principles of API design, which will enable you to create efficient, scalable, and also maintainable interfaces between software systems. Here is what we're going to cover in this lesson. We'll start from what APIs are and what is their role in system architecture. Then we'll cover the three most commonly used API styles, which are REST, GraphQL, and GRPC. We'll discuss the four essential design principles that make great APIs, and also how application protocols influence the API design decisions. We'll also cover the API design process, so starting from the design phase to development phase to deployment, so we'll see how that process looks like. So let's start by understanding what is an API. API stands for Application Programming Interface, which defines how software components should interact with each other. Let's say on one side you have the client, which is either the mobile phone or the browser of this user, and on the other side you have the server, which will be responding to the requests. So API here is just a contract that defines these terms, which are what requests can be made. So it provides us with an interface on how to make these requests, meaning what endpoints do we have, what methods can we use, and so on. What responses can we expect from this server for a specific endpoint? So first of all, it is an abstraction mechanism, because it hides the implementation details while exposing the functionality. For example, we can make a request to save a user data in this server, but we don't care at all about how the logic applies behind the scenes inside of this server, so we only care about the interface that is provided through this API. And we only use that endpoint, and we store the user without even knowing about implementation details. And it also sets the service boundaries, because it defines clear interfaces between systems and components, so this allows us to have multiple servers. We can have one server that is responsible for managing the users, we can have another one that is responsible for some other records, let's say for managing the posts and so on. So this allows different systems to communicate regardless of their underlying implementation, like client browsers with servers or servers with another servers and so on. Now let's focus on the most important API styles you will encounter during the design phase. These are RESTful, GraphQL and GRPC. The most common one out of these is REST, which stands for Representational State Transfer. These type of APIs use resource-based approach by using the HTTP methods as a protocol. One of the advantages of REST APIs is that they are stateless, meaning that each request contains all of the information needed to process it, and we don't need any prior requests to be able to process the current request. And it uses the standard methods on HTTP protocol, which are get for fetching data, post for storing data, put or patch for updating data, and delete for deleting data. So based on its characteristics, the REST is most commonly used in web and mobile applications. Next we have GraphQL, which is the second most common API style after the REST APIs. GraphQL is a query language that allows clients to request exactly what they need. This means that it comes with a single endpoint for all of the operations, and we can choose what we are expecting to receive from this API by providing the payload in the request. And operations here are called query whenever we are retrieving data or mutation whenever we are updating data. So this is the equivalent in put or patch or post in the RESTful APIs. And there is also a subscription in operations, which is for real-time communication. The advantage of GraphQL APIs is that it allows us to have minimal round trips. Let's say we need some data that in RESTful APIs we will need to make free requests to get all of this data. In GraphQL case, we can make a single request and get all of this data, avoiding the unnecessary tool requests that we will otherwise have to make in RESTful. And because of that, this is the recommended option for complex UIs. So wherever you have some complex UIs where on one page you might need different data, on another page you might need some other complex nested data. In these cases, GraphQL is the better choice over RESTful APIs. And the last option is GRPC. I would say this is the least common one out of these three. GRPC is a high-performance RPC framework, which is using protocol buffers for communication. The methods in GRPC are defined as RPCs in the protocols, and it supports streaming and bidirectional communication. This is an excellent approach for microservices especially, and internal system communication. As it is more efficient when you are working between servers compared to GraphQL or compared to RESTful APIs. So the difference between REST, GraphQL, and GRPC APIs is kind of clear, but let's also clarify the real difference between REST and GraphQL APIs on examples. So as you saw, REST comes with resource-based endpoints. For example, here if we take a look at these requests, you can see that the resource here is users. So you always expect to see some users' endpoint or some followers' endpoint or let's say posts' endpoint. So it is resource-based. And sometimes we might need to make multiple requests for getting the related data. As you can see here, we need let's say the user details, but we also need the user posts and followers. So in this case, we need to make free requests to get all of these data. And it uses HTTP methods to define operations. As you can see, these are HTTP endpoints, and we are using the get method specifically. And the response structures are fixed, meaning if you got one response for this specific user, next time you can expect to have exactly the same response structure, maybe some data will be modified, but the structure always remains the same. And it also provides explicit versioning. So as you can see, it comes with V1 for the V1 API. Then later, if it got a major upgrade, then this will become V2 and so on. And you can use the headers on the requests to leverage the HTTP caching on RESTful APIs. Now if we compare that to GraphQL APIs, it comes with a single endpoint for all operations. So mostly it is slash GraphQL or slash some API endpoints that is commonly used for all operations. And in this case, we will use a single request to get precise data that we need, and we will use the query language of GraphQL. This is what the query language looks like. As you can see, we start with a query and then we define what we need. For example, we need the user with ID123. Then we need the name of the user, the posts, and then we define whatever we need from the posts. Maybe we need only title and content and nothing more. And also the followers and what we need from followers, maybe only names. So this allows us to be more efficient in our requests compared to RESTful APIs, where we will need to make free requests for this same data. This means that client needs to specify the response structure. But in this case, the schema evolution is without versioning. So here, as you saw, it is with V1, V2, and so on. In this case, the schema usually evolves without versioning, but there is also a common pattern to start versioning the fields. For example, you can have followers V2, and that will be the second type of followers schema. But you can also go without versioning. So you can just start modifying the followers or posts. If you are sure that there are no other clients using your old API. And in this case, you can leverage the application level caching instead of the HTTP caching. Now let's discuss the major design principles that will allow us to create consistent, simple, secure, and also performant APIs. Ultimately, the best API is the one that we can use without even reading the documentation. For example, if you saw the previous endpoints in the users, you see that we have slash users slash one to three. And obviously, we are expecting to get the user details of this specific user. And if you make a request, for example, to that endpoint to fetch user details, but then you find out that it also updates some followers or something while making this request. Then obviously, that is a very bad type of API, as we didn't expect it to do such operations. So first of all, the good API should be consistent, meaning it should use the consistent naming, casing, and patterns. For example, if you use camel case in one of the endpoints, let's say you have user details, and you do this in camel case, but in another case, you do it with a skynade case like user slash details. Then this is not common, and this is not consistent. The second key principle is to keep it very simple and focus on core use cases and intuitive design. So you should minimize complexity and aim for designs that developers can understand quickly without even maybe reading the documentation. And simplicity again comes down to this, which is the best API is one that developers can use without even reading the documentation. Next obviously, it has to be secure. So you have to have some sort of authentication and authorization between users. Also if you have inputs, then you need to make sure that these are validated and you should also apply rate limiting. So these are the most basic things that you have to do to keep your API secure. And the last pillar is performance. So you should design for efficiency with appropriate caching strategies with pagination. If you have a large amount of data, let's say thousands of posts, you don't want to retrieve all of these whenever they make a request to get the posts. So you should always have pagination with some limit and offset. Also the payloads, meaning the data that you will send back should be minimized. And also whenever possible, you should reduce the round trips. So if you have the opportunity to send some small data along with the request of one of the endpoints, then it's better to do this if you know that you're going to use it instead of making another end point for making a request to get the same data. Now each of these APIs use different protocols and we will learn more about this in the next lesson, but basically your protocol choice will fundamentally shape your API design options. For example, the features of HTTP protocol directly enable restful capabilities. So it makes more sense to use HTTP along with restful APIs because it also provides you with status codes and these are great to be used with crowd operations that you will have in restful APIs. On the other hand, web sockets, which is another type of protocol, enable real-time data and also enable bidirectional APIs. So this can be used along with real-time APIs, wherever you need some chat application or some video streaming. This is a good use case of WebSocket APIs. In case of GraphQL APIs, you again will use the HTTP protocol instead of WebSockets or GRPC. GRPC on the other hand can be used among with microservices in your architecture to make it faster compared to HTTP. So your protocol choice will affect the API structure and also the performance and capabilities. Therefore, you should choose it based on its limitations and strengths and the one that makes more sense in the type of API that you will be developing. Now let's discuss the API design process. It all starts with understanding the requirements, which is identifying core use cases and user stories that you will need to develop. Also defining the scope and boundaries because if it's a huge API, then you probably won't develop all of the features at once. So you should scope it to some specific features that you will be developing and also what are out of scope for now. Then you should determine the performance requirements and specifically in your API case, what will be the bottlenecks and where you need to make sure that it's performant. And you should also not overlook the security constraints. So you should implement all of the basic features like authentication, authorization, the rate of implementing, but maybe some more stuff depending on the API that you'll develop. When it comes to design approaches, there are a couple of ways to go about it. The first one is top-down approach, which is you start with high-level requirements and workflows. This is more common in interviews where they give you the requirements on what the API will be about and then you start defining what the endpoints will be, what the operations will be and so on. But there is also the bottom-up approach, which is if you have existing data models and capabilities, then you should design the API based on this. So this is more common when you're working in a company and they already have their data models and capabilities of their APIs. So you should take that into account when designing the API. And we also have contract-first approach, which is you define the API contract before implementation, meaning what the requests should look like and what the request should be. And this is more similar to top-down approach and this is also commonly used in interviews. When it comes to lifecycle management of APIs, it starts with the design phase, where you design the API, discuss the requirements and the expected outcomes of the API. And only after that you can start the development and maybe local testing of your API. After that you usually deploy and monitor it, so you do some more testing, but now on staging or on production. But then it also comes the maintenance phase and this is why it's important to develop it with keeping the simplicity in place. So it will be easier for you to maintain or for other developers to maintain in the future. And lastly, APIs also go through the application and retirement phase. So some APIs eventually get deprecated because there might come up a new version of the API that you should use or let's say you are transitioning from V1 to V2 API. So that's also the deprecation phase of the V1 API. So developing APIs is not only in the development phase, as you might assume, it's not just coding. So the big part of it is designing it and also keeping it maintainable and also eventually you might need to retire it at the end. So let's recap and see what our next steps are. We learned what APIs are and about the most dominant three type of API styles, which are RESTful, GraphQL and GRPC. We've covered the four key principles that will guide us when creating API designs effectively. And you now also understand how the design choice of your protocol will influence the design of your API and also the whole API design process from start to finish. But we didn't discuss the limitations and strengths of these API protocols. So that's why in the next lesson we will learn all about the API protocols that we can use with API design and which one we should choose based on the requirements of our API. Before we get into the next lesson, just knowing the API principles on a high level won't get you far. In interviews you'll usually get cold immediately if you're trying to fake it and if you have never implemented them in real projects. If you're a developer with one to five years of commercial experience based in US, Canada, Europe, Australia or New Zealand and you're stuck in junior to mid-level roles, but you want to move into senior positions, master API design and other concepts and start earning senior level salaries, then you can apply to work with me one on one. This is exactly what I help developers do inside of my mentorship program. We take these concepts and apply them hands-on in real work projects. The same way senior engineers will work in top companies. So the first link in description is where you can apply. But only apply if you're serious about advancing to senior roles, otherwise our calendar is fully booked all the time and if your application doesn't seem like a good fit, then unfortunately we'll have to cancel it. I think the wrong protocol for our API can lead to performance bottlenecks and also limitations in functionality. That's why we need to first understand these protocols, which will allow us to build APIs that meet our specific user requirements for latency, throughput and also interaction patterns. That's why in this lesson we'll cover the role of API protocols in the network stack. The two fundamental protocols which are HTTP and HTTPS and also their relationship to APIs. Also another common type of protocol which is WebSocket for real-time communication. We'll also cover advanced message queuing protocol which is commonly used for asynchronous communication. And lastly we'll cover the GRPC which is Google's remote procedure call and it is also another common type of protocol used commonly within servers. Start by understanding the application protocols in network stack. Application layer protocols seat at the top of network stack, building on top of protocols like TCP and UDP which are at a transport layer. These protocols at the application layer define the message formats and structures, also the request response patterns and management of the connections and error handling. Now below that we have many other layers like the network layer or data link layer or even physical layers but when building APIs we are mostly concerned with the API layer protocols which are HTTP, HTTPS, WebSockets and so on. The most common type of protocol and also the foundation of Web APIs is HTTP which stands for Hypertext Transfer Protocol. This is the typical interaction between client and server when they are interacting over HTTP. As you can see client always sends on request and they define the method which can be get, post or other methods and they define the resource URL which can be at slash API slash products. Let's say they are requesting data for this specific ID of the product and they also define the version of the HTTP protocol that they are using. They also define the host which is the domain of your server where the information is accessed and usually they also authenticate before accessing any resources so it can be either a bearer token or a basic authentication or a and so on. So once the request is authenticated in the server it receives the response which is in similar format and it's in HTTP response so you get the HTTP version which is again the same as you request it with and a status code which can be 200 if it was successful or it can be 400 if the client was error or 500 if the error happened in server and so on. You receive the content type which can be usually application JSON but it can also be a static web page or something else and there are many other headers that you can control like controlling cache you can use the cache control header or some other properties but these are the main things that you would notice in HTTP request response cycles. Now when it comes to methods you have get for retrieving data post for creating data in the server put or patch for updating data partially or fully and delete for removing data from the server and when it comes to status codes which are received by the server so you have 200 series which are successful cases you have 300 for redirection 400 means that client made an error in the request so this is an issue from client site or 500 which means that server made an error or like some error happened in the server which means that this is the issue in this server and these are the common headers like content type which is defined by the server usually but also from the client authorization for making a request and authorizing to the server accept headers cache control user agent and there are more headers but these are the common ones then we also have HTTPS which is basically the same HTTP protocol but with some sort of TLS or SSL encryption which means that our data is now protected in transit when we are making requests so it adds a security layer through this TLS or SSL certificates and the encryption and it protects data in the transit and benefits of HTTPS is obviously your data is encrypted in the transit it comes with data integrity and you also authenticate users before providing any data and it also adds SEO benefits and you have many risks when you are using HTTP only without any encryption so the golden standard is to always use HTTPS in servers the next type of protocols are web sockets while we have HTTP which is very good at request response patterns sometimes HTTP has limitations for example let's say you're pulling some data let's say this is a user chat so you have the client and server on the client side you have the user chat and on the server you have the messages between two users when one of the users messages the other it sends a request to the server to notify that a message has been sent and it receives a response from the server maybe the messages from the other users if they are any and then next time if you need to know if you have new messages you need to make again another request to the server and maybe you don't have any new messages so you will receive an empty response with no new data so this was basically a non-necessary request response cycle and you might request from some other time let's say from one minute and receive a response now you have some messages but it can be also empty again so this way is not ideal for real-time communication as you can see you get increased latency you waste some bandwidth with making requests that are empty and you also use the server resources without the need of making requests to the server and for such cases we have web sockets which solve this issue so in web socket you have usually a handshake that is happening within the first request and now you have both like two-side communication between client and the server which means that once the handshake is being made the server can independently decide to push data to the client let's say now you have two new messages on the server so a server can decide to send these messages to the client without even client requesting for it but client can still request data so if client needs some external data or more data from the server it can still make requests but server is now also able to independently push data to the client so this is what unlocks the real-time data with minimal latency as soon as you have some new data in the server it pushes the new data to the client and it also reduces the bandwidth usage by allowing bidirectional communication in client server model with HTTP you would make let's say new requests per five seconds or ten seconds to see if there are any new data in the server but in this scenario you don't make any more requests other than the first one and now whenever there are new data server will push it and whenever there are no data to be requested then you don't need to make unnecessary requests to the server the next very common type of protocol is advanced message queuing protocol which is an enterprise messaging protocol used for message queuing and guaranteeing delivery in this setup you usually have the producer which can be either a web service or payment system or something like that and on the other side you have the consumer which can be the processor of the payments or notification systems and stuff like that so producer publishes messages to the message broker and here is where you have the advanced message queuing protocol you have queues in the middle let's say one of these queues is for order processing so whenever a new order has been placed producer publishes a message to this queue and then whenever this consumer is free it can pull messages from this queue and start updating the inventory and data in the database this allows the consumer to only pull data from here whenever it has capacity and whenever this consumer is busy with some other tasks it leaves the message in the queue and then later on whenever it has some free capacity it will pull the message and start updating the data and when it comes to exchange types you have direct one-on-one exchange or fan out or topic-based communication and you will explore this more when we come to the message queuing section the other common type of protocol is grpc which works with protocol buffers this is a high performance rpc framework invented by google and it uses hdtp2 for transport meaning the second version of the hdtp this means that clients should support hdtp2 otherwise this can't be used between client and server but that's why this is most commonly used between servers so usually the client is another server and we have some other microservices communicating with each other with this grpc framework it mainly uses protocol buffers and it also comes with built-in streaming capacities because it uses hdtp2 so these are the most common types of api protocols there are many more but usually in 90% of cases you would see only these protocols and when choosing the right one you should mainly consider the interaction patterns usually by default you go with hdtp if it's just a request response cycle but if you're building something like real-time chat or some real-time communication then you would need to go with fab sockets the choice also depends from the performance requirements so if you have multiple servers microservices communicating with each other and there is an opportunity to use grpc for example then you can go with it to increase the performance and speed of the communication but it also comes down to client compatibility for example most browsers don't support the latest version of the hdtp that's why grpc isn't that very common for browser server communication it also comes down to the payload size meaning the volume of the data and encoding security needs based on the authentication encryption and so on and also the developer experience so the tooling and documentation and it also comes down to the developer experience because you're mostly going to work with this api and it needs to have good documentation and tooling for you to fully work with this type of api protocol so to recap we have explored the role of application protocols in network stop the hdtp and hdtps which are the most fundamental types of protocols fab sockets for real-time communication amqp which stands for advanced message queuing protocol which allows us to have asynchronous communication and adding message queues between the consumer and producer and also grpc which stands for google remote procedure call and the main advantage of this is that it's high performance rpc framework which uses hdtp2 for transport so we discussed the application layer which includes these protocols that we usually use for building api's but we don't know yet about this transport layer which includes the tcp and udp so in the next lesson we are going to discuss this layer and understand which of these transport layers whether tcp or udp are the best choice depending on the api that we are building most developers work with api's but never think about what's actually delivering those packets like how does it happen that the request is being made from client to server and how does this request go through the internet that's where the second layer comes in in the osi model which is the transport layer that has the tcp and udp inside of it these are both transport layer protocols meaning they handle how data moves from one machine to another over the network but both are doing it very differently in this lesson we'll learn about these transport layer protocols we'll start with tcp which is the reliable but slower version then we'll learn about the udp which is in short it's faster and unreliable version of tcp and we'll compare both of them and decide which one we need to choose based on the api requirements let's start with tcp which stands for transmission control protocol think of it like sending a packet with a received tracking and also signature that is required so when you set some packets over the internet you usually don't send all of it at once sometimes the data is larger let's say it's divided in three chunks so you need to send them separately the first chunk the second chunk and also the third chunk so in this case tcp guarantees delivery of all of these three chunks if one of these packets is lost or arrives out of order tcp will resent or reorder it it's also connection based which means that before sending any data it performs a three-way handshake which is establishing the connection between client and server it also orders these packets let's say the client receives the first packet first and third packet then the second packet it makes sure that it's reordered to first second and third this of course adds overhead but it ensures that it's accurate and reliable that's why api's that involve payments authentication or user data always use tcp on the other hand we have udp which stands for user datagram protocol it's fast and efficient but the downside of this is that it doesn't guarantee that all of the packets will arrive for example if you're sending four packets from the server to the client one of these packets might be lost and it won't be pushed to the client and udp won't make sure that this eventually gets delivered so there is no delivery guarantee there is also no handshake or connection or any sort of tracking but because of these trade-offs it is faster transmission and it comes with less overhead as it doesn't need to make sure that all of the packets are delivered or in the correct order for example in video calls udp can be the best protocol because if some information was cut in the middle or let's say you're in a call with someone and their internet connection lacks you don't need to receive that old connection or all data on what they said because you are in the call right now so udp is the go-to for video calls online games or live streams because if one of these packets drops it's still fine and you don't need to go back and re-send this packet you can just move on and send the next packets this is what the free step hand shake looks like in tcp as you can see the first step is that client sends a request to the server in the second step server syncs and acknowledges the request and in the first step the client acknowledges the server and this is where the connection is established between the client and server and now they can start sending data back and forth on top of this tcp protocol so in short tcp is the safer and reliable version of udp but it is slower and on the other hand udp is faster and lightweight but it is risky for example if one of the packets in between the source and destination is lost it doesn't re-send it so there is no guaranteed delivery but on the other hand if in tcp one of the packets is lost after some timeout it still resends the first packets and this way it guarantees that all data will be delivered compared to udp where some data might be lost but it will still keep going and when choosing between those two these are the main things that you need to look for if you need the connection to be safe and reliable then you need to go with tcp or if you need it to be fast lightweight but some data loss might be acceptable then you will need to go with udp for example it is best for using tcp in banking's emails payments and so on and on the other hand udp is mostly used in video streaming streaming gaming and so on these are the main things that you need to know about the application and transport layers and these are the only layers that will need to be used to building apis and in the next lesson we will learn about restful apis and how we usually design apis in restful format restful apis let different parts of a system talk to each other using the standard hgdp methods they are the most common way developers build and consume apis today and in this video you'll learn how to design clean rest apis by following the proven best practices so that you avoid creating messy and inconsistent patterns make the apis hard to use and maintain we'll start by learning about the architectural principles and constraints of restful apis about resource modeling and url design also the status codes and the error handling as well as filtering sorting and so on and we learn the best practices when using and developing restful apis let's start from the resource modeling resources are the core concepts in rest let's say you have the business domain which consists of the products orders and reviews when modeling these to a restful api you usually convert these into nulls and not verbs meaning that the product becomes products order becomes orders and same for the reviews these can be collections or individual items for example this first request which is to slash api slash products we'll return you the collection of products not a single product but on the other hand you could have slash products and slash specific id of a product which will return you the individual item and notice that we are using slash products when retrieving the collection of products and we are not using something like get products which will be not a best practice in restful apis as i mentioned we are using nulls here and not verbs so to fetch orders for example you don't define the url as get orders you just define it as slash orders and depending on the method that we'll use let's say it's a get method then you will retrieve the orders if it's a post method then you will create an order and so on so all the resources should be clearly identifiable through the URLs for instance this is an example of getting a collection this is an example of getting a specific item and also nested resources should be clear defined for example if you want to retrieve reviews for some specific product then we would assume that if you make a request to slash products slash id of that product and then slash reviews you would get the reviews for that specific product but in real world apis you rarely want to return all the results at once that's why we usually incorporate filtering sorting and pagination in apis so let's start from the filtering for example if you make a request to get all the products you usually add some query parameter which in this case you can see it's category so you're first of all filtering them by category and then also with the end sign you add that they should be in stock so the in stock should be true and this way you are only returning the items that you're going to display on the UI and you're not making some requests that will waste the bandwidth of this API and also it will be a huge response for you in the front-end site next you also have sorting in this case again it's controlled through the query parameters and query parameters are anything that start after the question mark in the URL so in this case you usually pass the sort attribute and this can be for example ascending by price or ascending by reviews or it can be also the descending order so based on this you will get the response from the API in a sorted order because if you for example have thousand items in the backend in the database you don't want to retrieve all of these in unsorted order to the front-end because let's say the front-end now needs to sort them by the price ascending this means that it needs to make requests to get all of the products which are these thousand items that you have in the database so that will be very inefficient that's why we do the sorting in the backend instead so your backend should support sorting functionality this way the front-end can just make a request to your backend and pass this sort query parameter and then that way it will get the sorted products to be displayed on the screen and next we also have pagination again with the query parameter you usually pass the page which you want to retrieve and also the limit because if you don't pass the limit then again it will give you all of the products starting from the page 2 till the end which can be a lot of items so you also pass some sort of limit and that limit is whatever you're going to display on the front-end and then based on that you will get the response and here let's say you fetched 10 items so you're going to display those 10 on the UI and then once they click on the next page you will make another request to the page 3 this time and you will get the next items from the server now usually we use page for pagination but there is another common attribute that is offset so some api is used offset instead of the page and they use this in combination with limit which basically means if you have thousand items so offset will tell the api from where to start counting these thousand items and the limit is the same as you have it here so it's basically limiting the number of items that you are getting from this offset to retrieve to the front-end and the last option you can also have this cursor based so instead of page and limit you would pass a cursor which will be the hash of the page you want to retrieve so this approach of adding filtering sorting and pagination comes with benefits so first of all it saved the bandwidth of your server it also improves the performance both in the server side and on the front-end side and it also gives the front-end more flexibility because now you can fetch only the things that you need and not some unnecessary data from the database now let's come to the http methods that rest api is used because they rely on http protocol and hence they are using the http methods especially for crowd operations so these are the most common types of crowd operations you would see in rest api's first of all we have the get method which is used for reading data from the api so this is for retrieving resources as you saw like retrieving the products retrieving the reviews and so on and the url usually looks like this you make a get request to the slash api slash version of the api slash the resource name and these type of requests are both safe and idempotent which basically means if you make a request to slash products two or three times you expect to receive the exact same output every time unless some new products obviously have been added to the database next we have the post method this is usually when you're creating a resource in your server the common example is again you will make the request to exact same endpoint as you have it for the get to create a collection but in this case instead of get you are using post method and this tells the api that you need to create a resource in the products and not retrieve them these type of requests change the state of the server they are adding a new item and also they are not idempotent which means that they are creating a resource so the first time you create a resource you will get the id of the first item that you created the second time you create it you will get the id of the second one and so on next we have the put and patch methods which are very similar where they are updating resources in your api but they do it a bit differently the put method replaces the whole resource whereas the patch method partially updates the resource in your apa now you can see that the request URL is exactly the same in both of their cases so it's to slash products slash id of a product you want to modify just in case of the put request it will take this whole product with the id of one two three and it will basically replace it with the new one that is coming from the front end whereas in case of the patch it will again take this item from the database with id one two three but it will update it partially let's say you just updated the title from the front end and you made the request it patch method so this will only update the title of this product and it will leave the other parts other properties unchanged and the last crowd operation is delete and we use delete method in this case and obviously as the name tells it deletes the resource from the database so again the URL is exactly the same as you have for modifying items it's to slash products slash id of the resource and in this case you are not passing anything in the request body so you are just making a delete request to this item and you are removing this from the database and each of these operations return you different status codes depending on how the request went whether it was successful or not for that we have status codes and error handling in restful apis so you should use the appropriate status codes when working with rest apis for example the 200 series are for successful requests for example 200 is okay 201 is resource has been created 204 is there is no content here let's say you made a request the previous request we were talking about to slash products slash some id of a product and you successfully retrieved this item this means that you also need to set the status code to 200 because the request has been successful in the other case where you're creating a product and you're making a post request to slash products this time you shouldn't respond with the same 200 code because 200 generally means that the status was okay but in 201 case it means that the resource has been created and in this case since you're creating a new product you should obviously respond with 201 status code meaning resource has been created you also have 300 series which are for redirection let's say you make a request to a URL and now this URL has been moved to somewhere else so it will respond with 300 series and it will redirect you to the new URL in 400 series we have the client errors so this is whenever your front end made a bed request or the user made a bed request for example 400 is a generic bed request in 401 we have unauthorized requests meaning the user is not authenticated to make this request for 404 we have not found so generally when you visit some URL or you make a request for some specific resource that doesn't exist you would get this 404 status code so for 400 case let's say you made request with invalid parameters or some wrong JSON format in this case you would get a generic 400 request but if a user makes a request to get some product which is let's say the product with this ID and it doesn't exist in the database after querying it then you should respond with 404 status code meaning that the resource has not been found and lastly we have 500 series these are things when error happens in your server so you don't know the exact reason and it's also not a client error meaning client requested everything properly and in this case we throw unexpected server side errors you generally respond with a server error message and you return the 500 status code along with it when it comes to best practices of RESTful APIs first of all notice that we are using plural nouns for all of the resources so instead of slash product we are using slash products for retrieving the products collection so you should always use the plural in this case also in the crowd operations we use the proper HTTP methods for example when making a request to delete users we expect to make a request to users slash ID of a user and not some post request to slash users slash ID so first of all the HTTP methods needs to be properly set up and also the URL we don't expect some random things like slash delete to delete a resource from the database as you saw we also support filtering sorting and pagination in good REST APIs not only pagination for example in this case we only have the page free but we cannot limit the amount of products that we want to retrieve whereas in this case we can fully control what we want to get from the API we want to get the items from page free we want this number of limit to be applied on the products and we also want to apply some sort like sorting to sort the price or sort by ratings and so on and also versionings in the RESTful APIs as you noticed in all of these requests they all come with a prefix which is slash API and then slash the ID of the API which is either V1, V2, V3 and so on so let's say in the future you migrate your API and you start using a bunch of new features but you also break something in the previous version one then if you use the versioning you won't break it on the front end because they can use the old version of your API and still use the old features and functionalities while you continue to develop the new version let's say version free and you support new features here and you might have broken something here but they are still using the old API so this doesn't impact the end users so to recap we learned about the REST architectural principles and constraints also about the resource modeling and URL design and how we model the business domain into the RESTful API domain also the status codes error handling and the proper methods to be used with the basic CRUD operations and lastly we covered the best practices for RESTful APIs that you should use to keep your APIs consistent and also predictable for other developers who are using it before we move on to the next section just knowing these CRUD operations and routes it's good as a starting point but if you've never built a RESTful API or GraphQL API at a lower level and implemented these concepts then this is not going to take you far you need to also do the practice other than the theory if you're a developer with one to five years of commercial experience based in US, Canada, Europe, Australia or New Zealand and you're stuck in junior to mid-level roles but you want to move into senior positions master API design and other concepts and start earning senior level salaries then you can apply to work with me one-on-one this is exactly what I help developers do inside of my mentorship program we take these concepts and apply them hands-on in real-world projects the same ways in your engineers will work in top companies so the first link in description is where you can apply but only apply if you're serious about advancing to senior roles otherwise our calendar is fully booked all the time and if your application doesn't seem like a good fit then unfortunately we'll have to cancel it traditional RESTful APIs offer return too much or too little data which requires us to do multiple requests for a single view to get all the data that we need GraphQL solves this issue by giving clients exactly what they requested for but designing GraphQL APIs is different from designing RESTful APIs that's why in this video we'll cover the core concepts of GraphQL and why it exists the schema design and type system of GraphQL queries and mutations error handling and also best practices for designing GraphQL APIs let's start by understanding why GraphQL exists in the first place it was created by Facebook to solve a very specific pain which is clients needing to make multiple API calls and still not getting the exact data that they needed for example if we imagine we have the Facebook APIs like user API post API comments and likes for the Facebook page most of the times client can make requests to all of these APIs separately and still not get all the data that it needs which will require it to do multiple requests to the same API this of course adds up to the overall latency of the page because the page is still not loaded until all of these requests are made and the data is fetched but in case of GraphQL APIs you have a single GraphQL endpoint so the client specifies the shape of the response and this one endpoint handles all of the data interactions it is still an HTTP request but as you can see we can specify the exact data that we need for example we need the user with ID123 and we need only the name of the user also posts and from the posts we can specify only title so we don't need the images for this view and again with the comments you can specify the exact data that you need within the object so that you are not doing over fetching of the data now let's see the schema design and type system of GraphQL and how it's different from RESTful APIs the schema in this case is a contract between the client and server in schema first of all you have types which can be for example user type that you specify and you specify all the fields that exist on this user type which are ID name posts and so on and as you can see if the type is not a primitive type like posts then you can specify another type of post array and then this post type can be defined separately next we have queries to read data so this is the equivalent of doing get requests in RESTful API you specify the query and function of the query this can be the user query which fetches the user with specific ID and also the return type of the query which in this case is the user type that we defined above and GraphQL also comes with mutations you can think of this as the equivalent to post, put, patch and delete methods in RESTful APIs so anytime you are mutating data in the database you are making mutation query here as you can see we have an example of create user method which accepts name and of course many things in real world and then it returns the user type that we have defined above so if you have good schema design in GraphQL it should mirror your domain model and it should be intuitive and flexible next once you define the schema design and type system you can start querying and mutating data with this GraphQL API for that we have queries for fetching data again this is like the get requests in RESTful APIs and here you can specify exactly what you need from the user this is the same user method that we defined there in the schema so here you can also specify the exact attributes like the name posts and from posts you need the title only and this will make a request to your GraphQL API and return the exact data that you requested similarly you can also use the mutations that you defined for example if you have a create post method defined as a mutation you can use this to mutate the post for example setting the title and body of the post and then you also specify what data you need to retrieve after this post is created which is ID and title when it comes to error handling in GraphQL APIs this is a bit different than in RESTful APIs since GraphQL always returns 200 okay status for all responses even if there was an error in this case we have to return errors field in the response which will indicate that there was an error so partial data can still be returned with errors like in this case we have the user which is null and then we have the errors field which indicates that you have the status code 404 message not found and path which is the user in your schema as you can see in this case you can specify the status code in the errors array since we are returning 200 status codes for all GraphQL requests that's why we have the status code specifically mentioned in the errors so that we know what kind of error this is which is user not found there are also best practices that we normally follow when designing GraphQL APIs first of all the schemas that we saw it's a good practice to keep them small and modular also we should avoid deeply nested queries for example you can have a user and then nested post and then within the post you can have a comment so this can be infinitely nested and to avoid that we usually implement query limit depth which is how depth you can go like how many layers nested you can have in your data so you specify something like six or seven layers deep you also use meaningful naming for types and fields so that it also makes from the client side because they both are going to use the same schema and when mutating data we always use the input types for mutations before a system can authorize or restrict anything it first needs to know the identity of the requester that's what authentication does it verifies that the person or system trying to access your app is legit and in this video you'll learn how modern applications and the authentication from basic to bearer tokens to oof to authentication and gvt tokens as well as access and refresh tokens and also single sign-on and identity protocols before learning the different types let's first understand what is authentication authentication basically answers who the user is and if they are allowed to access your system so whenever a login request is sent either by the user or another service this is where we confirm the identity of the user and either provide them access so approve their request or reject it with unauthorized request this is basically the first step before authorization begins which is the topic of the next lesson so before you access any data or perform any actions on this service the system needs to know who you are and this is where the authentication is used the first and simplest type of authentication is basic authentication this is where you use username and password in combination and you send a login request which contains the base 64 encoded version of username and password this is a very simple way of encoding data and it's easily reversible and because it's easily reversible it's now considered insecure unless it's wrapped within HTTPS but even with that it is now very rarely used outside of the internal tools in the company next we have bearer tokens which are more secure compared to basic authentication here you send the access token with each request instead of the username and password encoding so whenever the client needs to access resources they send this token within the request and then your API verifies or rejects the token and if it verifies then you send the successful response with the data that they requested bearer tokens are the standard approach nowadays especially in API design because it is fast and stateless which makes it easy to scale those APIs the next type is OAuth 2 authentication in combination with GVT tokens so OAuth 2 is a protocol which is the second version of OAuth it lets users log in through a trusted provider like Google or GitHub so user sends a request to access your resources and if you allow them to authenticate with Google basically Google sends your app GVT token which contains the information of this user this is how that payload will look like usually they send you the user ID or the email the username and more stuff and also the expiration date for this GVT tokens this is a signed object which then you pass from your app to the API and then your API will authenticate based on this information GVTs are also stateless similar to bearer tokens which means that you don't need to store sessions between their requests and each request can be executed separately next we also have access and refresh types of tokens so modern systems use short-lived access tokens which expire faster and also long-lived refresh tokens which usually expire later than the access tokens access tokens are used for API calls so whenever you want to get some data from the API you send this access token to access the data and refresh tokens on the other hand are used to renew the access tokens so whenever the access token expires this is where you will use the refresh token to get a new one a new access token behind the scenes so this way users won't be logged out they will stay logged in and also your system will stay secure because you are frequently renewing this access token and one note here is that you should typically keep the refresh tokens in the server site for security reasons and lastly we have SSO which stands for single sign-on and identity protocols that are used with it single sign-on lets users to have one login so login once and access multiple services for example when you log into google you can access both Gmail, drive and also calendar and all of their other services and behind the scenes this SSO uses either SAML protocol or OAuth 2 protocol OAuth 2 is used more often nowadays for the modern applications to login with google or with github or any other service provider it is a modern and JSON based and on the other hand SAML protocol uses XML based approach but still SAML is very popular in the legacy systems and in companies that use things like Salesforce or internal dashboards so these are identity protocols which means that they will define how apps securely exchange the user login information between each other but authentication is just the first step before users can access your service so this tells you who the user is and if they are allowed to access your service that is when they send a login request and you confirm or deny their identity but after that you also have the authorization step which tells you what resources exactly this user can access to basically tells you what they can do what the user can do in your system and that is what we will cover next in the next video before getting into authorization there is a difference between how juniors would implement such authentication models and how seniors would implement it senior developers know that authentication is about securing tokens refresh flows and preventing attacks and they also build it in a secure way while considering the trade-offs if you only know the theory then companies will see it right through you and if you want to implement those at a lower level with my guidance and one-on-one support then that's why we have the mentorship program if you're a developer with one to five years of commercial experience based in us Canada Europe Australia or New Zealand and you're stuck in junior to mid-level roles but you want to move into senior positions master API design and other concepts and start earning senior level salaries then you can apply to work with me one-on-one this is exactly what I help developers do inside of my mentorship program we take these concepts and apply them hands-on in real-world projects the same way senior engineers will work in top companies so the first link in description is where you can apply but only apply if you're serious about advancing to senior roles otherwise our calendar is fully booked all the time and if your application doesn't seem like a good fit then unfortunately we'll have to cancel it authorization is the step that happens after authentication once someone is logging in into our system so once the login request is approved which means that the system now knows who the user is the next step is deciding what they can do which is the step of authorization it needs to check what resources or actions that user has permissions to access and also what are the denied actions for this user this is how we control security and privacy in the systems and in this video you learn how applications and systems manage permissions using the three main authorization models the first one is role-based access control next we have attribute-based access control also access control list which is another way of managing authorization plus you learn how technologies like OAuth 2 and GVTs help us to enforce those rules in practice so authentication happens first which tells us who the user is and if they are allowed to access our system but on the next step we have authorization which determines what you can actually do as a user in this system if we take a look at key top as an example and accessing repositories on github there you have different permissions for different users for example user a can have right access only which means they can only push code to this repo but on the other hand we can have user b and here you can ground only read access which means they can only read this repository but they cannot push code to it or they cannot create pull requests and on the other side we can have also admin users which have full control so they can manage all the settings for the repository they can either decide to delete this repository and so on so you can see that different users can have different access controls on systems to manage these access controls we have common authorization models so the one that we just looked at is the role-based authentication model which assigns roles to users something like admin editor or read-only access right-only access and this is the most common approach among these authorization models but we also have attribute-based access control which is based on the user or resource attributes so this is more flexible and more complex compared to the role-based authentication and the other common approach is to have access control lists ACL and each resource here has its own permissions list so you can assign permission lists to a resource and this is what will determine what resources you can access for example this is a common way of managing google docs and we will look at this in more detail now and each of these models has its trade-offs pros and cons so these depends on the specific system requirements but real systems often combine also multiple models together to have more complex and more secure setup so first up we have role-based access control or RBAC as an acronym here users are assigned to roles and each role has a defined set of permissions for example as you saw with the github you can have admins and admins usually full access to all resources so they can create they can read or update resources they can even delete resources and also manage other users in the roles and next you have editor which is usually a bit less than admin so they can edit content like creating or reading content or updating resources but they cannot delete resources and they cannot also manage other users and next you can have viewer users which can only read data so they can read the resources and content but they cannot update anything or they cannot create anything in your system this is the most common way in authorization models and this is used in apps that you use daily like you saw with github or stride dashboards or cms tools team management tools and so on the next model is attribute-based access control or ABAC in short this access control goes beyond the roles so it uses the user attributes or resource attributes and environment conditions to define the access some example policy you can see here let's say you want to only allow access if some conditions are met in this case whenever the user department is set to HR and you can combine this with multiple conditions like whenever the resource attribute equals to internal and so on and only in this case you allow them access and you either allow them read access or write access so this can also be combined with the role-based authorization but in this case you are checking the user model or resource model in your database and based on the attributes you either allow or deny the access so here as you can see we are checking user attributes like the department age or whatever you want to check here next you can also combine it with resource attributes like confidentiality or the owner of the resource or classification and this can also be combined with environment like time of the day location device type and so on since you're combining these attributes to either ground or restrict access this is more flexible than the role-based authorization but it requires good policy management and generally it's more complex and you can encounter conflicts here with the attribute-based access control the third common type is the access control lists instead of providing role-based access or attribute-based access you can have access control list for the specific resource let's say you have a resource like a document or a JSON file and here you can have a permission list on which users can access this document like user-allies has only read access or user-bob has both read and write access and another user has no access to this document so as you can see we're managing two things here first of all which users are allowed to access this document and second what are their permissions so each of the users has different permissions on this document ACLs are highly specific and also user-centric which means it's hard to scale them well in systems with millions of users or objects unless you manage them carefully but for example google drive is one example of this where you have documents like a google doc and then you share this google doc with your colleagues right so you share someone with read access only and then you share this doc with someone else but now they can also edit and add comments to this document so this is a example of ACL access control list which is used in google drive and google documents this gives you more control over resources and documents but it's also harder to scale with millions of users but it's possible as you can see because google drive is using this for their documents excel sheets and so on so these were the access control models but how do systems enforce those authorizations these are where oaf2 and gvt or access tokens come into play so first we have oaf2 which is delegated authorization which is a protocol used when service wants to access another services resources on behalf of a user for example if you want to let a third party up read your github repositories let's say you're deploying your up to versatile so you need to give versatile control over your repository on github instead of giving your username and password to the third party application which won't be secure at all because you don't know what they can do with your username and password this way you are giving them full control instead github gives them the token that represents the permissions which you approved to use so you as a user send the request with the third party up to request access to your repositories and then github gives you the access token which you should create so you should also provide what resources what repositories this third party up can access and also what they can do can they create read update or can they delete or whatever the permissions you set and then github sends them the token which contains the permissions which this third party up is allowed to use and oaf2 defines the flow for securely issuing and validating those tokens so you give them the access token and not your password which represents the permissions that you approved personally so it can be reading specific repos or also creating pushing to those repositories but not deleting those repositories and next we have also token based authorization using gvt or bearer tokens and permission logic once a user is authenticated most systems use a token typically a gvt token or this can be also bearer token that carries this information like user id the roles like admin or editor and also scopes which is what scopes they are allowed to access and whenever this token is expiring and who is the issuer of this token so whenever a user makes a request it always carries this token information and reaches to the beckon server this is where the server will check your token and validity and it will apply the appropriate permission logic so to not confuse this with authorization models there is a key distinction the token usually carries the identity and claims of your user as you see it here but authorization models like role-based or attribute-based this is what defines what is allowed to access as a user so tokens are just mechanisms while these are authorization models so in summary authorization isn't just letting users in like authentication but it also controls what they can access once they are in we learned what authorization is what are the three most common authorization models which are role-based attribute-based and access control lists and also you saw a couple of real-world examples like how github manages your authorization tokens and this should give you an idea on when to use each model based on the system that you're building and you also saw some implementation patterns with oof2 or gvt tokens each of these models has their own trade-offs their own pros and cons and real systems often combine multiple models to stay flexible and secure APIs are like tours into your system if you leave them unprotected then attackers and anyone can walk right in and do whatever they want with your user data and overall the system that's why in today's video we'll look at seven proven techniques which will help you to protect your APIs from unwanted attacks the first one we have in the list is rate limiting which controls how many requests a client can make in a given time for example you can set a limit for user a to make let's say 100 requests per some period of time to your API and if they cross that limit and let's say make hundred and one requests then you block the next request and allow some time to pass before they can send their next request if you don't set this to your API then attackers can overwhelm your system they can send like thousands of requests per minute and then overwhelm your API which will take your system down or it can also brute force your data and these rate limits can be set per endpoint for instance let's say you have some slash comments endpoint and here they can send a request to either create a comment or fetch comments you can set that limit for endpoint level so these comments endpoint will be set to some strict number of requests per minute you can also set it per user or IP address let's say nay we have the IP address of first user and then before the second see for this one and your attacker has some IP address which corresponds to the if you get the 101 request from the IP address then you will know that this user overused the API so you will block it at the user IP level and there is also overall rate limiting to protect from the deals attacks since you can set the rate limit to work per user or per IP address that means that this attacker alone cannot send that many requests you will block it with your rate limiting in the API but what they can do is they can spin up some bots and each bot will have their own limit right let's say you've set it to 100 per IP address so each of these bots has 100 and overall they have more than you would allow or your system could handle that's why you have also overall rate limiting which can be some bigger number so whenever all the traffic coming into your server reaches or passes this number then you will temporarily block all requests until you find out the root cause and of course these numbers are just examples so in reality it's much more than 1000 but that's just an example the second one on the list is course which stands for cross origin resource sharing this controls which domain can call your API from a browser and without proper course malicious websites could treat users browsers into making requests on their behalf for instance if your API is only meant to serve your front and up which is at up dot your domain dot com then only requests from this source should be allowed if anyone else sends your request like up another domain dot com then you should block this request and not allow them to use your API for authenticating or using any of its data the third one is also a common one which is SQL and no SQL injections injection attacks can happen when the user input is directly included in the database query for instance attacker can modify it and send some queries to read or delete your data here for example this part bypasses the checks entirely and then attacker can use this query to start reading data from your database or modify anything or they can also delete all the data all the user data and any other tables that you have in this database so to fix this we always use parametrized queries or ORM safeguards the next technique to use is firewalls firewall acts as a gatekeeper filtering the malicious traffic from the other normal traffic so typically you have it between your API and the incoming traffic for example if you use the AWS's web application firewall these can block requests with unknown attack patterns such as suspicious SQL keywords or strange HTTP methods which means it will block any suspicious requests from attackers but it will allow others to bypass the request and reach to your API some APIs are also private and should only be accessed from specific networks that's why we have also VPS which stands for virtual private networks the APIs that are within the VPN network can only be accessed by someone who is also within that same network which means that some APIs are public facing meaning these APIs will allow any requests from the internet from your users but this for example can be within the VPN network which means if a user from web tries to reach your API then this request will be blocked because the user is not within the same network but on the other hand if you have another user here which is within the VPN network they can make a request to these APIs and in this case they will bypass the checks and their request will reach to your APIs this is useful where you have internal tools let's say you have internal admin dashboard and the API for this admin panel will only be reachable by employees connected to the company VPN next we have CSRF which stands for cross-site request forgery these tricks are logged in user's browser into making unwanted requests to the API let's say you as a user are logged in into your bank system and your bank system uses cookies for authentication if the bank system is not secure and they only use session cookies another malicious site might use your cookie and submit a hidden transferring money request through your cookie so to prevent such a tax companies also use CSRF tokens in combination with session cookie so the banking system will check if the session cookie is present but it will also check if the CSRF token matches with the one that they have and if it doesn't then it will block this request from the other unknown source while it will allow request from your behalf and the last one we have is XSS or it's also called cross-site scripting these leads attackers to inject scripts into web pages served to other users for example if you have a comment section and this comment gets submitted to your API next your API will also store it in a database you can get normal requests like nice picture or something like that and this will get to your API your API will store it in the database so everything is fine there but what if an attacker places a script in this comments section and within this script they can try to do many different things for example they can try to fetch the cookie for another user or they can try to inject something into your database and if you allow this then it will reach to your server and the information will be written into the database later when the other users load this comments section on their screen they will get also the injected comment directly into their webpage and the browser will execute this malicious javascript code into the other browser before ending the video again reminding you about the mentorship program if you're a developer with one to five years of commercial experience based in us Canada Europe Australia or New Zealand and you're stuck in junior to mid-level roles but you want to move into senior positions master API design and other concepts and start earning senior level salaries then you can apply to work with me one-on-one this is exactly what i help developers do inside of my mentorship program we take these concepts and apply them hands-on in real-world projects the same way senior engineers will work in top companies so the first link in description is where you can apply but only apply if you're serious about advancing to senior roles otherwise our calendar is fully booked all the time and if your application doesn't seem like a good fit then unfortunately we'll have to cancel it
