Timestamp: 2025-09-11T16:33:37.073805
Title: How He Ships Side Projects with Claude Code KZN6ul6zLvk
URL: https://youtube.com/watch?v=KZN6ul6zLvk&si=HCr9lDL1es_OpkZp
Status: success
Duration: 30:01

Description:
**核心结论:** AI编码工具通过提供更高级别的抽象和自动化，使开发人员能够在有限的时间内更高效地工作，从而实现增量式的进步并开启全新的项目和应用场景。

**内容大纲与总结:**

**I. 引言：AI编码工具对开发者日程的变革**
    A. **核心观点:** AI编码工具显著提升开发速度，尤其适用于面临时间碎片化挑战的开发者（如兼顾会议的管理者或有家庭责任的父母）。
    B. **背景与痛点:** 在传统编码模式下，短暂的空闲时间（如15分钟）往往因启动成本高昂而被浪费；AI工具将"管理者日程"转变为"创造者日程"。

**II. AI编码工具的关键优势**
    A. **提高生产力与效率:**
        1. **应对碎片时间:** 允许在中断的时间段内进行编码，使短时投入也能产出成果。
        2. **降低心理门槛:** 减少编码前的阅读和编写工作量，激发开发者承担更具挑战性的项目，减少拖延。
    B. **自动化与简化任务:**
        1. **内容处理自动化:** 例如，为大量博客文章生成摘要，帮助快速了解公司焦点和发展轨迹。
        2. **自定义解析器生成:** 自动编写用于提取网页元数据（如作者、发布日期、标题）的解析器，适应不同网站的CSS结构变化。
        3. **代码库维护:** 辅助识别和移除代码库中的遗留代码及其依赖项，尤其在大型项目中提升效率。
    C. **成本效益与技术普及:**
        1. **本地LLM应用:** 利用本地模型（如Olama）处理大量文本摘要任务，显著降低API调用成本。
        2. **降低学习曲线:** 开发者无需深入学习特定代码库或框架即可使用，通过AI工具解释和应用新知识（例如使用Pygame开发游戏）。
    D. **抽象层次的提升:**
        1. **类比语言演进:** 类似于从低级语言（如C）到高级语言（如PHP、Ruby）的转变，AI工具让开发者能够解决更高层次的问题，摆脱底层细节。
        2. **赋能创新:** 降低开发门槛，使构建针对小众市场或个人兴趣的项目变得可行，如同电动自行车拓展了出行方式。

**III. 实践案例：Matt MacKay的Plush Cap项目**
    A. **项目介绍:** Plush Cap是一个分析面向开发者公司的市场推广活动的工具。
    B. **LLM应用实例:**
        1. **博客内容摘要:** LLM生成公司博客文章的单段摘要，用于快速理解其发布重点。
        2. **解析器开发:** 使用AI生成和维护用于从公司博客中提取结构化数据的自定义解析器，应对不同网站的布局变化。
        3. **测试与验证:** AI工具能够根据多个示例URL测试解析器的健壮性，确保数据提取的准确性。

**IV. 使用AI编码工具的挑战与考量**
    A. **技术债务问题:** AI工具可能复制现有代码库中的错误设计模式，反而加剧技术债务。
    B. **架构决策局限性:** AI在提出重大架构性改变时表现不佳，其建议可能不切实际，需要人工监督和否决。
    C. **人工干预与审查的必要性:**
        1. **Git工作流:** Git提交、代码审查和部署等关键环节仍需人工控制，以确保代码质量和系统稳定性。
        2. **文件清理:** AI生成的代码可能留下未清理的文件，需要人工介入。
    D. **“双重现实”的辩论:** AI编码工具的实际效果和价值因个人经验、项目背景、时间和使用方式的不同而差异巨大，没有普适的单一结论。
    E. **行业未来展望:**
        1. **并非取代:** 历史表明，新工具的出现往往导致软件复杂性增加，而非取代程序员。
        2. **创造新机遇:** 未来将出现大量新的工具和服务来管理因AI辅助开发而产生的更复杂系统。

**V. 个人工作流与建议**
    A. **Matt的工作环境:** 利用Tmux和Vim进行多任务处理，通过不同颜色区分项目，避免混淆。
    B. **多代理策略:** 同时使用2-3个AI代理处理代码库的不同独立组件（如数据收集、Web应用、重构），通过API接口进行交互。
    C. **对开发者的建议:**
        1. **从兴趣项目入手:** 选择一个有趣且即便失败也无妨的副项目来探索和学习AI编码工具。
        2. **持续学习:** 结合YouTube教程和AI解释来不断扩展技能栈。
        3. **享受过程:** AI工具使编码变得更具乐趣和可行性，让开发者能持续投入热爱的工作。

---

<Mermaid_Diagram>
graph LR
    subgraph "核心概念 Core Concepts"
        A["AI编码工具 (LLM)"]
        B["开发者 (管理者/父母)"]
        C["有限时间/碎片化"]
    end

    subgraph "关键优势 Key Benefits"
        D["生产力提升 Productivity Boost"]
        E["“创造者日程” Maker Schedule"]
        F["降低拖延，激发雄心 Reduce Procrastination, Increase Ambition"]
        G["自动化重复任务 Automate Repetitive Tasks"]
        H["降低学习曲线 Lower Learning Curve"]
        I["开辟新项目/应用 Unlock New Projects/Apps"]
        J["享受编码乐趣 Enjoy Coding"]
    end

    subgraph "应用示例 Application Examples"
        K["Plush Cap项目 Plush Cap Project"]
        L["编写自定义解析器 Write Custom Parsers"]
        M["生成博客摘要 Generate Blog Summaries"]
        N["代码库重构 Refactor Codebase"]
        O["本地LLM (Olama) Local LLM (Olama)"]
    end

    subgraph "挑战与考量 Challenges & Considerations"
        P["技术债风险 Tech Debt Risk"]
        Q["架构决策薄弱 Weak Architectural Decisions"]
        R["人工审查与控制 Manual Review & Control"]
    end

    subgraph "宏观影响 Macro Impact"
        S["抽象层次提升 Higher Abstraction Level"]
        T["软件复杂性增加 Increased Software Complexity"]
        U["新机遇与就业 New Opportunities & Jobs"]
    end

    B --> C;
    C --> A;
    A --> D;
    A --> E;
    A --> F;
    A --> G;
    A --> H;
    A --> I;
    A --> J;

    G --> L;
    G --> M;
    G --> N;
    A --> O;

    A --> P;
    A --> Q;
    P --> R;
    Q --> R;

    A --> S;
    S --> T;
    S --> U;
    T --> U;

    K -- "应用场景 Applied To" --> L;
    K -- "应用场景 Applied To" --> M;
    K -- "采用 Uses" --> A;

    style A fill:#D6EAF8,stroke:#3498DB,stroke-width:2px,color:#2C3E50;
    style B fill:#E8DAEF,stroke:#8E44AD,stroke-width:1.5px,color:#2C3E50;
    style C fill:#FADBD8,stroke:#C0392B,stroke-width:1.5px,color:#2C3E50;

    style D fill:#D4EFDF,stroke:#2ECC71,stroke-width:1px,color:#2C3E50;
    style E fill:#D4EFDF,stroke:#2ECC71,stroke-width:1px,color:#2C3E50;
    style F fill:#D4EFDF,stroke:#2ECC71,stroke-width:1px,color:#2C3E50;
    style G fill:#D4EFDF,stroke:#2ECC71,stroke-width:1px,color:#2C3E50;
    style H fill:#D4EFDF,stroke:#2ECC71,stroke-width:1px,color:#2C3E50;
    style I fill:#D4EFDF,stroke:#2ECC71,stroke-width:1px,color:#2C3E50;
    style J fill:#D4EFDF,stroke:#2ECC71,stroke-width:1px,color:#2C3E50;

    style K fill:#FCF3CF,stroke:#F4D03F,stroke-width:1px,color:#2C3E50;
    style L fill:#FCF3CF,stroke:#F4D03F,stroke-width:1px,color:#2C3E50;
    style M fill:#FCF3CF,stroke:#F4D03F,stroke-width:1px,color:#2C3E50;
    style N fill:#FCF3CF,stroke:#F4D03F,stroke-width:1px,color:#2C3E50;
    style O fill:#FCF3CF,stroke:#F4D03F,stroke-width:1px,color:#2C3E50;

    style P fill:#F2D7D5,stroke:#E74C3C,stroke-width:1.5px,color:#2C3E50;
    style Q fill:#F2D7D5,stroke:#E74C3C,stroke-width:1.5px,color:#2C3E50;
    style R fill:#D1ECF1,stroke:#3498DB,stroke-width:1px,color:#2C3E50;

    style S fill:#EBF5FB,stroke:#5DADE2,stroke-width:1px,color:#2C3E50;
    style T fill:#EBF5FB,stroke:#5DADE2,stroke-width:1px,color:#2C3E50;
    style U fill:#EBF5FB,stroke:#5DADE2,stroke-width:1px,color:#2C3E50;
</Mermaid_Diagram>

Content:
 You know, I think there's a lot of questions around like, does this actually help you to move faster? I think so much of that depends on your situation. For me, I'm in meetings like often eight or nine hours a day. So if I can spin up a bunch of stuff that's like working and occasionally take a look at it and be like, oh, okay, cool. You know, or that looks good. I can get a lot more done. Paul Graham wrote this essay what 16 years ago maker schedule manager schedule. I actually think that LOM coding tools can make a manager schedule into a maker schedule. It allows you to code in interrupted time. If you're a parent and you're trying to ship your project on nights and weekends and you've only got 15 minutes, I have generally found that I do not use the 15 minutes if I'm coding by hand because it's just overwhelming the amount of code I need to read and write in order to ship a small thing. I literally will steal this phrase from like, Arm and Ronecker who's like the creator of flask. I am more ambitious when I use the AI coding tools. I procrastinate less. I'm like, I'm just going to go write that prompt and then it'll start and then I'm hooked. Then I want to finish that thing and I want to ship it. Hey, all I'm Greg and this is a conversation I have my good friend, Matt MacKay and excited to share with you all. It was a pretty long conversation and I edited it down to like the really juicy parts. I don't know if this is quite the right way to do these interviews in the future or not, but let me know what you think of the format. I try to keep it really, really dense. Also, just wanted to give a shout out to MacKay because at the beginning of this year, I set a goal to get from zero to 10,000 YouTube subscribers and I just hit that goal. And so thank you for watching. But also thank you to Matt because when he was working as VP of Debrell at Assembly AI, he hired me to do some YouTube work for their channel and that was one of the first times that I had worked with a real professional crew producing content for the YouTube channel. And I learned so much and it's because of him and because of his site, plush cap that I really looked at the YouTube channels that were out there for DevTool companies and felt like there was a big opportunity to create my own channel. So Matt's been a really big part of my journey this year. And so it's really quite an honor to have this conversation with him and to publish this video as the first one I'm publishing after I hit that goal, 10,000 subscribers. My name is Matt MacKay. I'm the VP of Developer Relations at DigitalOcean. I was with Twilio for many years with you, Greg, running developer evangelism, developer content. And I was a professional software developer, purely a professional software developer for over 10 years. And I still code nights, weekends, whenever I get the chance when I'm not in meetings. And using AI agents and AI coding tools has completely changed how much I'm able to code, particularly on side projects. Tell me about plush cap. Plush cap is an analyzer for go-to-market motions for self-service developer-focused companies. So we think about developer tool companies. Anyone, any company that is targeting software developers as their primary audience, their paying customer, that's really what this tool is analyzing. Let's take a look at like DigitalOcean's blog. If we take a look at like January, all of these summaries have been generated by an LLM. And this is what I typically do if I'm trying to get up to speed on what a company is doing. I'll just read, I'll just consume a one paragraph summary on everything that they have posted on their blog. And then I can absorb, you know, 100 blog posts in just a few minutes. And it gives me kind of an arc of like what the company is focusing on, like what you choose to publish to your blog and announce to the public, is often a reflection of what the company's priorities are and where they're investing. You know, I've got 500 different companies across plush cap, and I've found that writing parsers for every single company is actually what needs to happen. So I was previously writing these by hand. I've written like 150 of them by hand. And what they do is they pull out things like CSS attributes of like, who's the author, who's the, what's the publish date, what's the title. Now I have a cloud code right the, the individual parsers date published is correct, but the author returned as none when it should be. And then I'll copy and based in. And then here are some more example URLs to test with, and then I'll give it like a whole list. So I'll just, I'll just go pull a bunch of them. Blog, blog, blog. Okay. And then I'll just paste these in. So now it is just going to go basically grab that. And I'm sure like people use like fire crawl and all sorts of other tools, but like this is just like vanilla. A cloud that I've been, I've been using to just like grab, grab files. So it's just going to, since normally what I do is I have a long running session with a lot of different where I'm just like, here's a blog post, here's a blog post, here's a blog post, and it'll just, it has all the context ready so it'll just go and, and write the custom implementation. And so like I'll just do yes proceed, it's going to go grab that that URL. It's checking to see. So what it's going to find is that there's no existing custom implementation. It's using like, there's basically like a generic implementation for extracting the metadata from company blog posts. And it needs, it realizes like, Oh, I actually need to go and write a custom implementation that'll pull the author properly. And there's enough variations across all these different companies that, you know, the way that their blogs are structured the CSS like a zillion different things that you kind of end up, if you want to pull enough metadata reliably. Like that the keywords reliably pull metadata. You essentially need custom implementations for these things. And then you also need to really watch so that you're not pulling bad data along the way because companies will, you know, update their blogs, their blog designs. Now the problem is, is like, even if like five companies update their blog designed by month. You know, out of the 500 that's still like pretty annoying. So I was updating all those by hand in order to get the right metadata before. So now I can just go tell Claude to be able to go do that and just like there's already an architecture and a structure behind scraping these these blog posts. Okay, so now it's going to update. It's going to create like an update dbt.yaml file, which is like basically like there's these custom parsers that are that will know how to pull the proper data out of the blog post. So it's implementing the fix. It's going to go test it with a bunch of URLs and I actually find that this is really key. So it really needs, I think, a list of blog posts to test against because the naive implementation is just to go. Okay, I want to go get the CSS class and then I call it a day or whatever, but then it won't be consistent across a lot of the blog posts. So here it's looping through all the different URLs that I've given it and testing it and making sure like yep, pull the author correctly, pulled the date published, pulled the title across every single one. So if you admit there's variations, it'll then create a more generic, it'll either create a more, it'll create like out routes like exception handling for like different types. And what's funny is that's what I was doing by hand. I found that there was enough variations across these blog posts. Some companies have several different styles to blog posts, or they won't publish dates on all them, or the date or they won't publish authors. There's all these different permutations even for a single company. And so by giving it a bunch of examples to make sure that it can test properly, then it can actually make sure that the implementation is what it needs to be. Okay, so now we can go back. And we'll just rerun this and what we'll do is we'll do a force update. Now we can see extracted author is Bruno, the date is correct, it pulled the word count, and essentially like now it's correct because it's got this custom implementation. So the cool part is to now we can go and go pull another one, right. And that worked. And then we can go pull another one. And normally what I would do is I just drop all these URLs into like a file and I'll just go pull them all down. But now, you know, I like test a few of them. And so now if we go back to the DPT blog, we'll see that there's a few of them here, and they're all structured with the data here. So that's how just like, you know, have Claude go and run and implement a custom parser for this. And of course, like you can map this across like the whole code base, right? Like I've got established patterns. Go copy this pattern and apply it across different, you know, areas or something that I'm thinking about. Okay, so now Claude's written a custom scraper for you. What kind of you've manually tested that on a few different use cases and you're getting the results you want. Now I assume it's time to commit. What, how do you do that? Are you like, can you walk me through like what you would do now and like lock in these changes that it's made. Yeah, so there's like, you know, on the command line, I'll just take a look blog post manager. So it's made some changes to the blog post extractor. This was actually from a previous thing when I was doing with LaunchDarkly so I kind of combined a couple of changes here but typically, you know, be a little bit better about the separating them out. And then really this is the one that actually matters. I could probably just commit this separately, which is just the DBT custom like YAML. So, so then I'll just do get add. I commit updating, you know, like DBT implementation push the change. Now this is just a script change so I just run these in the background. I don't run these on the same server but if there was a code change on the server like I'm updating a template or something like that, then I just have like a one like script that'll just go and deploy the changes. I run supervisor on a digital ocean droplet. And so it'll just show all the new changes. The other way is like, I actually do like something like database migrations and then I have like a separate like deploy for that because that's obviously a more involved set of steps. Like most of the time what you want to do is you want to just like ship incrementally a bunch of changes really quickly. And so like you want the simplest possible deploy. If there's a more complicated deploy, then, you know, I can run all the scripts that are related to that, or even just have like a Ansible playbook that'll handle that. I actually don't have Claude doing the deploys, mostly because again like I've already written all that stuff myself. So I don't need it to like update a lot of that stuff. So this is where it's like a little bit of a hybrid of like, I already have a lot of established infrastructure and that is infrastructure works well. There's nothing broken about it. What I need is the speed and the iteration of like creating new pages, fixing when companies have changed their CSS designs. And now I can't accurately reliably pull their data. And for that it's really good. Right. It's just, it's just updating things within the scaffolding that I've already said. Any particular reason why you are still doing all of the get actions as opposed to having Claude do that. Well, first off, I found it to be slower. And I use the get actions to check the code before it's committed. Right. So that is my step. That is like my manual like, let me make sure that I'm committing the things that are appropriate because I've actually found that, you know, though, it'll leave files and things like that. It won't always clean up after itself. Because you have to put a manual step in place to force yourself to do the things that if it was fully automated, you probably just forget about them. Up to you. Do you want to show, because you mentioned supervisor on digital ocean droplet do you want to show that off at all. Like I literally will just hit the deploy script. It's going to, it's going to populate the, pull the code from get, get hub from the get the remote get repository. Just restart supervisor. And then it's done. It'll be live. And that's just deploying to a digital ocean droplet. Yeah, yeah, I've just got a digital ocean like, you know, 14 bucks a month droplet with a, you know, enough. The big component to this is. If we take a look at the sequel light database. I have a 33 gig sequel light database. Now, to be fair, like this is storing a lot of stuff that probably I could start to remove like it's storing all of the raw HTML. We have a little bit different setup than a lot of folks are using these AI assistants might look like, could you talk me through it? This is T mux plus VIM that's just like running locally in the command line that I usually have like between like, I don't know, two and six windows open. Typically a window open for my local development server and often one for like a task queue. Sometimes I'll use different colors as well, just so I can quickly see it. But so, so plus I've actually also has two different parts. So there's like the main web application that actually runs. And so I'll use like this color. I was like a dark background for that. And then I might use something like a something like blue. So that way, like immediately, I'm not just like editing the wrong file in the wrong project or something like that because you have like a bunch of different windows open your flying back and forth like a lot of times it's just easy to like be typing in one and not even realize that you're like kind of like screwing it up and whatnot. So that's how I organize. And so like maybe this gets into a little bit of how I just organize. Claude, which is like here's here's my setup. So, so my setup with Claude is I typically run between two and three different agents on different parts of the code base. So I know some folks try to do like a Git workflow where they do branches and stuff off of the different Claude agents. I just find that that's like just for me personally, it's like too much complexity. So what I like to do is just have different parts of the code base or separate the code base out into different independent components. So I have like a data collection piece and I can be modifying that. And that data collection piece only interacts with the web application through an API. This blue background was was removing some legacy code that I had out there. I was doing a previous caching method. And so I just said, I actually really like this use case for LOMs, which is like identify everywhere in the code base where this thing that I'm thinking about refactoring or removing. Where does it appear? Where are the dependencies? Where's everything across the entire code base? So, especially in large code bases, it's going to identify stuff that you may not be able to get just through static analysis or whatever. It's going to just go grabbing through directories and find all sorts of different dependencies that needs to be removed. One of the most important things that I've identified with using LOMs and established code base, which is technical debt actually becomes 10 times or 100 times more of a problem. So it's copying the designs of other parts of the code base. So if the design over here is wrong, and then you're a plot and the LOM is copying that. Oh, all of a sudden the design is wrong across a bunch of different areas of code base. So I actually think the technical debt and keeping time for improving technical debt, removing technical that is actually more important when using LOMs. So blog summary generator. What this does is I'm running locally Obama, which I need to update apparently. So this is going to go to the plush gap API, hold down a random blog post, and then it's going to use my local LOM to generate a summary for it. Could you tell me more about why you're using Olama there. So we could use any LOM, but I've got a powerful Mac book. I found that some of the smaller LOMs, the open source all open weighted LOMs, are able to generate perfectly reasonable summaries if I just given an input text. There's a hundred thousand blog posts here. And if I sent the text to one of the APIs for opening eye or anthropic or even some of the other ones, it would still cost me a reasonable amount of money. I might as well just use my local system to generate a summary for most of them. And if I need a more powerful LOM in some cases, if a blog post is really long, it doesn't fit in the context window, then I can ship it off to the API. So I'm not really sure what I'm matching do you have for when a feature is a good idea or when a change is a good idea for a cloud code and when you need to dig in and do it manually. I found the biggest issues that I've had with it are primarily when it's suggesting architectural changes that I am just like, you should definitely not do that. I'm just going to use the code in a way that I would never do. And a lot of times just kind of like going off on its own. So I think that's where I've had the biggest issues with it using opus and using the plan mode I used to plan mode all the time. It helps. But that's really where you've got to check it. It's not it's often not suggesting like a minor tweak but like something that kind of sprawls and then I'm just like, blow it all away. After 15 20 minutes it's just like, that's actually where I think the biggest problems are. That's why I think the biggest successes are like I already have the patterns. Don't change the pattern. I want you to do that. I want you to just like do this incremental improvement. And that's I think also matches side projects too. It's like my goal is just to ship every single day. I think it's like a little tweak even if it's like a backend week. I actually haven't made a ton of front end changes recently because I've been really trying to expand and try to get every single company's data out there. And so like to me it's like everything is just about that iteration, not about like the whole design the whole thing. So, did you be up for showing your your git commit graph? I have always been as consistent as possible about, you know, one or two contributions a day. But what I've noticed is I've done a lot heavier like I almost never had a 13 contribution day before like even going back unless I was like, you know, over the holiday. And that's typically where I had a big contribution day, whereas now I can have those all the time. I think there's like been a higher intensity since I've started using this tool is more rigorously like I was like, I would, I would argue that like over the last six months I was experimenting a lot. But a lot of times it wasn't really getting me the results or I was using it in a way where it was like, I was like, analyze this or like hit like it was more passive. And I'm more, I would say, more comfortable with the proactive creation and letting it go to its thing. I also personally feel like there was a big increase for me when cloud four came out and when anthropic launched the cloud max plans. Yes. Well, this is all when I decided to get the the pro and max plans. Before that I was not, I mean, I was like occasionally use something but then you're on the API clock and I just didn't feel good about it. Tell me about full stack Python real quick, because I think that it's really cool that you have such a long history of teaching developers to code. Yeah, so full stack Python is a site that I worked on for about 10 years. Still love the site. It's a full stack Python.com. And it's essentially like, I'm a Python developer and I just like wrote about like everything you want to know about like web deployment and deployment hosting options and like, what are whiskey servers and what, what is this at a high level look like and I just really liked working on it. Right. I, similar to like how I work on plush cap and I code every day, I would just write every day. And so like as a developer, this was like my way, like given back to the community was all open source and things like that. So I wrote like something on the order of like 100,000 words. And then I just needed a break after like 10 years, I just like really needed a break. So I kind of stepped away from it. And then I happened to step away in 20 ended like 2022, 2023. And then LMS kind of came out of, I wouldn't say it came out of nowhere because I'd used them a little bit with the early early GPT, GPT three, but they were becoming good enough that it was actually like pretty hard for me to understand how I could do this. And it wasn't something that you could just get out of an LOM, especially as the LMS got better it's like, you could just go in the chat TPT or go into Claude and say like, what is a whiskey server and it'll give you like all the up to date information, whereas like for me. I was updating all this by hand and updating these links and, you know, it was, I think, valuable for its time but it's almost like, like a lot of content sites are grappling with right now like I was just catching up with someone from CSS CSS tricks. And they're like same challenge like how would you in the world of LMS you can ask LOM any question, get a really detailed answer and then ask a follow up questions. What is the value of doing the content to, you know, to free your audience. Again, there are models for value but I just didn't want to go down those routes like I just don't have time for it. So for me, this was just like something I worked on every single day to keep my skills sharp. And then I just found that I, it wasn't as valuable for the community as I think, you know, was previously. So that's, yeah. There's a lot of folks in our world who fit that description. They got into this line of work because they love writing code. They become a people manager. They probably don't get a code as much as they used to or as they would like. What advice would you have for someone who fits that profile for how they can start coding again with the help of these tools? How would they get started? I actually think that it makes it more accessible to ship all sorts of things that you don't have experience in. So I'll give you an example. My son and I were just like creating our own game. I have never programmed anything in Pi Game. Obviously, I know Python never programming anything in Pi Game. So we just started, I was just like creative game in Pi Game and we created Snake and then we were like drawing little like sprites and things like that and adding into the game and it was like adding different rules. So I won't end boss and we'll go to different levels on those things like that's wildly empowering. Am I going to release this as some professional game? No, of course not. But it's a great side project, right? And like helped me to just feel like, okay, I'm going to like build this thing and learn how to use, you know, one of the command line tools. That's actually how I felt like I got more comfortable with cloud code because I picked this side project that I could just like kind of throw away at the end if I didn't, you know, after we had fun with it. And I think that's actually the big thing is like, it doesn't really matter with the ideas just like pick something and just like go start working on each day. And like, then you're going to learn and I actually found like YouTube is wildly valuable for this stuff. I learned a lot more from YouTube videos. So like, there's, I kind of have this give and take. It's like, I watch like some tips videos and maybe I picked like three or four tips out. I'm intentional about them. And maybe then like, then I'll go back like a couple weeks later and I'll watch some more tips videos. Right. And so like, there's just like this iterative process where if you have one or more side projects, you can just kind of like, try intentionally try those things out and add them to your tool belt. And that's like, that's the definition of being a software developer, right? Like, just getting better honing the craft. Just building cool stuff because you think it is fun. That's, that's what I would say. I just think that the other thing is like, it can allow you to just like. You don't have to go learn that code library to use it. You can ask it to use the library and then have it explain it to you. That's so different from pre L M era. That's especially true for smaller projects where you're building it just for you or just for your kids. Yeah. Yeah. I mean, there's just different, there's different modes of what you're shipping. Right. And so. Also, too, like I would be much more careful about these tools if I was shipping something for production at work, which, you know, I'm not. So I just, I think the challenges right now there's just a lot of hype. I think the only truth is like that you try it yourself like that's what being a software developer is like to try some of these things like they are not like the end all be all. In some cases, these tools are going to do a lot of good. They're going to help a lot of people ship some things that they otherwise never would have shipped. I think a lot of other cases are going to be misused and they're going to generate a lot of legacy code. There's going to keep software developers employed for a very long time to come debugging all those issues. So there's, there's like multiple angles to this. And that's why I think there's so much of the back and forth in the community of like, L M SOC, LMS are good, you know, like all this, because frankly, all of the perspectives are correct. Depending on where they're coming from, it's all relative viewpoints in magic. There's like this concept of like dual reality where you can have two people experience the same moment and be in the room, see the same thing and tell very, very different stories about what happened. And I think you're seeing the same thing with the vibe coding debate. Like, someone's all of our stories are based off of our personal experiences and our personal context and like depending on what you're working on the constraints under which you're working on your goals. You know, your experiences with these things are going to be wild. And the time period, I tried this stuff six months ago, 12 months ago, it wasn't there. It just wasn't good enough. And now I've tried it again and it's good for some things. And then, you know, some people are going to say, oh, exponential progress. This is going to be good at everything. And we won't need people anymore. And I'm kind of like, eh, I mean, maybe, I don't know, how could you possibly say that with any level of confidence. I saw it sweet yesterday. It's like, my baby has doubled in size over the last like two months. Like he is on track to a way, you know, 14 times. Even, well, primogen had like happy 26 months into six months from now. All coders will be out of a job. Yeah, it's just nobody knows, you know, no, no, like it, but it's, it's really fascinating playing with it. I still firmly believe that this is on the trajectory of like, cobalt was going to replace all programmers. Low code, no code, UML code generation was going to replace all programmers. And now what happens every level of tools that we build, the level of complexity in the software increases by the amount that it enables you to. So, I think that's probably where we're going. And I think the crazy thing is, is like that probably opens up huge number of opportunities for not just like the realm of like observability companies or error monitoring or whatever it is. There's probably a whole landscape of things that need to be created to deal with the future complexity of all of the additional code and everything that we're creating. So, I don't know. I mean, I really don't see like a how this end, this is not the end of history. Like, this is just like so clearly going to be like that next stage up and keep a lot more people employed, I think. It feels like the next level of abstraction. I'm just able to now think a level up in the same way that when I moved from, you know, C to PHP or to Ruby or something like that, like there were just problems I didn't have to solve anymore and I was able to do more. And that's what this feels like. Yeah, exactly. And I think a lot of companies are, there's a lot of AI companies, particularly like seed and series A round companies are deliberately staying small. I think it was like lovable has like 20 or 25 people, at least, you know, recently and like, you know, some of these teams are really small and I think it's partially because they're just rediscovering. You don't need these massive teams to put your product out there. Like that was the whole ethos, not with any LMS back in like 2010 2011, higher and seemingly talented engineers. And they will get a ton of stuff done. They just happen to use different tools back then. So like, I feel like a lot of times when there's a lot of talk about like, oh, this startup only has 10 people on there already at like some huge figure it's like, well, and that's because of LMS like no, that's how it also was like 10 years ago without LMS. So I don't really understand what the argument is there. So we lived in Brooklyn. We got an e-bike. A lot of people think that the e-bike is all about doing the same things you would normally do on a bike, but just faster and easier. But that's not true. It's like because the the energy required is so much less. You're now able to do things that you fundamentally would never do before. And so now we can take the kids and go grocery shopping and bring home three bags of groceries. Like now we can go to the park that's five miles from our house and as opposed to only going to the park that's three blocks from our house. And I think what we're going to see the same thing with coding is it's not like we're just going to build all of the same applications that we built before, but we're just going to do it faster and with fewer engineers. So it's like now we will build pieces of software that it never would have made sense to build before. Like now we can build smaller pieces of software for smaller audiences because the activation energy is so much less. Yeah, I definitely think so. And again, it can open up. I think that's a lot of what my messages have been like for some people who operate under certain constraints. And this is wildly empowering. And you operate under incredibly tight time constraints as like a VP and as a parent of a young kid and the fact that you're still able to ship code every day is pretty awesome to see. So I still get to do the thing that I love doing, which is shipping code.
