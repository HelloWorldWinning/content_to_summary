Timestamp: 2025-09-07T11:33:39.456210
Title: [Ilya Top 30] Ilya Sutskever 推荐的第一篇神作：复杂熵 - 复杂动力学第一法则  混沌与秩序之间的新物理定律 yukH6wUAX58
URL: https://youtube.com/watch?v=yukH6wUAX58&si=wXqSEZwCu7DoSBra
Status: success
Duration: 33:26

Description:
## 总结：复杂动力学第一法则

这篇内容围绕伊利亚·萨茨克维尔（Ilya Sutskever）推荐的“Top 30”论文系列中的第一篇博客文章——“复杂动力学第一法则”（First Law of Complex Dynamics）展开，深入探讨了复杂性的定义及其在物理、信息论和人工智能领域的体现。

### 1. 伊利亚·萨茨克维尔背景

伊利亚·萨茨克维尔是一位全能型的AI科学家，曾是AlexNet、Seq2Seq的发明者之一，深度参与AlphaGo项目，并联合创立OpenAI（担任首席科学家），主导GPT大模型研发。他以其对技术安全的执着闻名，并在与山姆·奥特曼的“政变”后离职，创立了Safe Super Intelligence公司。他以“模型又动，信息又动”的实战派风格，将ML的理论与实践推向极致。

### 2. 核心概念：复杂动力学第一法则

*   **基本观察：** 在一个封闭系统内，尽管“商”（熵，混乱度）根据热力学第二定律持续增加，但“复杂度”却经历了一个“先增后减”的过程。
*   **例子：** 牛奶与咖啡混合：
    *   **初始状态：** 低商，低复杂度（牛奶在上，咖啡在下，结构简单）。
    *   **中间混合状态：** 商增加，复杂度达到峰值（出现漩涡、渐变等复杂结构）。
    *   **最终混合状态：** 商达到最大值，复杂度降低（完全混合，结构趋于简单）。
*   **其他类比：** 宇宙（大爆炸简单 -> 现今复杂 -> 热寂简单）、房间凌乱。
*   **提出者：** 著名物理理论学家Seth Lloyd在FQXI会议上提出此猜想。

### 3. 复杂度的定义演进

为准确捕捉“先增后减”的复杂度模式，文章探讨了四种复杂度的定义：

*   **3.1 商 (Entropy)：**
    *   **定义：** 玻尔兹曼熵（微观排列组合数）或香农熵（信息混乱度）。
    *   **问题：** 商总是在增加，无法体现复杂度先增后减的模式，且将完全随机的状态视为高商，不符合我们对“复杂结构”的直觉。

*   **3.2 科式复杂度 (Kolmogorov Complexity)：**
    *   **定义：** 生成一个对象所需的最短计算机程序描述的长度。
    *   **优点：** 引入“压缩”概念，能描述分形等复杂结构。
    *   **问题：** 纯粹的噪音（完全随机）具有最高的科式复杂度，与商类似，未能将无序的混乱与有结构的复杂性区分开来。

*   **3.3 老练度 (Sophistication)：**
    *   **定义：** 描述一个对象作为一个更广阔集合中“典型成员”所需的最短程序描述。
    *   **优点：** 成功捕捉到初始和最终状态的复杂度较低（非常简单或完全随机的状态，程序描述都很短）。
    *   **问题：** 中间状态的复杂度未能保持高位。有数学证明表明，通过“初始状态模拟T步”加一个常数（Log T + C）的程序，也能简洁地描述中间状态，导致其中间状态的老练度并不高。

*   **3.4 复杂商 (Complex Entropy / Resource-Bounded Sophistication)：**
    *   **定义：** 在老练度的基础上，引入“资源限制”（如计算力限制）。即，在有限的计算资源下，描述一个对象作为一个更广阔集合中“典型成员”所需的最短程序。
    *   **突破：** 成功捕捉到“先增后减”的复杂度模式。因为中间状态要么需要极其复杂的程序直接描述，要么需要巨大的计算资源从初始状态模拟生成。在资源受限下，描述程序复杂度和计算资源消耗的总和在中间状态达到峰值。

### 4. 复杂商与大型语言模型 (LLM)

*   **本质连接：** 伊利亚·萨茨克维尔将LLM的训练过程视为对全球网络信息的一种极致压缩。LLM就是这种“复杂商”的巅峰体现——它既不随机也不简单，并且在有损压缩的前提下，很难再被进一步压缩。
*   **DNA类比：** LLM好比互联网（动物园）的“DNA”，它捕捉了数据中最本质的规律和模式。
    *   无生命星球：复杂度低，易于基础物质描述。
    *   有生命生态：复杂度高，需DNA这样复杂的蓝图。
    *   人类大脑：因其蕴含深刻思想和内在模型，被认为是宇宙中最难被压缩的系统，具有最高的复杂商。
*   **核心思想：** 最有效的压缩往往需要最深的理解。LLM通过压缩信息揭示了隐藏的“秘密”。

### 5. 结论与展望

“复杂动力学第一法则”是一个深刻的猜想，它提出了宇宙中可能存在一个类似热力学第二定律的新物理规律，统一了物理学、信息论和人工智能领域对复杂性的理解。这是一个开放式问题，等待未来的研究者去探索和解决。

---

**核心要点：**
“复杂动力学第一法则”提出在封闭系统中，复杂度遵循“先增后减”的模式，这一现象通过引入资源限制的“复杂商”概念得以精确刻画，并与大型语言模型作为信息压缩的极致形态有着深刻联系。

---

**总括框架：**
本文以伊利亚·萨茨克维尔推荐的“复杂动力学第一法则”为切入点，首先阐述了该法则的核心现象——复杂度在熵增过程中呈现“先增后减”的模式；随后回顾并批判性地分析了熵、科式复杂度、老练度等传统复杂度定义未能完全捕捉这一现象的原因，最终引入并强调了“资源限制的老练度”（即复杂商）如何成功地解释了这一模式；最后，将“复杂商”的概念与大型语言模型（LLM）的本质及其作为信息压缩极致形态进行了深刻的关联和类比。

---

<Mermaid_Diagram>
graph TD
    subgraph "A. 引言与背景人物"
        A1["伊利亚·萨茨克维尔 (Ilya Sutskever)"]:::person --> A2("推荐 'Top 30' 论文系列"):::context;
        A1 -- "AI领域巨擘" --> A3("AlexNet, Seq2Seq, AlphaGo");
        A1 -- "OpenAI首席科学家" --> A4("GPT大模型研发");
        A1 -- "理念: 深度理解与AI安全" --> A5("Safe Super Intelligence创始人");
        A2 --> B1;
    end

    subgraph "B. 核心概念: 复杂动力学第一法则"
        B1["推荐文章: 复杂动力学第一法则"]:::title;
        B1 -- "观察现象" --> B2("封闭系统内");
        B2 -- "符合" --> B3("热力学第二定律 (商增)");
        B2 -- "但复杂度表现为" --> B4("先增后减模式"):::highlight;
        B4 -- "示例" --> B5("牛奶与咖啡混合");
        B4 -- "示例" --> B6("宇宙的演化");
        B1 -- "提出者" --> B7("Seth Lloyd (猜想)");
    end

    subgraph "C. 复杂度的定义演进"
        C0["如何精确定义 '复杂度'?"]:::problem;
        C0 --> C1["定义1: 商 (熵)"];
        C1 -- "问题: 始终增加" --> C1_fail("不符 '先增后减'");
        C0 --> C2["定义2: 科式复杂度"];
        C2 -- "概念: 最短程序描述长度" --> C2_prop("强调压缩性");
        C2 -- "问题: 随机噪音复杂度高" --> C2_fail("不符终态低复杂度");
        C0 --> C3["定义3: 老练度 (Sophistication)"];
        C3 -- "概念: 描述为集合典型成员的最短程序" --> C3_prop("克服初始/终态问题");
        C3 -- "问题: 中间状态仍可被简单模拟程序描述" --> C3_fail("未能保持中间高复杂度");
        C0 --> C4["定义4: 复杂商 (Complex Entropy)"]:::success;
        C4 -- "在老练度基础上增加" --> C5("资源限制 (算力)"):::modifier;
        C4 -- "定义: 有限资源下, 最短程序描述集合典型成员" --> C6("成功捕捉 '先增后减' 模式"):::highlight;
        C6 -- "原因: 中间状态需高程序复杂度 或 高计算资源" --> C7("程序复杂度 + 计算资源 = 高值");
    end

    subgraph "D. 复杂商与人工智能 (LLM)"
        D0["伊利亚推荐理由: 复杂商与AI的深刻联系"]:::connection;
        D0 --> D1["大模型 (LLM) 的本质"];
        D1 -- "视为对互联网信息的极致压缩" --> D2("信息压缩的巅峰形态");
        D2 -- "处于复杂商的巅峰" --> D3("既不随机也不简单, 难以再压缩");
        D1 -- "类比" --> D4("LLM是互联网的DNA");
        D4 -- "例子" --> D5("人类大脑: 最难压缩的系统");
        D0 -- "核心理念" --> D6("最深理解实现最有效压缩");
    end

    subgraph "E. 结论与展望"
        E0["复杂动力学第一法则的意义"]:::conclusion;
        E0 -- "暗示宇宙存在" --> E1("新的物理规律");
        E0 -- "统一" --> E2("物理学、信息论、人工智能");
        E0 -- "目前仍是" --> B7;
        E0 -- "鼓励" --> E3("对开放问题的深入研究");
    end

    %% Styling
    classDef person fill:#D4EDDA,stroke:#28A745,stroke-width:2px,color:#333;
    classDef context fill:#E0F2F7,stroke:#3498DB,stroke-width:1px,color:#333;
    classDef title fill:#FFDDC1,stroke:#E67E22,stroke-width:2px,color:#333;
    classDef highlight fill:#FFECB3,stroke:#FFA000,stroke-width:2px,color:#333;
    classDef problem fill:#F8D7DA,stroke:#DC3545,stroke-width:2px,color:#333;
    classDef success fill:#D4EDDA,stroke:#28A745,stroke-width:2px,color:#333;
    classDef modifier fill:#ADD8E6,stroke:#6495ED,stroke-width:1px,color:#333;
    classDef connection fill:#FFF3CD,stroke:#FFC107,stroke-width:2px,color:#333;
    classDef conclusion fill:#D1ECF1,stroke:#17A2B8,stroke-width:2px,color:#333;
    classDef C1_fail fill:#FFE0B2,stroke:#FF9800,stroke-width:1px,color:#333;
    classDef C2_prop fill:#C8E6C9,stroke:#4CAF50,stroke-width:1px,color:#333;
    classDef C2_fail fill:#FFE0B2,stroke:#FF9800,stroke-width:1px,color:#333;
    classDef C3_prop fill:#C8E6C9,stroke:#4CAF50,stroke-width:1px,color:#333;
    classDef C3_fail fill:#FFE0B2,stroke:#FF9800,stroke-width:1px,color:#333;
</Mermaid_Diagram>

Content:
大家好我是近今天来给大家带来一系列有序文章的第一片这一系列有序文章是一列SusKaver推荐的30片论文这个故事大概是这样的一列SusKaver对他的Open-Aid同事说如果你学会了这40片论文你就学会了这个世界上关于RML重要的内容的90%然后呢尽管这个文章一系列一开始是40片文章但是并没有一个官方的这么一个list然后后面传织传织就变成了30片然后无热心的网友和他这个同事一共找到了27片所以尽管他非常有名的叫做Top30但其实只有27个文章而且这20片文章并不都是论文其中包括很多这种博客然后我呢还是简单介绍一下一个LiaSusKaverLiaSusKaver最有名的时间呢其实是他解估了Open-Aid C.O山茅特曼然后呢在那一次证变中呢他彻底出圈然后做一个科学家有一些这种执着然后对于这种技术安全的这么一个执着然后这是他最出圈的一个时间但在这之前呢其实他已经有一些非常有名的一些work了然后首先呢是AlexNet他在加拿大失从Jackson的然后Jackson的就是AI教父刚拿了诺贝务理学奖的那个人然后他跟这个他的师父还有师父Jackson的还有Alex一起发明了这个AlexNet然后在这个比赛中取得了巨大突破并且拉开第二名很多很多这种很多粉然后依量呢跟他这个师兄和Jaypehinden就一起加入了Google然后也算是先洗了深度学习的这一波浪差然后就是然后他加入Google以后呢他就开始研究NRP自然语言处理他发明了Secrease2Secrease然后把RSTM推到了时代的最前一年然后他并且深度参与了AlphaGo的项目然后也是未列AlphaGo的维促不多的作者之一然后在这之后呢他离职了然后去跟ShangMotoman还有Alomask一起创立了AlphaAI然后他作为首席科学家呢带领各种团队呢引领了Skelling Law引领了这种GPT大模型的这么一个研发然后就是他著名的去解雇ShangMotoman的事情因为他比ShangMotoman更注重安全然后他就发动了政变然后解雇了ShangMotoman经馆后续呢ShangMotoman又重新掌权重新多权多回了AlphaAI的控制权然后伊利亚也在这个事件之后不到一年就离职了然后他现在呢是开了一个新的公司叫做Safe Super Intelligence然后他是本来继续当CSL但是在CIO被Mata重新发展以后他自己开始当任了CIO然后伊利亚呢可以说是在MLG呢激动模型又动Info并且是一种实战派比如说他不仅理论还有很多很多这种实战的Coding的这么一个能力他是又动软件又动硬件然后又动这种模型又动这种强化学习这个全能型的天才然后我们今天呢就要讲他推荐的第一篇论文其实是一个伯克这个伯克的名字叫做Furslal of Complex of Dynamics也就是复杂动力学的第一法则然后这个文章讲的是怎样的一个事情呢就是说在一个封闭系统内我们通常会看到商是在不断增加的但是他的复杂性却经历了一个先增后检的一个过程然后我们看一个例子就是这个牛奶与咖啡红盒的例子我们在最左边的这张图可以看到牛奶在上面咖啡在下面在红盒之前呢它的商也是非常的低也就是它的混乱度非常的低然后它的复杂性也非常的低它非常的简单然而在混合的中间状态就是它的商混乱度稍微增加了一点以后它的复杂度其实是非常高的因为我们可以看到中间的见边呀中间的这种窝饼啊这种复杂的结构然后最终呢就是混合好的一个状态它的商达到了最大尺但是它的复杂度呢似乎又降了下来因为它就是完全混合的一个状态没有非常复杂的结构也就是说我们的商混乱程度呢一直在增加然而它的复杂性呢却经历了一个先增后检的一个过程我们直觉上呢可以看到这种很多的这种类似的这种拍拖包括宇宙呀就是大爆炸的时候呢非常简单最终宇宙热迹呢也非常的简单但是现在我们复杂的宇宙非常的复杂然后物理上呢就是说似乎我们能够感受到有一个更深藏的这么一个物理规于就像热力学第二定律一样有一个非常非常复杂的这么一种热力学然后甚至包括这种信息论呀人工智能呀都在这其中包含了一些角色然后我们之后可以聊到为什么这个这个复杂度跟信息论以及生物智能有着深刻的联系然后我们把这个问题呢算是正式化的用物理的角度来聊一下也就是说我们可以看这张图也就是说它的它的横着是时间它的重着是复杂度或者是这种伤也就是混乱度混乱层度呢根据热力学第二定律是不断增加的但是它的复杂度呢经历了一个先增后检的这么一个过程然后这个这一件事情呢是由非常著名的物理理论学家上caro提出的它在一个FQXI conference中提到了这么一件事情这个FQXI呢是Fundational Question Institute然后这一篇这个我说了这些问题我说了这些问题我说了这些问题我说了这些问题我说了这些问题我说了这些问题我说了这些问题然后这一篇这个会议呢是在一个由从挪威开网各版哈奔的一个游轮上举行的也是非常的好滑然后这一他提出的这么一个理论呢其实是彻底上彻底改变了我们对于复杂度的这么一个理解尽管我们对复杂度还没有一个非常精确的定义但是直觉上告诉我们复杂度是似乎是经历了一个先增后检的这么一个过程然后我们在接下来背景之事也就是热力学第二定律这Second Law of Thermal Dynamic也就是商增定律然后他的一个封闭系统内的商是指责不减的然后一个例子就是比如说你一个直觉的理解这个方式就是说比如说你一个物子如果你不收拾就会越来越乱东西会不断的变复杂然后在信息论里就是说一个一串零或者一串一或者一串零一零一零一的组合呢也是低伤的一个状态然后如果他是随意的零和一的话他呢就变得伤呢就复杂度混乱程度呢就变得非常的高然而我们可以看到这种复杂度呢似乎是有一个叫做不同的这么一个判断因为完全随意的状态似乎也没有那么复杂然后如果一个物子他彻底的混乱了我们似乎觉得他也没有那么复杂因为他就是随机的嘛也就是说我们可以看到这种复杂度经历了先增后检的这么一个过程所以这里的核心问题就是说是否有一个新的物理规律然后来统治了这么一个复杂度的这么一个进化的这么一个过程这么一个问题呢我们就需要一个精确的一个定义首先呢我们会讲这种复杂度有四个定义然后我们先也就是商然后是科是复杂度然后是老练度然后是最终做者提出的这么一个complex着复杂商的这么一个定义然后在这四个定义中呢我们会先讲到就是说为什么前三个定义呢都不够好就是关于复杂的定义为什么都不够好首先第一个就是说为什么不能直接用商来取代来代表这个复杂度我们刚才其实已经核心原因我们其实刚才你说到了就是因为商呢一直是在增加的然后他随着这种复杂度的增加我们想要看到一个地件的这么一个Python然后我们我们这个商是怎么到底是怎样的一个定义呢然后在波尔滋曼呢给了一个波尔滋曼上的一个定义也就是最常用的这么一个定义也就是S等于KBLogMiga他给了这么一个公式KB呢也就是涂中的这个K呢就是一个日历学常数然后LogMiga呢就是他这种所有排列祖国这么一个过数各数我们不用去太深入地去理解这个公式但是直觉上就是说他通过这么一个公式然后能够能够测量这东西到底有多么混乱然后当他祖国混乱的话他的排列祖国的各处就会多一点然后然后他的商就会大一点然后他就是通过这么一个微观的尺度排列祖国这么一个方法来定义了一个商然后这里呢其实可以提到一下这种San No Anchipi也就是香农商也就是信息商也就是在我们进行信息压缩的时候如果他不能被压缩了他就是高商的如果他可以被Significant的压缩然后01101的这种祖国然后他的这种香农商呢其实就是很低的然后在这种数学上呢其实这两商呢是等价的然后商的具体就是说我们提到的商职增加的具体是怎样的一个特点的就是说在这种商的视角里我们可以看到他不断的增加并且在这种Uniform Random的就是完全随意的一个状态的然后他是看起来是更加的混乱的也就是说他对于我们想要的一些属性包括Strachite啊Pitron啊甚至包括Meaning啊也就是结构模式还有意义都是没有一些理解的然后他反而给这种完全混乱的程度呢增加了很多的伤这个显然不符合我们想要的这种复杂度的定义就是说复杂度我们想要的复杂度跟这种混乱程度还是有很多的区别的因为我们想要这种复杂度在中间状态是更高的所以我们就需要另一个工具然后我们就会提到这个ComableCoreOfComplacity也是科式复杂度科式复杂度本日上的就是这么一个定义他的定义是说你JandleRate这么一个东西所需要的最短的一个程序的一个描述也就是说对于我们可以用一段自服券来描述这么一个我证比如说011010101然后我们就可以把它变成01成元也就是说我们用一样程序就可以写出来这么一个自服券如果都是0的话 前就是0成元如果都是1的话就是1在写n次 对吧如果是完全随机的话呢它呢 也非常的复杂这个科式复杂度呢ComableCoreOfComplacity显然它跟Antiope是非常的相似的它跟Antiope也是伤有着一个共同的属性就是说对于纯粹的噪音它是没法完全的Compress的然后即使这样它其实引入了一个非常有趣的概念就是说它引入了一个Compressing的概念然后我们稍微介绍一下ComableCoreOf这个人科式复杂度的这么一个创立者这个人这个人呢 其实是一个大的一个数学家它是比乡农也就是信息论的开创者稍微挽了20年所以它的这种理论都是基于这种乡农上的然后它这种ComableCoreOf复杂度呢它对复杂度有着非常非常深刻的理解然后推动了这种复杂度的发展我们后面提到的东西呢其实也是基于这种科式复杂度基于这种压缩的这种压缩呢其实就包含了这个算是图零机的这么一个设定然后你写一段程序来去抵犯这个Stream抵犯一个系统然后生成一个这么一个系统所需要的最小的一个字复杂然后也就是说像这种分型的图形其实在乡农上的视角甚至是无限的然后但是在这种ComableCoreOfComplacity的底你可以写一个分型的一个程序就能创造出这种图形也就是说把它的压缩成了一个更短的字复杂然后它对于这种复杂度深刻的理解呢包含了它提出了一个概念叫做Sophistication也就是老练度这么一个概念所以它这个老练度呢其实也是ComableCoreOf提出来的直接上讲这个Sophistication就是说这个Sophistication就是说也是就是说最短的程序能Describe Describe这么一个X这个X就是任何一个系统包括Stream 包括任何一个系统但是它家里怎么样一个设定呢它家的一个设定就是说我不一定要完全生成这么一个Element就是说这个元素属于一个更广阔的一个集合然后只需要生成这个集合中的一个元素就可以了然后这样的话它摆脱了紫阳的一个问题就是说当你Stream或者说是当你这个完全合合合的咖啡是完全随机的时候我不需要完全生成Exlex里生成完全精确的一个匹配我只需要生成一个匹配它的这么一个我们有一个这种上帝判别器就是这种Oracle能直接判断说你跟另一个元素同时属于这么一个集合然后我们就能定义这个复杂度我们就能定义这个你的Sophistication就是你的生成这么一个东西的一个最胆程序也就是说我们对于一个非常非常简单的Stream就是Comical Guarrel复杂度 科是复杂度非常小的时候它的这么一个Stream也是非常短的我们保持了这么一个优秀的出性然后它最终非常复杂的时候也就是不是最终非常混乱的时候也就是完全随机的时候它的这么一个Sophistication也是非常的低也就是说它在歧视状态和最终状态它的Sophistication复杂度都是非常低的这个我们似乎看起来是非常的Promising了然后我们就是想要验证一下它的在中间状态的这么一个Sophistication是高的然后我们想要这么一个属性它是否满足了呢非常不幸的是它并不能满足一个非常厉害的数学家证明了这个Sophistication的无法超过Log T加 CC是一个常数Log T就是时间 也就是说我们有一个Hack我们有一个解 就是说我们直接从初是状态模拟在加上Log Tstab我们就能得到这么一个Sanpo它可以完全代表现在的状态然后它并且能可以Trick这种Auerko就是说我中间的牛奶半混合的状态也是可以与通过Log T加 C来描述的也就是说它的复杂度在中间状态也没有变得非常高所以它不符合我们想要这么一个复杂度先增后检的这么一个属性但是没有关系它也算是带我们走了巨大的一步因为它满足了起始状态和最终状态复杂度都非常低的这么一个属性只是它的中间状态也可以通过一个非常厉害的程序可以破解这个作者就是想在这个老链度的这么一个状态上再打一个补丁然后它就是说这个真正的突破就是说要在这个程序中要设定这种Resource Boundary的Zouer也就是说我们想要负现这个我们必须要Limit也就是限制它的资源因为你从一开始那个状态继续去跑这么一个模拟然后跑替步它其实是非常费资源的我们只需要再加上一个资源的限制它中间的这种复杂度就上来了然后我们再重新规划一下这个定义就是说我们这个复杂的这么一个定义就是最短的程序能够抵犯这个Object是一个Ginetic member并且它是有限的资源然后它到底有怎样的Implication呢就是说它一开始的这么一个状态显然是低伤的并且是低复杂度的因为我们可以用一个非常简单的程序也就是确实状态比如说全是零这么一个状态去描述它最终状态也是非常简单的因为它是完全随机我们只需要说Random三跑就可以了只有中间状态它是非常复杂的然后我们可以想到它其实有几种方式来描述这么一个状态一种情况的就是说我们一个B提个Bit的描述0和1、0和1然后我们把整个的完整的状态给记住下来另一种方法就是说我们去软Simulation我们去跑一个实验然后跑到T步我们就得到这么一个状态然后我们回到咖啡和牛奶的例子出示状态我们可以明显的看到它最简单的描述方式是牛奶在前咖啡在后一个非常简单的程序最终的状态我们最好的描述就是用咖啡和牛奶一比一然后完成随一中间状态描出起来就非常的吹气了它有两种描述方式一种是用纯粹的比如说上面牛奶中间多少层是多厂牛奶和咖啡的混合比然后我们取一个进寺或者我们甚至取一个Linux Regression但是这个仍然可能会不能精确的描述状态然后我们可能需要更多的这种描述方式层描述时钟状态另一种状态我们就是取一个出示状态然后我们去跑一个simulation然后它呢在跑T步以后我们就会得到类似近似于这么一个中间状态的一个状态然后也就是说我们可以要么是把原本的那个描述变得非常的贵要么我们就是把资源费在跑实验的这么一个compute上计算力算力上然后它的这么一个资源限制的老连度的这么一个状态呢显然你无法同时减少计算力或者计算减少它的计算的复杂度或者以及这个程序的复杂度你只能减少其中的一个然后我们的这么一个伤的一个复杂度的定义呢是他们俩的合也就是说在中间状态呢它的值就非常的高了它就完全符合了我们想要的这么一个曲线然后这就是它想要的这么一个复杂商的这么一个定义也可以教复杂就是资源就是算力限制的复杂度算力限制的老连程度然后这里呢我们就要延伸一下就是说这个复杂商的这么一个定义到底跟大模型跟人物质能有怎样的关系为什么伊利亚会推荐这篇文章呢这是因为它把这个R&M的本质就看成了一个对于世界上所有信息的网络上所有信息的一个压缩然后伊利亚SusKW和音美达的CEO黄人熏真算黄人熏有一个非常有名的一个桑桑在2023年他们就讨论了人工质能还有这种信息论的一个本质然后大模型呢就是一个算是一个叫做复杂商的一个颠缝它的既不随机也不简单并且它很难继续压缩它就是有损的一个压缩然后伊利亚就把整个的一个讯练的一个过程看成了一个对信息的压缩的一个过程把它压缩进这么模型的权重之中然后为什么说它的复杂商无法再被减少呢就是因为如果你想要描述它的话你要么用零合一这种二斤制的数据去描述它显然你无法压缩再压缩它了因为如果你随便改变其中的字节的话你会影响模型的性能然后或者另一个描述方法就是说你把这个讯练过程给描述出来然后这个显然是更无效的这么一个描述因为它这么一个讯练过程的需要包含它的所有讯练数据这种数据显然是消耗了更多的寸出空间更需要更多的Biz然后一伽就说到如果你想要把这些互联网的数据compress的非常的好的话压缩的非常好的话你就需要找到一些隐藏的一些秘密也就是你想最有效的压缩呢以反而需要最深的理解然后RM就是大模型的就是作为这么一个秘密的一个集合体然后它使得这种信心的无法被更多的被压缩了是因为它其实已经抓取到了这种数据上最本质的一个规律然后这里我会提出一个非常有趣的一个类比就是大模型的其实更像是DNA就是我们这个世界包括这种所有的生物呀都是互联网然后我们想要把比如说一个动物呀一直猫一直搞一个大枪呀给压缩呢其实我们只需要它的DNA我们就可以复刻这个动物尽管它不完全一样但我们能忍然分辨出来它是大枪也就是说大模型在这里呢更像是DNA然后是最本质的这么一个区别最本质最核心的这么一个模式然后所有的这些动物呢包括我们生存的这种生态呢就是互联网然后它其实呢可以被压缩的尽管它的伤呢是已经是比较比较的这种复杂度呢已经是比较高了然后如果是没有生命的一个星球呢它显然它的这么一个压缩的程度呢是更高的因为你可以就是通过一些基础物质就能秒数出来它而不需要DNA这么复杂的东西也就是一个星球如果毁灭了的话然后它也是完全的造生包括宇宙的这种热机状态呢它的复杂度也是非常的低的也不需要DNA这么复杂的这么一个事情去来描述它所以大模型就是像是我们就像是DNA互联网的就像是动物园这里有一个非常有意思的点就是人类人类到底能不能被压缩呢如果是原始人的话我们似乎觉得它更能够被压缩然而一个有思想的人它似乎就更难以被压缩了因为它其实会有一些更加深刻的思想也就是说它脑海里还有一个模式的模型它还有一些知识被引拜的了它的大脑中也就是说它的大脑是最难被压缩的因为你很难完全复杌出来就是说一个具体的人的一个大脑所以人的这种复杂商其实是更高的Compalite trophy更高这也是一个非常有趣的观察这就是相当于是说这种复杂商对于这种大模型的这么一个影响之后我们还有怎样的一个延伸的就是说我们似乎发现了一个宇宙的一个新的物理规律也就是复杂商先增后检然后这个复杂度跟这种混乱度也就是伤似乎是不太一样的并且这个复杂伤似乎是统一了就是说在物理上包括既然一科学还有人工智能亚都是有影响的都是发现了同样的规律然后它也算是对以后的这种发展的有着非常非常深远的一个影响而且最扭的就是说它是一个提出问题的人它并没有解决问题就是说这个上并没有去给出这么一个问题解因为我们都知道像这种科学研究最最最最扭的人都是初提的人也就是提出猜想的人包括但不限于费马大定理之前是费马猜想然后包括这种离曼猜想都是最扭的人都是提出猜想的人然后像这个复杂商的这么一个定义对于这种信息压缩呀包括这种GZP都是有非常深远的影响的然后它甚至可以牵扯到这种听机问题就是图临机的这么一个计算机科学非常本质的一个问题然后还有最近的一些发展呢包括显示复杂的也就是Parton的complasticity也是最近的一些研究然后我们后续可以再给大家做延伸的一些阅读然后这一个热力学第一不叫热力学就是这么一个复杂动力协的第一定力仍然是一个conjecture仍然是一个猜想然后它是一个开放式问题就说它还没有答案然后有兴趣的观众和读者可以继续去深入研究这个问题然后说不准下一个诺别这样就是你呢谢谢大家
