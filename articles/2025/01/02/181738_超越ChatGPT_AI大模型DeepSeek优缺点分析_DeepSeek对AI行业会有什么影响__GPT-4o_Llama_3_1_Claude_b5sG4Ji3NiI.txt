Timestamp: 2025-01-02T18:17:38.675247
Title: 超越ChatGPT？AI大模型DeepSeek优缺点分析，DeepSeek对AI行业会有什么影响？｜GPT-4o｜Llama 3.1｜Claude b5sG4Ji3NiI
URL: https://www.youtube.com/watch?v=b5sG4Ji3NiI
Status: success
Duration: 11:22

Description:
**核心要点:**

1. **DipSync的优势:**
    *   性能卓越: 在数学推理和代码生成方面表现突出，整体性能与其他主流大模型（如ChatGPT、Claude、Llama 3）相当。
    *   训练成本极低: 训练成本仅为其他大型模型的百分之一，训练时间也大幅缩短。
    *   开源: 代码和训练方式公开，允许用户免费使用并进行优化。
    *   价格优势: API调用费用远低于其他模型，更具价格竞争力。

2. **DipSync的劣势:**
    *   反应速度稍慢: 响应时间较长，文字生成速度也略慢。
    *   上下文理解能力有限: 只能理解较短的上下文，超过限制需要重新开始对话。

3. **DipSync的影响:**
   *  **对其他大模型:** 价格战的开端，可能迫使其他大模型降低价格或寻求差异化竞争。
   *  **对芯片行业:** 表明硬件差距可通过软件优化弥补，可能影响高端芯片的利润率。

**核心结论 (一句话):**

DipSync以极低的成本实现了与主流大模型相当的性能，其开源和低价策略将对AI大模型市场产生重大影响。

**根本结论 (一句话):**

DipSync的出现打破了大模型必须依赖高昂算力的局面，预示着AI技术在成本效益方面的重大进步。


Content:
好大家好 最近Chag GBT又多了一个竞争对手DipSync 也是一个大约模型最近发布了他的3.0版本在发布之后大家发现他的性能可以比Dopn AI的Chag GBT同时和一些其他的主流大约模型比方说Klaude还有Mata的Lama3都不相上下DipSync是由一家中国的公司深度求所训练的它的母公司是换方面话一个规模超过百亿的私目量化基金那为什么DipSync这几天这么火用简单的话来说它就是用更低的成本做到了其他大约模型相同甚至更好的效果这个视频我们就来对比一下DipSync和其他的大约模型比如说Chag GBT在成本和效果上到底有什么差异并且来分析一下DipSync的出现对于AI行业可能会有怎么样的影响首先我们就来看一下DipSync和Chag GBT等一种大约模型相比它到底做到了什么样的能力首先我们来看这张图这张图展示的是六个大约模型在各个方面上的对比这六个模型分别是DipSync最新发布的V3版本以及2.5版本同时还有阿里巴巴的千万模型Math的Lama 3.14.5B还有OpenMGBT4O以及Client 3.5我们就来看一下这六个模型在各个方面上的表现首先我们也看出来DipSync也就是最左边这个蓝色的柱子在各种任务上的表现其实都是非常优秀的特别是在中间的3个Math 500AIM-1224和CodeForest在这3个上面DipSync的表现都是第一名这个Math 5001500到数学题目评估的是模型在数学推理上的表现但这个AIM-1224也是一样的它是一个美国的数学竞赛评估的也是数学推理的表现而右边的CodeForest评估的是模型在边层上的能力所以说我们可以发现DipSync在数学计算以及在边层上它的能力都是要比其他的模型来得更高的而在左边的两项测试多任务理解以及复杂问题上的表现表现的A比较不错它的格分仅仅比CodeD释出CodeY的格分第二高的所以通过这个图片我们可以看出来DipSync和其他的大约模型比较在不同的方面都取得了不错的成绩但光是成绩不错的一点其实是不足以让大家如此惊讶的DipSync最让大家惊讶的其实是它的训练时间非常的短并且它的训练成本非常低整个训练DipSync的过程用了2048块GPU训练了两个月如果换算成GPU小时就等于278万个GPU小时我们做一个对比训练DipSync花了278万个GPU小时而训练MATAN的LAMMA 3.1模型总共花了3080万个GPU小时所花的训练成本整整上了一个数量级并且训练使用的GPU还不是同一种GPU由于今年中国遭到了美国的芯片管制所以DipSync只能用H800芯片来训练而LAMMA 3.1用的是更先进的H100芯片训练的所以说相比于LAMMA 3.1模型DipSync比3用了更加落后的芯片仅仅训练了十分之一的时间就把这个模型训练出来了并且表现得还不错如果我们看整体的成本训练DipSync总共花了557万美元而像训练OPEN-ELEGPU小时MATAN的LAMMA 3以及CLOW的训练界大模型成本都在数一美元的级别所以说如果N训练成本来看DipSync训练成本是其他对标大模型的百分之一而它的效果却可以做到和其他的大模型相当除此之外DipSync还是一个开源的模型所谓开源模型是它的代码以及训练方式都是公开的所有人都可以访问和使用而像的GPU COW以及CLOW的这些都是避养模型他们的代码以及训练方法大家都是不清楚的而一个模型开源的好处对于使用者来说就是可以免费的使用这些技术并且可以根据自己的需求对这些代码进行进一步的优化而同时对于DipSync来说由于它代码都是公开的所以它的工作原理会更加透明大家对它的性能度可能也会更高一些那么说起来DipSync训练成本有低效果和其他又差不多它是不是就没有弱点了呢其实DipSync和其他的大圆模型来对比还是有几个比较明显的弱点第一个就是它的反应速度可能会慢一些平均来说它的手致小硬时间是1.1秒而GP4和Cloud基本上都在1秒之内这个手致小硬时间试词你给大圆模型输入了指令输入了问题之后这个大圆模型需要多久来回答你的问题像刚刚我的反应时间就有1.14秒但是说实话这0.0的差异其实大家感受也不大除了小硬时间DipSync给答案的时候它的文字深层速度也会稍微慢一些它平均每秒钟可以深层87.5个透坑而像GP4和Cloud的平均每秒可以深层1百和90个透坑这边有人就会问了Token是什么意思Token在英文里面你可以简单的理解成一个词语在中文里面就可以简单的理解成一个字因为不管是英文里的一个词或者中文里的一个字它都代表着一个意思但是代表着一个意思的最小单位就被叫做Token其实说实话每秒钟深层的Token它的差异在10%其实我们是不太能够感受的到的所以这个也只能够算是一个小缺点还有一个缺点就是Depsyk比较明显的缺点了它在理解上下文的时候它总共只能够理解13万的透坑而像GP4和Cloud都能够理解200万的透坑但这个理解上下文是什么意思因为每个大约模型在跟你对话的时候它都会根据整一个对话的上下文背景来去理解你这个问题到底是什么意思而Depsyk它能够理解能够记住在上下文长度是有限的比方说我在使用的时候如果我聊到东西稍微长一点那我就会很容易看到它给我发说我们对话超过了最大对话长度它建议我在重新开一个对话那就有说我们聊天聊着聊着它就聊不下去了很重要的情况在GP上面我是目前还没有遇到过的从开一个对话你之前跟它说说过的内容在新的对话里就不再存在了所以如果你要跟它铺垫什么背景你就需要重新再说一遍Depsyk能够月毒的上下文短这个缺点其实在使用过程中是蚂蜜显的它聊着聊着就不跟你聊了让你去重新开个对话重感受其实也不是特别好所以这个其实能够算Depsyk一个比较大的缺点除此之外Depsyk之前还有过一个小问题就是你那用英文问他WorthModelRU的时候他会告诉你他是Chaggbt那这个在今天早上我设的时候他确实是这样然后我后面还用中文问问他一下你和Chaggbt是怎么关系那这个时候他就开始否认了自己跟Chaggbt没有任何关系自己是Depsyk那后来我在今天下午又有重新设理一下我又用英文问他WorthModelRU那这个时候他好好的已经修复了他就说自己是Depsyk模型所以如果你现在想看他说自己是Chaggbt那你就完了一步你提前一天其实就可以看到那这个其实也不是一个非常大的问题这很可能是在讯恋Depsyk是个大语言模型的时候所用的语料很多都是由Chaggbt所深沉的所以他就产生了这种结果那类似的问题像之前的Google Gmin也发生过当时如果在POL评论上掉用Google Gmin用中文问他你是谁他又会告诉你自己是百度的文心语模型同样的这个可能也是因为Google Gmin在讯恋他的中文语经的时候用的是百度文心语模型所深沉的内容那可惜现在这个小问题已经被修复了大家已经看不到了那下面我们就来说一下Depsyk的出现对于整个AI大模型行业以及AI新面行业到底会有什么影响首先我们就来说一下对于其他大模型来说会有什么影响那现在这些AI的大圆模型他们的盈利方式主要分为四大块那第一个就是订阅服务比方说你订阅Cygbt的GPT Plus每个月要交20刀那第二点就对于邪来说邪也对于这些大圆模型的使用量会比较大不仅仅是我们个人这样问一个问题这种比较小的使用量所以说对于邪来说这些大圆模型就会提供自己的API接口比方说一个企业就可以掉用Cygbt的API接口做一个自己公司的正能克服这个API接口就会按照企业的调原量收费你用的越多说得前也越多那这种使用API接口的公司一般是一些中小企业而对于一些大公司这些大圆模型就会专门的做一些定制化的举约方案那这个其实跟调原API接口逻辑的差不多的只是定制化的程度会更高一些比方说美国公司Baspy就用Google的机密模型来帮他做虚拟克服那除了以上三种商业模式之外第四种商业模式就是将软件和硬件结合比如说现在苹果的Apple Intelligence里面就签入了Cygbt把Cygbt预装到Apple里面虽然据说Apple是没有给Cygbt打钱白用了这一项服务但是这也是一种商业模式那除了Apple还有Google把自己的机密里整合到Google自己的手机里面去也是这种软件硬件相结合的模式说了这么多大圆模型的商业模式是为了说什么呢下一代也看出来了目前这些大圆模型他们主要的引力方式就是通过向企业提供自己的API接口企业使用自己的服务越多那自己就可以赚更多的钱而Dipsick由于它的训练成本更低所以说它接口调用的费用是其他大圆模型的十分之一甚至百分之一那么这边可以看下Dipsick模型调用API的收费它每输入100万的投肯收费是0.1到1块钱而每输出100万的投肯收费是两元而相对应的GbT4收入和输出的收费分别是无美元和食物美元所以说一个企业如果有需求在Dipsick和GbT4都能够满足的情况下Dipsick收费是GbT4的几十分之一所以说Dipsick的价格竞争力在其他的大圆模型中是非常强的相当于就直接在大圆模型里面开打的价格价而它收费这么低的原因也是因为它的训练成本比其他模型要低得多除了对于其他的大圆模型有影响Dipsick出现可能还对于一些芯片设计公司有影响那比方说就是因为大的芯片前面我们也说了训练书Dipsick靠的是因为达的H800显卡H200显卡它是特供给中国的一种显卡它是在H100显卡基础上降低了某一些参数才能够被允许卖给中国而现在Dipsick居然拿着H200显卡做出了和其他大圆模型相同的能力这样就让大家发现了其实硬件上的差异可以通过你软进行的进步来弥补所以在未来这个可能会影响顶尖芯片和落后芯片之间价格的差异芯片稍微差一点我也能够在其他地方找不回来所以呢像因为达这种高端芯片在未来他利润率会受到挑战不过其实这一点影响可能也不那么大一方面Dipsick确实用没那么好的显卡做出了顶尖的效果那另一方面如果Dipsick拥有了H100显卡如果他用更好的芯片说不定他能够做出更好的大圆模型进一步打败其他竞争对手所以说未来对于高端芯片的需求很可能也没有那么容易就会受到挑战那以上就今天的视频如果你还有什么想知道的请在评论你告诉我我用Dipsick帮你去查感谢你看到这里我们下次再见拜拜
