Timestamp: 2025-01-12T03:01:35.039248
Title: How to estimate arch model - eviews tutorial complete
URL: https://youtu.be/_-HFP5KXwIk?si=kRQUcRyKQ0ijjPuT
Status: success
Duration: 27:06

Description:
Okay, here's a summary of the provided content, structured as requested:

**I. Outline and Structured Summary**

*   **Introduction:**
    *   The video tutorial focuses on estimating ARCH (Autoregressive Conditional Heteroskedasticity) models.
    *   The presenter provides data for replication and EViews work files for purchase.
*   **ARCH Model Basics:**
    *   ARCH models, introduced by Engle (1982), address heteroscedasticity (non-constant variance) in time series.
    *   Traditional models assume constant variance, but many time series exhibit volatility clustering.
    *   ARCH models focus on modeling variance, not the mean, of a time series.
    *   Volatility clustering means periods of high/low volatility tend to be followed by similar periods.
*   **Key Concepts:**
    *   Heteroskedasticity: Variance changes over time.
    *   Autoregressive: Conditional on past lags.
    *   Volatility models require stationary time series (mean), but can have non-constant variance.
    *   The variance depends on past squared innovations (residual errors).
*   **Formal ARCH Model Specification:**
    *   Mean equation (e.g., AR model): `yt = c + φyt-1 + εt`
    *   Error term equation: `εt | Ft-1 ~ N(0, ht)`
    *   Variance equation: `ht = α0 + α1εt-1^2 + α2εt-2^2 ... + αnεt-n^2`
    *   Conditions:
        *   `α0, α1, ..., αn > 0` (positive variance)
        *   `Sum(αi) < 1` (mean reversion/stability).
        *   `α1 > α2 > ... > αn` (more recent lags have greater weight).
*   **Steps to Estimate ARCH Models:**
    1.  **Mean Equation (Part 1):**
        *   Step 1: Check for stationarity.
        *   Step 2: Identify and estimate an appropriate ARMA/ARIMA model.
    2.  **Variance Equation (Part 2):**
        *   Step 1: Check for ARCH effects (heteroskedasticity test).
        *   Step 2: Estimate the ARCH model (determine lag order).
*   **Practical Application (Toronto Stock Exchange):**
    *   Demonstration using Toronto Stock Exchange (TSX) data.
    *   TSX level data is non-stationary; returns (differenced log) are stationary.
    *   An ARMA(1,1) model is selected for the mean equation based on correlogram analysis.
    *   Heteroskedasticity test confirms ARCH effects.
    *   Correlogram of squared residuals helps determine the ARCH order (ARCH(2) chosen).
    *   ARCH(2) model is estimated in EViews, ensuring positivity and sum < 1 conditions of alpha.
*   **Model Diagnostics:**
    *   Re-check for heteroskedasticity (no remaining ARCH effects desired).
    *   Check for autocorrelation in residuals (should be white noise).
    *   Conditional variance series is generated and graphed with the returns to show variance changes.

**II. Core Point**

The core point is that ARCH models allow for the modeling of time-varying variance in time series data, specifically the dependence of the variance of the error term on its past values, making them suitable for capturing volatility clustering often found in financial data.

**III. Fundamental Point**

The fundamental point is that traditional econometric models' assumption of constant variance is often violated in real-world time series, and ARCH models provide a way to account for this by explicitly modeling heteroskedasticity, providing a richer understanding of the time series' behavior, and more accurate modeling.

**IV. Overarching Framework**

The overarching framework is a two-part process: first, modeling the mean of a time series with traditional methods like ARIMA and then, modeling the variance with ARCH models when heteroscedasticity is present, and the process contains steps of data preprocessing, model identification, model estimation, and diagnostic checking.

**V. Conceptual Map**

<Mermaid_Diagram>
graph LR
    A[Time Series Data] --> B(Stationarity Check);
    B -- Non-Stationary --> C[Transform Data (e.g., returns)];
    B -- Stationary --> D(Mean Equation Model);
    C --> D;
    D -- ARIMA/ARMA --> E(Residuals);
    E --> F{Heteroscedasticity Test (ARCH Test)};
    F -- ARCH Effects Present --> G[Variance Equation Model (ARCH)];
    F -- No ARCH Effects --> H[Model Complete];
    G --> I(ARCH Order Selection);
    I --> J{ARCH Model Estimation};
    J --> K(Model Diagnostics);
    K -- Satisfied --> H;
    K -- Not Satisfied --> I;
     H --> L[Final Model];
    L -->M(Conditional Variance Analysis)
     M-->N(Plot with TS Data)
    subgraph "Part 1: Mean Equation"
        B
        C
        D
        E
    end
    subgraph "Part 2: Variance Equation"
        F
        G
        I
        J
        K
        M
    end
    style A fill:#f9f,stroke:#333,stroke-width:2px
    style H fill:#ccf,stroke:#333,stroke-width:2px
    style L fill:#aaf,stroke:#333,stroke-width:2px
    style N fill:#aaf,stroke:#333,stroke-width:2px
</Mermaid_Diagram>


Content:
[Music] hello everyone welcome back to another reviews video tutorial my name is juan and today i'm going to teach you how to estimate arch models interviews this is a topic that a lot of people ask me about so here i took the time to make this video i hope you find it useful and that it helps to clarify your doubts that you had about this topic i want to let you know that there is a link in the description where you can download the data to replicate the content and also in that page you will be able to find a link where you can buy the evie's work file with all the results in case you are interested in that and also will include the slides of this video so let's begin then with arch models arch stands for auto regressive conditional heteroskedasticity this model was introduced by engel in 1982 in his paper entitled autoregressive conditional heteroskedasticity with estimates of the variance of united kingdom inflation the model was later expanded in 1986 by wallerslab when he introduced carch models so so far we have focused on modeling the mean of the dependent variable so in other words we were trying to predict what is the value of for example gdp in the next quarter or inflation or interest rates however in this lecture we are not going to focus on the mean we are going to focus on the variance so traditional econometrics models assume that the variance of the disturbance term is constant over time yet many economic time series face periods of higher volatility than usual violating the homoscedasticity assumption therefore asset holders and financial institutions may be interested in estimating not only the returns but also the variance of the assets so we'll talk a little bit about volatility clustering for today's example i have toronto stock exchange returns and here is the graph where starts in 2016 goes to the present 2021 this is daily data and you can see that the returns the volatility has been pretty stable over time however there's been a big gap in here there's been a big issue here in the beginning of 2020 with kobe then we've seen that the volatility has increased in a significant way and it has remained quite volatile over this period so when we are talking about volatility clustering this is to mention that it's a common effect in equity markets and its periods of small volatility are followed by small volatility periods however when there is a period of higher volatility then those periods are followed by higher volatility periods as well moving to this next slide you can see i have included on one axis i have included the returns with the volatility here increasing in the 2020 and this is the graph of the exchange of the tsx exchange and you can see that it has been in an increasing trend however in 2020 there has been a big drop and that's the reason why volatility had increased consequently assuming that the variance is constant over time might not be appropriate and we might not be incorporating all the volatility that is in this variable so let's move to talk about some considerations of arch the concept arch refers to series with volatility changing over time that's why we're talking about heteroskedasticity and it's conditional to previous lags autocorrelation that's why we're talking about autoregressive conditional so it's basically we're saying it's not constant over time the variance and that variance is going to be conditional yes it's going to be changing depending on what happened in the previous in the previous lags yes in the recent past so volatility models are performed over stationary time series we are talking about the mean but with a non-constant variance so when modeling arch the variance depends on past squared innovations so we previously learned how to estimate the mean of a univariate time series with arima models so now we will verify if the model shows periods of higher volatility by checking the existence of harsh effects let's move into the formalities of arch models this first equation is the mean equation i have my variable yt which is going to be explained by a constant and the lag value of itself and an error term so this is an autoregressive model be aware that the mean you can estimate it also with moving average components you can estimate an arma model so whatever the type of specification that you do will be fine as long as you all we need to do is to estimate find an appropriate model to estimate the mean the second equation corresponds to the error which is going to be conditional to the previous information and it's following a normal distribution with zero mean and here in the ht i have the variance is going to depend on time and this h stands for heteroskedasticity so some people put here the sigma square some other um like textbooks on the paper of a granger uh do the h so that's why i have written an agent here so what is this h what is this variance going to be depending on well this variant depends basically on on a constant and the previous uh square residual errors so what are we trying to say in here so basically all we are saying with this type of specification is that the variance the volatility of the variance is going to be basically depending on what happened in the previous in the recent past and this model has to satisfy a couple of conditions so the first thing of all is that the alpha 0 and all the other alphas as well alpha 1 alpha 2 until alpha n have to be bigger than 0 and this is to guarantee a positive variance the second thing that we have to ensure is that the sum of all the alphas so alpha one until alpha n um the sum doesn't exceed one and the reason that we need that to be true is so the model always returns to the same mean and it doesn't have an explosive result and finally what we need to ask is that all the alpha so alpha 1 has to be bigger than alpha 2 and has to be bigger than alpha 3 and has to be bigger than alpha n so basically we are going to be estimating an arch model with potentially more than one lag yes that's why there's a p in here we have to determine how many arch components we are including in our variance model but what we need to verify is that the first leg is going to be bigger than the second line and it's going to be bigger than the third line bigger than the n lag and the reason for this is because the recent pass has more influence than older lags what we're saying basically with this um statement is that what happened yesterday will have more weight that what happened probably three four five six months ago okay so recent information is going to have more um it's going to have more weight than very old information what are the steps to estimate arch models well estimating arch models involves two parts and each of this part has two steps so the first part is the mean equation where the two steps involving estimating the mean equation are stationarity our variable needs to be stationary to estimate the mean equation and the step number two is well finding the appropriate arima model to estimate the mean we have already seen how to estimate arima model so i'm not going to focus too much on explaining the whole procedure of arima models so please feel free to watch my arima models tutorial and then part two is the variance equation so once we have estimated the mean we need to check if there exists arch effects or not and if it and if it does exceed starch effects then we have to estimate the arch model so let's begin with part one so the first part would be checking for stationarity you would normally do a graph analysis correlogram formal test but for this example we're just going to be taking a look at the authentic filter results and confirm if our variable is non-stationary levels but we have to then check if it's stationary differences any views i have here my variable the toronto stock exchange i'm going to open this variable and we're going to see the graph and as you can see this graph has a positive trend where there's a big drop in the beginning of 2020 due to code and then it goes back to this positive trend so this clearly is showing a non-stationary variable we can do the unit root test the augmented key filter test and i'm going to include a trend and an intercept because we can see there is a positive trend in this so the first thing that i would take a look at here is whether including the constant and the trend was appropriate and we can see that at the five percent significance level we can confirm that included the constant and the trend where appropriate since the p-value is smaller than point zero five and here we have the results of our tests the results are telling me that we cannot reject my null hypothesis so we're going to be moving now into working with the returns which the returns of these of the toronto stock exchange they'll be stationary um and also that's what we are interested about determining yes the volatility of our returns so i'm going to generate the variable i'm going to type i would like to call it returns and i'm going to type d log so i'm using differences unlock and that's what it's going to estimate for you the returns of your variable so i i have here the tsx which is my variable so i'm going to hit ok and i have estimated now my variable returns we're going to see the graph and as you can see now here i have the returns this is basically applying differences and logs to your variable and this variable does look uh that it has a stationary however we can definitely see that the variance is non-con is not constant yeah so this is what we are interested in modeling so we're going to go into view unit root test we are going to select nothing no trend or intercept because it doesn't have a trend um so we're going to hit ok now and we can see that the returns yes once we apply differences unlock my variable is stationary since i can i can reject my null hypothesis that my series has a unit root consequently my series is stationary so that's that's good so we can now estimate the mean equation so that's going to be the step number one so now we are going to move in step number two we have already checked for stationarity we have confirmed that my serious um toronto stock exchange is not stationary levels but when we take a look at the returns this is applying differences and logs my series is stationary and now we will try to identify an arima model yes we will select the order of p and q p is for the auto regressive component and q stands for the moving average components looking at the krillogram so let's go into views now and estimate the mean equation i'm going to open my variable returns that we have just generated i'm going to go into view and corellogram we're going to leave in levels as you can see recall from my tutorials where i where i guys show you how to estimate the ribba model so we have to look at the autocorrelation and the partial autocorrelation to to be able to identify the orders of p and q so all of those bars that are exceeding my confidence balance those are potential lag orders however due to parsimony and just to make it simple i'm just going to be estimating an arima 1-1 model but please be aware that you could try with other type of specifications as well as you can see here there are a couple bars that are exceeding however as i mentioned i'm interested in estimating um a parsimonious model this is not included so many likes and it's just for this example so we're going to estimate the mean so i'm going to type in my command section ls which is for list squares now the name of my variable which is returns i'm going to include a constant an ar1 term and then an ma1 term that's what we have determined by looking at the correlogram so i'm going to hit enter now and here i have the results of my model we can see that the ar component is appropriate is significant statistically significant and also my moving average component is statistically significant now that we have estimated the equation of our mean including an ar 1 and an ma1 component we can move into part 2 which is going to be checking for the existence of the arch effects so we're going to conduct the heteroscedasticity test and select the arch option the null hypothesis of this test is that there is no existing arch effects up to the specified line and the alternative hypothesis is that there are art effects up to the specified light as a hint if the p-value is smaller than. 05 at the five percent significance level we reject the null hypothesis and confirm the existence of arch effects so any views what we want to do right now is to check whether exists arch effects or not in my model i'm going to go then in view residual diagnostics and heteroskedasticity tests we're going to select the arch option and in the number of lags we're going to leave for now a one however later on i'm going to show you how we can determine the right amount of likes to include in this model so i'm going to hitting okay for now and here we have the test output and let's go back into the slides so we can do an analysis of these results in my screen you can see the heteroskedasticity test output here i put that the null hypothesis is that there is no arch effects up to the specified lagged order and as a hint if the p-value is smaller than 0. 05 we reject the null hypothesis and we confirm the existence of arch effects so that's what we can see in our example we can see that we are rejecting the null hypothesis and we are confirming that there exists architects in my model indeed remember that we included one lag in the test specification and we can see that this five percent significant level including that one lag is appropriate so my heteroskedasticity test is telling me that there are artifacts and also that including one arch one arch effect is appropriate however i would like to know if including more arch elements are appropriate in this model let's talk about how to determine the arch order so we have tested for the existence of arch effects up to order one however we can include more arch effects in the model we can review the correlogram of the square residuals and similar to arima models the partial autocorrelation function we'll provide some insights about the order recall parsimony we want to keep the model simple so we don't want to over fit the variance equation including so many large components finally recall that the arch effects cannot be negative so sometimes overfitting the model this is including so many lags is going to make all your arch effects negative so that's definitely not appropriate it's not a correct specification so that if that happens to your model where you see that there are many arch lags that become negative you need to start removing lags from your model specification so this is one of the flaws of arch models is determining the order of arch effects some models can incorporate many lags and this can be a bit complicated and even annoying to deal with so this is when guards models come to play as garch models can provide an alternative solution to dealing with arch models with so many lags however for this tutorial we are not going to focus on garch we'll proceed now with our arch model estimation so we're going to do now is we're going to double check what is the correct order of arch components to include in the variance equation so any views what we're going to now is go into view residual diagnostics and correlogram square residuals we're going to leave the default lag specification and here what we can see is that in the autocorrelation there is some persistence yes in the lux so that's basically why our test our heteroskedasticity test was confirming the existence of arch effects we can see that there is some persistence in this autocorrelation and also in the partial correlation we can see that there are some significant bars so that's what suggesting is possible arch effects so again we want to keep a parsimonious model so i'm not going to be including too many artifacts but what we can do is definitely test perform again the test and include more lags so i'm going to go into view um a residual diagnostic heteroscenasticity test and again you guys can try you can include more lags however for this example i'm just gonna stick to two remember that if you include too many you're going to be overfeeding the model and some of your arch effects are going to become negative and that shouldn't be the case so let's just for this example going to using two lags so using two lags we can confirm then again is that both legs are statistically significant so then doing an arch an arch uh folder 2 is going to be appropriate so now it's time to estimate our arch 2 model so we have a model for the mean equation which remember we are including a constant we said that for the mean we were including an ar1 and an mi1 component and also we agreed to include two arch effects so let's go now into views and let's estimate this arch to model you're going to go into quick estimate equation and the first thing that i recommend you to do in here is to go into arch when you're going to arch the following is going to appear and as you can see the first box is asking you to write what is your mean equation i remember that my mean equation was well the returns of of the toronto stock exchange then was including a constant the ar1 mod component and the ma1 component and the second part the second box in here is asking me how many arch and garg effects we want to include four guards we're going to put zero since we haven't talked about carch models in this tutorial and for arch we have agreed that we were going to use two lags two arch effects and the second thing that you want to check is going to options and you want to ensure that the back pass parameter is set to 0. 7 you definitely don't want to put it into one because that's going to be the unconditional um unconditional back pass parameter so we're going to stick it into 0. 7 and we're going to hit ok so here we go now we have estimated our arch two model we have that the two lags are statistically significant and here we have again the first um table this first part corresponds to the mean equation and the second part corresponds to the variance equation the way that you're going to write your model is first the mean equation we have the toronto stock exchange explained by a constant the outer regressive component and the moving average component and then we have the variance equation which is explained by the constant and the two lags that we have included in the in the arch specification as we can see the variance adds up to 0. 8 so remember that as a condition it cannot exceed the unit so alpha 1 plus alpha 2 they both make up to 0. 8 the persistence of the volatility is higher the closer it gets to one so in this case 0. 8 is relatively close to 1 so we can see then that the persistence of the volatility is quite high so now that we have estimated our arch to model we have a last step that is taking a look at the model diagnostics so the first thing will be the heteroskedasticity and what we need to do is to conduct the arch test again so what we should verify once we conduct the arch test again is that there are no arch effects because otherwise what your model then your result is suggesting you is that your specification is not appropriate that there still exists heteroskedasticity and that you should be including more large components and finally autocorrelation we have to look at the correlogram and there should be no significant lags the the probability of the q test should be bigger than 0. 05 so remember that the null hypothesis of this q test is that the residuals are white noise yeah so there is no autocorrelation so in order to confirm that hypothesis uh the p-value has to be bigger than point zero five so let's move into e-views and let's finish then with the model diagnostics to finish the model what we need to do then is to verify that there is no heteroskedasticity still present in this model so we're going to go into view residual diagnostics arch lm test again and we're going to include the two lags that we have used in our model and we want to verify now if there's still heteroskesticity so as you can see now the p-value is bigger than 0. 05 so what we are saying then is that there is no heteroskedasticity present still in this model so that's a good thing that's what we wanted and the last thing is checking for the autocorrelation the results have to be white noise so i'm going to go into racial diagnostics corelloram queue statistics and i'm going to leave the lag specification as default and as you can see in here in the oral correlation and partial autocorrelation is that there are no significant lags and furthermore if you can see here in the probability column remember that what i mentioned is that the q um the q test the null hypothesis is that my residuals are white noise and because the p-value is bigger than 0. 05 what we are saying then is that these residuals are white noise we cannot recheck the null hypothesis so this is very good as well so this arch model this arch 2 model satisfies the conditions that we have set for for arch models and something i would like to mention is that in this column the probability column you have values smaller than 0. 05 then your specification of the arch lags is not appropriate maybe you need to include more lags and once you perform again this correlogram accuse statistic test you're going to see then that all these values are going to be bigger than 0. 05 so that's something that you should consider is including more arch effects in the case that this column is telling you that there is autocorrelation the last thing that i would like to now is to display the variance of this model so i'm going to go into proc and make the large parian series it's going to tell if you how do you want to call it i would like to just call it of course conditional variance here we have the series then and we can view the graph of the conditional variance and here we have it so what we can do then with this conditional variance is we can plot it along with the toronto stock exchange i'm going to minimize this and i'm going to here i have the the series that we just generated with the tsx i'm going to open it as a group go into view graph and i would like to a last thing that is axis and scaling and i would like to have the conditional variance on the right scale axis sorry and here we can see that here we have our conditional variance graph and the toronto stock exchange and we can see how the variance has increased significantly in this moment where there is a big drop in the in the exchange that's going to be all the material for today so if you found this video useful i would like to invite you to subscribe to my channel since i'm going to be submitting many more tutorials about time series analysis my next video will be about guard models we're going to see how we can estimate guard models so if that's something you're interested about feel free to subscribe to the channel and as i mentioned in the link of the description you can download the data set for free and also you can buy the slides in case you're interested in and also you can get the abuse war file included in that package so once again thank you very much for watching and i hope you have a great day [Music] foreign
