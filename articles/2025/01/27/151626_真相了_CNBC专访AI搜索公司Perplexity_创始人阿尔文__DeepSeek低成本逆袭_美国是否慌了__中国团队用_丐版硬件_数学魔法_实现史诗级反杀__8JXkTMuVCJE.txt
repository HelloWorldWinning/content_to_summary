Timestamp: 2025-01-27T15:16:26.631981
Title: 真相了！CNBC专访AI搜索公司Perplexity 创始人阿尔文： DeepSeek低成本逆袭，美国是否慌了？ 中国团队用『丐版硬件+数学魔法』实现史诗级反杀？ 8JXkTMuVCJE
URL: https://www.youtube.com/watch?v=8JXkTMuVCJE&ab_channel=%E5%AE%8F%E8%A7%82%E6%B4%9E%E5%AF%9F
Status: success
Duration: 9:46

Description:
好的，这是对您提供的文本进行的总结和分析，包括核心观点、根本观点、框架结构以及一个使用 Mermaid 语法生成的概念图。

**1. 核心观点 (Core Point):**

在资源受限的情况下，中国人工智能团队通过创新性技术，如混合专家模型和低精度训练，显著提高了模型效率，对美国在AI领域的领先地位构成了挑战。

**2. 根本观点 (Fundamental Point):**

技术创新不单单依赖于充足的资源，限制反而可能激发更高效的解决方案，开源和产品化最终将推动AI的普及和应用。

**3. 总体框架 (Overarching Framework):**

*   **背景:** 美国和中国在人工智能领域的竞争，尤其是大语言模型（LLM）的研发。
*   **挑战:** 中国在硬件资源方面的劣势，以及美国在模型训练方面的先发优势。
*   **突破:** 中国团队通过技术创新，如混合专家模型（MoE）和低精度训练，在有限资源下实现了高效的模型训练。
*   **影响:** 中国的创新对美国在AI领域的领先地位构成挑战，并可能改变全球AI产业的格局。
*   **趋势:** 大模型走向平民化，推理优化成为新的竞争焦点，开源模式和产品化落地是关键。
*  **商业模式:** 新的AI平台广告模式，以及AI产品化落地的新方向和商业模式探索。

<Mermaid_Diagram>
```mermaid
graph LR
    subgraph Competition_Landscape [竞争格局]
    A[中美AI竞争] --> B(美国硬件优势);
    A --> C(中国资源受限);
    end

    subgraph Technological_Breakthrough [技术突破]
    C --> D(混合专家模型 MoE);
    C --> E(低精度训练);
      D --> F(高效模型训练);
      E --> F;
    end

    F --> G{创新解决方案}
    G --> H(模型效率提升);

    subgraph  Global_Impact[全球影响]
    H --> I(挑战美国领先地位);
    I --> J(AI产业格局变化);
    end
    
   subgraph  Future_Trends [未来趋势]
    J --> K(大模型平民化);
    J --> L(推理优化);
    K --> M(开源模式);
    L --> M;
     M --> N(产品化落地);
   end
    
    N --> O(新的商业模式);

    style A fill:#f9f,stroke:#333,stroke-width:2px
    style B fill:#ccf,stroke:#333,stroke-width:1px
    style C fill:#ccf,stroke:#333,stroke-width:1px
     style D fill:#bbf,stroke:#333,stroke-width:1px
      style E fill:#bbf,stroke:#333,stroke-width:1px
      style F fill:#afa,stroke:#333,stroke-width:1px
    style G fill:#cfc,stroke:#333,stroke-width:1px
    style H fill:#afa,stroke:#333,stroke-width:1px
      style I fill:#ff9,stroke:#333,stroke-width:1px
    style J fill:#ff9,stroke:#333,stroke-width:1px
     style K fill:#9ff,stroke:#333,stroke-width:1px
    style L fill:#9ff,stroke:#333,stroke-width:1px
        style M fill:#afa,stroke:#333,stroke-width:1px
        style N fill:#afa,stroke:#333,stroke-width:1px
         style O fill:#afa,stroke:#333,stroke-width:1px
```
</Mermaid_Diagram>


Content:
欢迎来到红关洞查 在这里我们立图呈现多样性观点祝你打破信息检访 这几天DPCK在国外彻底火了网上传什么的都有今天我们将分享CNBC对Pirplexity 创始人二文的采访二文对DPCK的看法还是相当中肯的希望能带给你启发 下面让我们进入对话面对如此复杂的新兴话题我们邀请了该领域的实战专家坚持模型中立立场的Pirplexity 联合创始人间CEO二文思维多巴赛雷他在我们的专题报导中多次发生并和我进行了超过30分钟的深入交流探讨深度求所DPCK的技术突破极其行业影响以及Pirplexity的发展规划这场对话干货满满值得完整零厅现在让我们进入正题首先我想了解局势的严重性能否描述中美人公制能竞赛的现状吗这场竞赛的堵住究竟是什么好的首先中国在竞争中面临多重劣势首要问题是硬件或取授现他们只能用性能较低的GPU基本相当于我们上代产品的水平再加上大模型天然更聪明的特点这种硬件差距让他们处于不利位置但硬币的另一面是需求催生创新资源授现反而迫使他们寻找替代方案最终竞爷发出更高效的解决方案这就像说你们必须做出顶尖模型但我不给资源自己想办法除非数学上证明完全不可行否则总有可能找到更高效的路径这种创新压力很可能让他们研发出比美国更高效的方案当然我们也能借见他们的开源成果这种在限制条件下的创新能力长期来看会成为他们的竞争优势目前每周最优秀的开源模型当初Mate的LAMM系列确实表现优异这类模型可以在普通电脑上运行但即便性能接近GPT4当时质量最接近的其实是参数量达4,051的版本而非能在本地运行的710参数版也就是说当时还没有叫乔联价优性能PD顶尖避远模型的开源方案无论是Anthropic还是Mistro AI都没能做到但深度求所突然推出个疯狂模型API价格比GPT4便宜识别比Crawd便宜15倍想因速度高达每秒16个偷坑部分基准测试甚至优于GPT4更惊人的是他们仅用于2048块H800GPU相当于1500块H100和500万美元总预算就完成了训练这比GPT4的训练资源少了20到30倍您强调的是效率突破用更低成本更差硬件达成目标当您真正理解他们的突破石油多震惊严读技术文当时我确实被他们的巧妙方案折服首先他们训练了混合专家模型Moee这种架构本身训练难度极大OPEN AI之所以能保持领先关键就在于解决了Moee训练中常见的损失直觉裂波动数值不稳定等问题他们不仅稳定了训练过程还创新性地采用8位付点训练据我所知这种低京度训练技术目前在美国扔属前演多数公司还在使用16位付点训练正是由于硬件资源受限他们被迫攻克了数值稳定性难题论文中宣称整个训练过程基本稳定意味著可以持续优化数据和模型更厉害的事整个训练周期紧60天看来确实让您大吃一惊绝对震惊过去普遍存在种偏见认为中国人只会模仿有人觉得只要美国停止发布研究细节不再开远他们就无法追赶但现实是深度求所的某些技术细节优秀到连MIT都接见到LAMOS的开发中这清楚表明中国已从模仿著转变为创新者我们上不清楚他们的训练数据细节虽然有猜测说使用了CHAGPT的公开输出但您认为存在真正的创新对吗?他们用14.8万一头肯进行训练现在互联网上充斥著CHAGPT生成内容灵印铁子X平台推文甚至文章工具都内置AI改写功能用户直接复制这些内容到网上自然就混入了LAYCHAGPT数据XAI也讨论过这个问题我认为不能因为某些提示慈祥印象四就否定他们的技术成就过去我们认为中国AI落后这次突破如何改变竞赛格局中国是在追赶还是已经反超如果说AntiRope正在追赶 OpenAI内同理中国也在追赶美国中国团队浮现欧文模型的论文数量甚至超过美国深度求所使用的算力规模其实和美国博士深刻获取的资源相当说实话PAPAXT当初放弃起字眼模型也是觉得追赶无望你们会在PAPAXT几终极成深度求所的模型吗已经在测试了他们提供 API和看源版本我们即可一调用接口也能本地不属低成本实现功能固然重要但更关键的是这件事打破了四位定式既然他们能有限资源做出优秀模型美国公司包括我们自己在美里有不努力创新了很多意见领袖如马斯克公开宣称中国无法在AI竞赛中胜出认为主导AI就等于主导世界经济您担忧中国展现出的这种能力吗首先马斯克是否说过中国追不上值的伤缺但关键是试图用封锁阻止追赶反而更危险如果中国做出最佳开源模型而美国开发者都在旗上构建应用这才是真正威胁生态系统的主动全将转移开源超越避远的历史规律我们都见证过当了阿妈问事实人们质疑该相信扎克伯格吗现在问题变成该相信中国吗开源模型的国家属性重要吗技术层面不重要模型全中完全有用户掌控但心里层面确实尴尬美国人才依赖他国技术中纠不妥况且开源协议可能随时变更所以本土创新至关重要我相信MET很快会推出忧郁深度求所的开源模型关键是美国应该用更好产品竞争而废为封杀而中国公司展现出更高兴价比的发展模式这对投入数十亿美元的美国巨头意味著什么显然未来会出现性能相当甚至更忧的开源替代品价格却便宜得多OPNA可能一转向新范畴Alice Satscaver提到的预训练是否触及天花板值的深思现在行业重点转向推理能力增强让模型在想因是思考更久使用工具与现实互动这正是OPNAI当前的法例方向但深度求所难道不会很快转向推理优化吗百分百会这正是我对他们后续发展出满期待的原因那那OPNAI的护成和究竟在哪目前他们的OE系统人距独特价值在处理复杂变成问题是展现出的准工程师水平上位被超越不过这种优势能保持多久存疑预计年底就会出现多个竞争者大模型正在变成大宗商品吗预训练模型确实在走这条老路未来推理模型也会经历同样过程出七少数玩家掌握决翘后期逐渐普及但像十四考星模型这种突破能否实现上不明朗深度求所的突破完成中国的Chach GPT时刻吗有这个可能至少极大增强了中国团队的信心证明在计算资源受限时他们总能找到创新路径这对投资格局有何影响据头文每年投入数百亿美元购置GPU但深度求所证明可能不需要如此稍前聪明做法是加倍投入推理优化毕竟基础模型正在快速连假化不过顶尖人才仍轻向加入率先突破的团队这种先发优势不容小趣奥特曼案是深度求所只是模仿者你怎么看这个领域本就相互借件谷歌手串川斯弗姆OpenAI将其产品化同理谁能把技术转化为好产品才是关键一年前您选择不参与模型军备竞赛如今看来非常明智能否谈谈这个决策如何指引 perplexity的发展当时连Card3.5这类模型都为出现只有GPT4一致独秀我们评估资深资源和人才后决定专注产品化落地用户需要的是能实施或去准确性源定制化见面稳定可靠的服务事实证明这个选择正确使用Card3.5后我们产品的换决率大幅下降用户量一年增长10倍听说黄人询也是你们的忠实用户他不仅是说说而已确实是高频使用者商业化方面你们开始尝试广告模式了我们在谨慎探索核心原则是答案质量绝不受广告影响赞助内容会明确标志用户可自由选择是否查看目前采用CPMG费不用导点击这和传统搜索引擎的强制点击模式截然不同按模型平民化已成趋势你们如何保持竞争力我们记受一与此也在开发付费功能比如支持多不推理的研究助手能进行深度分析的专业版但基础温达必须免费这是用户习惯也是我们必须守住的阵地广告主接受这种新模式吗大尔等品牌已在合作测试大家都明白5到10年后AI问达将取代传统搜索广告主希望在新平台早期就建立认知优势而不是被动跟随这完美呼应您开篇的观点需求催生创新广告主也在适应变革二文感谢您抽出宝贵时间好了以上就是本期节目的全部内容感谢各位的观看如果你觉得今天的内容对你有所帮助记得点赞订阅并帮忙分享给更多的人我们下期再见
