Timestamp: 2025-01-30T14:38:23.275821
Title: 投机采样？多令牌预测？DeepSeek V3如何提高大模型输出速度？ BCbzjItQWrg
URL: https://youtube.com/watch?v=BCbzjItQWrg&si=jstOjU9K0bDtGIPV
Status: success
Duration: 7:11

Description:
好的，这是对您提供的文本的总结，按照您的要求进行了结构化，并生成了 Mermaid 流程图。

**1. 核心要点（Core Point）：**

多头美杜莎模型（实际为多步并行预测）通过一次预测多个词语，在牺牲少量准确性的前提下，大幅提升了大语言模型的推理速度。

**2.  根本要点（Fundamental Point）：**

传统的大模型推理是逐词进行的，而多步并行预测则可以通过同时预测多个词语，从而大幅减少推理所需的迭代次数，提高效率。

**3.  总括框架（Overarching Framework）：**

*   **问题背景:** 大模型推理速度慢，尤其是在需要逐字生成文本时。
*   **解决方案:**  引入多步并行预测（又称多头美杜莎），一次预测多个词语。
*   **原理:** 从RNN和Encoder-Decoder结构出发，阐述了传统单步预测的局限性，然后介绍了多步并行预测如何通过预先计算多个输出，减少循环次数来提速。
*   **挑战:**  多步并行预测会牺牲一些准确性，因为预测未来的词语难度增大。
*   **优化方法:** 提出了使用类似于拉链的机制进行校正，在预测不确定时，退回一步，重新预测。
*   **应用案例:** 举例说明了多步并行预测在Bacon、DeepSeek-V3等模型中的应用。
*   **结论:**  多步并行预测在提升推理速度上优势明显，尽管会牺牲一定的准确性。

<Mermaid_Diagram>
  ```mermaid
  graph LR
      subgraph "传统逐字推理 (Traditional Per-Word Inference)"
          A[输入文本: 你好实践] --> B(RNN模型);
          B --> C[输出: 好];
          C --> D(RNN模型);
          D --> E[输出: 豆号];
          E --> F(RNN模型);
          F --> G[输出: ...];
          style A fill:#f9f,stroke:#333,stroke-width:2px
          style B fill:#ccf,stroke:#333,stroke-width:2px
          style D fill:#ccf,stroke:#333,stroke-width:2px
          style F fill:#ccf,stroke:#333,stroke-width:2px
          linkStyle 0,1,2,3 stroke:#555,stroke-width:2px
      end

     subgraph "多步并行预测 (Multi-Step Parallel Prediction)"
          H[输入文本: 你好实践] --> I(大模型);
          I --> J[输出: 好豆号];
           style H fill:#f9f,stroke:#333,stroke-width:2px
           style I fill:#cfc,stroke:#333,stroke-width:2px
           linkStyle 4 stroke:#555,stroke-width:2px
      end
      subgraph "优化策略 (Optimization Strategy)"
        K[预测: 不确定] --> L{回退一步}
          L-- yes --> M[重新预测]
          L-- no --> N[输出]
        style K fill:#ffc,stroke:#333,stroke-width:2px
          style L fill:#fcc,stroke:#333,stroke-width:2px
         style M fill:#ccf,stroke:#333,stroke-width:2px
      end
      O[传统逐字推理] --> P[速度慢]
      O --> Q[准确度高]
      R[多步并行预测] --> S[速度快]
      R --> T[准确度稍低]
      T --> K
    linkStyle 5,6,7,8,9 stroke:#555,stroke-width:2px
    
  style P fill:#ffc,stroke:#333,stroke-width:2px
  style Q fill:#ccf,stroke:#333,stroke-width:2px
   style S fill:#ccf,stroke:#333,stroke-width:2px
    style T fill:#ffc,stroke:#333,stroke-width:2px
  
  linkStyle 10,11 stroke:#aaa,stroke-width:1px
  
  ```
</Mermaid_Diagram>

希望这个总结和图表能够清晰地表达原文的核心思想。


Content:
大家好我是PhDVL像一个十二分四的牌子希望大家能够去多多的关注那么如果你要想去跟我们一起写配合的话就联系一下我们这个PhDHR然后它就会把你拉到我们的群里然后就可以跟我们一起写配合如果你要对我们写SERA配合比较感兴趣的话那可以来参加一下那今天这个大家讲一个有意思的东西叫做多头美督傻但这个多头美督傻这个名字其实是那个网上他自己起的这把这个名字你到往上去搜的其实是搜不到的这个东西的名字他有一个专业的名字但这个名字我觉得其实挺抽象的被这个名字提的挺切紧的所以说我就给大家用这个名字这个挺有意思这美督傻是个什么东西就是一个腰坏然后他身上长得很多头上长得很多的头对不对所以你看他一堆的头是不是然后呢你一管上得摘也可以就是这个模型叫管上得摘也可以你还是长一堆头嘛你把三头六臂然后这一堆头但这个美督傻的什么东西就今天说到了给大家讲讲就是说他本身是一个凡人女子然后呢有一个非常好看的这个容号但是呢因为他反正就是古希腊的那些神网这神网就瞎搞然后搞完了之后呢然后呢就把这个一个神件给得对了得对之后就把他背叙给我怪了然后这个头上有很多很多的这个他这个一个大头上有很多很多的小头就是这样一个故事所以就是这么一个事就是他把一个大头都非常一堆的小头他就讲这么一件事好的那这个模型呢他就叫这么个名字那这个名字是干嘛的呢就是我一个大模型居心心推理的时候他呢其实是需要花一些时间的这个大模型呢比如说我正常的模型都是怎么推影的比如说上海有什么好玩的地方我要把上书进去然后他的预测下一个字是什么那就是说下一个字是好但我呢如果要是一次能预测两个字的话那这样的话不就节省了一万的时间嘛因为他预大模型预测一个字和预测两个字他其实就是把这个书充了改一下对不对这个书充一个那个书充两个他书充两个呢其实也没有花太多的时间是不是所以说其实书充两个书充一个呢他的这个延迟呢其实是一样的那这样的话呢我们就可以降低一半的延迟那原来我们这个模型是怎么弄的我就找个张图给他接下来了那就是说比如说我说你好实践那我先把这个你呢放到这一个RN的模型里面这个其实是一个RN的模型这是一个RN的模型我把这个你的书的RN里面去之后的RN那他存主的一些数据在里面对不对所以说的这会变成好他告诉你下一个字是好然后再拿好的放进去然后那些会输出下一个东西的石豆号当然呢他可以输出很多很多不同的结果他都有概率但是呢你就会发现这个豆号的概率呢是比较高的所以他就可以这样一区输出知道了这个巨子最后的东西输出了你会发现这个输入呢和他的输出呢其实是错位的应该你呢值得到好然后好呢值得到豆号很多方的值得到是对啊张一职得到一个最后的结果这就是这样一个RN或者是传统版的其实也是同样的这样的一个玩法这个这样同的其实也讲实一件事这就是机器翻译的时候还有一个incoder还有一个dcoder对不对那比如说这就是传统方案吧那么呢我说我喜欢具会然后要把它翻译一下那就是说呢我把这个巨子整个数损具然后数损具之后呢最后一个是一个修指服告诉你就说我们可以开始翻译了然后呢修指服呢就对应了这数损具之后呢就把第一个字翻译出来的一个西班牙语呢就可以找到了耍石蜜然后呢这个辣物呢就是这个这个词然后呢后面就是这样一个词当然它不一定是一个字一个字对应的呀所以你看这就是蜜然后放在这然后呢蜜放进去后面输出的这一个词要注意的是如果这个是一个这个r的话呢这个东西呢你看这好多个四个单元其实它是同一个东西它是同一个模型你知道吧它是同一个模型然后呢它是这个模型的隐状态隐状态其实也不重要就是说它其实同一样的一个东西这边这个蓝色块都是同一个模型它是同一个模型这样输出输出它这个后面这个纸像其实可以没有就是说它就是它就是同一个模型对吧我们就是把你们塞塞进去之后呢看它的输出什么东西那这个红色也是同一个模型它不是说四个模型它是一个模型然后输出去一个东西它会得到一个东西对吧然后呢相当于就是我把这个词又输到这个模型里然后它会得到这样一个结果它是一样它只可以在展一点而已那我们说呢就是说呢这个模型的好处呢它就是能够把我们这个我们在输出一个巨子的时候本来是每一个都要去预测一遍对吧那你要进行这样一次一次的循环这样预测的话它需要花很多时间比如说呢预测每一个都需要花疫苗的话那这样的话我一次可以预测出了两个头这样的话就可以指花所以就这样的一个东西但是呢这个模型会有一个消息的问题这个问题就是说这个每都要头一可能预测得比较准但是你要预测得更往后的未来的话它本来应该是把海输到模型里面然后预测有但是呢你现在把这两个一起输出出来的话这个有它就不一定是准的因为它相当于是一个链条嘛你在最开始的时候错的一点你后面就会越错越敌补所以当你每都要头变得很多的时候其实你的最后的结果就会变得就是出入很大所以它还有一些别的方法来解决这个问题就是这单狨头机采样的一种方法就说呢我们可以在在这个比如说我当我输出这个有的时候发现一个有它都不是特别确定它在推进率可能只有50%在这个时候呢我们就把大王形在把这个海子再输进去然后让海的预测后面这两个字然后看这个字是不是还是有如果它还是还是有的话就输出有它说不是有的话就换一个字这样的话就可以解决问题它像就是一个拉锁一个拉链这就是相信是一个拉链然后这个拉头就把下拉拉锁那有时候会跳过一个靠对啊直接拉点跟这个拉链但这样的话有时候它就卡住了或者说它就是输出的结果就是越错越低谱那我们就让这个头呢让这个大模型的造后再错一辈对吧把海说进去然后再把后进行预测这样的话我们就可以降低它这个突现就是不准确的这样的一个情况那就是这样的一个这样的一个技术吧好的那我们说呢这个技术其实在很多地方都用到了比如说被空纳这个模型呢就用到了那把空纳这个模型呢它呢就是拉网然后就是它本来是拉网嘛然后把拉网呢在丝丹服务丝丹服务用这拉网呢在做了一些格外的一些训练然后留到了一个就说用完科研的这样的一个这样的一个大模型然后我们过大这个模型呢它呢也是就是使用了这样的一个方法去预测对来的多个头这样的话呢它就可以降低这个模型的这样一个输出延迟那说为空纳之外呢那这个dipc个v3的也用了dipc个v3我们大家可以去讲一下这个模型呢算是就说目前应该是进来这么多模型里面效率最高的一个模型那在这个也是所以才做出来这样的模型那这个模型它这个东西呢其实应该叫做多定排预测这是没多头每度上这个词就是这个网篮自己编出来的这个词根本不存在好吧但是这个字挺形象的就用了它其实叫多定排预测多定排预测的就是我同时一次呢预测下面的1到2个词源但是呢有可能就会它产生一些就是说这个词源可能会有些损失啊因为这个词源那可能就是到后面的时候对吧您的后面有3个词或者5个词的时候那个5个词它就预测的不太对了因为你要预测太未来的这个未来的对吧预测出来结果可能就会出现一些问题你先去报网预测明天的还行你同时预测5天之后的那这个预报可能就不是特别准的就发生这个问题但是它呢就是MTP这个方法那可以把它的这个生成的速度呢提高很多比较可以从原来这个20个提升到60对吧你一下提高到3倍因为它的同时预测为了3个词那这样的话就可以让这个速度变得非常快好了那今天这个视频呢就想要做点看大观看我们下期再见
