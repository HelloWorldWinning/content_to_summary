Timestamp: 2025-01-01T12:43:47.799411
Title: 2024 AI Winners!!! ðŸ’¥Best LLMs of 2024 ðŸ’¥
URL: https://youtube.com/watch?v=4NUtg4Aj1dI&si=s4ulIggOOstFQiD-
Status: success
Duration: 20:09

Description:
**Summary:**

1.  **Best Coding Model:** Claude 3.5 Sonnet excels at solving coding problems in popular languages.
2.  **Biggest Surprise of the Year:** OpenAI's first model with test-time scaling fundamentally shifted thinking about LLMs.
3.  **Biggest Disappointment of the Year:** Mistral, despite initial promise, did not challenge industry leaders and shifted to restrictive commercial use.
4.  **Best Large Context Model:** Gemini 1.5 Pro/Flash is optimal for long context windows and building memory layers.
5.  **Best Small Model:** Qwen (under 3 billion params) is a strong, domain-specific small model.
6.  **Most Underrated Model:** The Qwen family is high-performing, open-source, and not widely discussed.
7.  **Best Fastest Model:** Gemini 2.0 Flash is the go-to for speed without sacrificing quality or context window.
8.  **Best Multimodal Model:** Gemini 1.5 Pro excels in processing images, text, video, and audio, including speaker diarization.
9.  **Best Agentic Model:** Claude 3.5 Sonnet is excellent for building agents due to its reasoning and coding capabilities.
10. **Most Valuable Model:** Claude 3.5 Sonnet is the most versatile model, suitable for various tasks.
11. **Best Developer-Friendly Model:** GPT-4 is reliable and scalable for building SaaS products.
12. **Biggest Disaster Model:** Reflection 7B, despite its core concept, failed to deliver on promises.

**Core point to conclude with:**  The year showcased diverse AI models, with Claude 3.5 Sonnet emerging as a powerful and versatile choice, while specific models like Gemini 1.5 Pro/Flash also stood out in specific contexts.

**Fundamental point to conclude with:**  2024 brought significant advancements in AI model capabilities across various areas, demonstrating an evolution beyond just pre-training to test-time scaling and task specialization.


Content:
all right welcome to the 2024 AI models awards ceremony grab your cup of tea or coffee whatever your prefer and we going to give away 12 different Awards this is the award that they're going to get I don't have a big production unit for me to create a better award this is something that my kid designed so this is the award that we're going to give these companies we're going to give award in 12 different categories starting from the best coding model until going up to the best developer friendly model and each of these category is highly opinionated thought it's not based on LMS Arena it's not based on the benchmarks that they released I've worked with a lot of companies trying to craft AI strategy for them so this is based on my learning and what I tell people so if you were to watch one video before 2024 ends this is probably one video that could give you a summary of what kind of AI models that you can probably use first category is the best coding model I think this is undoubtedly one of the biggest category that everybody is interested in because if you if you were to develop applications like cursor where you want coding Assistance or if you were to develop Solutions like lovable datab button bold. new you need a strong Foundation model that can help you write programs computer codes this has been one of the most progressed area in 2024 in my personal opinion models have become really good at writing computer programs much better than me like very couple of days back I just gave a documentation that was in JavaScript I gave it to a model in this case it was GPT and asked it to give me the code back in Python and then it just did without a single line of mistake and I was quite surprised how it can do this but this winner is not from open AI the best coding model for 2024 is Claude 3.5 Sonet from anthropy clot 3.5 Sonet is this model where you can go with a coding problem and then it would most likely solve it for you um as long as the problem is not very Niche you're not writing assembly you're not writing C if if it is like very popular programming language python JavaScript HTML any JavaScript stack this is a model that you should probably blindly use to solve your coding problems in fact people who use cursor know that very well that Claude 3.5 Sonet has been one of the biggest uh strongest backers of cursor and that is why cursor is quite good because CLA 3.5 son is really good next one is the biggest surprise of the year and when I wanted to give this award like I had a lot of different models and thought like in fact like in multi modality but the one that I decided that this is the biggest surprise of the Year for me personally is open ai1 this is the first model that was productionize users could use it and that came with test time scaling and no other model had done this before and uh even if there were like a lot of papers like I have videos probably like one one and a half years old where we had a framework called reflection and that framework was telling how these models can actually go through different kind kind of an answer and then get back to you we also did a podcast with uh the AO I think first first winner or second winner or third winner I'm sorry uh but they what they did is they also built like a lot of candidate models generated candidate response during test time and then they picked one of the one by majority voting and then finally that model did the better one so but there was no single end point like a model that could do this and I think open a W1 or opena in particular deserves a huge amount of respect for bringing in this perspective Chain of Thought existed but open A1 actually came in and then say that okay we are going to deliver a model even if it is not like really high quality see the model was not like top quality even if it is not going to be high quality we came and delivered a model that completely shifts how people are thinking about llms not just anything about pre-training anymore but it is also about test time scaling so I think opena 01 deserves a huge rank Vote or this this award Sam Alman if you want to collect it please reach out to me if you were to give a second runner up I would have probably given this to 03 or if I were to give a runner up without open AI I would have given it to the Deep seek the very latest deep seek model that kind of crushes the open AI models in benchmarks the only reason I did not give deep seek as the biggest surprise of the year is because I kind of agree with Sam Alman here because it's very easy for you to take a model's response and then find youe another model and then beat The Benchmark rather really hard for you to design the foundation model which in itself is a really good model I think open a deserves the respect that they need there and deep seek from China is really good model but the biggest surprise of the Year for me personally changing a shift and thinking about how Frontier Model should work open A1 deserves this award let's get this one out of the way the biggest disappointment of the Year again a very personalized thought like you can have like different opinions for me personally a company that I believe would come and challenge open AI like anything that's what I thought it's a French company you might have guessed at this point but somehow it did not do it they've released a lot of models this year they've gone into different trajectories I'm happy that they still exist they did not go down like stability I mean stability still exist they did not go down like stability in the way like the CEOs fired or like CEO left the company and all these kind of unnecessary Shenanigans but this company I honestly thought they would be right up at the top but it is not uh this is mistl if you do not know the company I loved ml 7 billion parameter model but after that uh I hardly saw anything that was like you know mindblowing that could completely change the paradigma that could challenge the industry leader in fact they went onto a path where like stability they said okay these models like once Mr was like the open source Flag beer but they went into the spot where they said okay you can use these models for research purposes but you cannot use use this model for uh commercial purposes kind of like um a disturbing path but I know I know companies have to make money there are venture capital is waiting for you to make money I know the pain of running a company I'm not running a company I'm just running a YouTube channel but for me personally the biggest disappointment of the year is the French company Mr fourth award is the biggest or the best large context model so either the biggest context window or you want to call it or the best large context model and this is a category that is very very important for a lot of things that you do in life for example imagine I want to like create a model with all the items in my room and then I want the model to have the memory of it uh not not uh the only the in context memory but the complete memory of what it has so every time I can store like have a memory layer store everything in that and then I can retrieve it during my inference time send it to the model uh and uh if I where to do those things I want the model to have really long context window the ability to have long cont window I think in my mind there is no other model comes closer to this model that has done this job extremely well and if I were to use one model just for its long context despite the pain of dealing with the model that is without any doubt Gemini 1.5 Pro Gemini 1.5 Pro and Gemini 1.5 flash are the models that you would BL you should blindly use if you want the largest context if you want to build a memory layer for LMS you want to build like an AI th IST you want to build an AI tutor you want to have profile of the users and you want to send all these things during the inference time I think without any doubt you can blindly use the best large context model which is Gemini 1.5 Pro now coming to the smallest size the best small model that in my opinion is the quen 3 billion parameter or less than 3 billion parameter model quen is company Quin is a product from Alibaba I guess so this like basically a Chinese model so it does a pretty good job it's not like predominantly multilingual like uh mile but it does a pretty good job of giving you everything that you want uh they've got like different domain specific models like math model coding model uh so Quin undoubtedly the less than 3 billion parameter model is really good on if you were to pick up it for any particular task that you want to do in your local computer the best underrated model or the most underrated model in my opinion so you you might think about like lot of different models the model comes in a lot of YouTubers like me we speak about those models like for example we are like we like unpa PR units for open AI companies like anthropic companies like Google but there is like this one particular model I've always felt like a less number of people speak about it variety of reasons and they contribute to open source ecosystem they release mostly open weights they're quite transparent publishing papers and all these things and that model the most most underrated model in my opinion is the Quin family of models Quin you can collect it from China if you want so I believe Quin has been this model that that is really hitting the top of the mark sometimes but hardly been spoken about and they do what they do really good uh they're not trying at least in my opinion they're not trying to help you replace your opening APA call in that particular place but if you have got a router and if you want one of the models quen is really good the coding model is good um if you want to use their smaller models they are good they've got the larger models they're good they've got a vision model that is good so overall if you see a package that is like highly underrated not a lot of people talk about that is your Quinn family of models the next one is the best fastest model like if you want if you care about only speed the infinite speed I'm not talking about using Gro I'm not talking about using um let's say cerebra systems or um you know any other service provider accelerated Endo just talking about generally there is a model if you want the fastest response there are two ways for you to approach it one you can either go in the r route of a smaller model like I said go to quen and then use it or honorable mention for a smaller model as well like five um I don't know how many of you use f from Microsoft if you happen to use f let me know in the comment section because I personally do not know a lot of people using but I think F has grown into its own ecosystem at this point so but you don't want to go in the route of a small model you want to go in the route of a really like good model but you want fast I will close my eyes and then say that Gemini 2.0 flash is the model that you should pick if speed is your primary concern without trading off quality and accuracy a lot Google has nailed it Gemini 2.4 flash is quite amazing uh I don't exactly know how bad the rate limits are and I I have not signed up for vertex to use it so if you are one of those going through the pain of using it through vertex I can understand the pain that you have to go through with gcp but if you're using it from AI Studio from Google or if you're using it from AI studios's APA key then this is one of the best models coming also with a very long context window but also really fast model so Gemini 2.0 flash is really really good the next one is the best multimodel model so if you were to pick a model that is good with processing images that is good with processing text and if you were to process video as well like natively there are very few models in this world that can do like once again going back to the same example if I were to take let's say I've got a CCTV footage in my room uh which I do not have at this point why would I have CCTV inside my bedroom but lat us say for the sake of discussion I've got a CCTV footage I've got to check with my wife if she has got anything in there but if I've got a CCTV footage and I want to send it to a model maybe like 40 minutes I want to send it to a model and then ask for insights maybe I've got like a rack rack of books I want to read all the books maybe I've got like recipes in my refrigerate sorry in ingredients in my refrigerator or kitchen I want to find out what are the things that I can make with this there is I think only one model that can do a tremendously good job in this case once again it is Gemini 1.5 Pro I think this model has nailed multimedia processing like anything the images with audio video I'll tell you a thing uh if you know about ASR automatic speech recognition which which is a process in which you give the speech as a feed and then you do a bunch of things one of the important things that people do with speech recognition or speech to text is Speaker diarization very important for podcast like there are lot of different ways to do it if you're from traditional machine learning background you know about kin's clustering which is an unsupervised learning technique so you can in fact build a kin's cluster with K is equal to two if you know there are only two speakers and then do speaker diarization there are different methods but if you were to pick an llm like a large language model that natively processes audio and that can do speaker diation for you I I believe Gemini 1.5 Pro is the only model probably that can do I've not tested it with gbd4 o I've done like commentatory with gbd4 but not like audio processing so you can do audio processing you can do video processing you can do image processing you can generate text one of the best models if you were to do multimedia best multimodel generation best multimodel model so Google Sund if you want to visit Tamil Nadu anytime um I can come and give it to you probably others I told come and collect it sorry sorry S I cannot come and give it to you you have to collect it from me the next one is the best agentic model if there is one model that is really really good for agentic tasks like topnotch you want to build a research agent you want to build like a multi uh agent system you want to use pantic AI you want to use crew AI you want to use py autogen AI you don't want to use any framework you're fed up all the Frameworks you want to write your own code and use it for agents see uh the best agentic model is not very difficult to guess because and a good atic model should have two good things one it should have good reasoning capability second it should have good coding capability so what is the model that is good with reasoning and coding if you think then you would say that it is none other than Claude 3.5 Sonet so CLA 3.5 Sonet without any doubt is the best agentic model that is available in this world at this point if you were to build agents this is the best model now we are almost at the tail end of this video so only three more awards are there the best or the most valuable model in my opinion so if you were to pick a model um so as you know this this entire structure I've copied it from somebody like mkbs and Mr who's the boss like these are Tech YouTubers I've been following for many years they've done smartphone uh reviews smartphone Year End Awards I've diligently watched that I don't know if anybody is going to watch this video on 31st December I don't know how many of you are at home to watch this video but I wanted to put out this video kind of like mimicking what those guys do in the smartphone World So based on that if you so they what they do is they pick the MVP smartphone like one smartphone that is really good at everything it's not like good at one thing it is almost like kind of an averagely good at everything but collectively it is the best model that you you can use the same concept if you were to pick one most valuable model like if somebody comes to me and then says Hey Abdul like nobody's going to call me one little coder in my real life they're going to say hey Abdul uh this is a model uh I want to use for coding can you suggest me or maybe I want to use this model also for reasoning can you suggest me or maybe it's good if the model can also do like image processing can you suggest me hey but I also want to use this model for let's say some part of like planning task maybe I want to use this model to solve harder problems what is that model that you would suggest let me know in the comment section but if somebody asks me that question close my eyes I will blindly say the only model that you should go pick is clae 3.5 Sonet no doubt it's not clae 3.5 Opus because there is no clae 3.5 Opus a lot of people call this Claude 3.6 Sonet so whatever you would like to call it CLA 3.5 Sonet you CLA 3.5 Sonet CLA 3.6 Sonet whatever you would like to call it I think anthropic has cooked really good model I mean what are the intentions that they left open AI safety and all these things if you kept it aside they've built a really really good model so there you are anybody from anthropic if you want this award please reach out to me oh the most valuable model I would say Claud 3.5 son they've Hit The Benchmark even thinking models are trying to beat what CLA 3.5 son it has done so there is something definitely they've done quite amazing in the pre-training that people are still trying to beat it again a very surprising thing CLA 3.5 Sonet is not the leaderboard topper on LMS don't know what is happening but if you have to go with the vibe check or if you have to go with the awards presented by one little coder you should say claw 3.5 Sonet is the best model we have two more categories lift what are the two more categories the best developer friendly model see I know most valuable model now you may be like hey abdulah I want to build a SAS I be like don't go with claw 3.5 on it they've got a terrible infra I mean if you have paid for anthropic Pro you probably would know that half of the time it is almost like you know you can't use this model or they so they've got a terrible infra I think if there is one company in this world that has figured out infra like anybody that is definitely Google but I'm not going to suggest Google for this thing because I don't think they best developer friendly model their Vortex platform is still a pain to use you can use it with AI Studio but there's a lot of confusion lot of experimental model so if you want to build a SAS software as a service using one LM endpoint like not multiple llm endpoints using one llm endpoint one model that you want to to be Rock Solid and scaling in for a lesser downtime and the model should do all these things good like claw 3.5 sonid but except it's not from anthropic without a doubt it is GPT 4 this is still a good model a really good model doesn't click as much as claw 3.5 son it would click but if you are a developer you want to use a model that should do well with the SAS software as a service to build products applications Android applications iOS ations you should go with the open AI GPT 40 the best developer friendly model or the most perfect model to build your product on business on the final section I'm going to leave the final section uh the final section is the biggest disaster model of the year so if there is one model that got launched announced launch SL whatever you would like to call it and it had the biggest disaster in terms of PR in terms of quality uh I would say I don't know how many of you remember this is the reflection 70 billion parameter model I don't want to go deeper into the controversy there I think the fundamental principle behind reflection was quite amazing because reflection came into picture then open A1 came into picture except that reflection did not reflect on the promises that they made reflection probably is one of the biggest disasters people started becoming more skeptical whenever open model came into picture so biggest disaster of the Year reflection that award goes to you please please don't collect this award from me but otherwise uh I think this was a great year for AI models I've got the best video generation model Minx uh from China we have got haloo AI or we have got cling 1.5 we have got a lot of other these categories where these models are doing tremendously good Google has got like an experimental or a beta model for video generation V2 we've got Sora within chart jbd Plus subscription so this year has been really great for AI models so if you are watching this video I would love to know what is the model that I missed what is it something that you are looking forward for 2025 let me know in the comment section otherwise I'm so grateful that you're watching my video see you in another video Happy prompting
