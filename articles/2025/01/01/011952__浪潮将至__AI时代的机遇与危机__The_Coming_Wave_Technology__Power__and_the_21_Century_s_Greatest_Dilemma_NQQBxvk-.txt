Timestamp: 2025-01-01T01:19:52.831341
Title: 《浪潮将至》：AI时代的机遇与危机 ｜The Coming Wave Technology, Power, and the 21 Century's Greatest Dilemma NQQBxvk-Jiw
URL: https://youtu.be/NQQBxvk-Jiw?si=yTds64_Ne5FYLCVZ
Status: success
Duration: 14:36

Description:
**核心观点概要:**

1.  **科技浪潮与挑战：** 我们正处于科技变革时代，新科技浪潮（AI、合成生物学）带来巨大机遇的同时，也潜藏着巨大风险和挑战。
2.  **科技的双刃剑：** 科技既能推动社会进步，也能带来灾难，需谨慎对待，不能放任其野蛮生长。
3.  **遏制科技：** 需要主动引导科技发展方向，制定规则、设置边界，确保科技发展符合人类利益，类似于核能管理模式。
4.  **AI发展：** 深度学习等技术使AI快速发展，但模型规模扩大、开源趋势等带来计算成本、能源消耗以及被滥用等风险。
5.  **合成生物学：** 人工合成生命技术具有巨大潜力，但也可能造成生态灾难或被用于制造生物武器，需要加强监管。
6.  **科技与权力：** 科技力量影响权力格局，科技巨头和国家力量之间的竞争可能加剧，需要控制科技力量，防止被滥用。
7.  **遏制步骤：** 书中提出了10个遏制科技风险的步骤，涉及技术、社会、政策等层面，需要全盘考虑，步步为营。
    * 设计约束，预警机制，加强审计，提升技术能力，重新调整机力机制，改革政府，达成国际条约，重速科技文化，发动全球运动，全盘思考，步步为营
8.  **积极应对：** 我们需要拥抱变化，积极学习和适应，同时保持警惕，意识到科技的潜在负面影响，积极参与科技治理。

**核心结论 (一句话总结):**

科技进步既带来机遇也伴随风险，人类必须主动遏制其负面影响，才能确保科技为人类服务。

**根本结论 (一句话总结):**

在拥抱科技发展的同时，必须建立规则，积极应对挑战，防止科技失控，最终才能让人类受益。


Content:
欢迎来到我们的频道,享受这本书,今天分享的是穆斯塔法、苏莱曼、浪潮江峙、科技、权利与21世纪的最大困境。作者是是DipMind的联合创始人,也就是开发出Alpha Go打败维其世界冠军的那个公司。这本书的核心观点是,我们正处于一个前所未有的科技变革时代,新一波科技浪潮即将到来,他将彻底改变我们的生活、社会、乃至整个世界。但与此同时,他也带来了巨大的风险和挑战,我们必须谨慎应对,才能在这波浪潮中生存下来。你可能会好奇,一位AI领域的领军人物,为什么会写这样一本书。为了更好的理解作者的观点,我们先来回顾一下历史。人类文明史,其实就是一部科技发展史。从时期时代到青同时代,从蒸气机到互联网,每一次科技的重大突破都会带来生产力的飞跃,竟而改变社会结构和生活方式。咱们的祖先,最初只能依靠简单的石头工具来受劣和采集食物。后来,他们学会了使用火,也练金属,发明了农业,这才逐渐定居下来,建立了村庄和城市。在后来,印刷树,蒸气机,电力等等一系列的发明,更是彻底地改变了世界。每一次科技的重大突破都会带来生产力的飞跃,社会结构也会发生翻天覆地的变化,人们的生活方式更是日新月异。就拿书里提到的印刷树来说吧。15世纪的时候,这项技术就像野火一样,在欧洲大陆上迅速传播开来。你能想像吗?当时的人们突然之间就能接触到海量的书籍和知识,这在以前,可是想都不敢想的事情。印刷树的普及直接导致了文艺复兴和宗教改革。欧洲社会也因此迎来了一个全新的时代。工业革命的确让物质财富变得前所未有的丰富,但也带来了环境污染、贫富差距等等问题。所以说,科技就像一把双任剑,它既能造福人类,也可能带来灾难。说到这儿,我不仅想问大家一个问题,面对即将到来的新一波科技浪潮,我们应该如何应对呢?是像奥斯曼帝国那样,因为害怕印刷树带来的冲击,而选择禁止。还是积极拥抱变化,努力去适应新的时代?作者苏莱曼的答案是,遏制浪潮。他认为,我们不能放任科技野蛮生长,而是要主动去引导他的发展方向。当然,遏制AI的风险并不意味著要阻碍AI的发展。我们应该鼓励AI在各个领域的应用,让AI为人类创造更多的价值。这可不是建容意的是,新一波科技浪潮发展速度太快了,就像一道巨浪,果斜著巨大的能量,奔勇而来。AI时代就像一把翘动未来的双任剑,寄充满希望,又暗藏风险。深度学习的出现描述为AI领域的重大突破。深度学习是一种机器学习技术,它使计算机能够从大量数据中学习,并提高其性能。深度学习技术的突破性进展使得AI在计算机视觉,自然与言处理等领域,取得了显著的进步。AI技术的应用范围正在迅速扩展,从自动驾驶汽车到医疗诊断,再到金融交易,AI正在改变著我们生活的方方面面。同时AI已经开始渗透到各行各业,并将继续深刻地影响著我们的社会和经济。AI模型规模的快速增长。例如,Google开发的语言模型泡,该模型拥有5400亿个参数,相当于大约25万6000个成年人大脑中的神经元数量。作者指出,随著模型规模的增大,AI的性能也在不断提升,但也带来了更高的计算成本和能源消耗。同时作者观察到AI领域出现了开源的趋势。例如,MAT开源了其大型语言模型,Opt,175B,允许研究人员和开发者自由使用和改进。作者认为,开源趋势有助于推动AI技术的创新和普及,但也可能带来一些风险,例如被用于恶意目的。当下,AI已经成为国际竞争的重要领域,各国都在争夺AI领域的领导地位。他特别提到了,中国在AI领域的快速发展,并指出,中国政府已经制定了熊新伯伯的AI发展计划。作者认为,国际竞争可能会加速AI技术的进步,但也可能加剧地,求政治的紧张局势。同时,AI会不会导致大规模事业?毕竟,很多工作都可以被AI取代,从工厂工人到出租车司机,甚至律师,医生都有可能受到影响。AI会不会被用于制造武器,引发战争?现在已经出现了无人机,自主武器系统等AI武器,未来战争的形态将会发生怎样的变化呢?AI会不会发展出自我意识,威胁人类的生存?这或许是很多人最担心的问题。毕竟,科幻电影里已经掩过太多AI反判人类的故事了。面对这些问题,我们该怎么办呢?苏莱曼在书中提出了一个重要的概念,遏制。他认为,我们不能放任AI也满生长,而是要主动去制定规则、设置边界、确保AI的发展符合人类的利益。这就像我们对待核能一样。核能可以用来发电、造符人类,但也可以用来制造核武器、毁灭世界。所以,国际社会制定了各种条约和协议、限制核武器的扩散、确保核能的安全利用。对于AI,我们也需要采取类似的措施。当然,遏制AI的风险并不意味著要阻碍AI的发展。我们应该鼓励AI在各个领域的应用,让AI为人类创造更多的价值。关键在于,我们要找到一个平衡点,在发展AI的同时,也要防范AI的风险,确保AI最终服务与人类。你们觉得呢?2010年,科学家克雷格·文特尔和他的团队,硬是把人工合成的细菌基因组塞进一个空隙包里,正出了第一个完全由人工合成基因组控制的生物,新西亚。这是首例人造生命。虽然新西亚只是个单细包细菌,但这事意义重大呀。他意味著合成生物学这门技术,已经能人为操控生命了。你想想,如果有一天我们能随心所欲的设计,改造甚至创造生命,那会是什么光景。有一个GPRIGHT人类基因组编写计划的全球联盟,他们的目标是在十年内,把合成基因组的成本降到现在的千分之一。这意味著啥?意味著合成生命将不再是少数实验室的专利,而是像手机电脑一样,走进千家万户。合成生物学能干啥?他的应用范围可广了,简直让人难以置信。医疗方面,我们可以设计出能生产特效药的细菌,或者改造免疫细胞来干掉癌细胞。就像书里说的,未来人类的基因组将变得像橡皮腻一样,可以随意修改,那长生不老,反老还同,都有可能实现。农业方面,我们可以培育出不怕病重害的超级农作物,或者让农作物自己生产肥料,产量翻好几倍。环境方面,我们可以创造出能分解塑料垃圾的威生物,或者利用早类生产清洁能源,解决环境污染问题。但合成生物学这模合一旦打开,也可能放出些不太好的东西。要是人工合成的生物失控,会不会造成生态灾难?这就像外来物种入侵一样,后果不堪设想啊。要是不法分子,利用这技术,制造生物武器,后果会怎样?这些风险,作者在书里也有提到。他认为,我们必须在发展合成生物学的同时,加强监管,制定规则,防止技术被滥用。如,建立一个全球数据库,记录所有人工合成的生物体,方便追踪和监控。在比如,制定国际条约,禁止把合成生物学技术,用在武器研发上。当然,监管的目的不是要遏杀合成生物学,而是要引导他,朝著安全,可控,造福人类的方向发展。说白了,谁掌握了科技,谁就掌握了话语权,谁就拥有了更大的影响力。就像过去,谁能造出最封力的刀剑,谁就能称霸一方。现在,谁能掌握最先进的人工智能,合成生物学技术,谁就能在未来的竞争中,占据优势。英国东印度公司,这个私人公司,当年可是靠著先进的航海技术和武器,英生生在印度建立了殖民统治,甚至一度控制了全球一半以上的贸易。这足以说明,科技力量对权力的影响有多大。那在未来,谁会成为科技的主宰呢?苏莱曼认为,最有可能的是那些科技巨头,比如谷歌、亚马逊、威软等等。这些公司拥有雄厚的资金、顶尖的人材、海量的数据,他们在AI、生物技术等领域的研究已经走在了世界前列。想想看,如果这些公司利用手中的科技力量去追求私立,甚至控制政府决策,那会发生什么?就像科幻电影理演的那样,未来世界会不会被少数科技精英所统治?除了科技巨头,国家力量也不容忽视。特别是像中国这样的国家,正在大力发展人工智能、量子计算等监端科技,他们也是途通过科技来提升国家实力,甚至挑战美国在科技领域的霸主地位。那未来会不会演变成科技巨头和国家之间的决力呢?这两种力量,谁会最终胜出?更令人担忧的是,随著科技的快速发展,很多技术都变成了双任剑、技能造福人类,也能带来巨大的破坏。人工智能,可以用来诊断疾病,但也能用来制造杀人武器。那我们该如何控制这些强大的科技力量,防止他们被滥用呢?书中的第14章,详细列出了10个步骤,来实现对科技的遏制,就像潘登街踢一样,从具体的技术层面逐渐上升到更广泛的社会层面。设计约束,Constrained by Design,从一开始,就将安全和轮流考量融入科技的设计中。这就像我们在设计汽车的时候,就必须考虑安全带、技能、防爆死系统等等,确保汽车的安全性能。同样,我们在设计AI的时候,也必须将安全和轮流融入到算法中,避免AI做出伤害人类的行为。预警机制、Early Warning System限例预警机制,及早发现,并应对科技可能带来的风险。就像气象部门会发布台风预警一样,我们也需要建立类似的机制、监控AI、合成生物学等技术的研发和应用及时发现潜在的风险。加强审计,Inprove Auditing,定期对科技系统进行审计,确保其安全性和可靠性。这就像我们定期对汽车进行保养和减修一样,我们也需要对AI系统进行审计,确保其运行正常不会出现意外。提升技术能力,Bushtechnicocapacity,培养更多具备专业知识的人才,加强对科技的理解和控制。这就像培养更多的汽车工程师和维修计师一样,我们也需要培养更多的AI工程师和安全专家才能更好的应对AI带来的挑战。重新调整机力机制,Revising Sanctives改变现有的机力机制,鼓励科技向有利于人类的方向发展。比如,可以对那些研发安全、可靠、造福人类的科技的公司进行奖励,而对那些研发危险,不可控的科技的公司进行惩罚。改革政府、Reform Government、改革政府机构,提升其应对科技挑战的能力。这就像政府需要建立专门的交通部门来管理汽车一样,我们也需要政府建立专门的部门来管理AI和合成生物学等新兴科技。达成国际条约,Forge International Treaties,在全球范围内达成共识,共同制定科技治理规则。就像国际社会签署了,不扩散和武器条约一样,我们也需要签署类似的条约,限制AI武器的研发和使用。重速科技文化、Receptic Culture、改变现有的科技文化,让更多人关注科技的社会影响,而不是一位追求技术进步。这就像我们不能只追求汽车的速度和性能,而忽视了汽车的安全性和环保性一样。发动全球运动, Ignite Global Movement,发动全球性的社会运动,提高公众对科技风险的意识,呼吁政府和企业采取行动。这就像环保运动一样,我们需要发动类似的运动,呼吁全社会共同关注AI和合成生物学等技术带来的挑战。全盘思考,步步为营,Think of Listically and Walk the Path以上九个步骤,需要相互配合,形成一个完整的体系,才能有效的应对科技带来的挑战。这就像我们不能只关注汽车的某一个方面,而忽视了其他方面一样。我们需要全盘考虑,步步为营,才能确保科技最终服务与人类。虽然遏制科技的风险非常困难,但并非不可能。只要我们能够团结一致,采取切实有效的措施,就一定能够驾驭科技这批列码,让它成为推动人类文明进步的动力,而不是毁灭人类的凶气。我们正处于一个充满机遇和挑战的时代。科技的发展正在以前所未有的速度改变的世界,我们必须拥抱变化,积极学习和适应。但与此同时,我们也要保持仅行,意识到科技并非万能,它也可能带来负面影响。只有我们积极参与到科技治理中,才能确保科技的发展造覆人类,而不是带来灾难。最后,我想用书中的一句话来结束今天的分享,进步没有解药。任何试图为当今爆炸式发展的各种进步,找到自动安全的渠道,都将导致失败。希望今天的分享能够给大家带来一些启发。感谢大家的收听,我们下期再见。
