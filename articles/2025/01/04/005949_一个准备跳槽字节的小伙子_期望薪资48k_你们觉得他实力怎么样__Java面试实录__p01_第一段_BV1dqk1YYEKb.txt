Timestamp: 2025-01-04T00:59:49.441617
Title: 一个准备跳槽字节的小伙子，期望薪资48k，你们觉得他实力怎么样？【Java面试实录】 p01 第一段 BV1dqk1YYEKb
URL: https://b23.tv/Urm7WU7
Status: success
Duration: 15:00

Description:
好的，这是对您提供的文本的总结，并按照您的要求进行组织：

**核心思想概要**

1.  **求职背景与面试准备:**
    *   面试者曾面试字节跳动，二面被拒，因此准备模拟面试。
    *   准备内容包括面试高频场景题和进阶学习路线图。

2.  **工作经历:**
    *   **第一段经历 (出行行业):**
        *   负责2B出行业务，核心为订单相关业务的生命周期管理。
        *   参与高并发接口开发（QPS 5000，TPS 2000+）。
        *   接触并解决分布式系统相关问题，如限流、缓存、一致性。
        *   开发配置中心，提供多级缓存服务。
    *   **第二段经历 (近期项目):**
        *   负责整体价格设计，结合滴滴思想设计订单中台。
        *   开发组件，如幂等组件、RocketMQ的PCC自行实现。

3.  **项目经验深入 (出行行业订单业务):**
    *   参与订单创建、司机接单、旅程、结算等整个生命周期开发。
    *   **挑战1: 分布式锁:**
        *   传统排他锁不适用多端并发操作场景，自研基于Redis的可重入分布式锁。
        *   使用Hash数据结构，根据用户ID和场景ID实现可重入，利用Lua脚本保证原子性。
    *  **挑战2: 数据一致性:**
       *    早期订单创建不关心数据一致性，后续需要保证用户余额的正确性。
       *   采用TCC思想，基于Kafka实现两阶段提交，并使用本地消息表轮询保证最终一致性。

4.  **配置中心:**
    *   核心难点：多级缓存（JVM缓存、Redis缓存）的一致性保证。
    *   场景：后台配置，前台/APP访问，读多写少。
    *   策略：先写数据库，再更新缓存，使用分布式锁保证一致性。

5.  **面试问题与解答:**
    *   **分布式锁实现原理:** 详细解释了基于Redis的Hash结构、Lua脚本、超时机制和可重入的实现。
    *   **数据库分库分表:** 采用冷热分离策略，热库存储一个月内的订单数据，冷库存储过期订单。
    *   **AQS (AbstractQueuedSynchronizer):** 解释公平锁与非公平锁的区别，主要在于入队策略的不同。
    *  **JUC vs Synchronized:**  阐述 Synchronized 的锁升级机制，和基于 JUC的无锁机制 （CAS）区别，强调其性能特性。
    *   **GC 调优:** 通过线上监控分析FGC问题，发现CMS GC老年代碎片化问题，调整对象晋升策略，解决大对象缓存导致的频繁FGC，核心是调整配置更新策略，避免重复缓存无必要的对象。

**核心要点总结**

*   **核心点 (One sentence):** 面试者通过模拟面试，详细阐述了其在分布式系统、高并发、数据一致性和缓存等方面的实战经验。
*   **根本点 (One sentence):**  该面试者 展示了 具备解决复杂技术问题的能力，并且有丰富的实践经验 。

**整体框架/概念地图**

```mermaid
graph LR
    A[求职面试准备] --> B(工作经历);
    B --> C{第一段经历(出行行业)};
    B --> D{第二段经历(近期项目)};
    C --> E[订单业务全流程开发];
    C --> F[配置中心开发];
    E --> G[挑战1:分布式锁];
    E --> H[挑战2:数据一致性];
    F --> I[配置中心核心难点(缓存一致性)];
     I-->J[先写库，后更新缓存]
    A --> K[面试问题与解答]
    K --> L[分布式锁原理]
    K --> M[数据库冷热分离]
    K --> N[AQS原理]
     K --> O[JUC vs Synchronized]
     K --> P[GC调优]

```
**解释：**

*   **求职面试准备**：是整个内容的起点，引出面试者进行模拟面试的目的。
*   **工作经历**：分为两段，第一段重点在出行行业订单业务和配置中心，第二段是近期项目。
*  **核心挑战和解决方案**：在每个关键环节中（订单业务，配置中心，面试问题），面试者都深入讨论了遇到的挑战以及具体的解决方案。
*   **面试问题与解答**：详细解答了分布式锁、数据库分库分表、AQS、JUC和Synchronized，以及GC调优等技术问题，体现了面试者的技术深度。

希望这个总结对您有帮助！


Content:
跳槽字节七望四十八K,一起来看看它实力如何那你这一次曾经模拟面试的一个主要目的是什么呢?因为这边约了自己的面试自己之前面过然后二面挂了对这块不是特别有底气我也不知道具体的原因嘛,所以摸我底准备了一份面试高频场景题与一份大场进阶学习路线图200家精选减力模板需要的小伙伴评论区一键领取哦我主要说一下两段的工作经历版第一段做出行的算是2B出现好像拓破万本主要是做定当相关的一个业务像定当相关的整个生命周期的一些管理吧全链路的本身的并发量的话QPS有些部分的接口在5000左右高分期的时候TPS在2000多在这个项目当中像一些线流啊这些换存啊这些不现成啊分布式的一些问题基本也能碰到分布式系统当中的一些问题在这个项目当中业务当中其实做的比较多相对比较熟吧还有个就是配置中心的配置中心这一块的话其实就是做字眼做重灵当一这个字眼的说到配置中心其实更像是说一个提供一个多级缓存的一个服务然后服务里面我们服务的后台管理提供了一个可配置可交互的一个配置管理后台主要的一个使用方式给业务那个产品和运营人员的第二个的话也就是最近这个项目主要是做整体的一些价格设计啊以及结合滴滴滴的一种思想做一些定当中台的一些设计和落地吧像做了一些组建方面像密等的组建啊做一下机率ROCKET MQ的一种PCC的一种自行的实现这些吧项目也挺多的哈你可以挑一个具有大部分的项目可以讲一下它的一个基本的业务场景以及你在这个项目里面所遇到的一些挑战然后你是怎么样去解决这些问题的说一下就前面说的出行行业的一个定当业务开发吧定当业务开发整个的话就是说像定当的一个创建然后司机接单之后整个的一个定当创建的阶段然后旅业阶段就司机到达上车点接到乘客然后结算最后面的一个付款整个的一个定当的生命周期都是有参与开发的然后开发的一个角色的话是作为一个核心的研发之一吧主持人之一在这里碰到的一些问题其实比如说一开始的时候自己做了一些分布置锁就是基业Redis的可重入的一个分布置锁吧本身的话是说我们以前的一个分布置锁是排他所的或者说布置锁基本的就是分装好那些锁的话是布置锁但不太支持那个我们当时有一个业务场景是多端多端同时进行一个护教那多端同时护教但是又允许说同一端进行一个并发的一个护教这也是因为不但那是一个车型是有多种车型那这样的话就是需要这样的能力当时的一个技术的框架或者我们内部的集成好的一些工具当中是不太具备基于某个场景的或者自定义的一个场景的一个可重入所的能力的既然不具备那我们就是自己做一套实现还有个的话某些就是车型当中他的护教的时候在这之前出行行业和电商行业有一点不太相同的一点就是在创建定当的时候像电商行业当中你需要比较关心什么积分优惠券活动这些信息对吧然后或者说鱼额那这些的话需要在创建定当的时候进行一个冻结或者说其实就重要做一些数据的密等一致性的一些场景的一个控制当时在出行业当中创建定当的时候有部分项目之前做的时候其实不太需要因为我们的比较简单创建定当之后就是一个司机接单这个时候又是一个司机抢当的过程司机抢当了之后其实这个时候司机抢当它是一个并发的操作但是这个时候其实用个简单的分布所去做控制就好了但是对于数据一致性的这个场景下不太存在说以前的业务是不太存在跨系统或者说跨服务的一个数据一致性保证的一个场景诉求的保证诉求是在支付阶段后来我们的业务监控进来之后就是有些特定的一些车型定当创建的时候需要保证用户余额的一个足够我们当时的做法就是分两阶段第一个阶段就是先在交单之前先做教验但是这个就是在交单的过程中或者说定当创建的时候我们需要去保证它的一个一致性我们当时就是做了一个基于那阶段铁胶当时也是基于TCC就是卡夫卡的一种方式去做的定是轮巡加卡夫卡做了一个TCC本质上其实类似于保证它的数据一致在支付回来之后我们那会是基于做就是有一个本地消息表其实就是定时任务做轮巡消息回掉回来之后我们把这个消息进行本地的消息的一个缓存然后其实本质的目的就是最终一致基本是这个在这家公司还有个做了就配置东西我觉得核心的一些难点在用的是多级缓存TVM的缓存和Redis的缓存二级缓存在这个当中我们要去保证它的一些数据一致性当时的一个业务特点来说是后台配置然后前台或者说AVV进行一个访问本质上其实是独多写少的一个场景在这种场景下我们当时采用的一个策略是低于是数据写完之后我们再进行缓存商储的一种策略再基于分布式所我们当时也考虑到两种场景去做一种是说基于Tenno然后做最终一致还有也就是基于这种我们的一个数据库改完之后我们再去商储我们的Redis缓存当时考虑的是说我们业务场景是写少独多的场景能够通过先写数据库再商缓存这种方式去做的话实现上更简单而且也能满足业务数据基本是再满一个场景这里面有几个点描述的其实还是比较抽象的就可能听众听起来还是会觉得没有讲透的感觉我这里面提几个问题吧第一个的话就是你刚刚也提到分布式所的一个实现对吧你可以讲一下它的一个具体的一个实现的原理是什么吗你是具体怎么去录下去的这么一个过程分布式所的话我们实现的一个诉求是可重入然后场景可自定义实现的方式的话是基于Redis的去做的Redis的话我们采用的数据结构是基于Hash的一个数据结构P的话当时是一个用户ID这个是锁的P场景的话就是我们不同的端有一个不同的ID我们为不同的端给定了一个不同的ID然后基于这个ID去做可重入的我们在写的时候业务请求进来之后首先我们要先尝试过去锁尝试过去锁的话我们的逻辑是在基于RWA的脚本去做的在RWA脚本的逻辑是这样的先去看一下我Redis当中有没有存在P如果存在这个那我就看一下当前Hash结构当中的一个P值是不是当前的一个场景值如果是的话那OK我再看一下当前的重用次数重用次数也就是我的Hash的一个Value如果是我需要重入那如果我要进入那OK如果是0我就加一如果不是其他场景去其实就是就加加的操作那这就是进入的场景出去之后我们根据当前的用户ID和场景去把这个Value进行减减就是进和出的场景这里还要刺激到一些判断点比如说本身的话我们考虑到也是结合当时的业务场景我们的业务的较当的一个场景的话一般的接口在3秒钟左右这个也是基于监控我们做的一个统计在高峰期的时候我们记得统计那我们把左的一个超时时间设定在这里还有一个点是GC的一个时间我们也是通过监控去发现我们当时的一个GC大概在高峰期的时候一般的或者在30秒钟一次会进行一个4GC它的一个停顿时间大概在200毫秒左右结合这些信息我们把Redis锁的一个过去时间配置在了2秒钟左右会有一个Vogidog也就是Vogidog去轮旋去去期当这些的一个去期的时间然后锁的一个维持时间是在我们提供的这个锁的上面是可配的这里的锁的话我们也是说在实用的过程中就避免我们提供的两种方式去做一种是基于LokalUtile的方式去做还有的是我们也提供了AoT前面的方式去做之所以说提供两种方式的一种是基于前面方便一点那Utile到底就是我们想的在业务场景中会碰到一些特定的一些业务场景下可能会需要说我手动的去开启和关闭这样的一个自定应化的一个诉求基本是这些那我们简单交流一下存技术方面的跟公平生之后的温同学问的说这么大病发数据库是怎么样分过分表的这关你了解过吗数据库其实我们是做的是冷热分离其实我们的PPS只有在2000左右其实也算不上特别大的病发然后我们的一个数据库的热库的话是一个32G内存内存是32G的内存在这种场景下我们完全能够保证PPS的病发量的只是说数据量一天的定当量在560左右当量当存的就是承当量那PPS的话是在高分期的时候会有2000左右对于数据库的数据量来说我们是基于冷热分离冷热分离的话是一个月的时间热库是一个月是一个月内的订单所有订单以及我之前就是一个月以前没有支付成功的或者没有到订单中态的这些订单这冷热归党的话基本上是我们是往上两点多吧两点多到三点多的时候会把已经超过一个月的时间的这些订单进行归党归党之后这里会数据库对于Db来说它会执行一下这些碎片的整理这些的一些操作不过这些都是基于那个脚本去做的这个冷热库的分离你是存在时间来的时候不算是在一路来的时候是按照创建时间这里创建时间是分两个订单会有重点我们就说如果真态的话我们一直会留着然后已经到了中态的是超过一个月时间我们就直接给它归党比较经典的一个叫做Re-安全的LOCK你可以讲一下它的一个基本的实行员你看它其实我问到手载基本的我问到AQSAQS它其实就是一个对立的问题这里的话其实涉及到AQS它两类实现一个公平手和非公平手那公平手的话其实就是他们两个最大的区别就是说我在县城入站的时候先看一下当前所的持有方一个说公平所进站的时候它就直接往我的队伍去加然后如果非公平所先看一下我能不能通过AQS的方式获取到当前的所如果获取不到那这个时候我要进入站入站的时候这个也会进行判断一下我入站的时候当前的这个站头是不是跟我当前的一个县城的一个ID是或者县城是一致的如果是一致的那我直接获取到所如果不是那我就加到队伍去入队之后就直接返回了就是进一个等待的一个操作根据你的理解的话我们如果是用JOC包装的提供的这些所和直接用加瓦类字提供Synchronize的关键字你觉得会有什么区别分别有什么优势和劣势这其实是主要是说使用它的一个所调其实是和我们的Synchronize的关键字的所的一些场景的一些区别的从我的个人理解来说像Synchronize它本身是基于左的它会有一个所升级的过程其实一开始的话也是类似于天下所然后在没有升级之前它也是类似于ZS的一个策略升级完了之后它其实会用到操作系统级别的所这个所的级别参计是比较重的Synchronize的话它加所它的所升级完了之后其实是没办法进行一个降级的也就是说对于一些比如说一些秒杀或者说一些高病发的场景在短期当中会有净征净征完了之后把所升级了之后本身的话后续会一直用你的操作系统的一个重弹级所这样的话对于本身的一个性能来说适应有一定的降低的JOC当中提供的它的一个策略其实是基于无所的一种思路也就是说基本是基于ZS的一种策略来做的它的一个场景的话是消耗CPU的资源去进行一个等待它的一个优势是在于说如果说我对于某一个资源它的一个病发的竞争的场景比较少或者病发竞争的一个频次比较低的话那我们是推荐使用ZS的因为它本身是会进行一个原地等待原地等待的过程原地等待它其实是消耗CPU的可能你上面写的有对GC包括FGC做到进行一个调忧最快你可以先解释一下你的这么的经验吗可以举一个场景吧其实对于GC的调忧其实更多的是说我们也是根据欠上监控去看一下先说一下前皮是我们用的CMSCMSGC的话众所周知的就是说它的一个老年代它是基于资源商处的其实就是会存在一个那存税聘化的一个问题如果说FGC的次数多了之后会存在一个税聘化的问题那我们在业务过程当中我们会尽可能的去避免说线上CMS发生FGC的一些场景然后我们也是会根据线上的监控去查看观察当前发生了哪台机子或者说哪个服务发生了CMS的一个FGC在业务场景当中碰到一个问题发现了一个CMSG就是我们把线上的它的DCC导出来然后我们通过METER的一个工具进行分析METER工具这个时候我们其实也采过坑板就是这里分析的时候会有一个问题是它在分析过程中我们需要去分析就是老年代的在老年代中没有被就GC ROOT所指引的这些数据我们一开始分析的时候没有去把这个特性给勾散我们发现发现就内存当中的这些DC这些垃圾其实没有那么多的或者说跟我们实际的导出来的堆大小不太一致发现的坑中后我们去搜索了之后我们产生了FGC的一个原因是在于我们用的CMSGC然后CMSGC然后它用的策略是对于对象它的一个进身策略还是默认的也就是66的话在一个业务高峰期的时候我们发现会进行一个30秒一次样GC的一个操作有些对象经过6次样GC之后没有被样GC回收掉那这个时候它会进入到ODE区然后我们发现这些ODE区的这些对象很多的对象都是说GVM当中我们有一个MAP缓存然后这些MAP缓存是我们是定了一个定时任务定时任务会有5分钟去拉取一些配置过来然后缓存到这个HashMap当中但是这些HashMap当中很多配置其实是变更屏次不高的虽然说变更屏次不高但是在缓存的使用过程中它是原来历史的代码是直接拥有一个新的MAP出来把新的MAP的地址只给缓存的这个属性隔了一个星期之后内存当中会有非常多的这些HashMap对象然后HashMap里面存的就是那些大的长的这个是菌值然后这些菌都是一些配置值那我们发现了这个问题我们的一个采用的策略就是说把配置拉下来做先跟内存当中的对象进行比较如果是一致的那我们就不进行一个更新如果不一致的话不一致的我们再进行一个替换因为本身的话对于这些配置它是近代配置然后它的变更的品质是比较低的那本身比较低的这种场景下的话虽然说我们把这些策略变更为了真谅更新的这种策略之后虽然说也有一些历史的对象在OdeCity当中是不会被回收的其实这些都是垃圾但是本身的它的量已经降得非常低了通过这种方式我们就避免了就是现场发生4GC的一些场景我觉得你的话有一定的优势现物经验是一个优势从我整个表达来说也是相对来说比较自信的但是有一个问题我发现你的整个表达的逻辑性其实会稍微有一点点的乱这个视频给个三连大家觉得合不合适合适的不得了这个视频给个三连大家觉得合不合适合适的不得了
