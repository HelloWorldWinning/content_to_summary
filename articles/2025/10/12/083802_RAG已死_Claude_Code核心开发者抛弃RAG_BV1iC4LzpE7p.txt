Timestamp: 2025-10-12T08:38:02.683348
Title: RAG已死？Claude Code核心开发者抛弃RAG BV1iC4LzpE7p
URL: https://b23.tv/JOPxcx3
Status: success
Duration: 4:14

Description:
**总结大纲：**

*   **引言：AI处理海量文档的挑战**
    *   如何让AI高效准确地回答关于数百万页技术文档的问题。
*   **传统AI信息检索范式：检索增强生成（RAG/软格）**
    *   **核心理念：** 必须为AI构建完美结构化的信息系统。
    *   **具体流程：**
        1.  将文档切分成小段落。
        2.  每个段落通过算法转换为“欠入”（向量化）的特殊数字串。
        3.  将所有向量存储在向量数据库中。
        4.  用户提问时，问题也向量化，在数据库中匹配最相似的向量，检索出原文并结合生成回答。
*   **新兴AI信息检索范式：智能体式检索（Agentic Search）**
    *   **提出者：** 归谷顶级AI开发者，如Cloud核心开发者Boris、NASGraph核心开发者Less Martin。
    *   **核心理念：** 相信AI本身的智商，赋能AI自身智能，而非构建笨重的外部系统。
    *   **具体做法：** 完全不做索引，不使用向量数据库，不搞复杂RAG流程。
        1.  **提供基础文件操作工具：** 例如 `grep` (简单的文本搜索命令)。
        2.  **提供“地图”或“目录”：** 一个`LLM.TXT`文件，仅包含文档链接地址和高质量的内容描述（不含原文案）。
    *   **AI工作流程：**
        *   接收问题 -> 读取“地图” -> 根据文档描述自主判断潜在相关文件 -> 调用文件抓取工具获取文件 -> 如有需要，使用`grep`在文件内部进行关键词搜索。
*   **基准测试与结果（Less Martin的实验）**
    *   **测试方法：**
        1.  传统RAG（向量数据库索引）。
        2.  智能体式检索（地图+简单抓取工具）。
        3.  暴力灌输（将全部300万字文档直接塞给大模型）。
    *   **结果：** 智能体式检索（方法二）效果最佳，且在构建和维护上远比RAG简单。
    *   **关键成功因素：** “地图”中的文档描述必须足够精准和有效，以支持AI的准确判断。
*   **思维范式的深刻转变**
    *   **过去：** 认为AI不够聪明，工程师需耗费巨大精力外部结构化信息并喂给AI。
    *   **现在/未来：** 随着大模型日益智能，重点从搭建笨重外部系统转变为如何更好地赋能AI自身的智能，提供工具和线索，让AI自主探索和发现。
    *   **比喻：** 从“教孩子背诵卡片知识”转向“教孩子使用图书馆并自主遨游”。

**核心观点总结（一句话）：**
随着大型模型智能的不断提升，AI工程的核心趋势正从外部复杂的信息结构化转向通过提供恰当的工具和线索来赋能AI自身智能的智能体式检索。

**总体框架：**
AI信息检索范式从“外部结构化信息”向“赋能AI自身智能”的转变。

<Mermaid_Diagram>
graph LR
    A["AI信息检索挑战"] --> B("传统范式：检索增强生成(RAG)");
    A --> C("新兴范式：智能体式检索");

    subgraph "传统范式：RAG核心流程"
        B1("RAG核心信念：AI需完美结构化信息")
        B2("步骤1：文档切分")
        B3("步骤2：欠入/向量化")
        B4("步骤3：存储向量数据库")
        B1 -- "指导理念" --> B2; B2 -- "处理结果" --> B3; B3 -- "存储位置" --> B4;
        B -- "代表" --> B1;
    end

    subgraph "新兴范式：智能体式检索核心"
        C1("智能体式核心：相信AI自身智商")
        C2("赋能工具：基础文件操作工具(e.g., grep)")
        C3("探索资源：智能地图(LLM.TXT，优质描述是关键)")
        C4("AI行动：自主判断 -> 获取 -> 探索")
        C1 -- "赋能方式" --> C2; C1 -- "赋能方式" --> C3; C2 & C3 -- "支持" --> C4;
        C -- "代表" --> C1;
    end

    D["核心开发者洞察"] -- "推动" --> C;
    E["基准测试(Less Martin实验)"] -- "对比方法" --> B;
    E -- "验证有效性" --> C;

    subgraph "基准测试结果"
        E1("方法1：传统RAG")
        E2("方法2：智能体式检索")
        E3("方法3：暴力灌输")
        E4("结论：方法2效果最佳")
        E1 -- "不如" --> E4; E2 -- "优于其他" --> E4; E3 -- "不如" --> E4;
        E -- "包含" --> E1; E -- "包含" --> E2; E -- "包含" --> E3;
    end

    F["思维范式深刻转变"] -- "源于对RAG的不足" --> B;
    F -- "引向对智能体的信任" --> C;

    subgraph "AI工程思维转变"
        F1("旧思路：AI笨拙，需外部结构化喂养")
        F2("新思路：AI智能，赋能其自身探索能力")
        F1 -- "转向" --> F2;
        F -- "对比" --> F1; F -- "引领" --> F2;
    end

    G["未来AI工程方向：智能体式与结构"]
    C -- "预示" --> G;
    F -- "驱动" --> G;

    style A fill:#FFEBEE,stroke:#E57373,stroke-width:2px,color:#333;
    style B fill:#FFDDDD,stroke:#FF8888,stroke-width:1px,color:#333;
    style C fill:#DDFEFF,stroke:#88DDFF,stroke-width:1px,color:#333;
    style D fill:#FFF3E0,stroke:#FFB74D,stroke-width:1px,color:#333;
    style E fill:#E8F5E9,stroke:#81C784,stroke-width:1px,color:#333;
    style F fill:#F3E5F5,stroke:#BA68C8,stroke-width:1px,color:#333;
    style G fill:#C8E6C9,stroke:#4CAF50,stroke-width:2px,color:#333;

    style B1 fill:#FFCACA,stroke:#FF0000,stroke-width:1px,color:#333;
    style B2 fill:#FFDDDD,stroke:#FF8888,stroke-width:1px,color:#333;
    style B3 fill:#FFDDDD,stroke:#FF8888,stroke-width:1px,color:#333;
    style B4 fill:#FFDDDD,stroke:#FF8888,stroke-width:1px,color:#333;

    style C1 fill:#AADDFF,stroke:#00AAFF,stroke-width:1px,color:#333;
    style C2 fill:#BBDDFF,stroke:#55BBFF,stroke-width:1px,color:#333;
    style C3 fill:#BBDDFF,stroke:#55BBFF,stroke-width:1px,color:#333;
    style C4 fill:#CCEEFF,stroke:#99DDFF,stroke-width:1px,color:#333;

    style E1 fill:#FFF0F0,stroke:#FFCCCC,stroke-width:1px,color:#333;
    style E2 fill:#F0FFF0,stroke:#CCFFCC,stroke-width:1px,color:#333;
    style E3 fill:#F0F0FF,stroke:#CCCCFF,stroke-width:1px,color:#333;
    style E4 fill:#D4EDDA,stroke:#28A745,stroke-width:2px,color:#333;

    style F1 fill:#FFEEEE,stroke:#FFAAAA,stroke-width:1px,color:#333;
    style F2 fill:#EEFFDD,stroke:#AADD77,stroke-width:1px,color:#333;
</Mermaid_Diagram>

Content:
归谷顶级AI变成工具Cloud 扣着的核心开发者Boris提出了一个非常反直的减手方式完全不做任何所以而是采取更原始的方法这个方法彻底并记了所谓的软格路线这个视频我画三分钟给大家想一讯介绍一下首先我们来做一个思想实验想想想前面有几百万页的技术文档相当于一个小型突如管现在你要让一个AI整体能快速转确的回答关于这些文档的任何问题你会怎么做我想大部分人的第一反应肯定是得先整理这些资料就像我们整理突如管一样在AI的世界里面这些整理的流程通常就叫做软格也就是减所增强深沉寂数具体怎么做就是先把这几百万页的文档切成一个个小段落然后每个段落都用算法翻译成一串特殊的数字这个过程叫做欠入最后把所有这些数字都放进一个叫像亮数据库的东西里面当用户提问时AI就把问题也变成一串线数字然后去数据库里面找纳仙和它最像的数字把对应的原文断乱捞出来再结合这些资料来回答你这一套流程就是目前AI减所领域的标准答案它背后是一种信念我们必须为AI各简直完美的结构化了信息系统它才能好好地工作但是种种既向来看现在最顶尖的一批AI开发者正在抛弃这种复杂的玩法当串的核心开发者Less Martin在最近的一次深度访谈里面就分享了一个惊人的观察它发现像Sopebian公司开发Cloud Code的大神Boris他们做代码减所的时候采取了一种截然不同的方法就是完全不做任何所以你没有听说他们不搞什么相量数据库不搞复杂的软格流程他们用的是一种更简单甚至可以说是更原始的方法叫做智能体视减所这什么意思呢说白了就是他们不再废进新司的去为AI搭建一个精美的预处理好的知识供电参加相反他们选择相信AI本身的智商他们做的事情非常简单低他们不见所引苦而是给AI提供最基础最普速的文件操作工具原文里面提到一个词的Grant这其实就是陈续元在几十年前就在用了一个超简单的文本搜索命令第二他们会激行准备一份地图或者说木路在访谈里面这个被成为LMTX的文件这个文件里面没有原文案只有每个文党的链接地址和一段写的特别好的内容描述然后就没有然后工作去开始了AI拿到一个问题它不会去一个现成的数据库里面搜索它会先去读那个地图根据文件描述自动动脑子判断嗯这个问题呢答案可能藏在ACF这三个文件里然后它会自己调用那个简单的文件抓取工具把这几个文件捞过来看如果信息不够呢在有Graph这样的工具在文件内部进行关键词的搜索就像一个真正的人在电脑上去找资料一样NASMODY自己也特别好奇啊这两种方法到底哪一种更好呢于是它做了个基准测试用了三种方法去回答关于自家产品NASGraph的问题首先是传统方法就是把所有的文档都所引到相量数据库里面搞一套完整的软的第二就是智人体方法就是刚才说的只给一个在描述的LLMTEC文件和一个简单的抓取工具第三是暴力方法干脆把全部300万个头盆的文档直接塞给大模型结果呢你三种的效果出其好的是第二种那个最简单的智人体是搜索它的效果不仅好而且各件和维护起来比第一种方法简单太多太多了关键就在于那份地图里的描述要写的足够好让AI能够准确的判断所以你看这一背后其实是一种深刻的思维的变化过去我们认为AI不够聪明所以这些工程师必须把所有东西都结构化了味道它嘴边工作重新是构建外部的结构而现在随着大模型本身越来越智伦了顶级玩家的思路变成了与其花那么多力气去搭建一个笨重的外部系统不如把力气的花在如何更好的复轮AI自身的智伦上我们只需要给它足够好的工具和线索然后相信它让它自己去探索去思考去发现这就像教孩子学习一种是把所有支点都做成卡片让它一个一个去背另外一种的是教它如何使用突出馆然后放手让它自己去熬油这个智伦是与结构的理念显然已经预示了未来AI工程的一个重要方向
