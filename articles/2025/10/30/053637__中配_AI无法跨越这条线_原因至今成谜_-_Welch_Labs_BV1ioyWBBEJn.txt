Timestamp: 2025-10-30T05:36:37.883853
Title: 【中配】AI无法跨越这条线 原因至今成谜 - Welch Labs BV1ioyWBBEJn
URL: https://b23.tv/OZTk5Dm
Status: success
Duration: 24:06

Description:
好的，这是根据您提供的文本提炼的核心思想摘要。

### **核心观点纲要**

1.  **现象：神经缩放定律 (Neural Scaling Laws)**
    *   **核心发现**：AI模型的性能（以交叉熵损失值衡量）的提升并非随机，而是与三个关键因素——**算力、模型规模、数据量**——呈现出高度可预测的**幂律（Power Law）关系**。
    *   **表现形式**：在双对数坐标系下，这种关系表现为一条近乎笔直的下降直线，意味着投入更多资源，性能就会可预见地变好。这个规律惊人地稳定，几乎不受模型架构等细节影响。

2.  **实证：从理论到现实的验证**
    *   **OpenAI的开创性工作 (2020)**：首次系统性地揭示并量化了语言模型的缩放定律，并基于该定律成功预测了GPT-3的性能，证明了其强大的预测能力。
    *   **谷歌DeepMind的深化研究**：进一步证实了缩放定律，并首次在自然语言数据上观察到性能曲线的平缓区，从而估算出自然语言存在一个由其内在**“熵”（不确定性）**决定的、不可降低的损失下限。
    *   **GPT-4的终极证明 (2023)**：尽管其训练规模比GPT-3大了几个数量级，但其最终性能与OpenAI利用缩放定律在小规模实验上做出的预测惊人地吻合，确立了该定律作为AI发展“物理定律”的地位。

3.  **理论：流形假设的解释 (The Manifold Hypothesis)**
    *   **核心思想**：自然数据（如文本、图像）并非随机散乱地分布在高维空间，而是集中在一个维度低得多的**“流形”**结构上。
    *   **模型任务**：深度学习模型的本质任务，就是学习并描绘出这个低维流形的精确形状。
    *   **定律来源**：
        *   **数据量**决定了在流形上的**采样密度**。数据越多，点越密集，模型对未知点的预测误差就越小。
        *   **模型规模**决定了学习流形的**“分辨率”**。模型越大，就越能捕捉流形更精细的几何细节。
    *   **数学关联**：该理论从数学上推导出，模型的损失值与数据量/模型规模应呈幂律关系，这与观测到的缩放定律高度一致。

4.  **局限与展望**
    *   **性能天花板**：由于数据本身固有的不确定性（熵），模型的损失值无法被无限降低至零，存在一个理论上的性能极限。
    *   **能力涌现的未知性**：缩放定律能精准预测模型在核心任务（如预测下一个词）上的**整体性能损失**，但无法预测在特定规模下会突然**“涌现”**出哪些高级能力（如多步推理、数学计算）。
    *   **未来意义**：神经缩放定律是当前AI发展最重要的指导原则，它将AI工程从“炼金术”般的尝试，转变为一门可预测、可规划的科学，但其背后的根本原因仍在探索中，是通往更深层次AI理论的关键线索。

---

### **核心结论（一句话总结）**

AI模型的性能遵循着一个简单且可预测的缩放定律，即其错误率随算力、模型规模和数据量的增加而幂律下降，这一发现已成为驱动当前大型模型发展的核心指导原则。

---

### **内容的总览框架**

本文的论述框架遵循经典的科学探索路径：从**“经验观察”**出发，通过**“大规模实验”**进行验证，最后寻求**“深层理论”**予以解释，并探讨其**“局限与未来”**。

1.  **观察现象**：AI模型的性能提升曲线呈现出一种神秘而一致的幂律规律。
2.  **实验验证**：以OpenAI和DeepMind为代表的研究团队，通过构建GPT-3、GPT-4等超大规模模型，反复、精准地验证了该定律的有效性和预测能力。
3.  **理论解释**：引入“流形假设”，从数据内在结构的视角，为“为什么缩放定律会成立”提供了一个强有力的数学和几何解释。
4.  **总结反思**：明确了该定律的适用范围（预测整体性能）和局限（无法预测能力涌现、存在性能上限），并展望其作为AI领域“第一性原理”的未来潜力。

---

### **概念关系图 (Mermaid Conceptual Map)**

<Mermaid_Diagram>
graph TD
    subgraph "三大驱动因素 (The Drivers)"
        B["算力 (Compute)"]
        C["模型规模 (Model Size)"]
        D["数据量 (Data Size)"]
    end

    subgraph "核心定律 (The Core Law)"
        A["神经缩放定律 (Neural Scaling Laws)"]
    end

    subgraph "模型表现 (The Outcome)"
        E["模型性能 (以交叉熵损失衡量)"]
    end

    subgraph "理论解释 (The 'Why')"
        F["流形假设 (Manifold Hypothesis)"]
        G["高维数据位于低维流形上"]
        H["数据量决定'采样密度'"]
        I["模型规模决定'学习分辨率'"]
        F -- "推导出" --> G
        G & H & I -- "共同解释" --> A
    end

    subgraph "实证验证 (The Proof)"
        J["OpenAI (2020)"]
        K["GPT-3"]
        L["DeepMind (2022)"]
        M["GPT-4"]
        J -- "提出并预测" --> K
        K -- "验证定律" --> A
        L -- "深化并发现极限" --> N
        M -- "跨数量级精准验证" --> A
    end

    subgraph "固有极限 (The Ceiling)"
        N["不可约减的损失 (Irreducible Loss)"]
        O["数据内在的熵 (Data's Intrinsic Entropy)"]
        O -- "导致" --> N
    end

    P["能力涌现 (Emergent Abilities)"]

    B -- "增加" --> A
    C -- "增加" --> A
    D -- "增加" --> A

    A -- "可预测地降低" --> E
    N -- "设定了性能天花板" --> E
    F -- "从根本上解释" --> A
    A -.->| "无法直接预测" | P

    style A fill:#FFD700,stroke:#333,stroke-width:2px,color:#333
    style B fill:#B0E0E6,stroke:#333,stroke-width:1px
    style C fill:#B0E0E6,stroke:#333,stroke-width:1px
    style D fill:#B0E0E6,stroke:#333,stroke-width:1px
    style E fill:#D8BFD8,stroke:#333,stroke-width:2px
    style F fill:#F5DEB3,stroke:#333,stroke-width:2px,color:#333
    style J fill:#E6E6FA,stroke:#333,stroke-width:1px
    style K fill:#E6E6FA,stroke:#333,stroke-width:1px
    style L fill:#E6E6FA,stroke:#333,stroke-width:1px
    style M fill:#E6E6FA,stroke:#333,stroke-width:1px
    style N fill:#FFA07A,stroke:#B22222,stroke-width:2px
    style O fill:#FFC0CB,stroke:#333,stroke-width:1px
    style P fill:#98FB98,stroke:#2E8B57,stroke-width:1.5px,color:#333
</Mermaid_Diagram>

Content:
AI模型死活跨不过这岛看而且我们至今都没搞懂为啥训练AI模型是它的错误率通常会快速下降然后屈于平稳的模型越大效果越好但稍得算了也更多随著模型规模越来越大我们最终会得到这样一组曲线当我们把作标志换成对数可度后就会浮现出一条清晰的曲线所有模型都无法突破这条边界也就是所谓的计算自由前沿这个规律就是目前被广泛观察到的三大神经缩放定律之一只要参数选得不太离谱你会发现错误率跟算力模型大小数据及规模的变化规律出其一致而且神奇的是它几乎不受模型架构或其他算法细节的影响现在最有趣的问题是我们是不是发现了某种自然界的底层规律就像构建智能系统的理想起定律一样还是说这只是因为我们当前采用了神经网络AI路线导致的特殊现象如果我们不断增加数据量模型规模和算力这些模型到底能强到什么程度我们真能把错误率降到0吗还是说性能早往会卡在平静为什么数据量模型规模和算力会成为我们构建AI系统的天花板为啥他们和模型表现的关系能简单到这种程度2020年可是OPEN AI的转折年研究团队在1月份发布的这篇论文里直接展示了语言模型在不同规模下的性能变化趋势数据一幕了然团队给每组数据都逃你和了秘律方程这样就能精准预测性能会如何随著算力数据及规模和模型大小的变化而变化在对数作标图上这些秘律方程会呈现为直线而每条直线的协率就等于你和方程的指数指数越大取限就越抖性能提升也就越快研究团队发现这些增长趋势在高端模型上依然稳如老狗这也不如基本提前巨头了OPEN AI全年的战略布局当时团队测试的最大模型拥有15亿个可学系参数去年它大概要消耗1000万照次台体的算力一个PETAFLUP日就是每秒能进行1000万一次扶点运算的系统在一天内能完成的总计算量当时最顶配的因为的AV30显卡算力能达到30万亿次每秒所以用33块这种单价一万美元的显卡组个系统就能干到1000万一次的集团能力就在那个夏天随著GPT-3的横空出势团队基于经验预测的性能提升真的营养了OPEN AI团队这次可真是下了学本搞规模扩张他们和微软联手打造了一台超级计算机直接塞进去一万块V线显卡注意不是33块然后用3640千万一次且添的算力训练了这个参数高达1750亿的GPT富三GPBAM模型GPT富三的表现不仅完美贴合了年初预测的增长曲线而且试头4毫不见放缓这说明模型规模在网上对性能还能继续提升既然连GPT富三都没摩倒神经网路的天花版那极限到底在哪如果算力数据和模型规模管够我们能把错路率直接干到0吗OPEN AI团队在10月份发布的论文里对模型扩展性做了更深入的研究研究团队发现无论是图像键模还是视频键模各种问题都遵循同样的扩展规律研究还发现在不少其他问题上扩展效果还没达到0物差增长曲线就先平缓下来了只要搞明白这些错路率到底在测什么这个现象就说得通了像GPT富三这样的大园模型本质上都是自回归的这些模型的训练目标就是根据前面的单磁序列预测接下来最可能出现的单磁或次片段这些预测结果通常都会以概率相量的性式呈现简单来说当你输入一串文字时原模型就会突出一串0到1之间的概率值每个数字都对应著磁库里某个磁出现的可能性这些概率相量通常会经过Softmax规划处理确保所有概率加起来刚好等于1GPT富三的磁库可是有做足50027个单磁比如我们输入 Einstein的名字是这段文本模型就会突出一个长达5027位的相量我们期望这个相量在其他位置都接近0除了对应 Aber这个磁的那个所引位置顺便说下这个单磁对应的所引值是450090训练时我们其实知道接下来该出现哪个磁毕竟训练文本就摆在那这样我们就能算出一个误差值也叫损失值看看模型预测的结果和正确答案到底差多远这个损失值得太关键了因为它直接知道著模型参数的优化和学习过程那些天文数字的算力训练全是为了把这个损失值给压下来阶段损失值的方法其实是五花八门那 Einstein的例子来说正确答案对应的输出相量在第450090位应该是1所以我们可以把损失值定义为用1简去模型在这个位置给出的概率值如果模型百分百确定答案是 Einstein输出值唯一的话那损失值自然就是0了这很合理吧举个例子如果模型给出的概率是0.9那损失值就是0.1如果模型输出值是0.8那损失值就是0.2以此类推这种计算方式其实就是 LE损失寒数在很多机器取习问题上都挺好用的但10操纵发现改用交叉伤这种损失寒数后模型表现往往会更好交叉伤的理论推到有点烧脑但实际用起来却超级简单我们只需要对模型在正确答案所以出输出的概率值取负自然对数就行那 Einstein这个例子来说我们只要用模型在4290号位置输出的概率值取个负对数就能损失值了如果模型百分之100确定答案交叉伤损失就等于负的意的自然对数也就是0这个结果很合理和 LE损失的计算结果完全纹合如果模型对正确答案有90%的把握交叉伤损失就等于负的自然对数0.9也就是0.1左右和 LE损失值还是相当接近的当我们把交叉伤损失值所以模型输出概率的变化化成曲线就会发现刚开始损失值增长缓慢可一旦模型对正确答案的预测概率接近0损失值就会直线飙升也就是说如果模型对正确答案没啥把握交叉伤损失值就会飙升咱们之前看的所有比例图例纵轴上标的模型表现其实就是交叉伤损失值这是模型在测试机样本上算出来的平均结果模型对测试集中下一个正确答案的预测越有把握平均交叉伤损失值就越趋劲预令OP那样团队发现损失曲线区平缓而非归零这其实很好理解因为预测这类序列的下一个元素通常就没有标准答案嘛像 Einstein的名字是这种句子后面接什么词简直不要太明显但大部分文本可没这么简单GPT-3的训练数据大部分都来自网上抓取的文本如果我们搜神经网络是一种专语会发现后面能接待答案五花八门这些说法都没毛病解释神经网络本来就有千万种姿势这种与生俱来的不确定性就叫做自然语言的伤我们对语言模型最大的期待就是让它能高盖率预测出几个靠谱的后续词会选项而神奇的是大语言模型还真就做到了这一点举个例子这是Mata的喇嘛模型预测出的前五个候选词虽然我们永远没法把教杀上损失降到零但到底能逼近到什么程度呢我们能不能算出或者孤算出自然语言的伤质呢OpenAI团队通过给损失曲线你和包含恒定不可约物插现的秘密模型成功孤算出了第一分辨律图像视频等数据员的天然伤质针对每个问题它们用了两种方法来孤算数据的天然伤质第一种方法是看模型规模曲线在哪里区域平环第二种是看计算量曲线在哪里稳定下来结果发现这两种孤算方法得出的数据居然高度纹合要注意的是规模缩放秘率在这些情况下依然使用但加上这个长数向后双对数作标图上的曲视线就不再是比值一条了但有意思的是研究团队认识没发现原数据的性能增长有任何放缓的迹象但遗憾的是研究团队指出即便用上最大规模与缘模型的数据我们目前还是没发准却孤算出自然与缘的伤质18个月后谷歌DipMine团队发布了一系列大型神经缩放实验这次他们真的在自然与缘数据上观察到了计算效率编辑的冤屈现象他们根据实验结果你和出了一个神经缩放定律把总体损失拆成了三部分一部分虽模型规模变化一部分随数据级大小变化最后还有个雷达不动的固定象代表自然纹本的伤质实验数据表明就算模型和数据量无限大在海量纹本数据级上的平均交叉伤损失也不可能低于1.69一年后的2023年原州律日奥本来团队正式推出了GPT-4这份GPT-4几乎报告虽然写了100页但关于模型本身的技术细节几乎知字为题OpenAI团队以行业竞争和安全风险为由对这些关键信息手口如品不过这篇论文还是放了两张性能扩展曲线图训练GPT-4的烧仙程度简直离谱据说光成本就砸了一亿多美元在砸这笔句子之前团队就用简单的秘律法则做了预测他们把这条曲线套在小规模实验数据上来预估性能提升的幅度注意看这个图表用的是现行作表者不是对手作表者所以曲线变化看起来会更夸张一些如果我们把这条曲线放到对手作表系里看虽然会有些弯曲但整体上和我们见过的其他扩展曲线非常稳和最让人震惊的是OpenAI团队居然能如此精准的预测GPT-4的表现哪怕是在这么庞大的规模下要知道训练GPT-3已经需要惊人的3640千万一次付贴运算日了但根据泄漏的数据GPT-4的训练算例直接标到了20万千万一次付贴运算日据说动用了2.5万块因为的阿里林显卡足足跑了3个多月这说明神经网路的扩展规律简直牛道离谱从OpenAI2020年论文里提到的10的富巴斯坊Petaflop Days到这次GPT-4训练泄漏的20万Petaflop Days整整跨越了13个数量级这条规律居然都成立这就引出了核心问题为啥AI模型的性能会遵循这么简单的规律呢为什么数据量模型规模和算例偏偏就成了我们构建AI系统的电话版为啥他们和模型表现的关系那么简单之间呢要解答这些问题所去的深度学习理论往往远远跟不上时间的发展速度不过最近有研究给出了相当有利的解释深度学习模型之所以会呈现秘律增长是因为他们本质上是在用数据破解高为数据流行的奥密想彻底搞懂这些理论确实挺烧脑的培养直觉这事儿最好还是一步一步来想快速搞懂大约模型和其他应合之事本期视频赞助上BREWIN的就是你的最佳拍档每次研究神经苏放这类理论时我都从可能论文开始但光看论文真的只能懂个疲毓我一般都会自己写点代码来道故实验这样才能真正搞懂背后的门道BREWIN简直神了它能让你直接上手实操通过这个问题通过实件来高效学习他们准备了上千门互动课程数学编程数据分析和人工智能全都有BREWIN这个平台特别棒它能让你通过解决实际问题来培养直觉思维这简直就是我学习路上的关键发宝马上你就能看到一个神经网络学习manist数据级D为表证的动画演示了搞定这种大问题的小型版本简直是培养直觉的绝假方式BREWIN把这种学习方式打包成了每天只需花几分钟就能进步的模式坚持每天进步一点点积累下来的成果绝对让你惊喜BREWIN平台专门开始了大圆模型全套课程不仅包含我们之前聊过的预测下一个词和计算词会概率这些知识点还会带你深入挖掘背后的原理现在注册就能免费唱想30天BREWIN的会员不仅能体验大圆模型课程还能解锁平台所有内容直接访问BREWINorg Welch Labs或者点击视频剪辑里的链接就行了通过这个链接订阅BREWIN的年度会员还能额外享受8者优惠特别感谢BREWIN对本视频的赞助支持现在咱们说回神经网络的规模效应机器学习界有个挺酷的观点咱们模型训练用的数据级其实都存在于高为空间的流行上咱们可以把图片文字这些自然数据想像成高为空间里的一个个作表点举个例子在MNAST熟写数字数据节里每张图片都是由28成28项速组成的网格每个项速的挥渡值都用零到一支间的数字来存出来假设图片只有两个项速点咱们就能把这些双项速图片想像成二为空间里的作表点第一个项速的挥渡值对应X轴第二个项速的挥渡值就是外周作标了一张有两个纯白项速组成的图片在二为空间里就会落在00这个作表点上如果第一项速是纯黑第二项速是纯白的图片会落在作标01的位置而两个项速都是0.4挥渡的图片则会落在0.40.4的位置以此类推就算图片变成三个项速点这套方法照样管用只不过要升级到三为空间来看了那我们把28x28项速的麦克风的图片方大来看每张图片其实就变成了七八四为空间里的一个点在这个高为空间里绝大多数的点压根就不是手写数字咱们随便从这个空间里抓几个点把他们显示成图片就能明白这事了这些图片看起来基本就是一堆乱码想靠随机采样抽到手写数字那得祖文贸经验才行这种吸收性表明在七八四为的空间里可能藏这个低为结构这个结构上的每个点都对应一个真实存在的手写数字拿刚才那个三项速的图片打个比方如果我们发现第三个项速的亮度值就叫它X3吧永远等于第二个项速X2的余鲜值加1所有三项速的图片都会乖乖躺在三地空间的曲面上这个曲面就是由X3等于1加Cost X2定义的这个曲面其实是个二为平面咱们关靠X1和X2的两个作表中就能在三位空间里精准定位所有图片的位置了这下咱们连X3都用不著了我们可以把学习Mainless的分类的神经网络想像成用类似方式运作的系统拿这个网络架构来说吧到处第二层只有16个神经缘这就相当于把七八四为的输入数据压缩到了16位空间就像之前那个一家扩残数把三位空间压扁成二为一样神奇流行角度最面的地方在于它可不只是把数据压缩到低为那么简单这个流行的几合结构里往往藏著数据的关键信息举个例子如果我们用神经网络学习到的Math的数据几十六位表示通过U-Map这类渐为技术把它从16位压缩到2位这种技术会尽量保持高为空间的结构特征就能直观感受到这个几合形状了用图片对应的数字给每个点飙上颜色口我们就能发现随著神经网络不断训练逐渐掌握流行的形状相同数字的样本会在流行上具体成一个个小群落这可是机器学习领域的普遍现象在训练出来的流行上相思物体的图片或表达相近概念的纹本最终都会聚在一块儿理解深度学习模型运作的一个好方法就是把高为数入空间硬设到低位流行上这些数据点在流行上的位置可都是有讲究的那么流行假设和神经缩放定律到底有啥关系呢咱们来看这个神经缩放定律它直接把训练数据级的规模和模型在测试级上的焦杀商损失表现给挂钩了如果流行假设成立那我们的训练数据其实就是高为空间某个流行上的点而模型要做的就是摩清这个流行的形状训练数据在流行上的分布密度关键就看咱们手头有多少数据但也和这个流行本身的维度有关在一位空间里假设我们有第一个训练数据点流行总长度为L直接用L处以D就能算出训练点之间的平均距离S不过要注意与其直接计算点坚据在更高为度时不如想像每个点周围有个大小为S的领域有些领域会相互紧哀著数据点之间的时间距离其实还是S来到二位空间我们实际上是在用边场为S的小方块填满L成L的大正方形每个训练点就是这些小方块的中心这个大正方形的总面积AIR就等于数据点数量低成因每个小方块的面积也就是低成SS简单变形解架方程就能得出S等于L成因D的富二分之一次方现在升级到三位空间我们要用第一个边场为S的小理方体塞满L成L的大理方体让第一个小理方体的总体积等于大理方体积就能得出边场S等于L成因D的富三分之一次方当我们进入更高为度时数据点之间的平均距离会按照数据量的富为度分之一密词来变化我们之所以要关注流行上训练点的密度是因为当测试点出现时它的误差大小完全取决于它里最近训练点的距离假设我们的模型足够强大能完美你和训练数据的话咱们学出来的流行就会在训练数据点上和真实数据流行完美重合使用Railu基础韩数的深度神经网络可以在这些训练点之间进行现行差质来做出预测如果我们假设流行是光滑的就能用Tile的展开证明模型物差的增长幅度越等于最近训练点和测试点之间距离的平方我们发现训练点之间的平均距离会随著数据机大小D的富为次方再出于流行为度这个比例来变化所以咱们把这个相平方一下就能孤算出物差随数据机大小的变化规律最后算出D的富尔斯方出于流行为数别忘了咱们模型用的可是交叉商损失韩数但到目前为止流行分析里只考虑了预测值和真实之间的距离这就跟我们之前讨论过的L1损失只是一个意思同样用Tile展开来处理交叉商韩数的话我们可以证明交叉商损失会随著预测值和真实值之间距离的平方而变化根据最终理论结果交叉商损失应该会随著数据机大小D的富尔斯方出于流行为度的平方而变化所以这个D的富斯斯方除以小D的结果其实就是最糟糕的情况下的物差上限所以交叉商损失的下降速度至少会和这个相成正比甚至可能更快提出这个理论的团队管它叫分辨率受限缩放因为数据越多模型就越能精准补捉数据流行的细节有意思的是当分析模型规模和损失的关系时这个理论同样预测出了四次方关系简单来说新增的模型参数就像给模型装上了高清镜头能更精准地补捉数据流行的细节那么这个理论结果和实际观测数据对得上号码OpenAI和谷歌DipMine的团队都公布了自己的尼盒缩放系数这些数据跟理论预测对得上吗在2020年1月的片OpenAI论文里研究团队发现交叉商损失会随著数据及规模的复零点零几个五次方便化研究团队把这个数据称为CeptD如果理论成立的话AD应该大于等于数据本征尾度的四倍这最后一步可不好搞因为它要孤算数据流行的尾度也就是自然语言的内在尾度研究团队先从简单问题入手这些问题的内在尾度要么一支要么能轻松孤算出来研究团队发现当教师模型生成一支本征尾度的合成训练数据在有学生模型学习时理论锁放参数和实验数据匹配度相当高研究团队还发现这个复四字方出于地的预测公式在Amnest这类小型图像数据集上也完全说得通最后来看元数据套用观测到的复零点零九五这个锁放指数咱们可以算出自然语言的本征尾度大概是42左右研究团队用语言模型实测后发现学习流行的本征尾度其实要高得多直接标到了腰摆左右要注意的是理论上的不等事虽然依然成立但实际数据和人工合成四小规模数据机的结果可差远了现在我们手头这个理论确实挺有水腹力预测能力也不赖但要说它能统一解释Ai的一切还差得远呢这五年Ai的发展简直跟做火箭式的从2020年初Open AI发布第一片扩展轮到2023年GPT-T-4很空出事神经扩展定律给我们指名了一条性能持续提升的康装达道这里要化中点了虽然规模定律能神准预测下一个词的预测性了但具体会出现哪些特殊能力这事儿还真说不准想单次重组算是和多不推理这些能力简直像在不同规模阶段突然接锁的技能点一样神奇真没想到神经网络技术居然能带我们走到今天这一步当然了我们也不知道它的极限道理在哪里这些论文的作者很多都是物理学科颁出身从他们的研究方法和表述方式里你就能感受到他们正在追寻大义统理论的执著最大进的是看到他们把这种四位用在了AI研究上神经缩放定律堪称AI界的大义统理论点范它不仅给出了精准到吓人的使用数据更为智能系统的统一缩放理论埋下了让人欣养的线索未来五年缩放定律这些理论能带我们走多远AI到底能不能突破这条界线想想既让人兴奋了如果你喜欢我要吃Lapse的视频那你八成也会爱上我这本将需求的书这本书今年晚些时候就要上市了早在2016年我就做过一个超长的13级系列视频专门讲需求那些事需求这晚点简直太神奇了当年我就出过这本书的出版现在正忙著全面修订纠错还要大幅课充内容呢我的目标就是打造市面上最棒的需求教科书金装实体书今年晚些时候就会正式发货了现在点击下方链阶就能抢先预定了现在下旦还送2001.6版的免费PDF电子书立马就能下载最近我还倒过了几款新海报设计现在我的机火突破海报还推出了暗黑模式版本这些海报简直绝了能把视觉模型学到的数据流行直观呈现出来这些好东西在WashLab相电都能找到还有更多
