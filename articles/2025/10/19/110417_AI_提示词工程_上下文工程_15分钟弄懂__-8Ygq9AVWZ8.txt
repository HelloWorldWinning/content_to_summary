Timestamp: 2025-10-19T11:04:17.379321
Title: AI 提示词工程 上下文工程 15分钟弄懂！ -8Ygq9AVWZ8
URL: https://youtube.com/watch?v=-8Ygq9AVWZ8&si=DPWrmT9n9-mU9Mr2
Status: success
Duration: 16:24

Description:
好的，这是根据您提供的文本内容提炼的核心思想摘要。

### **核心思想摘要**

#### **一、 提示词工程 (Prompt Engineering)**

提示词工程是通过精心设计向AI提问的方式，以获得更精准、更稳定回答的技术。

*   **基本构成:**
    *   **系统提示词 (System Prompt):** 用于为AI设定角色、背景或行为准则，通常由应用内置，用户可间接影响。
    *   **用户提示词 (User Prompt):** 用户在聊天框中输入的直接问题或指令。
*   **核心技巧:**
    *   **零样本 (Zero-Shot):** 只提出要求，不提供具体范例，依靠模型自身能力完成任务。
    *   **少样本 (Few-Shot):** 在提示词中提供一或多个具体范例，引导AI模仿范例的风格或格式进行输出，在要求特定格式时尤其有效。
    *   **思维链 (Chain of Thought, CoT):** 引导AI在给出最终答案前，先分步骤思考和拆解问题，输出推理过程，从而提高复杂问题（尤其是数学和逻辑问题）的准确率。

#### **二、 上下文工程 (Context Engineering)**

上下文工程是在AI执行长程、复杂的自主任务时，通过管理和修改其“记忆”（即对话历史），确保它不偏离最初目标的技术。

*   **核心问题:**
    *   AI模型本身没有记忆，其“记忆”是通过每次请求都发送完整的对话历史（即“上下文”）来实现的。
    *   当AI Agent使用工具（如网页浏览）自主执行多步骤任务时，上下文会因包含大量的工具调用和返回信息而变得极其冗长和复杂，导致AI可能“忘记”最初的目标。
*   **核心技巧:**
    *   **引导AI记笔记 (Guiding AI to Take Notes):**
        *   提供一个“记笔记”工具，并用系统提示词指导AI先制定任务清单、记录关键信息，并将这份“笔记”放在上下文最显眼的位置（开头或结尾），时刻提醒AI核心目标。
    *   **缩短上下文 (Context Shortening):**
        *   **直接丢弃:** 舍弃较早的对话历史。
        *   **压缩总结:** 让AI模型总结概括旧的对话内容，用简短的摘要替换冗长的原文。
        *   **高级压缩 (RAG-like):** 将超长内容（如网页全文）存入临时向量数据库，在上下文中仅保留一个简短的指令和查询工具，AI按需查询片段，极大缩减长度。
    *   **优化工具返回值 (Optimizing Tool Returns):**
        *   在信息返回给AI模型前，由Agent预处理，剔除无关内容（如网页的HTML标签），从源头减少信息冗余。

---

### **核心结论 (Core Point)**

无论是提示词工程还是上下文工程，其核心目标都是通过精心设计与AI的交互方式和信息流，来确保AI能够更精准、更稳定地理解并执行用户的最终意uto。

---

### **内容总体框架 (Overarching Framework)**

本文内容框架遵循一个从**“优化单次人机交互”**到**“管理长程自主任务”**的递进逻辑，揭示了随着AI能力从简单问答向复杂Agent演进，人类如何通过不同的工程技术来驾驭和引导AI行为。

---

<Mermaid_Diagram>
graph TD
    subgraph "优化与AI的交互 (Optimizing AI Interaction)"
        direction LR
        A["提示词工程 (Prompt Engineering)"]
        B["上下文工程 (Context Engineering)"]
    end

    subgraph "提示词工程: 优化'如何提问'"
        P1["提示词 (Prompt)"] --> P2["系统提示词 (System Prompt)"]
        P1 --> P3["用户提示词 (User Prompt)"]
        
        P4["核心技巧 (Techniques)"] --> P5["零样本 (Zero-Shot)"]
        P4 --> P6["少样本 (Few-Shot)"]
        P4 --> P7["思维链 (Chain of Thought)"]

        P_Goal["目标: 精准、符合预期的回答"]

        P1 -- "构成" --> P_Goal
        P4 -- "实现" --> P_Goal
    end

    subgraph "上下文工程: 管理'对话记忆'"
        C1["问题: AI无记忆 & 上下文过长"] --> C2["解决方案: 管理上下文"]
        
        C3["核心技巧 (Techniques)"] --> C4["引导AI记笔记"]
        C3 --> C5["缩短上下文"]
        C3 --> C6["优化工具返回值"]

        C5 --> C5a["丢弃旧消息"]
        C5 --> C5b["总结旧消息"]
        C5 --> C5c["高级压缩 (RAG)"]
        
        C_Goal["目标: 确保AI在长程任务中不偏离方向"]
        
        C2 -- "通过技巧" --> C_Goal
    end

    A -- "针对单次交互" --> P1
    A -- "运用" --> P4
    B -- "应对长程任务" --> C1
    B -- "运用" --> C3

    style A fill:#D5E8D4,stroke:#333,stroke-width:2px
    style B fill:#DAE8FC,stroke:#333,stroke-width:2px
    style P1 fill:#FFF2CC,stroke:#333,stroke-width:1px
    style C1 fill:#FFD2CF,stroke:#333,stroke-width:1px
    style C2 fill:#E1D5E7,stroke:#333,stroke-width:1px
    style P_Goal fill:#F8CECC,stroke:#B85450,stroke-width:2px
    style C_Goal fill:#F8CECC,stroke:#B85450,stroke-width:2px
    style P4 fill:#FFE6CC,stroke:#D6B656,stroke-width:1.5px
    style C3 fill:#E1D5E7,stroke:#9673A6,stroke-width:1.5px
</Mermaid_Diagram>

Content:
不知从什么时候开始,很多简单的事情都得换一个高级的说法卖东西叫分销、赚钱、便宣、写文章、内容书出、拉人进群叫私欲引流就连AI写代码也得有个新词叫Wivecoding人们总是倾向用高级的词会来演改内容的规法今天我们来聊几个AI时代的流行词提示词、提示词工程、商下文以及那个宣称可以把提示词工程采在脚下摩擦的商下文工程大园模型刚出现的时候主要就是一个聊天机器人用户说你好,大园模型可能会回复,我很好你呢?经过几年的发展,AI的能力已经远远的超过了普通的聊天机器人但聊天依然是AI最核心,也是最实用的功能之一在聊天这个场景下,用户说的你好,就叫做Proud中文翻译过来提示词,所以提示词最基本的定义就是用户发给AI的话对于我很好你呢?这种四平八稳的回答虽然能满足大多数人在多数情况下的期望但这也注定这种回答将会是干巴巴了毫无特色的所以即使只是聊天也可以用上一些聊天机巧比如说我们可以用提示词给AI设定一个角色举个例子,你跟他说,你来扮演一个猫娘,接下来我说你好这个时候AI就可能回复,我很好你呢?名,把这种玩法推向极致的一个软件叫做Clythalve为了保证这几视频不为和谐,这里我就不展开多说了有兴趣的朋友可以自己去搜一下但是问题来了,你扮演猫娘这种设定,并不是用户对话内容本身把这种设定和用户真正想说的话混在一起不仅容易出戏,逻辑上也有点乱所以大模型的厂商们就把提示词分成了两部分向你扮演一个猫娘这种设定叫做Sitant prompt也就是系统提示词,而用户说的你好则叫做User prompt也就是用户提示词我们平时在聊天矿里输入的就是用户提示词而系统提示词通常是聊天机器内置的用户一般不能直接修改不过很多AI应用来提供了一些功能可以间接的影响系统提示词比如在CatGPT里面有一个叫做Customize ChatGPT的功能可以设定一些用户的个人偏好这些信息最终就会成为系统提示词的一部分从而影响CatGPT的输出内容这种通过系统提示词和用户提示词的组合来引导AI返回特定风格回复的做法就叫做提示词工程Proft Engineering当然了提示词工程可不只是用来玩角色扮演的它最核心的目的是通过一系列技巧来约束AI的行为让它的回复更加稳定减少错误和意外下面我们就来介绍几种常见的技巧比如说AI不太擅长处理数学问题再让它解数学体的时候就比较容易做错这个时候我们就会要求它在回复前仔细的检查确保它的答案是正确的在比如说有时候AI会拒绝回答我们一些问题这个时候就可以在提示词中告诉AI这件事情的严重性于是AI就会偏向于输出更加完整的答案了这些都属于行为的约束像这种只提要求但是不给AI模型具体例子的技巧还有一个专门的教法叫做ZeroShot与此对应的就是FuelShot这种方法是指用户可以在提示词里面先给AI几个具体的例子当作参考比如说我希望AI帮我把正常的句子转化成猫娘体我就可以在提示词里面先举例比如我们去吃饭吧转化成我们去吃饭好不好压秒我写了一个程序转化成我把程序录好了秒给出范例之后我们再提出真正的需求现在来转化这个句子亲爱的我买了包包送给你这样AI就会根据我们提供的例子给出更贴近预期的答案了比如说回复亲爱的我抓了老数送给你秒FuelShot这个技巧在要求AI返回特径格式的场景下会特别的有用比如说当我们写一个AI应用或者AIAZN的时候通常需要AI稳定的返回带有某种格式的自负串这种场景下用FuelShot就非常的合适如果有朋友想了解AIZN的是什么可以参考这两期视频或者我的知识星球我会分别从原理和编程实现讲明白AIAZN的到底是怎么回事连接我会制定在评论区除了ZeroShot和FuelShot还有一种更加旋学的技巧叫做思维链Chin of Salt简称COT举个简单的例子我们问AI一到数学体1加2成3等一多少因为大园模型本质上是一个概率模型它其实并不擅长做精确的数学运算对于这种问题尤其是在早期的模型上精度是比较低的这个时候我们就可以在问题后面多加一句话比如说不要先给出答案请一步一步的拆解问题并且给出每一步的中间结果收到这个指令之后AI的回复就可能变成了根据运算优先级第一步需要先计算二唱一三结果16然后再计算1加6最终结果是7虽然模型本身是没有变的但我们通过提示词引导它一步步思考然后再输出最终算对的概率就会大大的提升这就是所谓的思维链当然了我们举的这个例子有点过于的简单了即使不用思维链AI基本也不会算错而且如今的网页版聊天机器人大多数都内置了比我们这个例子强大的多的思维链功能不再需要用户手动输入额外的提示词了但他们背后的原理都是一样的都是通过提示词让AI自己分解问题输出推理过程从而解决更加复杂的问题总结一下所谓的提示词工程本质上就是通过精心设计我们向AI提问的方式来获得更精准更符合我们预期的回答在聊上下文和上下文工程之前我们首先要澄清一个事实AI模型本身是没有记忆的这意味著每次我们给AI发送一个消息对它来说都是一次全新的独立的请求但很显然我们在进行连续对话的时候是需要AI寄入我们聊过什么的否则对话就无法成立了那么这个记忆到底是怎么实现的其实在我们和AI聊天的时候并不是直接把消息发送给大语言模型的用户和AI之间还隔了一个AI agent或者聊天机器人的服务器正确的流程是这样的用户把消息先发给AI agent或者聊天机器人服务器聊天机器人会把消息发送给AI模型的同时还会保留下完整的历史纪录然后当它收到一条新的用户消息的时候它会把这条消息附加到历史纪录的末尾最后再把这个包含了所有过往信息的完整历史纪录一起发给AI模型这样一来AI模型本身是失意的但它们一次收到的信息都是完整的对话所以看上去就像有了记忆一样这个被一次性发给AI的完整的历史纪录就叫做上下温Context而如何管理和修改这段历史纪录的技巧就被叫做上下温工程Context and engineering那么这个上下文道里有什么好管理的呢其实如果AI只是一个简单的疑问义达形式的聊天机器人那我们之前聊的提示词工程基本就够用了因为在那种一来一回的对话中用户总有机会通过新的提示词来修正和引导AI的行为确保它的回答不会跑偏但是AI agent的出现让情况变得复杂了起来AI agent除了传递消息维护历史之外它还拥有一个工具箱里面有一些它自己定义的工具可以供AI模型来调用如果你觉得AI agent的概念有点复杂我们还是以往业版聊天机器人来举例许多往业版聊天机器人提供了网页流览功能这种聊天机器人本质上就是一个简单的AI agent而流览网页就是它提供了一个工具比如说当用户问猫娘的口头产是什么这个时候聊天机器人就会把当前的上下文连同它能使用了所有的工具说明一起都打包发送给AI模型AI模型收到消息之后就会发现工具箱里面有一个用于流览网页的工具可以用于是它可能会决定不直接回答用户的问题而是先用Google搜索一下此时AI模型就会返回一个特殊的指令叫做Torco这个指令大意就是帮我访问这个Google网址搜索猫娘的口头产是什么聊天机器人收到指令之后就会去调用访问网页的工具访问网页的工具就会去访问Google访回网页的内容接下来网页的内容会被打包成一条Torco Response消息和对应的Torco一起放到上下文之中而这个变得更长的上下文会被重新的发给AI模型这个时候AI可能还觉得信息还是不够又想去萌娘百科里面再查一下于是就又重复了一次刚才的那个过程上下文里面因此又多出了一对Torco和Torco Response对于比较复杂的问题在AI生成最终答案之前这样的一来一回可能会重复即时甚至上百次上下文就会变得特别特别的长这里请注意一下在这个漫长的探索过程之中用户能实家的影响只有在最最开头的那一句提示词而后续几十次Torco和Torco Response不仅数量多而且像是流兰网页这种Torco Response内容通常也非常的长不然想像当AI模型面对一个越来越长充斥了各种中间信息的上下文而用户又没办法即时的纠正它的行为的时候它的行动方向就很容易跑偏忘记自己到底要干什么所以如何通过一套程序化的规则来自动的管理和修改上下文确保AI在漫长的自主行动中使中符合用户的最初要求这就是上下文工程要解决的核心问题很可惜的是关于上下文到底要怎么管理目前还没有一个公认的完美方案不过这里我可以介绍几种在夜界比较常见比较有效的做法一招上AI学会记比计它的原理类似于我们之前提到的网页流览工具不过这次我们再给AI模型提供一个专门用来记比计的工具当AI在处理任务的时候如果想要记下一些关键信息就可以调用这个工具当然了只提供工具然后让AI自由的发挥记比计效果一般都不会太好所以我们还需要在系统提示词里面明确的给出比计的使用策略比如说我们可以这样知道模型一在行动前先将任务分解二在比计中写下你的任务清单三严格根据任务清单来执行任务四美完成一项就在比计中更新该项的状态这样以来当AI再拿到猫娘的口头产是什么这个问题的时候但模型自己就会先头脑风暴出一个任务清单比如说一用谷歌搜索猫娘二用蒙娘百科搜索猫娘三综合两次的搜索结果总结出口头产然后AI就会通过之前我们介绍的tool code方法调用记比计的工具让Agent把这个清单记录下来现在我们来看一下整个上下文是什么样子里面包含了最开始的系统提示词和用户提示词还有AI调用记比计的tool code和tool response其中的tool response一般不会包含什么有用的信息只是告诉AI比计更新成功了而这里最关键的一步来了这个被保存的比计会被Agent插入到整个上下文的开头或者结尾这个插入的位置其实也是有讲究的因为现在的大语言模型普遍采用的是传统former架构而这种架构天生就对输入信息的开头和结尾部分特别的敏感所以即使上下文变得非常长无论AI中间执行了多少次tool code和tool response开头结尾的信息也基本不会被模型忽略写著核心目标的任务清单和最初的提示词始终都处在最显眼的位置当AI完成一项任务比如用Google搜索猫娘它又会根据系统提示词的指示再次调用记比计的工具把第一项任务标记为一完成然后开始执行第二项通过这种方式就能很大的程度上保证AI在执行复杂的任务的时候不会跑偏当然了比计里面也不仅限于记录任务的清单比如说我们还可以通过系统提示词让AI记录搜索出的关键信息便于后续进行总结等等但无论记录什么这项技术的本质都是人类拥护通过控制最初的提示词来指导AI如何写比计再通过把比计放到上下文中最显眼的位置来间接引导整个AI的处理流程那么既然上下文太长是问题的根源另一个优化的方向就是让它变短最直接的做法就是直接丢掉太老的消息只保留新的消息当然了最开始的系统和用户提示词部分是必须要保留的不然AI就不知道自己要干什么了如果你觉得直接舍弃信息这种方式太暴力了可能会丢失关键的内容那么还有一种更加优雅的做法就是压缩许多Agent会把较老的消息提取出来然后让AI模型去总结其中的关键信息再用这个精链的总结去替换掉原来的上下文从而达到压缩的目的除了这些还有更高级的压缩方法某些Tourist Bounce可能会非常的长比如说包含了一篇上万字的文章这个时候Agent就会先把Tourist Bounce的内容处理后存到一个脸时的相量数据库里面这个过程就类似我们之前讲过的Rug技术Rug的知识可以回顾我做的这一期视频连接我会指点到评论区文章存入之后Agent就会修改这次的Tourist Bounce不再包含原文而是用一句话来代替比如说文章已经存入知识库我为你提供了一个新的工具叫做Cory Document你可以用它来查学文章的片段然后AAM模型就只要查找自己感兴趣的片段就可以了这样以来一个几万字的Tourist Bounce就会压缩成了一具几十个字的指令和一些AI主动查出来的片段上下文的长度就得到了很大的控制还有一种方法是直接优化工具的反回值比如说对网页流暖工具Agent可以先去掉网页里面不必要的HTML标签只把最核心的内容反回给AI模型从源头就减少信息的荣誉当然了这里我提到的只是机中比较常见的上下文观力方法这是一个非常热门的AI应用研究方向新的研究和技术也在不断的涌现之中总而言之无论是我们前面聊的记忆技还是刚刚所说的减少上下文长度的各种方法所有所有的一切目的都只有一个在人类用户无法实实干预AI行动的时候确保AI模型时中都记得自己最初的任务是什么小学的时候老师问我们长大以后想做什么当时我在作业本上写下的答案是当老师因为我觉得他们是超人什么都懂什么都能讲的明明白白的也不知道老师当时花了多少心思到底用了什么神奇的方法过去了几十年我现在依然还记得这里是程全老王我们下期再见
