Timestamp: 2025-08-13T00:36:55.890727
Title: 《如何用AI（几乎）做任何事》：MIT公开课的讲义入门 0P5soSTxA8Q
URL: https://youtube.com/watch?v=0P5soSTxA8Q&si=38U8h1e-F1vYM7yN
Status: success
Duration: 49:32

Description:
**核心思想总结：**
AI的成功源于对数据的深度理解、系统化的调试实践、跨模态信息的有效融合，以及大型模型架构与高效训练范式的不懈探索。

**总览框架：**
系统化、数据驱动、模型-架构与工具并重的AI研发与应用范式。

**总结大纲：**

**一、 AI研究与调试：系统化方法论**
    *   **痛点：** 神经网络的“无声失败”，调试难度高。
    *   **核心调试流程（“秘籍”）：**
        1.  **理解数据：** 深入检查数据质量、分布、模式及潜在偏差。
        2.  **搭建基线模型：** 快速实现端到端流程，确保基本功能跑通。
        3.  **小数据集过拟合诊断：** 在小样本上故意过拟合以验证模型实现和结构无误。
        4.  **正则化与泛化：** 应用L1/L2、Dropout、数据增强等技术防止过拟合。
        5.  **超参数调优：** 细致调整学习率、优化器、批次大小、网络结构等。
        6.  **性能榨取：** 采用集成、长时间训练、精细学习率策略等进一步提升性能。
    *   **常见调试问题及对策：**
        *   损失值NAN：检查学习率、初始化、数据异常、梯度爆炸。
        *   损失不变化：调整学习率、增加模型容量、检查数据和梯度流。
        *   训练准确率高但验证准确率低（过拟合）：加强正则化、数据增强、获取更多数据、降低模型复杂度。
    *   **常用工具：**
        *   **通用框架与生态：** PyTorch, HuggingFace (Transformers, DataSets)。
        *   **大模型优化工具：** Bits & Bites (量化), Flash Attention (Transformer加速), LoRA (高效参数微调)。

**二、 多模态AI：理解与融合不同信息模态**
    *   **定义：** 机器理解、处理和融合来自不同模态信息（文本、图像、音频、视频等）。
    *   **关键概念与挑战：**
        *   **一致性：** 不同模态数据结构、表示方式的统一。
        *   **连接性：** 学习不同模态数据间内在的对应关系。
        *   **交互性：** 模态结合如何产生新意义（冗余、互补、协同）。
    *   **六大核心挑战：** 表示、对齐、推理、生成、迁移、量化。
    *   **核心模型示例：CLIP：**
        *   **原理：** 通过对比学习，将图像和文本映射到共享向量空间，实现跨模态对齐。
        *   **意义：** 赋予强大的零样本分类能力和通用跨模态理解，推动大规模预训练。

**三、 大型模型与生成式AI：前沿技术与未来方向**
    *   **大型语言模型（LLM）发展：**
        *   **核心架构演进：** 从RNN到Transformer，自注意力机制解决长距离依赖和并行计算。
        *   **训练范式：**
            *   **预训练：** 在海量无标签文本上进行自监督学习，获取通用语言知识。
            *   **微调：** 适应特定任务，包括指令微调（理解并遵循用户指令）和对齐（Alignmen，通过RLHF使模型行为符合人类价值观）。
    *   **大模型高效训练与推理技术：**
        *   **LoRA：** 通过引入低秩矩阵实现参数高效微调，大幅降低成本。
        *   **Mixture of Experts (MoE)：** 在扩大模型容量的同时，控制实际计算量。
        *   **量化：** 压缩模型体积，加速推理，降低资源消耗。
    *   **多模态大模型（LMMs/VLMs）：**
        *   **实现策略：** 保持LLM主体不变，通过适配器模块转换其他模态信息；或设计统一原生多模态架构。
    *   **生成式AI：扩散模型与流匹配：**
        *   **扩散模型（Diffusion Models）：** 通过逐步加噪和去噪过程，生成高质量、细节丰富的样本（如文生图）。
        *   **流匹配（Flow Matching）：** 学习直接将简单先验分布转换为目标数据分布的向量场，是生成模型的新方向。
        *   **条件生成：** 允许根据特定输入条件（文本、图像等）控制生成内容。
        *   **常用架构：** U-Net（图像生成），Transformer（LLM及多模态生成）。

<Mermaid_Diagram>
graph LR
    A["AI研发与应用范式"] -- "核心挑战与解决方案" --> B("AI研究与调试");
    A -- "拓展边界" --> C("多模态AI");
    A -- "前沿探索" --> D("大型模型与生成式AI");

    subgraph "AI研究与调试"
        B1["痛点: 无声失败"] --> B2("系统化调试流程");
        B2 -- "第一步" --> B3("数据理解");
        B2 -- "第二步" --> B4("搭建基线模型");
        B2 -- "第三步" --> B5("小数据过拟合诊断");
        B2 -- "第四步" --> B6("正则化与泛化");
        B2 -- "第五步" --> B7("超参数调优");
        B2 -- "第六步" --> B8("性能榨取");
        B3 --> B9("常见调试问题");
        B4 --> B9;
        B5 --> B9;
        B6 --> B9;
        B7 --> B9;
        B9 -- "对策" --> B10("调试工具");
        B10 -- "通用框架" --> B11("PyTorch/HuggingFace");
        B10 -- "大模型特定" --> B12("Lora/Bits&Bites/Flash Attention");
    end

    subgraph "多模态AI"
        C1["定义: 理解处理融合多模态信息"] --> C2("核心概念");
        C2 -- "底层差异" --> C3("一致性");
        C2 -- "内在关联" --> C4("连接性");
        C2 -- "组合效应" --> C5("交互性");
        C1 --> C6("六大核心挑战");
        C6 -- "如何表示?" --> C7("表示 (Representation)");
        C6 -- "如何匹配?" --> C8("对齐 (Alignment)");
        C6 -- "如何推断?" --> C9("推理 (Reasoning)");
        C6 -- "如何创造?" --> C10("生成 (Generation)");
        C6 -- "知识复用?" --> C11("迁移 (Transference)");
        C6 -- "如何评估?" --> C12("量化 (Quantification)");
        C8 -- "示例模型" --> C13("CLIP");
        C13 -- "原理" --> C14("对比学习");
        C13 -- "意义" --> C15("零样本分类/跨模态理解");
    end

    subgraph "大型模型与生成式AI"
        D1["LLM发展"] --> D2("核心架构: Transformer");
        D2 -- "取代" --> D3("RNN局限");
        D2 -- "基础" --> D4("自注意力机制");
        D1 --> D5("训练范式");
        D5 -- "通用知识" --> D6("预训练 (MLM/CLM)");
        D5 -- "任务适应" --> D7("

Content:
欢迎收听今天我们要一起深入探讨一下你提供的这些关于人工智能的精彩资料内容确实是相当丰富富贵面横广从这个模型调试的具体方法到比较复杂的多摩太学习再到现在非常火的大型模型会前沿的声承谁呀可以说是AI领域的一张愧详细的地图了对我们今天的任务就是帮你输理一下从这些资料里提练出最核心又有价值的那些间接我们希望通过这次讨论让你对怎么有效的进行AI研究和调试有一个更清晰的流程概念还有就是理解处理向图像文本这种混合数据类型也就是多摩太AI它里面的一些核心难顶和机遇最后也会聊聊现在大家都在关注的大预模型就是LM还有各种声承是AI他们是怎么运作的基本原理是什么我们的目标就是帮你快速的但又比较深入的把握住这些可以说是挺复杂的AI领域的关键脉落想象一下这就像是一次为你良身定制的AI知识深度游帮你把这些点串起来对我们会特别关注几多可以说是冠川始终的关键问题比如说为什么神经网络的调试感觉总是那么极手挑战性那么大它不像传统软件那样错了就给你报过错这个确实很多的还有就是当我们要处理比如说图像文本甚至音频这些不同类型的数据混合在一起的时候这会带来哪些独特的机遇又会遇到哪些难题以及当然了现在这些能力超强的大型模型还有那些能生成图像文笨的生成是AI他们接下来的发展方向大家会是什么样的这些都是我们这次要重点聊的好我们就不让弯子了直接切入第一个打话题AI的研究与调试此料理提到一个非常有意思也确实是很多研究者会遇到的痛点就是神经网络的失败它往往是无声的对无声的失败这个描述很形象是的不像我们写传统代码可能一个语法错误或者一个逻辑Bug编辑或者运行时就会明确告诉你哪里出错了但神经网络它可能就是不学习或者效果很差损失寒暑不动了或者精度上不去但它不会崩溃也不会直接包错它就默默地失败了这确实让调试变得特别特别困难你需要像真态一样去找线索所以这就凸显了有一个结构化的系统性的调试流程是多么重要不能像眉头苍硬一样乱撞的确如此资料里其实提到了一个挺不错的调试密集或者说是一靠方法论我觉得很值得我们深入聊聊这个方法论强到首先第一步也是最基础的一步就是要与数据融为一体与数据融为一体这个听起来有点宣呼具体是指什么呢听起来是有点但其实很实在意思就是在你开始写任何磨情代码之前你得先花大量时间去彻底的理解你的数据这包括比如说仔细检查数据的质量有没有缺失值有没有一场值标签是不是正确的数据清洗这步不能省对还要看数据的分布它的模式是什么样的比如说图像数据看看样本是不是多样有没有一些奇怪的模式或者偏差文本数据也是看看长度分布词评人们的理解数据的偏差也很重要对吧不让模型可能会学到一些我们不想要的东西完全正确比如说如果你的训练数据里某个类别的样本特别少或者某个场景下缺乏数据模型就可能在这方面表现很差就就是偏差你得先意识到这些问题所以第一步是深入理解数据检查质量模式偏差这是基础那之后呢在对数据有了充分把握之后第二步是快速搭建一个最简单的端到端的模型股价这个模型不需要复杂可能就是一个非常基础的网络结构目标是先让整个流程能跑通从数据加在预处里到模型前向传播损失计算反向传播残数更新最后到评估相当于先建立一个Base Line一个最起码能工作的版本没错一个能跑通的股价同时也要建立一个简单的激现Base Line性能比如对于分辣任务你可以先试试逻辑回归或者一个非常简单的CNNMLP这能给你一个比较的起点有了股价和激现接下来资料里提到了一个挺有意思的步骤就是在一个小的数据集上故意去过你合这个我得问问为什么要去追求过你合我们不是一直要逼连过你合吗问得好这确实听起来有点反直觉但这里的过你合是作为一种整段手段而不是最终目标它的逻辑是这样的如果你选择一个非常小比如说只有几十个或者几百个样本的自己一个足够强大的模型理论上应该能够完全记住这些数据达到接近百分之百的训练准确率或者把训练损失降到非常非常地因为它看到的样本少完全可以死经备对如果你在这个小的数据上你的模型都无法达到很高的训练准确率或者损失降不下去那就说明很可能你的模型实现本身就有问题我明白了也就是说如果连这么简单的开键考试都考不好那说明要么是模型结构设计的问题要么是代码实现比如提独计算损失韩数什么的可能有8个正是这个意思这是一种快速排除模型结构或者代码硬上的方法它帮你隔离问题因为在这个阶段你不用太担心数据本身的问题因为数据量小也不用太担心放话问题你只关注模型能不能学的动这个技巧确实很高明先确保模型本身具备学习能力对只有当你确认你的模型能在小数据上成功过你合之后你才能比较有信心地说我的代码实现和基本结构大概是没问题的然后你才能进入下一步那下一步就是开始真正关心范化防止模型只记住讯类数据了吧没错排除了基本的实现错误后我们就要开始考虑模型在新数据上的表现了也就是范化能力这时候就要引入正则化了正则化比如像像L1L2成法像或者抓泡子之类的吗对L1L2正则化通过给模型的状态增加成法像来限制模型的复杂度抓fought则是在训练过程中随机丢气一部分神经缘强迫网络学习更乳胖的特征减少新元之间的共同适应还有像数据增强也是一种很有效的政则化手段增加数据的多相信让模型见过更多市面可以这么理解选择哪种政则化以及政则化的强度这本身也是需要调试的这就引出了下一步对吧调整超参数是的在模型能够正常训练并且有了一定的政则化之后接下来就是细致的调整各种超参数了这包括学习率可能是最重要的超参数之一学习率衰减策略优化器的选择AdamSGD等Batch Size大小还有网络结构本身的参数比如层数宽度以及刚才说的政则化强度等等调整超参数感觉是个挺繁瑟的过程有什么好的策略吗嗯确实传统的比如网格搜索Grid Search但它效率不高特别是参数多的时候随机搜索Random Search通常更有效一些现在也有一些更高级的方法向被夜死优化Basement Optimization它会根据之前的试验结果来更智能的选择下一组参数这些都需要耐心和经验啊非常需要这个阶段的目标是找到一组让模型在验证极上表现最好的超参数组合在验证极上表现最好然后呢是不是就差不多了基本流程是这样最后一步可以说是诈取性能当你找到了比较好的模型结构和超参数后可能会尝试一些极成方法And symbol比如把多个不同模型的预测结果结合起来或者进行更长时间的训练使用更精细的学习率调整策略等等这一球内最后一点点的提升对所以你看这个流程理解数据搭股价建机线小数据过你和准断证据化防过你和调参优化诈取性能它强调的是一种系统性的寻序见尽的排错和优化过程这炮方法轮确实非常清晰感觉能避免很多盲目是错当然有好的方法轮也离不开好的工具工具确实能极大的提高效率资料理也提到了不少比如现在非常流行的PyTorch和HuggingFace生态对PyTorch提供了灵活的底层框架而HuggingFace的Transformers库几乎成了NLP领域的事实标准提供了大量的预讯练模型和方便的接口还有DataSets库处理各种数据籍也很旁边这些确实让研究者和开发者能站在巨人的肩膀上是的而且针对现在越来越大的模型还有一些专门的优化工具比如资料提到的Bits & Bites它是做什么的Bits & Bites主要用于量化款台ZeSyn简单来说就是用更少的比特术比如8比特整数甚至4Bit来表示模型的全重和几活值而不是通常的32Bit扶点数这样做的主要好处是主要是两个一是显著减小模型的体积方便存储和部署而是降低计算和内存贷款需要可以加快推力速度或者在资源有限的设备上运行大模型当然量化可能会带来一点精度损失需要全衡用精度换效率那Flash Tension听起来很快对Flash Tension是针对穿Former模型中计算量和内存占勇都非常大的自助一力South Tension技术的一种优化实现它通过一些巧妙的计算技巧比如分块计算台领和重计算Recomputation来减少GPU内存的读写次数从而在保持计算结果几乎不变的情况下大幅提升注意力的计算速度并减少内存占勇对于训练和推力长续练的大模型来说效果非常显著这些工具听起来都很硬和但对于处理大模型确实是刚需资料还提到了Lora这有什么Lora全程是Low Rank AdaptationDG吸引这是一种非常流行的高效的参数微调Parameter Efficient Fine Tuning PEFT技术微调我们知道就是拿预讯练好的大模型在特定任务上再训练一下Lora特别在哪里它的特别支出在于它并不去更新预讯练模型的全部参数那些参数是动结的它只在模型的某些层通常是Transformer的注意力层或前费的网络层旁边增加一对小的低质的矩阵可以想象成两个细长的矩阵相成只训练这对新加的小矩阵对在微调时只训练这对低质矩阵的参数因为这对矩阵非常小所以需要训练的参数量相比整个模型来说可能只有百分之零点几甚至更少那训练成本就大大降低了是的极大的降低了微调所需的计算资源和时间而且因为原始模型参数没动你只需要为每个新任务保存那个小小的老Rogs就行切换任务也很方便这个技术听起来非常有吸引力怪不得这么流行他让个人开发者或者资源有限的团队也能比较容易的去适配和使用那些强大的预讯廉大模型掌握这些调试方法和工具确实能让我们在AI研究的路上走得更顺畅我们再回到调试细节上资料里也举了一些矩皮的例子比如遇到损失值变成NAN怎么办对NAN not a number无效数字这是个很常见但也很让人头疼的问题他通常因为计算过程中出现了数值不稳定比如最常见的原因可能是学习率过高导致参数更新幅度太大直接飞出去了或者是踢肚爆炸踢肚直变得非常大导致后续计算一出那怎么检查呢首先要检查学习率试试调低很多其次检查模型的全重出事化不好的出事化也可能导致早期训练不稳定还要检查输入数据看看是否有一场值或者本身就存在难有时候某些数学运算比如对付数取对数或者除以零也会导致难需要一步步排查是哪个环节出了问题使用踢肚拆检Gradient Clipping也是一个常用的防止踢肚爆炸导致难的方法嗯 需要耐心那如果损失不变化呢一直停留在一个直上下波动呢损失不变化或者变化非常缓慢也有几种可能一种可能是学习率太低了模型走得太慢陷入了某个局部最优惑者安点可以试试提高学习率另一种可能呢另一种可能是模型本身的复杂毒不够容量太小无法你和数据比如说你用一个简单的现性模型去你和一个非常复杂的非现性关系那损失可能就很难下降这时候需要增加模型的复杂毒比如加深网络层数或者加宽还有可能是数据本身的问题吗对如果数据本身没有提供足够的信息或者标签有物模型也可能学不到东西还有就是要确保踢肚回传的路径是通常的有时候代码8个可能导致踢肚无法传到前面的层明白了还有一个常见情况训练机准确率很高但厌证去准确率差很多这个太典型了这几乎就是过你合的明确信号模型在训练书率上表现太好像个指挥背书的学生到了心体墨厌证级就不会做了非常形象的比喻这时候就需要回头去看我们之前说的政责化了加强政责化比如增大抓炮的比例或者增加L1L2成法的细素对或者使用更多的数据增强如果有可能的话或取更多的更多样化的训练数据通常是解决过你和最有效的方法还可以考虑降低模型的复杂度调识AI模型真是一门实践性很强的艺术需要级和理论知识工具使用和大量的经验确实如此它不像解数缺体往往没有唯一的正确答案更多的是一个不断试错分析调整的过程好的关于AI研究和调试的基础我们聊得紧深入了接下来我们转向下一个同样非常重要且有趣的话题多摩太AI多摩太这个领域现在也非常热首先我们得明确一下什么是多摩太AI它研究的核心是什么简单来说多摩太AI研究的是如何让机器理解处理和融合来自不同摩太的信息摩太指的就是信息的不多形势对吧比如我们最常见的文本是一种模态图像是另一种模态对还有Audio视频深色数据比如温度压力表格数据时间序列数据等等这些都是不同的模态我们人类其实天生就是多摩太的处理器我们看图说话听声变人结合视觉和听觉看电影没错多摩太AI的目标就是让机器也具备类似的能力能够综合利用多种信息来源这里面的关键挑战是什么呢资料里提到了几个核心概念数据的一致性连接性和交互性能展开说说吗好这上个特性是理解多摩太数据的基础也是挑战的来源首先是一致性Haton Regenetti不同摩太的数据他们的底层结构统计特性甚至数据的围度和表示方式都可能完全不同比如图像是相诉点的网格文本是离散的词序列Audio是连续的波情差别非常大对这就给如何统一的表示和处理这些数据带来了第1个挑战你不能简单地把相诉职和词像量拼接带一起就完事了那连接性呢连接性指的是不同摩太数据之间往往存在的内在关联比如一张图片和他的文字描述他们指向的是统一个或相关的概念一段视频画面和他的背景音乐或对话也是紧密观联的理解这种连接是多摩太学习的关键吧非常关键模型需要学习到这种跨摩太的对应关系比如要能把图像中的一只猫和文本中的单词猫联系起来最后是交互性这又是指什么交互性关注的是当不同摩太的信息结合在一起他们如何相互作用产生新的意义或信息这种交互可能有很多种形式比如荣誉荣誉不同摩太可能提供了相同信息比如图像和文字都描述了一只红色的苹果这可以用来相互验证提高辱邦性也可能是互补complementarity不同摩太提供了信息的一部分需要结合起来才能得到完整的理解比如看一个人的口型视觉和听他发出的声音听觉结合才能更准确的试别语音尤其是在草杂环境下这个例子很好还可能是邪童Cinertical或者叫新信息New Information不同摩太的结合可能会产生单独摩太无法表达的更深层次的含义比如电影中画面和音乐的结合营造出的特定氛围或情绪理解了一致性带来了表示的挑战连接性要求模型学习跨摩太关联交互性则涉及到如何有效分容信息以实现互补或者产生心意正是如此基于界切特性资料里总结了多摩太研究面临的六大核心挑战这六个挑战可以说是惯装了整个领域的研究方向哪六大挑战我们来一一看看第一个是表示这个刚才提到了因为一直性就是如何学习到能够有效普拙和融合不同摩太信息的特别对目标通常是学习到一种联合表示或者是一种协调表示让不同模太的信息能够在同一个或者相关观联的向量空间中进行比较和操作比如把图像和文本都应设到一个共享的余意空间里是的这是常见的做法既要保留每个模太自身的特性又要能体现他们之间的观联这是一个基础性的挑战好第一个是表示第二个呢第二个是对齐对齐就是找到不同模太数据中相互对应的元素和部分没错比如在一段教学视频里把老师讲到的某个概念与音和屏幕上展示的对应换灯片内容图像文本对应起来或者在一张图片里把文字描述带着红色帽子的男孩和图片中男孩带着红帽子内部分趋御对应起来这个感觉非常重要是建立跨魔太理解的基础绝对是没有好的对齐模型很难真正理解不同模太信息之间的细力度关系很多下游任务比如图像描述声程视觉文达都非常遗赖与准确的对齐第三个挑战是什么第三个是推理推理在多魔太场景下推理意味着什么他指的是不仅仅是简单的识别或对齐信息而是要能够结合多个魔太的信息并可能利用外部的常识或领域知识进行更复杂的多部推断能取个例子吗比如视觉文达VQA就是一个典型的例子给你一张图片问一个问题比如图片左边的那个穿蓝色T-续的人在斗什么模型不仅要理解图片内容找到穿蓝色T-续的人的位置还要理解问题的意图并结合两者进行推理才能回答出它正在踢足球有些更复杂的推理可能需要结合图片相关文本甚至常识知识库才能完成明白了这笔简单的模式识别要难得多第四个挑战第四个是生成这个比较好理解就是让模型创造新的多魔太内容对比如根据一段文字描述生成对应的图像Tax to image或者反过来为一张图片生成详细的文字描述Image capturing还可以是生成带有特定表情和动作的虚拟人对话AudioVizualsensis或者根据文本生成视频等等生成无情现在非常火多魔太生成是其中一个重要方向是的生成任务不仅要求模型理解内容还要求它具有创造性第五个挑战是千疑Transference千疑是指知识的千疑吗是指知识如何在不同魔太之间或者从资源丰富的魔太任务千疑到资源吸缺的魔太任务比如说比如我们有大量的文本数据可以用来训练强大的语言模型那能不能把从文本中学到的知识千疑到数据量相对较小的任务上比如帮助理解图像或者视频或者在一个魔太上学到的表示能不能帮助提升另一个魔太的任务性能这涉及到知识如何跨热魔太的界限进行有效利用感觉这对于解决某些领域数据吸书的问题很有价值的确最后一个第六个挑战是量化Consurfing量化这个不是指模型压缩那个量化吧哈哈不是那个这里的量化指的是如何客观全面的衡量和评估多魔太模型性能以及如何理解模型的内部工作机制是评估和客解释性的问题对多魔太任务通常很复杂评估起来也比单魔太任务更难比如声承任务怎么评估声承内容的质量多样性和语输入的匹配程度推力任务怎么评估推理过程的正确性确实向声承图像主观性也挺强的是的而且理解这些复杂的模型为什么会做出这样的预测或者声承这样的内容也就是可解释性也是一个重要的研究方向我们需要量化的方法来评估和比较不同的模型和方法总结一下这六大挑战表示对其推理声承千一量化这确实涵盖了多魔太AI研究的主要方面和难点这六点提供了一个很好的框架来理解这个领域刚才我们提到对其是很多应用的基础资料里特别提到了像Clip这样的模型能具体讲讲他是怎么工作的以及为什么他这么重要吗当然Clip全程是Contrasted Language Image Pre-Training是Open AIT出的一个非常有影响力的模型他的核心思想就是通过对比学习Contrastive Learning来学习图像和文本之间的对应关系对比学习对你可以想象一下他在训练的时候会看到大量的图像文本对比如一张狗的图片和文本一直狗在草地上玩耍对于每一张图片他还会看到很多其他的文本描述其中只有一个是正确的配对的其他的都是不相关的复养本反过来对于每个文本描述也只有一个图像是配对的其他图像都是复养本Collective目标就是学习一个图像编码器和一个文本编码器这两个编码器能把输入的图像和文本分别应设到一个共享的向量空间中应设 by 同一个空间然后呢在这个共享空间里他要做的是让配对的图像文本相量尽可能的靠近相似度高而让不配对的图像文本相量尽可能的远离相似度低啊通过对比来学习哪个跟哪个是一对正是这个意思通过在海量的图文对数据上进行这种对比学习Collective的图像编码器和文本编码器就能非常好的理解图像内容和文本描述之间的现役观点这有什么好处呢学到了这种观点之后好处非常大最直接的一个应用就是强大的零项本分类能力零项本就是说模型没见过的类别也能分对比如我想让Collect去做 image net图像分类但我并不需要用 image net的炫炼数据去微调collect那怎么做我只需要为每个 image net的类别比如毛狗飞机构造一个文本体式比如一张毛的照片A photo of a class然后来了一张新的图片我用Collect的图像编码器把它编码成一个项量嗯同时我把所有类别的文本体式比如A photo of a catA photo of a dogA photo of a plane也都用文本编码器编码成项量然后比较相似度没错计算图像项量和哪个类别的文本项量最相似就把它预测为哪个类别因为Clip 预训练书已经学到了图像和文本的语对应所以即使它没在 image net上专门训练过也能通过这种方式进行分类而且效果还相当不错这太神奇了等说通过学习图文对齐它获得了一种通用的夸模太的理解能力可以这么说Clip的成功极大的推动了后续很多多模太大模型的研究它证明了在大规模数据上进行夸模太预许练的巨大潜力它为解决我们刚才说的表示和对齐这两个核心挑战提供了一个非常有效的犯事明白了Clip确实是多模太领域的一个离程碑是的那么有了这种夸模太理解能力的基础我们自然会想能不能把这种能力和现在非常强大的大型语言模型LLM结合起来呢这就引出了我们下一个要深入探讨的核心内容大型模型与生成是AI的前进对先说说大型语言模型也就是LLMLLM的发展可以说是今年来AI领域最引人注目的突突之一了它的基础加高眼睛是怎样的资料里提到了从RN到Tranceformer这是一个关键的眼镜早期的训练模型比如循环神经网络RNN及其变种LSTMGREU他们在处理文本等训练书记上取得了不错的进展但他们有什么局胜性吗主要有两个比较大的局限一是他们处理训练是1次进行的很难进行大规模的病型计算训练效率手线二是对于非常长的训练他们容易出现提度消失或提度包扎的问题导致很难捕捉到长距离的依赖关系比如一篇文章开头提到的信息可能到结尾时模型就忘记了长距离依赖是个难题然后Tranceformer架构出现了它彻底改变了局面Tranceformer的核心是自主义李米基Self-attention自主义能简单解释一下吗简单来说自主义一夜远显模型在处理训练中的每一个词或抽肯时都能直接的同时的关注到训练中所有其他词并计算他们之间的相关性或者说重要性不是像NNA依次传递信息而是一步到位看到全局对它可以根据当前要处理的词动态的给训练中所有词包括它自己分配不同的注意力权重这样模型就能更容易地补着到长距离的依赖关系比如带词它只带的是前面哪个名词而且因为这种计算可以并行进行训练效率也大大提高了是的这是的训练更大更深的模型成为可能Tranceformer架构尤其是它堆叠起来的Ancoder Decoder或者Decoder only结构成为了现代LLM的基始比如BirtGPT系列都是基于Tranceformer的有了强大的架构还需要数据和训练方法LLM通常是怎么训练的资料理提到了预训练和微调对LLM的训练通常分为两个主摇阶段预训练Pre-Trining和微调Fine-Tuning预训练是在海量的通常是无标签的文本数据上进行了目标是让模型学习到通用的语言知识比如语法长时世界知识的目标签数据那模型怎么学习呢通过一些自神俊动学习Self-supervised learning的人物比如像Birt使用的样码语言模型Masked Language Model任务简单说就是随机遮掉Mask输入句子中的一些词让模型去预测这些被遮掉的词是什么让模型做完型停控对还有像GPT系列使用的下一词预测Next-Token Prediction或者叫英国语言模型Cozle Language ModelCLM就是给定一段文本的前锥让模型去预测下一个词应该是什么让模型像习小说一样不断接龙没错通过在天文数字级别的文本上进行这些自神俊动学习任务模型迫备去理解语言的结构和模式从而学习到强大的语言表示能力这个预讯连阶段非常耗费计算资源预讯连好之后模型就有了通用的语言能力然后是微调阶段是的微调阶段我们会用一个相对小一些的带有特定任务标签的数据级来进一步训练预讯连好的模型让它适应特定的下游任务比如用情感分类的数据级微调让模型学会判断文本的情感倾向对或者用问答数据级微调让模型学会回答问题传统的微调是针对特定任务的但现在的好像更强调指令微调Instruction tuning和对齐Alignment没错这是一个重要的发展趋势仅仅做任务微调模型可能能完成任务但它的输出格式风格安全性等不一定符合人类的期望指令微调就是用大量指令想应对的数据来微调模型比如指令把这句话翻译成法语想应对应的法语翻译指令总结这段文字的主要观点想应主要观点总结通过学习大量的指令模型能更好的理解并遵循用户的指令让模型更像一个有用的助手对但仅仅遵循指令还不够我们还希望模型的行为能符合人类的价值观比如城市无害有帮助这就是对齐Alignment要解决的问题特别是与人类偏好的对齐这就要用到基于人类反馈的强化学习Reinforcement from Human FeedbackRLHF对吧是的RLHF是实现对齐的关键技术之一它通常包含几个步众首先需要收集人类的偏好数据比如对于同一个指令让模型生成几个不同的回答然后让人类标注哪个回答更好哪个更差用人的反馈来告诉模型什么是好的回答对然后用这些偏好数据去训练一个奖利模型Reword Model这个奖利模型能够给模型的任意一个输出打分分数越高表示越符合人类偏好相当于训练了一个人类品位的打分器可以这么理解最后把这个奖利模型作为信号使用强化学习算法比如PPO进端策略优化或者DPO直接偏好优化来进一步为挑LLM目标是让LLM生成的回答能在奖利模型那里获得更高的分数通过强化学习让LLM学会逃好这个奖利模型从而生成更符合人类偏好的内容它试图直接从偏好数据中学习策略可能更稳定一些整个RLQF流程比较复杂但对于提升LLM的可用性和安全性至关重要明白了从Transformer架构到预讯练再到指令微调和RLHF对齐这一系列技术共同造就了今天强大的LLM是的但正如我们之前讨论调试工具时提到的这些模型太大了训练和推理的成本都非常高所以高效训练和推理的技术也非常关键我们刚才提到了Lora用于高效微调资料理还提到了模一对模AE全程是混合专家Mixed of Experts这是一种只在扩大模型规模的同时控制计算成本的Architecture混合专家听起来像是有很多小模型在一起工作可以这么理解在一个模AE层中会有多个专家网络同时是前会网络FFN同时还有一个门控网络Gate Network当输入数据比如一个Token的表示来到这一层时门控网络就会决定把这个输入路由给哪个混内几个专家去处理也就是不是所有的专家都要处理所有的输入对于每个输入可能只有少数几个比如一两个专家被激活并进行计算其他的专家则保持沉默这样的话模型的总参数量可以非常大因为有很多专家但实际处理每个输入时的计算量却可以相对较小因为只用了部分专家正是这个原理模AE允许模型容量和计算量在一定程度上结偶这使得我们可以训练出参数量达到万一级别的超大模型而推理时的计算成本却可以控制在可接受范围内像MixedTrow等模型就成功应用了模AEArchitecture当然模AE也有它自己的挑战比如复载均衡通性开销等这个思路确实很巧妙除了模AE和Lora我们之前也提到了量化Countization它主要是在哪个阶段起作用量化主要是在推理Inference阶段也就是模型部署和使用时发挥作用当然也有一些量化感知训练的技术可以在训练阶段就考虑量化主要目标还是压缩模型加速推理对通过把32Bit扶点数FP32的权重和机火值转换成16Bit扶点数F-16BF-168Bit等数NT8甚至更低的位数比如4Bit可以大幅减少模型的内存占用和计算需求这对于在手机编辑设备或者即使在似乎器上降低服务成本都很有用非常有用当然量化位数越低潜在的精度损失风险就越大所以需要在效率和精度之间做一个全衡现在有很多成熟的量化工具和算法可以在保证精度损失可控的情况下实现显住的加速和压缩了解了Lora, Moor,量化这些都是应对大模型挑战的使用技术那么我们怎么把LOM的强大能力扩展到多模太领域呢比如让它理解图像这是目前研究的热点方向通常称为多模太大模型Large Multi Model Models LMMs或视觉与严模型Vision Language ModelsVLMMs由几种主要的方法嗯一种常见的方法是保持预讯练好的LOM不动或者只做少量调整然后训练一个适配器adapter模块适配器对这个适配器负责把来自其他模太比如图像的信息转换成LOM能够理解的格式通常是类似文本token embedding的项量比如先用一个图像边马器像clip的图像边马器或者其他新原VIT提取图像特征然后通过一个小的网络适配器把这些图像特征转换成一系列特充的视觉偷肯是的思路就是这样然后把这些视觉偷肯和用户的文本输入比如一个问题拼接在一起为给LOM这样LOM在处理序列时就能同时看到文本信息和被转换过来的视觉信息了吗没错通过这种方式就可以让LOM理解图像内容并完成向图文问答v秀question answering或图像描述声程等任务想拉法melegb-t4等模型就采用了类似的方法这种方法的有点是能比较好的负用现有强大的LOM听起来是一种比较经济的方式还有其他方法吗也就是说从一开始就设计一个能够同时处理多种模太输入的统一架构并在包含多种模太数据的数据极上进行大规模的预讯练这种方法是不是更彻底但成本也更高对理论上可能获得更好的模太融合效果但设计这样的架构和收集处理大规模多模太预讯练数据都是巨大的挑战向Google的揭秘乃据说就采用了更偏向原生多模太设计的思路不同的技术路线各有优劣多模太大模型无疑是未来了一个重要发展方向绝对是它让我们离真正能像人意样理解和交互的AI更进了一步最后我们来简单聊聊另一个前言领域生成是AI特别是资料理提到的扩散模型和流匹配好的生成是AI的目标是创造新的数据比如图像文本奥丢等近年来扩散模型的Fusion models成为了生成高质量数据的明星技术尤其是在图像生成领域像Stable Defusion,Megerni等背后都有它的声音扩散模型听名字好像和物理过程有关有一点关系它的核心思想其实挺巧妙的分为两个过程前向过程FowerProcess和反向过程ReverseProcess前向过程很简单我们拿到一张真实的图片然后一步一步地逐渐的往图片里添加造生通常是高丝造生直到最后图片完全变成了一个纯粹的造生样本这个加造生的过程是预先定义好的可以精确控制把清晰的图片变成随机造生这有什么用呢关键在于反向过程反向过程的目标是从一个纯粹的造生样本开始学习如何一步一步地逐渐地把造生去处掉最终恢复或者说生成一张清晰的看起来军事的图片学习一个去造的过程对模型通常是一个Unit结构的新鲜网络的任务就是在每一步预测应该从当前的造生图片中去处掉哪些造生才能让它更接近上一步稍微清晰一点的图片通过在大量真实图片上训练这个去造网络它就能学会数据底层的分布规律等训练好之后我们就可以从一个随机造生开始不断应用这个去造网络最终生成一张全新的图片正式如此扩散模型通过这种逐步去造的方式能够生成细节非常丰富质量非常高的样本听起来很强的那刘匹佩呢它和扩散模型什么有不同刘匹佩是另一种先进的生成模型饭式可以看作释对扩散模型的一种拖展或改进它不一定需要像扩散模型那样模拟一个加造去造的过程而是更直接的学习一个项量厂vector field这个项量厂定义了如何把一个简单的鲜艳分布比如高丝噪音中的点连续的变形或者流动到猫标数据分布比如真实图像中的点学习一种从造生到真实数据的路径可以这么理解它通过一种称为刘匹佩的目标寒树来训练模型使得模型能学习到这个正确的流动路径相比获在模型刘匹佩可能在训练上更稳定更高效或者更容易处理某些类型的数据这是一个相对较新的方向但非常有潜力扩设模型和刘匹佩听起来都是从造生生成数据的强大技术那我们怎么控制生成的内容呢比如我想生成一直猫在太空苍利的图片这就需要条件生成了刚才说的是无条件生成就是随机生成样本条件生成允许我们根据特定的输入条件来控制生成过程这个条件可以是文本描述对文本描述是最常见的条件之一也就是text to image生成也可以是其他图像比如图像修复风格签移或者是类别标签甚至是草图在扩设墨星或刘匹佩里怎么加入这个条件呢有很多方法比如可以把条件的表示比如文本的embeiding也输入到那个去造网络UNIT让网络在预测Noise时同时考虑条件信息或者通过一种叫做classifier free guidance的技术在生成过程中引到模型向符合条件的方向靠拢嗯让生成过程听指挥对条件生成极大的扩大了生成模型的应用范围资料里还提到了UNIT和transformer作为常见的生成模型架构是的UNIT因为其具有对称的编码器结码器结构并且带有跳跃连接Skip connections能够很好地结合低层细节特征和高层屎于一特征所以在图像生成任务特别是扩散模型中非常常用而transformer凭借其强大的训练接模能力和对长距离一代的捕捉不仅在LLM中大放一彩在生成领域也越来越重要比如可以把图像看作一系列的patch小块的训练用transformer来接摩他们之间的关系进行生成如VIT或者在多摩太生成中用transformer来融合不同模太的信息看来transformer确实现在AI的一个核心引擎可以说是无处不在了好了我们今天从AI调试的细缝方法聊到了多摩太AI的核心挑战与关键技术像clip再到LLM的发展训练对齐和效率优化最后接触了像扩散模型流匹配这样的前延生成技术那种确实非常丰富信息量是挺大的如果要快速回顾一下我们似乎可以体练出几个关键点我觉得有几个核心思路是贯穿始终的第一深入理解数据是基础无弄试调试还是建模一切都要从数据处罚对那个与数据融为一体第二采用系统性的方法特别是在调试这种无声失败普遍存在的情况下结构坏的流程比如我们讨论的那个秘籍远比随机场式要有效兵免忙着摸像第三理解核心挑战和关键技术比如在多摩太领域理解表示对齐等挑战直到像Clip这样的技术是如何工作的在LLM领域了解预讯练为条而LHS的原例以及LOWER,MOE等效率工具保护入关键概念和风法第四持续关注快速发展的架构和工具Tunformer,Unit这些架构以及像PyTorchHuggingFace,FlashAttention这些工具他们极大的推动了领域的发展善用工具能使办工贝总结的很好理解数据系统方法关键技术关注架构与工具这似乎是架域当前AI发展浪潮的关键我觉得是这样当然AI发展非常快持续学习也非常重要那么在这次深入探讨的最后你有没有什么问题或者思考方向可以留给我们的听众让他们在未来接触或应用AI时可以进一步思考的嗯我想可以从几个角度来思考首先当你未来面对一个AI项目或者一个问题时可以先问问自己我处理的数据是单一模太的还是多模太的如果是多模太那么根据我们今天讨论的你觉得最主要的挑战会是表示学习还是跨模太对齐或者是更复杂的推理时别出核心挑战有助于你选择核适的技术路线嗯先简段问题类型和核心难点其次可以思考一下对于我手头的具体任务是利用现有的强大的预讯年大模型比如LMM或VLM然后通过微调可能用Lora等高小方法来适配更有效还是我的任务比较特殊可能需要设计一个更专用化的更小的模型这设计到成本效率和性能的全好大模型Versus专用模型这是一个常见的选择体对最后也许可以更宏观的想一想我希望AI在这个任务中扮演什么角色是作为一个强大的特征体曲气还是一个决策者一或者是一个内容生成气这决定了你可能需要关注的技术重点是表示学习判别模型还是生成模型思考AI的定位和目标对带着这些问题数据模太与挑战模型选择策略AI决策定位去审视你遇到的AI应用场景可能会帮助你更深入的力节问题并更有针对性的去寻找解决方案更好的价于AI这个强大的工具非常好的思考方向从整段问题到选择策略再到明确目标这确实能帮助大家在实践中更好的应用AI好了希望我们今天这次成篇府的深入探头能让你对AI调试多模太大型模型和生成是AI这些可能有些复杂的概念有了更清晰更结构化的把握希望能有所帮助非常感谢你的参与和分享不客气
