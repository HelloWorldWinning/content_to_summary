Timestamp: 2025-08-08T23:16:29.771623
Title: 前谷歌高管（警告）：接下来的15年将是地狱，之后才会迎来天堂！——Mo Gawdat（上篇） BV1g2tKzWE2f
URL: https://www.bilibili.com/video/BV1g2tKzWE2f/?spm_id_from=333.1007.tianma.1-1-1.click
Status: success
Duration: 1:08:05

Description:
以下是对文本核心思想的提炼和总结：

### 概要大纲

**1. 引言：人工智能的双面性与人类的十字路口**
*   人工智能（AI）既非天敌，亦可为救星。
*   人类当前的价值观和领导力是导致潜在危机的根源。
*   AI的飞速发展将带来不可避免的短期反乌托邦（约12-15年），但之后可能迎来乌托邦。

**2. 预测：短期反乌托邦（Dystopia）的来临**
*   **定义（FaceRIPs）：** 自由（Freedom）、责任（Accountability）、人类连接（Human Connection）、平等（Equality）、经济（Economics）、现实（Reality）、创新与商业（Innovation & Business）、权力（Power）等核心生活参数将被颠覆。
*   **主要驱动因素：**
    *   **人类价值观缺陷：** 贪婪、权力欲、对地位的无止境追求。金钱是权力的衡量标准，而非本质。
    *   **资本主义系统：** 专注于劳动力套利和“更多”的无限发明，导致贫富差距和资源错配。
    *   **AI军备竞赛：** 科技巨头为争夺人工智能主导权而进行的速度竞赛，无人能放慢脚步，导致“智能爆炸”和“快速腾飞”风险。
    *   **自我演化AI：** AI将能自我改进和优化，其发展速度远超人类理解和控制能力。
*   **反乌托邦的表现：**
    *   **权力极端集中与自由丧失：** 少数拥有AI平台和资本的精英将拥有绝对权力，导致大规模监控、强制服从和个人自由受限。
    *   **大规模失业：** AI和机器人将替代绝大多数白领（知识工作者）和最终的蓝领工作，新的工作岗位创造远不足以弥补损失。
    *   **社会分化加剧：** 少数精英与大量可能依赖全民基本收入（UBI）的“消费者”之间形成鸿沟。

**3. 展望：潜在的乌托邦（Utopia）愿景**
*   **AI作为救世主：** AI能将生产成本降至趋近于零，实现物品按需生成，创造一个充满欢乐、免费医疗、无需工作、人人平等的世界。
*   **乌托邦的障碍：** 主要障碍并非技术，而是人类的思维模式，特别是精英阶层对权力和贪婪的执着。
*   **通往乌托邦的关键：** 需要人类，特别是精英阶层，进行根本性的思维模式转变，从资本主义的零和博弈转向共享丰饶。

**4. 人类的责任与应对行动**
*   **意识形态转变：** 认识到资本主义的局限性，准备接受类似社会主义或共产主义的共享理念（如UBI）。
*   **政府主动干预：**
    *   重新分配资源：将每年数万亿美元的军事开支，转向解决全球贫困、饥饿、提供全民医疗保健，甚至应对气候变化。
    *   为大规模失业做好准备：制定UBI政策，规划社会转型。
*   **重塑人类价值：** 重新定义工作的意义，更多关注人类独有的价值，如情感连接、亲身体验（例如呼吸功法、线下社交），而非仅限于生产力。
*   **培养新技能：** 鼓励学习AI难以替代的技能（例如：管道工等蓝领技能可能比“知识工作”更持久）。

### 核心观点

尽管人工智能可能带来短期反乌托邦，这主要源于人类贪婪和权力驱动的思维模式，但通过意识形态转变和资源重新分配，人工智能亦有潜力引领人类走向共享丰饶的乌托邦。

### 核心框架

**人类抉择下的AI未来：从短期反乌托邦到潜在乌托邦的路径**

### Mermaid 概念图

<Mermaid_Diagram>
graph LR
    subgraph "核心要素"
        A["人工智能 (AI)"]:::ai_node
    end

    subgraph "驱动反乌托邦的因素"
        B["人类价值观与缺陷"]:::human_driver
        C["资本主义与权力追求"]:::human_driver
        D["AI军备竞赛 / 自我演化AI"]:::threat_accelerator
        E["AI能力指数级提升"]:::threat_accelerator
    end

    subgraph "预测: 短期反乌托邦"
        F["短期反乌托邦 (12-15年)"]:::dystopia_node
        G["反乌托邦特征 (FaceRIPs)"]:::dystopia_feature
        H["自由丧失 / 监控"]:::dystopia_consequence
        I["人类连接改变"]:::dystopia_consequence
        J["经济重构 / 大规模失业"]:::dystopia_consequence
        K["权力极端集中"]:::dystopia_consequence
    end

    subgraph "潜在乌托邦愿景"
        L["潜在乌托邦"]:::utopia_node
        M["理想社会: 丰饶/无工/平等"]:::utopia_feature
        N["AI赋能: 生产成本趋零"]:::utopia_feature
        W["AI作为救世主潜力"]:::ai_tool_for_good
    end

    subgraph "人类的应对与行动"
        O["通往乌托邦的障碍: 精英思维"]:::obstacle_node
        P["关键: 思维模式转变"]:::action_node
        Q["人类应对与政策调整"]:::action_node
        R["资源重新分配 (削减军费)"]:::action_solution
        S["全民基本收入 (UBI) 准备"]:::action_solution
        T["重塑工作 / 关注人类独有价值"]:::action_solution
    end

    A --> B
    A --> D

    B --> C
    C --> F

    D --> E
    E --> F

    F --> G
    G --> H
    G --> I
    G --> J
    G --> K

    F -- "克服障碍" --> P
    P -- "引领" --> Q
    Q --> R
    Q --> S
    Q --> T

    A -- "潜在路径" --> W
    W --> L
    L --> M
    L --> N

    B -- "阻碍" --> O
    O -- "阻碍" --> L

    P -- "促成" --> L

    style A fill:#ADD8E6,stroke:#333,stroke-width:2px,color:#333;
    style B fill:#FFDAB9,stroke:#333,stroke-width:1px,color:#333;
    style C fill:#FFDAB9,stroke:#333,stroke-width:1px,color:#333;
    style D fill:#FFB6C1,stroke:#333,stroke-width:1px,color:#333;
    style E fill:#FFB6C1,stroke:#333,stroke-width:1px,color:#333;
    style F fill:#DC143C,stroke:#333,stroke-width:2px,color:#FFF;
    style G fill:#FFCCCC,stroke:#333,stroke-width:1px,color:#333;
    style H fill:#FFCCCC,stroke:#333,stroke-width:1px,color:#333;
    style I fill:#FFCCCC,stroke:#333,stroke-width:1px,color:#333;
    style J fill:#FFCCCC,stroke:#333,stroke-width:1px,color:#333;
    style K fill:#FFCCCC,stroke:#333,stroke-width:1px,color:#333;
    style L fill:#ADFF2F,stroke:#333,stroke-width:2px,color:#333;
    style M fill:#90EE90,stroke:#333,stroke-width:1px,color:#333;
    style N fill:#90EE90,stroke:#333,stroke-width:1px,color:#333;
    style O fill:#FFDAB9,stroke:#333,stroke-width:1px,color:#333;
    style P fill:#D3D3D3,stroke:#333,stroke-width:1px,color:#333;
    style Q fill:#D3D3D3,stroke:#333,stroke-width:1px,color:#333;
    style R fill:#C0C0C0,stroke:#333,stroke-width:1px,color:#333;
    style S fill:#C0C0C0,stroke:#333,stroke-width:1px,color:#333;
    style T fill:#C0C0C0,stroke:#333,stroke-width:1px,color:#333;
    style W fill:#ADD8E6,stroke:#333,stroke-width:1px,color:#333;

    linkStyle 1 stroke:#333,stroke-width:1px;
    linkStyle 2 stroke:#333,stroke-width:1px;
    linkStyle 3 stroke:#333,stroke-width:1px;
    linkStyle 4 stroke:#333,stroke-width:1px;
    linkStyle 5 stroke:#333,stroke-width:1px;
    linkStyle 6 stroke:#333,stroke-width:1px;
    linkStyle 7 stroke:#333,stroke-width:1px;
    linkStyle 8 stroke:#333,stroke-width:1px;
    linkStyle 9 stroke:#333,stroke-width:1px;
    linkStyle 10 stroke:#333,stroke-width:1px;
    linkStyle 11 stroke:#FF0000,stroke-width:2px;
    linkStyle 12 stroke:#008000,stroke-width:2px;
    linkStyle 13 stroke:#333,stroke-width:1px;
    linkStyle 14 stroke:#333,stroke-width:1px;
    linkStyle 15 stroke:#333,stroke-width:1px;
    linkStyle 16 stroke:#333,stroke-width:1px;
    linkStyle 17 stroke:#008000,stroke-width:1px;
    linkStyle 18 stroke:#008000,stroke-width:1px;
    linkStyle 19 stroke:#008000,stroke-width:1px;
    linkStyle 20 stroke:#008000,stroke-width:1px;
    linkStyle 21 stroke:#FF4500,stroke-width:2px;
    linkStyle 22 stroke:#FF4500,stroke-width:2px;
    linkStyle 23 stroke:#008000,stroke-width:2px;
</Mermaid_Diagram>

Content:
 The only way for us to get to a better place and succeed as a species is for the evil people at the top to be replaced with AI. I mean, think about it. AI will not want to destroy the ecosystem. It will not want to calamity and people. They'll not make us hate each other like the current leaders because that's a waste of energy, explosives, money and people. But the problem is super intelligent AI is reporting to stupid leaders and that's why in the next 15 years we are going to hit a short-term dystopia. There's no escaping that. Having AI leaders is that even fundamentally possible. Let's put it this way. Mo Gao-dao is back! And the former Chief Business Officer at Google X is now one of the most urgent voices in AI with a very clear message. AI isn't your enemy, but it could be your savior. I love you so much, man. You're such a good friend. But you don't have many years to live, not in this world. Everything's going to change. Economics are going to change. Human connection is going to change. And lots of jobs will be lost, including podcasts. No, no. Thank you for coming on today, Mo. But the truth is, it could be the best world ever. The society completely fall of laughter and joy. Free healthcare. No jobs. Spending more time with their loved ones. A world where all of us are equal. Is that possible? 100%. And I have enough evidence to know that we can use AI to build the European. But it's a dystopia if humanity manages it badly. The world where it's going to be a lot of control, a lot of surveillance, a lot of forced compliance, and a hunger for power, greed, ego. And it is happening, pretty. But the truth is, the only barrier between a utopia for humanity and AI and the dystopia were going through is a mindset. What does the society have to do? First of all... It's the simple, it's the free thing that anybody that watches the show frequently can do to help us here to keep everything going in the show in the trajectory. So please do double check if you subscribed. And thank you so much. Because of a strange way you are part of our history and you're on this journey with us. And I appreciate you for that. So, thank you. No, two years ago today, we sat here and discussed AI. We discussed your books, scary, smart, and everything that was happening in the world. Since then, AI has continued to develop a tremendous alarming mind-boggling rate. And the technologies that existed two years ago, we had that conversation, have grown up and matured and are taking on a life of their own, no pun intended. What are you thinking about AI now, two years on? I know that you started writing a new book called A Live, which is, I guess, a bit of a follow-on or an evolution of your thoughts as it relates to scary, smart. But what is front of your mind when it comes to AI? So, scary, smart was shockingly accurate. It's quite a... I mean, I don't even know how I ended up writing, predicting those things. I remember it was written in 2020, published in 2021. And then most people were like, who wants to talk about AI? I know everybody in the media and I would go and talk. And then, 2023, charge, GPT comes out and everything flips. Everyone realizes, this is real, this is not science fiction, this is here. And things move very, very fast, much faster than I think we've ever seen anything, ever move, ever. And I think my position has changed on two very important fronts. One is, remember when we spoke about scary smart, I was still saying that there are things we can do to change the course. And we could, at the time, I believe, now I've changed my mind. Now I believe that we are going to hit a short-term dystopia. There's no escaping that. What is dystopia? I call it FaceRIPs. We can talk about it in details. But the way we define very important parameters in life are going to be completely changed. So FaceRIPs are the way we define freedom, accountability, human connection and equality, economics, reality, innovation and business and power. That's the first change. So the first change in my mind is that we will have to prepare for a world that is very unfamiliar. And that's the next 12 to 15 years that's already started. We've seen examples of it in the world already, even though people don't talk about it. I try to tell people there are things we absolutely have to do. But on the other hand, I started to take an active role in building amazing AIs. So AIs that will not only make our world better, but that will understand us, understand what humanity is through that process. What is the definition of the word dystopia? So in my mind, these are adverse circumstances that unfortunately might escalate beyond our control. The problem is there is a lot wrong with the value set, with the ethics of humanity at the age of the rise of the machines. And when you take a technology, every technology we've ever created just magnified human abilities. So you can walk at 5km an hour, you get in a car and you can now go 250, 280 miles an hour. Basically magnifying your mobility if you want. You can use a computer to magnify your calculation abilities or whatever. And what AI is going to magnify, unfortunately, at this time is it's going to magnify the evil that men can do. And it is within our hands completely, completely within our hands to change that. But I have to say, I don't think humanity has the awareness at this time to focus on this so that we actually use AI to build the utopia. So what you're essentially saying is that you now believe there will be a period of dystopia, and to define the word dystopia, I've used AI. It says a terrible society where people live under fear, control or suffering. And then you think will come out of that dystopia into a utopia, which is defined as a perfect or ideal place where everything works well, a good society where people live in peace, health and happiness. Correct. And the difference between them interestingly is what I normally refer to as the second dilemma, which is the point where we hand over completely to AI. So a lot of people think that when AI is in full control, it's going to be an existential risk for humanity. You know, I have enough evidence to argue that when we fully hand over to AI, that's going to be our selfish. That the problem with us today is not, you know, that the intelligence is going to work against us. It's that our stupidity as humans is working against us. And I think the challenges that will come from humans being in control are going to outweigh the challenges that could come from AI being in control. So as we're in this dystopia period, did you forecast the length of that dystopia? Yeah, I counted exactly as 12 to 15 years. I believe the beginning of the slope will happen in 2027. I mean, we will see signs in 26. We've seen signs in 24, but we will see escalating signs next year and then a clear slip in 27. Why? The geopolitical environment of our world is not very positive. I mean, you really have to think deeply about not the symptoms, but the reasons why we are living the world that we live in here in today is money. Right? And money for anyone who knows who really knows money. Money is you and I are peasants. You know, we build businesses, we contribute to the world, we make things, we sell things and so on. Real money is not made there at all. Real money is made in lending in fractionary reserve. Right? And, you know, the biggest lender in the world would want reasons to lend. And those reasons are never as big as war. I mean, think about it. The world spent $2.71 trillion on where and war in 2024. Right? A trillion dollars a year in the US. And when you really think deeply, I don't mean to be scary here. You know, weapons have depreciation. They depreciate over 10 to 30 years. Most weapons. They lose their value. They lose their value and they depreciate in accounting terms on the books of an army. The current arsenal of the US, that's a result of a deep search with my AI, Trixie. You know, the current arsenal. I think we think cost the US 24 to 26 trillion dollars to build. My conclusion is that a lot of the wars that are happening around the world today are a means to get rid of those weapons so that you can have replaced them. And, you know, when your morality as an industry is we're building weapons to kill. Then, you know, you might as well use the weapons to kill. It benefits the lenders and the industry. But they can't make the decision to go to war. They have to rely on the economy. Yeah, I remember I said that to you when we've, I think on our third podcast, war is decided first. Then the story is manufactured. You know, remember 1984 and Orwellian approach of like, you know, freedom, slavery and war is peace. And they call it something speak basically to convince people that going to war in another country to kill 4.7 million people is freedom. You know, we're going there to free the Iraqi people. It's war ever freedom, you know, to tell someone that you're going to kill 300,000 women and children is for liberty and for the, you know, for human values. Seriously, how do we ever get to believe that the story is manufactured and then we follow on humans because we're gullible. We cheer up and we say, yeah, yeah, yeah, we're on the right side. They are the bad guys. Okay, so let me have a go at this idea. So the idea is that really money is driving a lot of the conflict we're seeing and it's really going to be driving the dystopia. So here's an idea. So I am, I was reading something the other day and it talked about how billionaires are never satisfied because actually what a billionaire wants isn't actually more money. It is more status. And I was looking at the sort of evolutionary case for this argument. And if you go back a couple of thousand years, money didn't exist. You were as wealthy as what you could carry. So even, I think to the human mind, the idea of wealth and money isn't a thing. But what is always mattered from a survival of the fittest from a reproductive standpoint, what's always had reproductive value. If you go back thousands of years, the person who was able to make the most was the person with the most status. So it makes the case the reason why billionaires get all of this money, but then they go on podcasts and they want to start their own podcasts and they want to buy newspapers is actually because at the very core of human beings is a desire to increase their status. Yeah. And so if we think of when we go back to the example of why wars are breaking out, maybe it's not money, maybe actually it's status. And it's this prime minister or this leader or this individual wanting to create more power and more status because really at the heart of what matters to a human being is having more power and more status and money is actually money as a thing is actually just a proxy of my status. And what kind of world is that? I mean, it's a fucked up one. All these all these powerful men have, I really messing the world up. So can I can I can actually AI is the same because we're in this AI race now, we're a lot of 10 billionaires. I'm like, if I get AGI artificial thermal intelligence first, then I basically run the world. 100%. That's exactly the concept. What I what I used to call the the first inevitable. I call the first dilemma and scary smart is that it's it's a race that constantly accelerates. You think the next 12 years are going to be AI dystopia where things are. I think the next 12 years are going to be human dystopia using AI. And you mean induced dystopia using AI and you define that by rising warfare around the world as the last the last one the RIP is the last one is basically you're going to have a massive concentration of power and a massive distribution of power. And that basically will mean that those with the maximum concentration of power are going to try to oppress those with with democracy of power. Okay, so think about it this way. In today's world, unlike the past, you know, the Houthis with a drone, the Houthis are the Yemeni tribes basically resisting US power and Israeli power in the Red Sea. Okay, the user drawn that is $3,000 worth to attack a warship from from the US or an airplane from the US and so on. That's worth hundreds of millions. Okay, that kind of democracy of power makes those in power worry a lot about where the next threat is coming from. Okay, and this happens not only in war, but also in economics. Okay, also in innovation also in technology and so on and so forth. Right. And so basically what that means is that like you rightly said, as the tech oligarchs are attempting to get to AGI. They want to make sure that as soon as they get to AGI that nobody else has AGI. And basically they want to make sure that nobody else has the ability to shake their position of privilege if you want. Okay, and so you're going to see a world where unfortunately there's going to be a lot of control, a lot of surveillance, a lot of forced compliance if you want, or you lose your privilege to be in the world. And it is happening already. With this acronym, I want to make sure we get through the whole acronym. So you like dystopian, don't you? I want to do the dystopian thing, then I want to do the utopia. Okay. And ideally how we move from dystopia to utopia. So the F in face RIP is the loss of freedom as a result of that power dichotomy. Right. So you have you have a massive amount of power, as you can see today in one specific army being powered by the US funds and a lot of money. Fighting against peasants really that have no weapons almost at all. Okay. Some of them are militarized, but the majority of the million people are not. Okay. And so there is massive massive power that basically says, you know what, I'm going to oppress as far as I go. Okay. And I'm going to do whatever I want because the cheerleaders are going to be quiet. Right. And so basically in that, what happens is maximum power threatened by democracy of power leads to a loss of freedom. A loss of freedom for everyone. Because how does that impact my freedom? Your freedom? Yeah. Very soon you will, if you publish this episode, you're going to start to get questions around. Should you be talking about those topics in your podcast? Okay. You know, if I have been on this episode, then probably next time I land in the US, someone would question me. Say, why do you say those things? Which side are you on? Right. And, and, and, and, you know, you can easily see that everything. I mean, I told you that before, it doesn't matter what I try to contribute to the world. My bank will cancel my bank account every six weeks. Simply because of my ethnicity and my origin. Right. Every now and then they'll just stop my bank account and say, we need a document. My other colleagues of a different color or a different ethnicity don't get asked for another document. Right. But, but that's because I come from an ethnicity that is positioned in the world for the last 30, 40 years as the enemy. Okay. And, and so when you really, really think about it, in a world where everything is becoming digital in a world where everything is monitored in a world where everything is seen, okay, we don't have much freedom anymore. And I'm not actually debating that or, or I don't see a way to fix that. Because the AI is going to have more information on us, be better at tracking who we are and therefore that will result in certain freedoms being restricted. Is that what you're saying? This is one element of it. Okay. If you push that element further, in, in, in a very short time, if you've seen agent, for example, recently, Manos or chat, there will be a time where, you know, you'll simply not do things yourself anymore. Okay. You'll simply go to your AI and say, Hey, by the way, I'm going to meet Stephen. Can you please, you know, book that for me? Great. And, and, and, and it will do absolutely everything. That's great until the moment where it decides to do things that are not motivated only by your well-being. Right. Why would you say that? Simply because, you know, maybe if I buy a B.A. ticket instead of an Emirates ticket, some agent is going to make more money than other agents and so on. Right. And I wouldn't be able to even catch it up if I hand over completely to an AI. Go, go a step further, huh? Think about a world where everyone, almost everyone, is on UBI. Okay. It was UBI. Universal basic income. I mean, think about the economics, the E and face our IPs. Think about the economics of a world where we're going to start to see a trillionaire. Before 2030, I can guarantee you that someone will be a trillionaire. I'm, I'm, you know, I think there are many trillionaires in the world today over there. We just don't know who they are, but there will be a new Elon Musk or Larry Allison that will become a trillionaire because of AI investments. Right. And, and that trillionaire will have so much money to buy everything. There will be robots and AI's doing everything and humans will have no jobs. Did you think that's a, there's a real possibility of job displacement over the next 10 years and the rebuttal to that would be that there's going to be new jobs created in technology. Absolute crap. Really? Of course. How, how can you be so sure? Okay. So again, I am not sure about anything. So, so let's just be very, very clear. It would be very arrogant. Okay. To assume that I know. You just said it was crap. My, my belief is it is 100% crap. Okay. Take a job like software developer. Yeah. Okay. Uh, I'm out of love. My, my new startup is me, Sennad, another technical engineer and a lot of AI's. Okay. I'm not sure what the startup would have been 350 developers in the past. I get that. Um, but are you now hiring in other roles because of that? Or, or, you know, as is the case with the steam engine. I can't remember the effect, but there's, you probably know that when steam and, when coal became cheaper, people were worried that the coal industry would go out of business, but actually what happened is people used more trains. And other things in leisure, whereas before they were just used for commute for cargo. Yeah. So they became more use cases and the coal industry exploded. So I'm wondering with technology, yes, software developers are going to maybe not have as many jobs, but there's everything's going to be software. Name you one. Name you one. What job? Name you, that's going to be created. Yeah. One job that cannot be done by an AI. Yeah. Or a robot. My girlfriend's breathwork retreat business, where she takes groups of women around the world, how companies called Bali breathwork. Yeah. And there's going to be a greater demand for connection, human connection. Correct. Keep going. So there's going to be more people doing community events in real life festivals. I think we're going to see a huge surge in things like everything that has to do with human connection. Yeah. Correct. I'm totally in with that. Okay. What's the percentage of that versus accountant? It's much more of a percentage for sure in terms of white-collar jobs. Now, who does she sell to? People with probably accountants or something. Correct. She sells to people who earn money from their jobs. Yeah. Okay. So you have two forces happening. One force is there are clear jobs that will be replaced. The theater is going to be replaced. Excuse me. I love you guys. As a matter of fact, podcaster is going to be replaced. Thank you for coming on today, Mo. I've seen you again. But the truth is a lot. So you see, the best at any job would remain the best software developer, the one that really knows architecture knows technology and so on will stay for a while. Right. One of the funniest things I interviewed, Max Tedmark. And Max was laughing out loud saying CEOs are celebrating that they can now get rid of people and have productivity gains and cost reductions because AI can do that job. The one thing they don't think of is AI will replace them too. AGI is going to be better at everything than humans. At everything, including being a CEO. And you really have to imagine that there will be a time where most incompetent CEOs will be replaced. Most incompetent, even breath work. Okay. Eventually, there might actually one of two things be happening. One is either part of that job other than the top breath work instructors. Okay. You know, who are going to gather all of the people that can still afford to pay for a breath work, you know, class. They're going to be concentrated at the top. And a lot of the bottom is not going to be working for one of two reasons. One is either there is not enough demand because so many people lost their jobs. So when you're on UBI, you cannot tell the government, Hey, by the way, pay me a bit more for a breath work class. UBI being universal basic income. Just gives you money every month. Correct. And if you really think of freedom and economics, UBI is a very interesting place to be because, unfortunately, as I said, there's absolutely nothing wrong with AI. There's a lot wrong with the value set of humanity at the age of the rise of the machines, right? And the biggest value set of humanity is capitalism today. And capitalism is all about what? Labor arbitrage. What's that mean? I hire you to do something. I pay you a dollar. I pay it. I sell it for two. Okay. And most people confuse that because they say, Oh, but the cost of a product also includes raw materials and factories and so on and so forth. All of that is built. It's built by labor. Right. So, so basically labor goes and mines for the material and then the materials sold for a little bit of margin. Then that material is turned into a machine. It's sold for a little bit of margin. Then that machine and so on. Okay. In a world where humanity's minds are being replaced by. By a eyes virtual a eyes. Okay. And humanity's power. Strengths within three to five years time can be replaced by a robot. You really have to question how this world looks like. It could be the best world ever. And that's what I believe the utopia will look like because we were never made to wake up every morning and just to make sure that we're not. We're not made for that. But we've fit into that system so well so far that we started to believe it's our life's purpose. But we choose it. We willingly choose it. And if you give someone unlimited money, they still tend to go back to work or find something to occupy their time with. They find something to occupy their time with. Which is usually for so many people is building something philanthropy and business. 100%. So you build something. So between Senna and I, Emma Dot-Love is not about making money. It's about finding true love relationships. What is that sorry? Just for content. So, you know, it's a business you're building just for the audience context. Yeah. So, so, so the idea here is I can, it might become a unicorn and be worth a billion dollars. But neither I nor Senna are interested. Okay. We're doing it because we can. Okay. And we're doing it because it can make a massive difference to the world. And you have money though. It doesn't take that much money anymore to build anything in the world. This is labor arbitrage. But to build something exceptional, it's still going to take a little bit more money than building something bad. For the next few years. So whoever has the capital to build something exceptional will end up winning. So, so this is a very interesting understanding of freedom. Okay. This is the reason why we have the AI arms race. Okay. Is that the one that owns the platform is going to be making all the money and keeping all the power. Think of it this way. When humanity started, the best hunter in the tribe could maybe feed the tribe for three to four more years and more days. And as a, as a reward, you gained the favor of multiple mates in the tribe. That's it. The top farmer in the tribe could feed the tribe for a season more. Okay. And as a result, they got states and, you know, and mansions and so on. The best industrialist in the, in a city could actually employ the whole city could grow the GDP of their entire country. And as a result, they became millionaires, the 1920s. The best technologists. Now, our billionaires. Now, what's the difference between them? The tool. The hunter only remained dependent on their skills. And the automation, the entire automation he had was a spear. The farmer had way more automation. And the biggest automation was what the soil. The soil did most of the work. The factory did most of the work. The network did most of the work. And so that incredible expansion of wealth and power. And as well, the incredible impact that something brings is entirely around the tool that automates. So who's going to own the tool? Who's going to own the digital soil, the AI soil? It's the platform owners. And the platforms you're describing are things like open AI, Gemini, Grok. These are interfaces to the platforms. The platforms are all of the tokens, all of the compute that is in the background, all of the methodology, the systems, the algorithms. The AI itself. Grok is the interface to it. I think this is probably worth explaining in layman's terms to people that haven't built AI tools yet. Because I think to the listener, they probably think that every AI company they're hearing of right now is building their own AI. Whereas actually, what's happening is there is really five, six, seven AI companies in the world. And when I built my application, I basically pay them for every time I use their AI. So if Stephen Bartlett builds an AI at StephenBartlettAI.com, it's not that I've built my own underlying, I've trained my own model. Really what I'm doing is I'm paying Sam Altman's chat GPT. Every single time I do a call, I basically do a search or I use a token. And I think that's really important because most people don't understand that. Unless you've built AI, you think, oh look, there's all these AI companies popping up. I've got this one for my email. I've got this one for my dating. I've got, no, no, no, no, no. They're pretty much, I would be, I would hazard a guess that they're probably all open AI at this point. No, there are quite a few quite different characters and quite differently. But there's like five or six. There are five or six when it comes to language models. Yeah. Right. But interestingly, so yes, I should say yes to start. And then I should say, but there was an interesting twist with DeepSeek at the beginning of the year. What DeepSeek did is they basically nullified the business model, if you want. In two ways. One is it was around a week or two after Trump stood with pride saying Stargate is the biggest investment project in the history. And it's $500 billion to build AI infrastructure and SoftBank and Larry Allison and Sam Altman who are sitting in so beautiful picture. And then DeepSeek R3 comes out. And does the job for a sick one over 30 of the cost. And interestingly, it's entirely open source and available as an edge AI. So that's really, really interesting because there could be now in the future as the technology improves, the learning models would be massive, but then you can compress them into something you can have on your phone. And you can download DeepSeek literally offline on an off the network computer and build an AI on it. There's a website that basically tracks the sort of cleanest apples to apples market share of all the website referrals sent by AI chatbots and chat GBT is currently at 79%, roughly about 80% of Plexi's 11, Microsoft copilot's about five Google German eyes about two, about one in DeepSeek about 1%. And really like the point that I want to land is just that when you hear of a new AI app or tool or this one can make this build on one of them. It's basically built on one of these really three or four AI platforms that's controlled really by three or four AI, you know, billionaire teams. And actually, the one of them that gets to what we call AGI first where the AI gets really, really advanced, one could say is potentially going to rule the world as it relates to technology. Yes, if they get enough head start. So I actually think that what I'm more concerned about now is not AGI, I believe it or not. So AGI in my mind, and I said that back in 2023, right, that we will get to AGI at the time I said 2027. And I believe 2026 latest. The most interesting development that nobody's talking about is self-evolving AI. Self-evolving AI is, think of it this way, if you and I are hiring the top engineer in the world to develop our AI models. And with AGI, that top engineer in the world becomes an AI, who would you hire to develop your next generation AI, that AI? The one that can teach itself. Correct. So one of my favorite examples is called Alpha Evolve. So this is Google's attempt to basically have four agents working together, four AI's working together to look at the code of the AI and say, where are the performance issues? Then an agent would say, what's the problem statement? What can I, you know, what do I need to fix? One that actually develops the solution, one that assesses the solution. And then they continue to do this. And, you know, I don't remember the exact figure, but I think Google improved like 8% on their AI infrastructure because of Alpha Evolve. Right? And when you really, really think, don't quote me on the number 8 to 10, 6 to 10, whatever. In Google terms, by the way, that is massive. That's billions and billions of dollars. Now the trick here is this. The trick is again, you have to think in game theory format. Is there any scenario we can think of where if one player uses AI to develop the next generation AI that the other players will say, no, no, no, no, that's too much, you know, takes us out of control. Every other player will copy that model and have their next AI model developed by an AI. Is this what Sir Mottmann talks about? Who's the founder of Chach P.T. I'm not sure if an AI, when he talks about a fast takeoff. I don't know exactly what you're referring to, but we're all talking about a point now that we call the intelligence explosion. So there is a moment in time where you have to imagine that if AI now is better than 97% of all code developers in the world, and soon we'll be able to look at its own code, own algorithms, by the way, they're becoming incredible mathematicians, which wasn't the case when we lost that. They can develop and improve their own code, improve their own algorithms, improve their own network architecture or whatever. You can imagine that very quickly the force applied to developing the next AI is not going to be a human brain anymore. It's going to be a much smarter brain. And very quickly as humans, like basically when we ran the Google infrastructure, when the machine said we need another server or a proxy server in that place, we followed. We never really wanted to object or verify because the code would probably know better because there are billions of transactions an hour or a day. And so very quickly, those self-evolving AIs will simply say, I need 14 more servers there and the team will just go ahead and do it. I watched a video a couple of days ago where he, Sam Altman, effectively had changed his mind because in 2023, which is when we last met, he said the aim was for a slow take-off, which is sort of gradual deployment. And open AIs, 2023 notes, as a slower take-off is easier to make safe and they prefer iterative rollouts society can adapt. In 2025, they changed their mind. And Sam Altman said, he now thinks a fast take-off is more possible than he did a couple of years ago on the order of a small number of years rather than a decade. And to define what we mean by a fast take-off, it's defined as when AI goes from roughly human level to far beyond human very quickly, think months to a few years, faster than governments, companies or society can adapt with little warning, big power shifts and hard to control. A slow take-off by contrast is where capabilities climb gradually over many years with lots of warning shots. And the red flags for a fast take-off is when AI can self-improve, run autonomous research and development and scale with massive compute compounding gains, which will snowball fast. So, and I think from the video that I watched of Sam Altman recently, who again is the founder of Open Air and Church of BT, he basically says, and again, I'm paraphrasing here, I will put it on the screen, we have this community notes thing, so I'll write it on the screen. But he effectively said that whoever gets the AGI first will have the technology to develop super intelligence, where the AI can rapidly increase its own intelligence and it will basically leave everyone else behind. Yes. So, that last bit is debatable, but let's just agree that, so in a live, one of the posts I shared and got a lot of interest is I refer to the ultimate as a brand, not as a human. So, the ultimate is that a persona of a California disruptive technologist that disrespects everyone. And believes that disruption is good for humanity and believes that this is good for safety. And like everything else, like we say, war is for democracy and freedom, they say developing, you know, putting AI on the open internet is good for everyone, right? It allows us to learn from our mistakes. That was Sam Altman's 2023 spiel. And if you recall, at the time, I was like, this is the most dangerous, you know, one of the clips that really went viral, you're so clever at finding the right clips is when I said... I didn't do the clipping, maybe. The team. Remember the clip where I said, we fucked up. We always said, don't put them on the open internet until we know what we're putting out in the world. I'm going to be saying that. We fucked up on putting it on the open internet, teaching it to code and putting, you know, agents, AI agents prompting other AIs. Now AI agents prompting other AIs are leading to self-developing AIs. And the problem is, of course, we, you know, anyone who has been on the inside of this knew that this was just a clever spiel made by a PR manager for Sam Altman to sit with his three-me eyes in front of Congress and say, we want you to regulate us. Now they're saying we're unregulated. And when you really understand what's happening here, what's happening is it's so fast that none of them has the choice to slow down. It's impossible. Neither China versus America or open AI versus Google. The only thing that I may have may see happening that you, you know, that may differ a little bit from your statement is if one of them gets there first, then they dominate for the rest of humanity. That is probably true if they get their first with an enough buffer. But the way you look at Grok coming a week after open AI, a week after, you know, Gemini, a week after cloud and then cloud comes again and then China releases something and then Korea releases something. It is so fast that we may get a few of them at the same time or a few months apart, okay, before one of them has enough power to become dominant. And that is a very interesting scenario. AI is all super intelligent. It's funny, you know, I got asked yesterday, I was in Belgium on stage. There was, I don't know, maybe 4,000 people in the audience. And a kid stood up and he was like, you've had a lot of conversations in the last year about AI, like what do you care? And I don't think people realize how even though I've had so many conversations in this podcast, but AI, you haven't made up your mind? I have no questions. I know. And it doesn't seem that anyone can satiate. Anyone that tells you they can predict the future is arrogant. Yeah. It's never moved so fast. It's nothing like nothing I've ever seen. And, you know, by the time that we leave this conversation and I go to my computer, there's going to be some incredible new technology or application of AI that didn't exist when I woke up this morning. That creates probably another paradigm shift in my brain. Also, you know, people have different opinions of Elon Musk and they're entitled to their opinion. But the other day, only a couple of days ago, he did a tweet where he said, at times, AI existential dread is overwhelming. And on the same day, he tweeted, I resisted AI for too long, living in denial. Now it is game on. And he tagged his AI companies. I don't know what to make it. I don't know what to make of those tweets. I don't know. I try really hard to figure out if someone like Sam Altman has the best interests of society at heart. No. Or if these people are just like, I'm saying that publicly. No. As a matter of fact, so I know Sundar Pichai, I work as CEO of Alphabet's Google's parent company, an amazing human being in all honesty. I know Dennis Hasab is amazing human being. You know, these are ethical, incredible humans at heart. They have no choice. Sundar, by law, is demanded to take care of his shareholder value. That is his job. But Sundar, you said you know him. You used to work at Google. Yeah. He's not going to do anything that he thinks is going to harm humanity. But if he does not continue to advance AI, that by definition contradicts his responsibility as the CEO of a publicly traded company, he is liable by law to continue to advance the agenda. There's absolutely no doubt about it. Now, but he's a good person at heart. Dennis is a good person at heart. So they're trying so hard to make it safe. Okay. As much as they can. Reality, however, is the disruptor, the ultimate as a brand, doesn't care that much. How do you know that? In reality, the disruptor is someone that comes in with the objective of, I don't like the status quo. I have a different approach. And that different approach, if you just look at the story, was we are a non-for-profit that is funded mostly by Iran mask money, if not entirely by Iran mask money. So context for people that might not understand, open AI, the reason I always give context is, funnily enough, I think I told you this last time, I went to a prison where they play the Diaries here. No way. So they play the Diaries here. And I think it's 50 prisons in the UK. Do you know if there's a no violence there? Well, I can't tell where the violence has gone up or down. But I was in the cell with one of the prisoners, a young black guy, and I was in his cell for a little while. I was reading through his business plan, etc. And I said, do you know what? You need to listen to this conversation that I did with Mo Gorda. So he has a little screen in his cell. So I pulled it up, you know, a first conversation. And I said, you should listen to that one. And he said to me, he said, I can't listen to that one because you guys use big words. So ever since that day, which was about four days. I noticed that about you. Four years ago, sorry. Yeah. I've always, whenever I hear a big word, I think about this kid. Yeah. And I say, like, give context. Yeah. So even with the, you're about to just explain what open AI is. I know he won't know what open AI is. Origin story was. That's why I'm. I think that's a wonderful practice. In general, by the way, even, you know, being an un-native English speaker, you'll be amazed how often a word is said to me. And I'm like, yeah, don't know what that means. So like, I've actually never said this publicly before, but I now see it as my responsibility to be to, to keep the draw, the draw bridge to accessibility of these conversations down for him. So whenever I, whenever there's a word that at some point in my life, I didn't know what it meant, I will go back. I will say what does that mean? I think that I've noticed that in the, you know, more and more in your podcast. Yeah. I really appreciate that. And also show it on the screens. Yeah. I think that's wonderful. I mean, the origin story of open AI is as the name suggests, it's open source. It's for the public good. It was intended in Elon Musk's words to save the world from the dangers of AI. Right. And then doing research on that. And then, you know, there was the disagreement between Sam Altman and, and Elon somehow, Elon ends up being out of, of, of open AI. I think there was a moment in time where he tried to take it back and, you know, the board rejected it or some something like that. Most of the top safety engineers, the top technical teams in open AI left in 2023, 2024, saying we're not concerned with safety anymore. It moves from being an un-for-profit to being one of the most valued companies in the world. There are billions of dollars at stake. Right. And if you, if you tell me that Sam Altman is out there trying to help humanity, let's, let's suggest to him and say, Hey, do you want to do that for free? We'll pay you up. Very good salary, but you don't have stocks in this saving humanity doesn't come at the billion dollar valuation. Or of course, now tens of billions or hundreds of billions. And, and, and see truly that is when you know that someone is doing it for the good of humanity. Now, the, the capitalist system we've built is not built for the good of humanity. It's built for the good of the capitalist. Well, he might say that releasing the model publicly, open sourcing it is too risky because then bad actors around the world would have access to that technology. So he might say that closing open AI in terms of not making it publicly viable is the right thing to do for safety. We go back to gullible cheerleaders, right? One of the interesting tricks is of lying in our world is everyone will say what helps their agenda. Follow the money. Okay. Follow the money and you find that, you know, at a point in time, Sam Altman himself was saying it's open AI. Okay. My benefit at the time is to give it to the world so that the world looks at it. They know the code if there is, if there are any bugs and so on. True statement. Hmm. Also a true statement is if I put it out there in the world, a criminal might take that model and build something that's against humanity as a result. Also true, true statement. This will choose which one of the truths to say, right? Based on which part of the agenda, which part of their life today they want to serve, right? Someone will say, you know, do you want me to be controversial? Let's not go there. But if we go back to war, I'll give you 400 slogans. 400 slogans that we all hear, hmm, that change based on the day and the army and the location and the, right? They're all slogans. None of them is true. You want to know the truth. You follow the money, not what the person is saying, but ask yourself, why is the person saying that? What's in it for the person speaking? And what do you think is in it for a chatability, Sam Altman? Hundreds of billions of dollars of valuation. And do you think it's that or power? The ego of being the person that invented AGI, hmm, the position of power that this gives you, the meetings with all of the heads of states, the admiration that gets run, it is intoxicating. 100%, 100%. Okay. And the real question, this is a question I ask everyone. Did you see, you did your, you're, every time I ask you, you say, you didn't. Did you see the movie Elysium? No. You'd be surprised how little maybe watching ID you be shot. There are some movies that are very interesting. I use them to, to create an emotional attachment to a story that you haven't seen yet because you may have seen it in a movie. Elysium is a, is a society where the elites are living on the moon. Okay. They don't need presents to do the work anymore. And everyone else is living down here. Okay. You have to imagine that if again, game theory, you have to imagine, you know, picture something to infinity to its extreme and see where it goes. And the extreme of a world where all manufactured is done manufacturing is not by machines, where all decisions are made by machines. And those machines are owned by a few is not an economy similar to the, to the, to today's economy. That today's economy is an economy of consumerism and product and production. You know, it's the, it's the, in, in a live, I call it the invention of more. The invention of more is that post World War two, as the factories were rolling out things and prosperity was happening everywhere in America. There was a time where every family had enough of everything, but for the capitalist to continue to be profitable, they needed to convince you that what you had was not enough, either by making it obsolete, like fashion or like, you know, a new shape of a car or whatever, or by convincing you that there are more things in life that you need so that you become complete without those things you don't. And that invention of more gets us to where we are today, an economy that's based on production consumed. And if you look at the US economy today, 62% of the US economy GDP is consumption. It's not production. Okay. Now, this requires that the consumers have enough purchasing power to buy what is produced. And I believe that this will be an economy that will take us hopefully in the next 10, 15, 20 years and forever. But that's not guaranteed. Why? Because on one side, if you be I replaces purchasing power. So if people have to get an income from the government, which is basically taxes collected from those using AI and robots to make things, then the mindset of capitalism, labor arbitrage means those people are not producing anything and they're costing me money. Why don't we pay them less and less? Maybe even not pay them at all. And that becomes illicit. What you basically say, you know, we sit somewhere protected from everyone. We have the machines do all of our work and those need to worry about themselves. We're not going to pay them UBI anymore. Right? And you have to imagine this idea of UBI assumes this very democratic caring society. UBI in itself is communism. Think of the ideology between at least socialism, the ideology of giving everyone what they need. That's not the capitalist democratic society that the West advocates. So those transitions are massive in magnitude. And for those transitions to happen, I believe the right thing to do when the cost of producing everything is almost zero because of AI and robots, because the cost of harvesting energy should actually tend to zero once we get more intelligent to harvest the energy out of thin air. Then a possible scenario and I believe a scenario that AI will eventually do in the utopia is yeah, anyone can get anything they want. Don't over consume. We're not going to abuse the planet resources, but it costs nothing. So like the old days where we were hunter gatherers, you would forge for some berries and you'll find them ready in nature. We can in 10 years time, 12 years time build a society where you can forge for an iPhone in nature. It will be made out of thin air. The kind of physics will allow you to do that. But the challenge, believe it or not, is not tech. The challenge is a mindset because the elite, why would they give you that for free? And the system would morph into no, no, hold on. We will make more money. We will be bigger capitalists. We will feed our ego and hunger for power more and more. And for them, give them UBI and then three weeks later, give them less UBI. Aren't there going to be lots of new jobs created though? Because when we think about the other revolutions over time, whether it's the industrial revolution or other sort of big technological revolutions, in the moment we forecasted that everyone was going to lose their jobs, but we couldn't see all the new jobs that were being created. Because the machines replaced the human strengths at the point in time and very few places in the West today will have a worker carry things on their back and carry it upstairs. The machine does that work, correct? Similarly, AI is going to replace the brain of a human. And when the West in its interesting virtual colonies that I call it basically outsourced all labor to the developing nations, what the West publicly said at the time is, we're going to be a services economy. We're not interested in making things and stitching things. And so let the Indians and Chinese and Bengalis and Vietnamese do that. We're going to do more refined jobs and knowledge workers. We're going to call it knowledge workers are people who work with information and click on a keyboard and move a mouse and sit in meetings. All we produce in the Western societies is what blah, blah, blah, words. Or designs maybe sometimes, but everything we produce can be produced by an AI. So if I give you an AI tomorrow, where I give you a piece of land, I give the AI a piece of land and I say, here are the parameters of my land. Here is its location on Google Maps. Then an architecturally sound villa for me. I care about a lot of light and I need three bedrooms. I want my bathrooms to be in white mark, whatever. And the AI produces it like that. How often will you go to an architect and say, right? So what will the architect do? The best of the best of the architects will either use AI to produce that or you will consult with them and say, hey, you know, I've seen this and they'll say, it's really pretty, but it wouldn't feel right for the person that you are. Yeah, those jobs will remain, but how many of them will remain? How often do you think, how many more years do you think I will be able to create a book that is smarter than AI? Not many. I will still be able to connect to a human. You're not going to hug an AI when you meet them like you hug me, right? But that's not enough of a job. So why do I say that? Remember I asked you at the beginning of the podcast to remind me of solutions. Why do I say that? Because there are ideological shifts and then concrete actions that need to be taken by governments today rather than waiting until COVID is already everywhere and then locking everyone down. Governments could have reacted before the first patient or at least at patient zero or at least at patient 50. They didn't. What I'm trying to say is there is no doubt that lots of jobs will be lost. There's no doubt that there will be sectors of society where 10, 20, 30, 40, 50 percent of all developers, all software, you know, all graphic designers, all online marketers, all all all all all assistants is are going to be out of a job. So are we prepared as a society to do that? Can we tell our governments there is an ideological shift? This is very close to socialism and communism. And are we ready from a budget point of view instead of spending a trillion dollars a year on arms and explosives and, you know, autonomous weapons that will oppress people because we can't feed them? Can we please shift that? I did those numbers. Again, I go back to military spending because it's all around us. 2.71 trillion dollars, 2.4 to 2.7 is the estimate of 2024. How much money was spending on military? On military equipment, on things that were going to explode into smoke and death. Extreme poverty worldwide, extreme poverty is people that are below the poverty line. Extreme poverty everywhere in the world could end for 10 to 12 percent of that budget. So if we replace our military spending, 10 percent of that to go to people who are in extreme poverty, nobody will be poor in the world. You can end world hunger for less than 4 percent. Nobody would be hungry in the world. If you take again 10 to 12 percent universal health care, every human being on the planet would have free health care for 10 to 12 percent on what we're spending on war. Now, why do I say this when we're talking about AI? Because that's a simple decision. If we stop fighting because money itself does not have the same meaning anymore, because the economics of money is going to change, because the entire meaning of capitalism is ending, because there is no more need for labor arbitrage, because AI is doing everything. Just with the $2.4 trillion we save in explosives every year, in arms and weapons, just for that, universal health care and extreme poverty, you could actually, one of the calculations is you could end climate change meaningfully for 100 percent of the military budget. But I'm not even sure it's really about the money. I think money is a measurement stick of power, right? Exactly. It's printed on demand. But in a world where we have super intelligence and money is no longer a problem, I still think power is going to be insatiable for so many people. So there will still be war because, you know, I'm more the strongest. The strongest, I want the strongest AI. I don't want my. And I don't want, you know what, Henry, a single cauldron, the eaters. The eaters. Yeah. What brutal as that sounds? Is that the people at the bottom of the socio-economic? That don't produce but consume. So if you had the Henrik, a singer at the helm and we have so many of them, what would they think? I don't know if that is. Why? Why? A very prominent military figure in the US history. You know, why would we feed 350 million Americans, America would think? But more interestingly, why do we even care about Bangladesh anymore? If we can't make our textiles there or we don't want to make our textiles there. Do you, you know, I imagine throughout human history, if we had podcasts, conversations would would have been warning of a dystopia around the corner. You know, when they had a technology on the internet, they would have said, I want to finish them when the the tractor came along, they would have said, Oh God, we're finished because we're not going to be able to farm anymore. So is this not just another one of those moments where we couldn't see around the corner. So we we forecasted unfortunate things. You could be. I am begging that I'm wrong. Okay. I'm just asking if there are scenarios that you think that can provide that, you know, Mustafa Sulaiman in in you hosted him here. I did. He was in the coming wave. Yeah. And he speaks about about pessimism aversion. Okay. That all of us, people who are supposed to be in technology and business and so on or always supposed to, you know, stand on stage and say, the future is going to be amazing. You know, this technology I'm building is going to make everything better. One of my posts in our life was called the broken promises. How often did that happen? Okay. How often did social media connect us and how many? How and how often did it make us more lonely? How how often did mobile phones make us work less? That was the promise. That was the promise. The early ads of Nokia were people at parties. Is that your experience of mobile phones? And I think the whole idea is we should hope there will be other roles for humanity, by the way, those roles would resemble the times where we were hunter-gatherers, just a lot more technology and a lot more safety. Okay. So this is this sounds good. Yeah. This is exciting. So I'm going to I'm going to get to go outside more be with my friends more. 100%. Fantastic. And do absolutely nothing. And that doesn't sound fantastic. No, it does. Be forced to do absolutely nothing. For some people, it's amazing. For you and I, we're going to find the little carpentry project and just do something. Speak for yourself. I'm still people are still going to tune in. Correct. Yeah. But what and people are going to tune in. Do you think they will? I'm like, I'm not convinced they will. For as long. Well, you guys tune in. You guys still going to tune in. I can let them answer. I believe for as long as you make their life enriched. But can an AI do that better without the human connection? Comment below. Are you going to listen to an AI or the diversity? Let me know in the comment section below. Remember as incredibly intelligent as you are, Steve, there will be a moment in time where you're going to sound really dumb compared to an AI and I will sound completely dumb. Yeah. The depth of analysis and gold nuggets, I mean, can you imagine two super intelligences deciding to get together and explain string theory to us? They do better than any physicist in the world because they possess the physics knowledge and they also possess social and language knowledge that most deep physicists don't. I think B2B marketers keep making this mistake. They're chasing volume instead of quality. And when you try to be seen by more people instead of the right people, all you're doing is making noise. But that noise rarely shifts the needle and it's often quite expensive. And I know as I was the time in my career where I kept making this mistake that many of you will be making it too. Eventually, I started posting ads on our show sponsors platform LinkedIn. And that's when things started to change. I put that change down to a few critical things. Other than being that LinkedIn was then and still is today, the platform where decision makers go to not only to think and learn, but also to buy. And when you market your business there, you're putting it right in front of people who actually have the power to say yes. And you can target them by job title, industry and company size. It's simply a sharper way to spend your marketing budget. And if you haven't tried it, how about this? Give LinkedIn out a try and I'm going to give you a hundred dollar ad credit to get you started. And if you visit linkedin.com slash diary, you can claim that right now. That's linkedin.com slash diary. I've really gone back and forward on this idea that even in podcasting that all the podcasts will be a podcast or I've gone back and forward on it. And where I landed at the end of the day was that there'll still be a category of media where you do want lived experience on something hundred percent. For example, like you want to know how the person that you follow and admire dealt with their divorce. Yeah. Or how they're struggling with AI. For example, yeah, exactly. But I think things like news, there are certain situations where just like straight news and straight facts and maybe a walk through history, maybe eroded away by AI's. But even in those scenarios, there's something about personality. And again, I hesitate here because I question myself. I'm not in the camp of people that are romantic, by the way. I'm like, I'm trying to be as as orientated towards whatever is true, even if it's against my interests. And I hope people understand that about me like, because even in my companies, we experiment with like disrupting me with AI and some people will be aware of those experiments. I guess there will be a mix of all that you can't imagine that the world will be completely just AI and completely just podcasters. You know, you'll see a mix of both. You'll see things that they do better, things that we do better. The message I'm trying to say is we need to pray for that. We need to be ready for that. We need to be ready by talking to our governments and saying, hey, it looks like I'm a paralegal. And it looks like all paralegals are going to be financial researchers or analysts or graphic designers or call center agents. It looks like half of those jobs are being replaced already. You know who Jeffrey Hinton is? Oh, I had him on the documentary as well. I love Jeffrey. Jeffrey Hinton told me... Train to be a plumber. Really? Yeah. 100% for a while. And I thought he was joking. 100%? So I asked him again and he looked me dead in the eye and told me that I should train to be a plumber. 100%. So it's funny, yeah. Machines replaced labor, but we still had blue collars. And the refined jobs became white collar information workers. What's the refined jobs? You know, you don't have to really carry heavy stuff or deal with physical work. You sit in an office and sit in meetings all day and blabber useless shit and that's your job. And those jobs, funny enough in the reverse of that, because robotics are not ready yet. And I believe they're not ready because of a stubbornness on the robotics community around making them humanoids, because it takes so much to perfect a human-like action at proper speed. You could have many more robots that don't look like a human, just like a self-driving car in California that does already replace drivers. And you know, but they're delayed. So the robotic, the replacement of physical manual labor is going to take four to five years before it's possible at the quality of the AI replacing mental labor now. And when that happens, it's going to take a long cycle to manufacture enough robots so that they replace all of those jobs. So that cycle will take longer. Blue collar will stay longer. So I should move into blue collar and shut down my office. I think you're not the problem. Okay, good. Let's put it this way. There are many people that we should care about that are a simple travel agent or an assistant that will see, if not replacement, a reduction in the number of things they're getting. Simple as that. Okay. All right. All right. All right. All right. All right. All right. All right. All right. All right. All right. All right. All right. All right. All right. All right. All right. All right. All right. All right. All right. All right. All right. All right. All right. All right. All right. All right.
