Timestamp: 2025-08-25T01:05:38.204423
Title: OpenAI前科学家警告：“你根本不知道未来会发生什么” BV1Vnbiz2Ef6
URL: https://b23.tv/cbajrXg
Status: success
Duration: 18:13

Description:
好的，以下是根据您提供的文本内容提炼和总结的核心要点、总括性结论、总框架以及美人鱼概念图。

---

### 核心思想总结

#### 一、 伊利亚·萨茨克维尔的视角：AI的颠覆性与人类的终极挑战

1.  **AI影响的广度与深度**
    *   **非同寻常的时代**: 当前因AI而处在一个前所未有的时代，其影响已深刻改变学生学习方式。
    *   **超越工作与职业**: AI不仅将影响工作性质和职业选择，其挑战是前所未有且极其极端的。
    *   **未来AI的普遍能力**: AI最终将能够完成所有人类可学习的任务，因为人类大脑是生物计算机，数字计算机也能做到。
2.  **极速进展与难以想象的未来**
    *   **AI能力持续提升**: AI将持续进步，可能在数年内（3、5或10年）达到能完成所有人类任务的水平。
    *   **加速的研发与进步**: AI的普遍应用将极大加速研发、经济增长和AI研究本身，导致进展速度极快。
    *   **难以想象的未来**: AI带来的未来是极端而激进的，但又难以想象和情感上难以完全相信，即使是AI开发者本人也深感挣扎。
3.  **对人类的召唤**
    *   **“政治”比喻**: 就像政治会主动找上你一样，AI也会深刻影响每个人的生活。
    *   **亲身体验的重要性**: 亲身体验和观察AI的能力是建立直觉、理解其真实性的最佳方式，胜过任何理论解释。
    *   **人类的终极挑战与回报**: AI构成的挑战可能是人类有史以来最大的挑战，克服它也将带来最大的回报。
    *   **行动呼吁**: 关注AI，投入精力解决它带来的问题，因为无论喜不喜欢，每个人的生活都将深受其影响。

#### 二、 艾瑞克·施密特的视角：AI的演进时间表与深层社会变革

1.  **近期AI发展与职业冲击 (1-2年内)**
    *   **程序员与数学家的大规模替代**: 大多数程序员和顶尖研究生水平的数学家将在一年内被AI取代。
    *   **工作原理**: AI通过“单词预测”（如人类语言）或“猜想-证明”（如数学）进行优化，其规模远超人类。编程则通过编写代码直到通过测试来实现。
    *   **递归式自我改进**: AI已能自主生成10-20%的研究代码，预示着自我改进能力的迅速扩展。
2.  **通用人工智能(AGI)与超级人工智能(ASI)的展望 (3-6年内)**
    *   **AGI (通用人工智能)**: 预计3-5年内出现，定义为在数学家、物理学家、艺术家、作家、思想家、政治家等领域达到最聪明人类水平的系统（旧金山共识）。
    *   **代理系统 (Agent Solutions)**: 具备输入、输出和记忆，能学习并自主执行多步骤复杂业务流程（如购房、设计、施工）。这意味着所有商业、政府和学术流程都可能被自动化。
    *   **ASI (超级人工智能)**: 预计6年内出现，指智力超越人类总和的计算机系统（旧金山共识，基于规模扩展）。
    *   **巨大能源需求**: 实现ASI需要巨量的电力（千兆瓦级）。
3.  **社会影响与挑战**
    *   **社会准备不足**: AI发展速度远超社会、民主和法律的适应能力，缺乏应对这种智能水平的语言和框架。
    *   **就业观点**: 历史上自动化总是创造比消除更多的工作岗位，因此工作更可能被“改变”而非“消灭”，但鉴于亚洲人口趋势，此轮自动化可能有所不同，使得少数勤劳的人类能极大提高生产力。
4.  **AI技术核心进展与行业竞争**
    *   **多模态模型**: AI能处理图像等多种输入。
    *   **无限上下文窗口**: 实现分步规划（例如，构建房屋的复杂流程）。
    *   **代理 (Agents)**: 作为记忆源和行动执行者，但行业规范尚不明确，主要公司寻求控制权。
    *   **文本到代码**: AI能根据人类指令自动编写复杂程序，极大地自动化任务。
    *   **激烈行业竞争**: Anthropic、Google (Gemini)、OpenAI (Microsoft) 和 Facebook (开源模型) 等巨头在推理、预测、分类和多模态能力上激烈竞争。
    *   **AGI的定义与时间线争议**:
        *   **定义**: 具备人类智能的灵活性，能自主生成目标函数。
        *   **旧金山学派**: 认为在2-3个“周期”（每个约18个月）内达到超越人类总和的AGI。
        *   **施密特个人观点**: 可能性很大，但时间表可能没有那么快。

#### 三、 结论：AI的必然性与紧迫性

AI的加速发展将以前所未有的速度和广度重塑人类社会和所有职业，带来巨大的挑战和机遇，要求全社会立即关注并积极应对。

#### 四、 总框架

AI的加速演进及其对人类文明的深远影响：从近期职业颠覆到未来超级智能的诞生，以及随之而来的社会适应、伦理治理和生存挑战。

---

### Mermaid 概念图

<Mermaid_Diagram>
graph LR
    A["AI的加速演进: 前所未有的变革时代"]
    subgraph "伊利亚·萨茨克维尔的视角"
        B["AI影响的广度与深度"] --> C["未来AI能力: 完成所有人类可学习任务"]
        C --> D["智能加速循环: AI促进AI发展"]
        D --> E["难以想象的未来: 极端而激进"]
        B --> F["核心挑战: 人类有史以来最大"]
        F --> G["应对策略: 关注、参与、创造能量"]
    end

    subgraph "艾瑞克·施密特的视角"
        H["近期职业冲击 (1年内)"] --> I["程序员/数学家的大规模替代"]
        J["AI技术核心进展"]
        J --> K["无限上下文窗口: 分步规划"]
        J --> L["代理系统: 自动化复杂流程"]
        J --> M["文本到代码: 自动化编程"]
        I & K & L & M --> N["中期目标 (3-5年): AGI 通用人工智能"]
        N --> O["长期愿景 (6年内): ASI 超级人工智能"]
        O --> P["所需资源: 巨量电力"]
        N --> Q{"旧金山共识"}
        Q -- "AGI/ASI时间表" --> O
        Q -- "施密特个人观点: 可能性大，但时间更长" --> R["施密特个人观点"]
        H & J & N & O --> S["社会影响与挑战"]
        S --> T["社会准备不足: 法规、民主、语言滞后"]
        S --> U["就业观点: 岗位改变而非消灭 (历史趋势)"]
    end

    subgraph "行业动态"
        V["激烈行业竞争"] --> W[" Anthropic, Google, OpenAI, Facebook"]
        W --> J
    end

    A --> B
    A --> H
    A --> V

    G & T & U --> X["结论: AI影响的必然性与紧迫性"]

    style A fill:#F9F7D8,stroke:#333,stroke-width:2px,color:#333;
    style B fill:#ADD8E6,stroke:#333,stroke-width:1px,color:#333;
    style C fill:#C0E6FF,stroke:#333,stroke-width:1px,color:#333;
    style D fill:#C0E6FF,stroke:#333,stroke-width:1px,color:#333;
    style E fill:#C0E6FF,stroke:#333,stroke-width:1px,color:#333;
    style F fill:#FFB6C1,stroke:#333,stroke-width:1px,color:#333;
    style G fill:#90EE90,stroke:#333,stroke-width:1px,color:#333;

    style H fill:#ADD8E6,stroke:#333,stroke-width:1px,color:#333;
    style I fill:#FFD700,stroke:#333,stroke-width:1px,color:#333;
    style J fill:#D3FFD3,stroke:#333,stroke-width:1px,color:#333;
    style K fill:#C0E6FF,stroke:#333,stroke-width:1px,color:#333;
    style L fill:#C0E6FF,stroke:#333,stroke-width:1px,color:#333;
    style M fill:#C0E6FF,stroke:#333,stroke-width:1px,color:#333;
    style N fill:#FFA07A,stroke:#333,stroke-width:1px,color:#333;
    style O fill:#FF6347,stroke:#333,stroke-width:1px,color:#333;
    style P fill:#FFB6C1,stroke:#333,stroke-width:1px,color:#333;
    style Q fill:#FFFACD,stroke:#333,stroke-width:1px,color:#333;
    style R fill:#FFFACD,stroke:#333,stroke-width:1px,color:#333;
    style S fill:#FFB6C1,stroke:#333,stroke-width:1px,color:#333;
    style T fill:#FFB6C1,stroke:#333,stroke-width:1px,color:#333;
    style U fill:#FFD700,stroke:#333,stroke-width:1px,color:#333;

    style V fill:#ADD8E6,stroke:#333,stroke-width:1px,color:#333;
    style W fill:#C0E6FF,stroke:#333,stroke-width:1px,color:#333;

    style X fill:#F9F7D8,stroke:#333,stroke-width:2px,color:#333;
</Mermaid_Diagram>

Content:
 You may not take interest in politics, but politics will take interest in you. So the same applies to AI many times over. Ilya Sutskivir, the man behind the invention of OpenAI, gave a pretty strong speech at the University of Toronto. He expressed great concerns about the upcoming AI, which might disrupt our entire world. Watch this. The reason it's not going to be the most conventional convocation speech is because there is something a little different going on. Right now, you all leave, we all leave in the most unusual time ever. And this is something that people might say often, but I think it's actually true this time. And the reason it's true this time is because of AI. Right, obviously. I mean, from what I hear, the AI of today has already changed what it means to be a student by a pretty considerable degree. That's what I sense and I think it's true. But of course, the impact of AI goes beyond that. What happens to the kind of work we do? Well, it's starting to change a little bit in some unknown and unpredictable ways. And some work may feel it sooner, some work may feel it later. With today's AI, you can go on Twitter and you can look at what AI can do and what people say. And you might feel a little bit of that. You wonder, hey, which skills are useful, which ones will be less useful? So you got these questions going on. And so you can say that the current level of challenge is how will it affect work and our careers? But the thing, the real challenge with AI is that it's really unprecedented and really extreme. And it's going to be very different in the future compared to the way it is today. Like, you know, we've all seen AI. We've all spoken to a computer and a computer has spoken back to us, which is a new thing. Computers would not do this in the past, but now they do. So you speak to a computer, then it understands you and it speaks back to you. And it also does it in voice and it writes some code. It's pretty crazy. But there are so many things it cannot do as well and it's so deficient. So you can say it still needs to catch up on a lot of things. But it's evocative. It's good enough that you can ask yourself, you could imagine, okay, fine. In some number of years, some people say it's in three, some people say it's in five, ten, numbers have been thrown around. It's a bit hard to predict the future. But slowly but surely or maybe not so slowly, AI will keep getting better. And the day will come when AI will do all of our, all the things that we can do. Not just some of them, but all of them. Anything which I can learn, anything which any, any one of you can learn, the AI could do as well. How do we know this, by the way? How can I be so sure? How can I be so sure of that? The reason is that all of us have a brain and the brain is a biological computer. That's why. We have a brain, the brain is a biological computer. So why can't a digital computer, a digital brain do the same things? This is the one sentence summary for why AI will be able to do all those things. Because we have a brain and the brain is a biological computer. And so you can start asking yourself, so what's going to happen? What's going to happen when computers can do all of our jobs? Right? Those are really big questions. Those are dramatic questions. And right now, like you start thinking about it a little bit, you go, gosh, that's a little intense. But it's actually only part of the intensity. Because what's going to happen? What will be the collective V want to use these? AI is for do more work, grow the economy, do R&D, do AI research. So then the rate of progress will become really extremely fast. For some time at least, these are such extreme things. These are such unimaginable things. So right now I'm trying to pull you into that a little bit into this headspace of this really extreme and radical future that AI creates. But it's also very difficult to imagine. It's very, very difficult to imagine. It's very difficult to internalize and to really believe on an emotional level. Even I struggle with it. And yet the logic seems to dictate that this very like it should happen. So what does one do in such a world? You know, there is a quote which is like this, which goes like this. It says, you may not take interest in politics, but politics will take interest in you. So the same applies to AI many times over. And in particular, I think that by simply using AI and looking at what the best AI of today can do, you get an intuition. You get an intuition. And as AI continues to improve in one year, in two years, in three years, the intuition will become stronger. And a lot of the things that we are talking about now, they will become much more real. They'll become less imaginary. In the end of the day, no amount of essays and explanations can compete with what we see with our own senses, with our own two eyes. And especially with AI, the very smart, super intelligent AI in the future, there will be very profound issues about making sure that they say what they say and not pretend to be something else. And I'm really condensing a lot into a small amount of information here, in time here. But overall, by simply looking at what AI can do, not ignoring it, when the time comes, that will generate the energy that's required to overcome the huge challenge that AI will pose. And the challenge that AI poses, in some sense, is the greatest challenge of humanity ever. And overcoming it, you'll also bring the greatest reward. And in some sense, whether you like it or not, your life is going to be affected by AI to a great extent. And so looking at it, paying attention, and then generating the energy to solve the problems you let feel come up, that's going to be the main thing. So that was Ilya's view. But to understand the full debate, I want you to watch this interview clip of Eric Schmidt, where he talks about a much broader impact of AI on human lives in the coming years. Watch this. Okay, so we believe, as an industry, that in the next one year, the vast majority of programmers will be replaced by AI programmers. We also believe that within one year, you will have graduate-level mathematicians that are at the tippy top of graduate math programs. There's lots of reasons to think this is going to happen. This is the consensus. You know, okay, well, that's pretty interesting. Now, I can't do that kind of math. Very few people can do that math. How can the computer do that math better than anybody else? To some degree, it's because math has a simpler language than human language. So the way these algorithms actually work is they're doing essentially word prediction. So you take a sentence, you take a word out, and then it learns how to put the correct word back in. This is called the loss function, and it's optimized to do that at a scale that's unimaginable to us as humans. So you do the same thing for math. But there you use a conjecture and then a proof format through a protocol called Lean. In programming, it's pretty simple. You just keep writing code until you pass the programming test. So strangely, the first question I always ask programmers is what language do you program in, and the correct answer is it doesn't matter, because you're trying to design for an outcome. You don't care what code is generated by the computer. This is a whole new world, okay? So that's one year, okay? What happens in two years? Well, I've just told you about reasoning, and I've told you about programming, and I've told you about math. Programming plus math are the basis of sort of our whole digital world. So the evidence and the claims from the research groups in OpenAI and Tropic and so forth is that they're now somewhere around 10 or 20% of the code that they're developing in their research programs is being generated by the computer. That's called recursive self-improvement, is the technical term. So what happens when this thing starts to scale? Well, a lot. One way to say this is that within three to five years, we'll have what is called general intelligence, AGI, which can be defined as a system that is as smart as the smartest mathematician, physicist, you know, artist, writer, thinker, politician, maybe not in the same level. But you get the idea, just the creative industries and so forth, but imagine that in one computer. Okay, well, that's pretty interesting. I called this, by the way, the San Francisco consensus, because everyone who believes this is in San Francisco. It may be the water. What happens when every single one of us has the equivalent of the smartest human on every problem in our pocket? So it means you have the best architect when you have an architecture problem. Another thing that's going on is the development of agent solutions. And agents are referred to systems that have input and output in memory, and they learn. An example here is that I want to buy another house. I happen to like Virginia. I grew up in Virginia. I say find me a house in the greater McLean area. Look at the, that's one agent. Look at all the rules. Figure how big a house I can build. That's another agent. Do the transaction to buy the land. That's another agent. Design the house with a human architect. But sort of ignore them for most of the thing, but they have to sign it off. And then I approve it, and then find the contractor. Hire the contractor, pay the bills, and at the end, sue the contractor for lack of rewards. Now, I just gave you the stupidest possible explanation. I just described every business process, every government process, and every, and every sort of academic process in our nation. So it isn't just the programmers that are going to be out of work. We're all going to be out of work. No, that's not a consequence. I'll come to that. But the reason I want to, I want to make the point here is that in the next year or two, this foundation is being locked in, and it's not, we're not going to stop it. It gets much more interesting after that. Because remember, the computers are now doing self-improvement. They're learning how to plan, and they don't have to listen to us anymore. We call that superintelligence, or ASI, artificial superintelligence. And this is the theory that there will be computers that are smarter than the sum of humans. The San Francisco consensus is this occurs within six years, just based on scaling. Now, in order to pull this off, you have to have an enormous amount of power. I was here yesterday testifying about this, and we need like, I can talk at some length about how many gigawatts, and how many nuclear power plants, and all that kind of stuff we can talk about separately. This path is not understood in our society. There's no language for what happens with the arrival of this. I wrote a book on this with Henry Kissinger called Genesis, which you know, I recommend obviously. Because I wrote it. Available on my mind. Available in your usual places. But the important point is, this is happening faster than our human, that our society, our democracy, our laws will address. And there's lots of implications. That's why it's underhyped. People do not understand what happens when you have intelligence at this level, which is largely free. That's the point. How do we get ready for it? Well, we start by talking about it. And by the way, on the jobs thing, everyone assumes that automation will eliminate jobs. If you look at the history of automation ever since the looms in 300 years ago, the jobs are changed, but more jobs are created than destroyed. In this case, you'd have to convince me that this time is different. If you look in Asia, where they, for whatever reason, are choosing not to have children, the Asian reproduction rate is in the order of 1.0 or lower. So they're rapidly disappearing. So the Asian countries are very, very quickly automating. The tools that I'm describing will allow the few humans that will be working very hard in 30 or 40 years if these trends continue. The rest of us will be dependent on those hardworking humans. It'll make their productivity more much greater. Now, here's another clip of Eric Schmidt. Here he shares much deeper concerns about upcoming AI technology. Watch this. One way to think about the AI that you all know, is think of it as a language to language. You ask a question, the answer comes back. You ask a question, you can even write code. Nowadays, the models are multimodal. So for example, you can take a picture and say, tell me what's in this picture. Technically, there are APIs which allow one firm to call an open AI or Gemini API, or anthropic, et cetera, and do the classification of the picture and so forth. These are all tactics that increase the intelligence of the underlying system. There are three things going on right now this year, so less than the time from you gave. To really interesting one is called infinite context windows. Infinite context windows means that you can keep feeding the answer back in as the question. So it allows you to do step by step planning. You know, how do I build a house? Well, the first is I have to find a contractor. I found a contractor. Would I have to talk to them? Then I have to have an architect. How do I find an architect? Then I have to tell the architect what to do and then design me the house. I'll give it to the architect. He can redesign it. You know, there's a series of steps. The next one they're called agents. And agents is a generally overused term. And most people think that agents will essentially act as memory sources. So an agent can be understood as it's watching something and when it sees it, it takes an action. It does that by knowing what to do based on what it's seeing. The specs for how agents work are completely undefined in the industry. The dominant companies want to have their own agents and they don't want the agents to interact because they want control for obvious reasons. Many people think that there will be an agent store that you will download like we see with apps, but not this year. And the third one is text to code. I don't know about you all, but I've programmed and managed programmers for more than 40 years. And they never do what I want. So can you imagine if the computer, you said, write me a program to do this and it actually writes the code? In our case, the program would be search through all the literature, find out who is working on energy policy, who has a technological background or a role in which they have to be technologically liberal, literate, identify them, rank them, score them based on whatever our goal is. And then automatically send them an invitation. If they say yes, say congratulations, they say no, why not? And call them and with a synthetic voice tell them that they're idiots for not coming. That's the kind of program I would write. Thank God I'm not doing that. But you see how easy it would be to automate tasks. So that's I think the first step. The next step is not as clear. There are sort of huge contests. There's a huge set of contests going right now, which are at a scale that's unimaginable. You have the big three in the US, Anthropic, which is a line with Amazon, Jim and I obviously from Google, OpenAI Microsoft. And let's assume they all do really well. It looks that they're doing really well. I can talk about what their problems are, but fundamentally they're doing well. You have Facebook, which has chosen an open source path for the 400 billion model. There's a lot of implications strategically, which we can discuss. All of these are vying for the best reasoning, the best answers, and then the best predictive analytics, the best image classifiers, and the best multimodal. That technology then diffuses, or the technical term is distilled into more specialized models. I think that's the action you'll see in the next one to two years. You did not mention artificial general intelligence. First, for those of us who aren't necessarily, totally up to speed on AI, what is it? And where are we? There are multiple definitions of AGI, but the term isn't around for 15 years. The basic idea is what is the point where you have the flexibility of a human in your intelligence system? So what we understand today is that these are called narrow AI approaches, although they're not really not narrow. You basically, they're initiated by a human. At what point is the question, can the computer generate its own objective function, its own goal? And how will that emerge? There's what I call the San Francisco school, because they're all in San Francisco, which is a separate set of issues, and they all talk to each other, and they've all convinced themselves that within two to three cranks of these systems, the crank is about 18 months, you get to AGI. And they define AGI as intelligence greater than the sum of human intelligence. I personally think that that's likely but not in three years, not in... What is the time frame, do you... We don't know.
