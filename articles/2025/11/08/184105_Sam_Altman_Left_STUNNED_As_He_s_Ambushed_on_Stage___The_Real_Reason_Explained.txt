Timestamp: 2025-11-08T18:41:05.949379
Title: Sam Altman Left STUNNED As He’s Ambushed on Stage | The Real Reason Explained
URL: https://youtube.com/watch?v=Vd8hL6ubJiU&si=lz63D_bXgFSeFkqq
Status: success
Duration: 28:01

Description:
好的，这是根据您提供的文本内容和要求生成的摘要分析。

### **一、核心观点结构化摘要**

1.  **核心事件：OpenAI CEO萨姆·奥特曼在舞台上被送达传票**
    *   **事件概述**：在旧金山的一场公开活动中，萨姆·奥特曼被一名抗议者冲上舞台递交法庭传票，场面一度混乱。
    *   **肇事方**：一个名为“停止AI”（Stop AI）的激进组织。
    *   **直接动机**：该组织成员因多次非暴力抗议（如堵塞OpenAI总部大门）而被起诉，他们试图通过传唤奥特曼，在其庭审中作证，将审判变为一场关于AI风险的公开辩论。

2.  **“停止AI”组织的理念与行动策略**
    *   **终极目标**：永久性地在全球范围内禁止超级人工智能（ASI/AGI）的开发。
    *   **核心理念**：他们坚信ASI对全人类构成“生存威胁”，其发展等同于“企图谋杀地球上的每一个生命”。
    *   **行动策略**：
        *   **公民不服从**：采取堵路、干扰公共活动、在OpenAI总部外抗议等方式制造社会影响。
        *   **媒体曝光**：故意采取可能导致被捕的行动，以牺牲个人自由为代价，吸引媒体关注，从而传播其核心诉求。
    *   **法律策略**：在法庭上采用“紧急避险”（Necessity Defense）进行辩护，即主张其轻微的违法行为是为了防止AI可能带来的种族灭绝这一更大的灾难。

3.  **更广泛的AI安全争议与公众情绪**
    *   **对OpenAI安全承诺的普遍质疑**：
        *   视频列举了多个案例证明外界对OpenAI“安全第一”承诺的怀疑，包括其为加速发展而缩减安全投入、前安全团队核心成员离职并加入更注重安全的公司（Anthropic）、以及多名前员工签署公开信批评公司的安全文化。
        *   引用AI教父杰弗里·辛顿（Geoffrey Hinton）的观点，指责奥特曼更关心利润而非安全。
    *   **全球AI竞赛的“囚徒困境”**：
        *   讨论了中美等国在AI领域的激烈竞争。如果美国单方面暂停研发，可能会在战略上落后于其他国家。
        *   “停止AI”组织对此的回应是，他们的目标是“全球性”禁令，首先从技术最领先的美国开始，再推动其他国家跟进。
    *   **日益增长的社会反AI情绪**：
        *   **精英层面**：该运动并非孤立存在，许多科技领袖（如史蒂夫·沃兹尼亚克）、诺贝尔奖得主和研究机构（如未来生命研究所）已多次发表公开信，呼吁暂停或禁止先进AI的研发。
        *   **公众层面**：“AI圈”之外的普通民众普遍对AI（特别是生成式AI）持负面态度，主要原因包括：
            *   **经济冲击**：担心工作被取代，尤其是在创意领域。
            *   **伦理与法律**：涉及数据窃取、侵犯版权、制造虚假信息。
            *   **社会成本**：高能耗对环境造成破坏，并可能推高电费。
        *   **市场反响**：企业（如可口可乐、Vogue）使用AI进行创作已引发了消费者的强烈抵制和负面评论。

### **二、核心结论（一句话）**

对萨姆·奥特曼的公开传票事件，揭示了一场由生存风险恐惧和广泛社会经济忧虑共同驱动的、日益壮大的反AI运动。

### **三、内容的总体框架**

该内容采用“**由点及面**”的叙事框架，从“奥特曼被传唤”这一具体戏剧性事件切入，层层深入地剖析了事件背后的行动组织（“停止AI”）、其策略动机，并最终扩展到关于AI安全的全球性争议和日益增长的公众抵制情绪这一宏观背景，构成了一个完整的社会议题分析。

### **四、概念关系图 (Mermaid Conceptual Map)**

<Mermaid_Diagram>
graph TD
    subgraph "核心事件 (The Incident)"
        A["萨姆·奥特曼被当众传唤"]
    end

    subgraph "行动方: ‘停止AI’组织 (The Actor: 'Stop AI')"
        B["核心理念: AI是生存威胁"] --> C["终极目标: 全球永久禁止ASI"]
        C --> D["行动策略: 公民不服从"]
        C --> E["法律辩护: 紧急避险"]
    end

    subgraph "争议背景 (The Broader Context)"
        F["对OpenAI安全承诺的质疑"]
        G["全球AI竞赛的'囚徒困境'"]
        H["精英层呼吁暂停AI研发"]
    end

    subgraph "社会反响 (Societal Reaction)"
        I["公众普遍的负面情绪"]
        J["原因: 工作替代与经济冲击"]
        K["原因: 版权、数据与伦理问题"]
        L["原因: 环境与社会成本"]
        I --> J
        I --> K
        I --> L
    end

    A -- "引爆点" --> B
    A -- "揭示了" --> F
    A -- "关联到" --> G
    A -- "呼应了" --> H
    D -- "旨在引发" --> I

    style A fill:#FF6347,stroke:#B22222,stroke-width:3px,color:#FFFFFF
    style B fill:#FFD700,stroke:#333,stroke-width:2px
    style C fill:#FFA500,stroke:#333,stroke-width:2px
    style D fill:#F0E68C,stroke:#333,stroke-width:1px
    style E fill:#F0E68C,stroke:#333,stroke-width:1px
    style F fill:#ADD8E6,stroke:#4682B4,stroke-width:2px
    style G fill:#B0C4DE,stroke:#4682B4,stroke-width:2px
    style H fill:#87CEEB,stroke:#4682B4,stroke-width:2px
    style I fill:#DDA0DD,stroke:#8A2BE2,stroke-width:2px
    style J fill:#E6E6FA,stroke:#8A2BE2,stroke-width:1px
    style K fill:#E6E6FA,stroke:#8A2BE2,stroke-width:1px
    style L fill:#E6E6FA,stroke:#8A2BE2,stroke-width:1px
</Mermaid_Diagram>

Content:
But what you guys are about to see is, But what you guys are about to see is, the moment that Samman was ambushed on, the moment that Samman was ambushed on, the moment that Samman was ambushed on, stage by someone trying to serve him a, stage by someone trying to serve him a, stage by someone trying to serve him a, subpoena. And this is a crazy story. So, subpoena. And this is a crazy story. So, subpoena. And this is a crazy story. So, let's talk about it., let's talk about it., let's talk about it., So what you guys are seeing on stage is, So what you guys are seeing on stage is, So what you guys are seeing on stage is, a story that literally just happened a, a story that literally just happened a, a story that literally just happened a, few hours ago. And the incident took, few hours ago. And the incident took, few hours ago. And the incident took, place on Monday night. And it was only, place on Monday night. And it was only, place on Monday night. And it was only, recently that the footage was revealed., recently that the footage was revealed., recently that the footage was revealed., And that's why everyone can now see this, And that's why everyone can now see this, And that's why everyone can now see this, footage being played. I'm actually going, footage being played. I'm actually going, footage being played. I'm actually going, to play you guys the footage with the, to play you guys the footage with the, to play you guys the footage with the, audio so you can actually hear what is, audio so you can actually hear what is, audio so you can actually hear what is, being said and you'll see just how crazy, being said and you'll see just how crazy, being said and you'll see just how crazy, this moment is. Even Sam Alman is, this moment is. Even Sam Alman is, this moment is. Even Sam Alman is, looking confused and he doesn't really, looking confused and he doesn't really, looking confused and he doesn't really, understand what's going on. I mean, at, understand what's going on. I mean, at, understand what's going on. I mean, at, the time I don't think anyone did at, the time I don't think anyone did at, the time I don't think anyone did at, all., all., all., &gt;&gt; Oh, sorry., &gt;&gt; Oh, sorry., &gt;&gt; Oh, sorry., &gt;&gt; I'm sorry. Go ahead., &gt;&gt; Can you take it off the stage?, &gt;&gt; Can you take it off the stage?, [Music], [Music], [Music], [Applause], [Applause], [Applause], Wow, getting off to a dramatic start, Wow, getting off to a dramatic start, Wow, getting off to a dramatic start, already., already., already., &gt;&gt; Um, well, &gt;&gt; Um, well, &gt;&gt; Um, well, &gt;&gt; so this video is now going viral because, &gt;&gt; so this video is now going viral because, &gt;&gt; so this video is now going viral because, of course it is, you know, pretty, of course it is, you know, pretty, of course it is, you know, pretty, dramatic. So, like I was saying, this, dramatic. So, like I was saying, this, dramatic. So, like I was saying, this, happened at the Sydney Goldstein Theater, happened at the Sydney Goldstein Theater, happened at the Sydney Goldstein Theater, in San Francisco where he was on stage, in San Francisco where he was on stage, in San Francisco where he was on stage, and he was actually having a, and he was actually having a, and he was actually having a, conversation with Steve Kerr and, conversation with Steve Kerr and, conversation with Steve Kerr and, moderator Manny Yukatel. Now, the man, moderator Manny Yukatel. Now, the man, moderator Manny Yukatel. Now, the man, walked on stage early on into the event, walked on stage early on into the event, walked on stage early on into the event, and he seemed to be holding up a, and he seemed to be holding up a, and he seemed to be holding up a, document claiming to have a subpoena for, document claiming to have a subpoena for, document claiming to have a subpoena for, Sam Olman. Now, if you don't know what a, Sam Olman. Now, if you don't know what a, Sam Olman. Now, if you don't know what a, subpoena is, it's basically a document, subpoena is, it's basically a document, subpoena is, it's basically a document, that means you have to legally appear in, that means you have to legally appear in, that means you have to legally appear in, court. Now, of course, I'm going to talk, court. Now, of course, I'm going to talk, court. Now, of course, I'm going to talk, about first what actually happened., about first what actually happened., about first what actually happened., Well, you can see the moderator or the, Well, you can see the moderator or the, Well, you can see the moderator or the, host was intervening and then security, host was intervening and then security, host was intervening and then security, actually, you know, manages to take this, actually, you know, manages to take this, actually, you know, manages to take this, guy off stage. And I think this was, guy off stage. And I think this was, guy off stage. And I think this was, pretty crazy because it now shows you, pretty crazy because it now shows you, pretty crazy because it now shows you, the level we are at when it comes to, the level we are at when it comes to, the level we are at when it comes to, these kind of situations. So most people, these kind of situations. So most people, these kind of situations. So most people, don't understand who this was and what, don't understand who this was and what, don't understand who this was and what, actually occurred and that's exactly, actually occurred and that's exactly, actually occurred and that's exactly, what I'll dive into because this, what I'll dive into because this, what I'll dive into because this, situation is a lot bigger than you think, situation is a lot bigger than you think, situation is a lot bigger than you think, and it points to a growing concern about, and it points to a growing concern about, and it points to a growing concern about, AI. So essentially what is going on, AI. So essentially what is going on, AI. So essentially what is going on, here? Why did this guy come on and, here? Why did this guy come on and, here? Why did this guy come on and, subpoena Sam? Well, essentially it's, subpoena Sam? Well, essentially it's, subpoena Sam? Well, essentially it's, from this group. So, this is the group., from this group. So, this is the group., from this group. So, this is the group., This is a group called Stop AI, and, This is a group called Stop AI, and, This is a group called Stop AI, and, their entire mission is to basically get, their entire mission is to basically get, their entire mission is to basically get, Asi or ASI permanently banned. And, Asi or ASI permanently banned. And, Asi or ASI permanently banned. And, they've been at this since April of, they've been at this since April of, they've been at this since April of, 2024. And they essentially want it to, 2024. And they essentially want it to, 2024. And they essentially want it to, just, you know, completely stop. Now, just, you know, completely stop. Now, just, you know, completely stop. Now, essentially what they tried to do is use, essentially what they tried to do is use, essentially what they tried to do is use, the subpoena to use that as a way to get, the subpoena to use that as a way to get, the subpoena to use that as a way to get, Sam Alman to appear in court, either to, Sam Alman to appear in court, either to, Sam Alman to appear in court, either to, give testimony or produce specific, give testimony or produce specific, give testimony or produce specific, documents. And they actually said that, documents. And they actually said that, documents. And they actually said that, this was what they wanted to do. So you, this was what they wanted to do. So you, this was what they wanted to do. So you, can see it says, "Our public defender, can see it says, "Our public defender, can see it says, "Our public defender, successfully subpoenaed Sam Alman to, successfully subpoenaed Sam Alman to, successfully subpoenaed Sam Alman to, appear at our trial where we will be, appear at our trial where we will be, appear at our trial where we will be, tried for nonviolently blocking the, tried for nonviolently blocking the, tried for nonviolently blocking the, front door of OpenAI on multiple, front door of OpenAI on multiple, front door of OpenAI on multiple, occasions and blocking the road in front, occasions and blocking the road in front, occasions and blocking the road in front, of their office." All of our nonviolent, of their office." All of our nonviolent, of their office." All of our nonviolent, actions against OpenAI. And get this, actions against OpenAI. And get this, actions against OpenAI. And get this, they were an attempt to slow down Open, they were an attempt to slow down Open, they were an attempt to slow down Open, AI in their attempted murder of everyone, AI in their attempted murder of everyone, AI in their attempted murder of everyone, and every living thing on the Earth., and every living thing on the Earth., and every living thing on the Earth., This trial will be the first time in, This trial will be the first time in, This trial will be the first time in, human history where a jury of normal, human history where a jury of normal, human history where a jury of normal, people are asked about the extinction, people are asked about the extinction, people are asked about the extinction, threat that AI poses to humanity. So, threat that AI poses to humanity. So, threat that AI poses to humanity. So, most people missed this statement. Most, most people missed this statement. Most, most people missed this statement. Most, people just saw the sant when it was, people just saw the sant when it was, people just saw the sant when it was, getting subpoenaed and thought that it, getting subpoenaed and thought that it, getting subpoenaed and thought that it, was just likely some, you know, standard, was just likely some, you know, standard, was just likely some, you know, standard, opening eye legal troubles. But no, this, opening eye legal troubles. But no, this, opening eye legal troubles. But no, this, is from an organization that have been, is from an organization that have been, is from an organization that have been, trying to really really get public, trying to really really get public, trying to really really get public, attention for some time now. And it, attention for some time now. And it, attention for some time now. And it, seems like they're finally managing to, seems like they're finally managing to, seems like they're finally managing to, break ground in terms of doing that., break ground in terms of doing that., break ground in terms of doing that., Because what most people don't, Because what most people don't, Because what most people don't, understand is that this is a company., understand is that this is a company., understand is that this is a company., Well, not a company, but this is an, Well, not a company, but this is an, Well, not a company, but this is an, organization that has been doing this, organization that has been doing this, organization that has been doing this, for a very long time. If you guys hadn't, for a very long time. If you guys hadn't, for a very long time. If you guys hadn't, known before, you know, they didn't have, known before, you know, they didn't have, known before, you know, they didn't have, much attention. However, they have, much attention. However, they have, much attention. However, they have, actually been causing quite the ruckus, actually been causing quite the ruckus, actually been causing quite the ruckus, at the Open Eye headquarters. Okay? And, at the Open Eye headquarters. Okay? And, at the Open Eye headquarters. Okay? And, this is from October 23rd, 2024 where, this is from October 23rd, 2024 where, this is from October 23rd, 2024 where, you can see the stop AI banner was there, you can see the stop AI banner was there, you can see the stop AI banner was there, and they essentially, you know, tied, and they essentially, you know, tied, and they essentially, you know, tied, chains around the OpenAI gates. They, chains around the OpenAI gates. They, chains around the OpenAI gates. They, were sitting there protesting. They've, were sitting there protesting. They've, were sitting there protesting. They've, been, you know, in the streets blocking, been, you know, in the streets blocking, been, you know, in the streets blocking, cars from moving forward. They have been, cars from moving forward. They have been, cars from moving forward. They have been, doing a lot in order to raise awareness., doing a lot in order to raise awareness., doing a lot in order to raise awareness., Now, they responded on Twitter. Someone, Now, they responded on Twitter. Someone, Now, they responded on Twitter. Someone, said, "You had me until this trial will, said, "You had me until this trial will, said, "You had me until this trial will, be the first time in human history where, be the first time in human history where, be the first time in human history where, a normal jury of people are asked about, a normal jury of people are asked about, a normal jury of people are asked about, the extinction threat that I poses to, the extinction threat that I poses to, the extinction threat that I poses to, humanity. Seems like you guys are, humanity. Seems like you guys are, humanity. Seems like you guys are, pushing for a title, trying to make your, pushing for a title, trying to make your, pushing for a title, trying to make your, mark more than anything." And they, mark more than anything." And they, mark more than anything." And they, responded by saying, "We have no, responded by saying, "We have no, responded by saying, "We have no, interest in a claim or popularity. All, interest in a claim or popularity. All, interest in a claim or popularity. All, we want to do is inform humanity about, we want to do is inform humanity about, we want to do is inform humanity about, the threat that we are facing. We are, the threat that we are facing. We are, the threat that we are facing. We are, calling for a permanent global ban on, calling for a permanent global ban on, calling for a permanent global ban on, the development of artificial super, the development of artificial super, the development of artificial super, intelligence." And once that is, intelligence." And once that is, intelligence." And once that is, achieved, we will be happy to go back to, achieved, we will be happy to go back to, achieved, we will be happy to go back to, being nobodyies. So this is the goal of, being nobodyies. So this is the goal of, being nobodyies. So this is the goal of, this organization. And remember, they, this organization. And remember, they, this organization. And remember, they, have been at this for a very long time., have been at this for a very long time., have been at this for a very long time., And I mean I say very long time. It's, And I mean I say very long time. It's, And I mean I say very long time. It's, only been around a year and a few, only been around a year and a few, only been around a year and a few, months. But in AI, that is a very long, months. But in AI, that is a very long, months. But in AI, that is a very long, time. And like I said, they've been, time. And like I said, they've been, time. And like I said, they've been, trying to get attention because this is, trying to get attention because this is, trying to get attention because this is, a very, very pressing matter. Now you, a very, very pressing matter. Now you, a very, very pressing matter. Now you, have to understand like I dove into a, have to understand like I dove into a, have to understand like I dove into a, few details and I've realized that they, few details and I've realized that they, few details and I've realized that they, had an interview where they actually, had an interview where they actually, had an interview where they actually, explain their stance in more detail and, explain their stance in more detail and, explain their stance in more detail and, essentially the main man here Sam Kchner, essentially the main man here Sam Kchner, essentially the main man here Sam Kchner, who has you know essentially been you, who has you know essentially been you, who has you know essentially been you, know arrested several times and I'm, know arrested several times and I'm, know arrested several times and I'm, pretty sure they were just like, pretty sure they were just like, pretty sure they were just like, misdemeanors but you have to understand, misdemeanors but you have to understand, misdemeanors but you have to understand, that they don't care about you know the, that they don't care about you know the, that they don't care about you know the, miners of getting arrested or you know, miners of getting arrested or you know, miners of getting arrested or you know, even if they end up in jail because they, even if they end up in jail because they, even if they end up in jail because they, believe that what they are doing is for, believe that what they are doing is for, believe that what they are doing is for, the greater good. In this short, the greater good. In this short, the greater good. In this short, interview clip, you're going to hear, interview clip, you're going to hear, interview clip, you're going to hear, them talk about the fact that like this, them talk about the fact that like this, them talk about the fact that like this, situation is bigger than them. They, situation is bigger than them. They, situation is bigger than them. They, don't see themselves as, you know, the, don't see themselves as, you know, the, don't see themselves as, you know, the, ones that deserve the attention. They're, ones that deserve the attention. They're, ones that deserve the attention. They're, just trying to raise awareness for what, just trying to raise awareness for what, just trying to raise awareness for what, AGI/ASI, AGI/ASI, AGI/ASI, will actually do., will actually do., will actually do., &gt;&gt; If these misdemeanor charges keep piling, &gt;&gt; If these misdemeanor charges keep piling, &gt;&gt; If these misdemeanor charges keep piling, up, what happens? What's the next step?, up, what happens? What's the next step?, up, what happens? What's the next step?, You currently have a court date. Is that, You currently have a court date. Is that, You currently have a court date. Is that, right?, right?, right?, &gt;&gt; Correct. Court dates. There was one on, &gt;&gt; Correct. Court dates. There was one on, &gt;&gt; Correct. Court dates. There was one on, October 15th at 9:00 a.m. and one on, October 15th at 9:00 a.m. and one on, October 15th at 9:00 a.m. and one on, October 24th at 9:00 a.m., October 24th at 9:00 a.m., October 24th at 9:00 a.m., &gt;&gt; So Sam, when you go to your court date, &gt;&gt; So Sam, when you go to your court date, &gt;&gt; So Sam, when you go to your court date, in a worst case scenario, is there any, in a worst case scenario, is there any, in a worst case scenario, is there any, possibility of like a year of jail time?, possibility of like a year of jail time?, possibility of like a year of jail time?, It got to be less than a year, right?, It got to be less than a year, right?, It got to be less than a year, right?, Maybe like weeks, months. What's the, Maybe like weeks, months. What's the, Maybe like weeks, months. What's the, worst case scenario?, worst case scenario?, worst case scenario?, &gt;&gt; I think from adding just preliminary, &gt;&gt; I think from adding just preliminary, &gt;&gt; I think from adding just preliminary, research on each offense. Yeah, it could, research on each offense. Yeah, it could, research on each offense. Yeah, it could, be a year or more. I don't really care, be a year or more. I don't really care, be a year or more. I don't really care, what the consequences are here, even if, what the consequences are here, even if, what the consequences are here, even if, pleading the necessity offense goes, pleading the necessity offense goes, pleading the necessity offense goes, poorly because I I just think people, poorly because I I just think people, poorly because I I just think people, have to do what we're doing now. Like we, have to do what we're doing now. Like we, have to do what we're doing now. Like we, we are running into potentially building, we are running into potentially building, we are running into potentially building, AGI extremely soon and once you build, AGI extremely soon and once you build, AGI extremely soon and once you build, that uh you hand over control and at, that uh you hand over control and at, that uh you hand over control and at, that point you're sure your future, that point you're sure your future, that point you're sure your future, extinction or everyone's job gets taken., extinction or everyone's job gets taken., extinction or everyone's job gets taken., So I mean people who don't do what we're, So I mean people who don't do what we're, So I mean people who don't do what we're, doing I think are grace. The problem is, doing I think are grace. The problem is, doing I think are grace. The problem is, like we have to stop this now. And if, like we have to stop this now. And if, like we have to stop this now. And if, blocking entrances is what you have to, blocking entrances is what you have to, blocking entrances is what you have to, do, then that's what we're going to do., do, then that's what we're going to do., do, then that's what we're going to do., Even if it results in us losing, I hope, Even if it results in us losing, I hope, Even if it results in us losing, I hope, we don't and I hope we do win the, we don't and I hope we do win the, we don't and I hope we do win the, necessity defense and we are basically, necessity defense and we are basically, necessity defense and we are basically, allowed to continue doing it. If that's, allowed to continue doing it. If that's, allowed to continue doing it. If that's, what will happen or not, someone has to, what will happen or not, someone has to, what will happen or not, someone has to, do something. Someone has to do, do something. Someone has to do, do something. Someone has to do, something now. And so you can see in, something now. And so you can see in, something now. And so you can see in, that clip that he's essentially arguing, that clip that he's essentially arguing, that clip that he's essentially arguing, the fact that like we don't have time to, the fact that like we don't have time to, the fact that like we don't have time to, debate around whether this is good or, debate around whether this is good or, debate around whether this is good or, whether this is bad, how this issue is, whether this is bad, how this issue is, whether this is bad, how this issue is, going to play out. people need to act, going to play out. people need to act, going to play out. people need to act, now. He's essentially saying that look, now. He's essentially saying that look, now. He's essentially saying that look, if no one does something, then we are, if no one does something, then we are, if no one does something, then we are, going to step up to the plate and do, going to step up to the plate and do, going to step up to the plate and do, something. Now, of course, you can see, something. Now, of course, you can see, something. Now, of course, you can see, this guy has a court date because it's, this guy has a court date because it's, this guy has a court date because it's, been several times where they blocked, been several times where they blocked, been several times where they blocked, the road, they blocked OpenAI's, the road, they blocked OpenAI's, the road, they blocked OpenAI's, headquarters, and what they talk about, headquarters, and what they talk about, headquarters, and what they talk about, is pleading the necessity defense. Now, is pleading the necessity defense. Now, is pleading the necessity defense. Now, I'm not a lawyer, but I'm going to give, I'm not a lawyer, but I'm going to give, I'm not a lawyer, but I'm going to give, you a simple explanation of what that, you a simple explanation of what that, you a simple explanation of what that, is. And the necessity defense is also, is. And the necessity defense is also, is. And the necessity defense is also, known as a duress of circumstances. And, known as a duress of circumstances. And, known as a duress of circumstances. And, it's basically just a legal principle, it's basically just a legal principle, it's basically just a legal principle, that argues that you know an unlawful, that argues that you know an unlawful, that argues that you know an unlawful, act was committed to prevent a greater, act was committed to prevent a greater, act was committed to prevent a greater, harm from occurring. And it applies in, harm from occurring. And it applies in, harm from occurring. And it applies in, extreme situations where a person is, extreme situations where a person is, extreme situations where a person is, forced to break the law because there is, forced to break the law because there is, forced to break the law because there is, no other reasonable alternative to avoid, no other reasonable alternative to avoid, no other reasonable alternative to avoid, a greater evil such as a threat or, a greater evil such as a threat or, a greater evil such as a threat or, serious injury. Now, I believe in this, serious injury. Now, I believe in this, serious injury. Now, I believe in this, case, what they're trying to do is say, case, what they're trying to do is say, case, what they're trying to do is say, "Look, we have no choice but to go to, "Look, we have no choice but to go to, "Look, we have no choice but to go to, their headquarters and, you know, their headquarters and, you know, their headquarters and, you know, barricade, not barricade themselves in, barricade, not barricade themselves in, barricade, not barricade themselves in, but, you know, stop traffic and just, but, you know, stop traffic and just, but, you know, stop traffic and just, cause a nuisance because AGI/ASI, cause a nuisance because AGI/ASI, cause a nuisance because AGI/ASI, will be that bad. I don't know if, will be that bad. I don't know if, will be that bad. I don't know if, they're going to win this. I'm not a, they're going to win this. I'm not a, they're going to win this. I'm not a, lawyer. I can't really say, but that's, lawyer. I can't really say, but that's, lawyer. I can't really say, but that's, the guys of what they're trying to win, the guys of what they're trying to win, the guys of what they're trying to win, when they, you know, are going to go to, when they, you know, are going to go to, when they, you know, are going to go to, court and face these, you know, charges, court and face these, you know, charges, court and face these, you know, charges, that they they may be facing." Now, I, that they they may be facing." Now, I, that they they may be facing." Now, I, think it's super interesting that, you, think it's super interesting that, you, think it's super interesting that, you, know, they're going ahead with this, know, they're going ahead with this, know, they're going ahead with this, stance, but you're going to see that the, stance, but you're going to see that the, stance, but you're going to see that the, story just continues to get more and, story just continues to get more and, story just continues to get more and, more interesting. And for those of you, more interesting. And for those of you, more interesting. And for those of you, guys who are wondering, okay, well, you, guys who are wondering, okay, well, you, guys who are wondering, okay, well, you, know, there's several ways that you can, know, there's several ways that you can, know, there's several ways that you can, go about doing this if you're trying to, go about doing this if you're trying to, go about doing this if you're trying to, raise awareness for what AGI is, there, raise awareness for what AGI is, there, raise awareness for what AGI is, there, are, you know, a billion different ways, are, you know, a billion different ways, are, you know, a billion different ways, that you could do this. But later on in, that you could do this. But later on in, that you could do this. But later on in, the interview, they also talk about why, the interview, they also talk about why, the interview, they also talk about why, they chose this specific way and why, they chose this specific way and why, they chose this specific way and why, they believe that it is more important., they believe that it is more important., they believe that it is more important., Let's take a look at Romel Ellen who, Let's take a look at Romel Ellen who, Let's take a look at Romel Ellen who, talks about you know why they've chosen, talks about you know why they've chosen, talks about you know why they've chosen, this specific path in terms of garnering, this specific path in terms of garnering, this specific path in terms of garnering, attention, attention, attention, &gt;&gt; AI employees I want to reach out to more, &gt;&gt; AI employees I want to reach out to more, &gt;&gt; AI employees I want to reach out to more, open eye employees for various tactics, open eye employees for various tactics, open eye employees for various tactics, and this is one of them so that's step, and this is one of them so that's step, and this is one of them so that's step, one the other step is through this we, one the other step is through this we, one the other step is through this we, will encourage other people to join so, will encourage other people to join so, will encourage other people to join so, some people might not get arrested some, some people might not get arrested some, some people might not get arrested some, people will those hardcore people who, people will those hardcore people who, people will those hardcore people who, get arrested kind of act as an example, get arrested kind of act as an example, get arrested kind of act as an example, of like I'm willing to sacrifice some, of like I'm willing to sacrifice some, of like I'm willing to sacrifice some, things in my life I'm willing to get, things in my life I'm willing to get, things in my life I'm willing to get, arrested in order to do this. Okay. So, arrested in order to do this. Okay. So, arrested in order to do this. Okay. So, then there are two things happening, then there are two things happening, then there are two things happening, here. One is the media gets on to this., here. One is the media gets on to this., here. One is the media gets on to this., The media kind of start sharing this, The media kind of start sharing this, The media kind of start sharing this, saying like hey wait what's happening, saying like hey wait what's happening, saying like hey wait what's happening, with these people start interviewing us., with these people start interviewing us., with these people start interviewing us., We can start talking more about our, We can start talking more about our, We can start talking more about our, concerns. We can start setting demands, concerns. We can start setting demands, concerns. We can start setting demands, in terms of what we want these AI, in terms of what we want these AI, in terms of what we want these AI, companies to restrict. We want, companies to restrict. We want, companies to restrict. We want, government to do to act how we can, government to do to act how we can, government to do to act how we can, collaborate together with other citizen, collaborate together with other citizen, collaborate together with other citizen, groups to restrict these AI, groups to restrict these AI, groups to restrict these AI, corporations. And the other thing is, corporations. And the other thing is, corporations. And the other thing is, yes, like Sam can actually go to trial, yes, like Sam can actually go to trial, yes, like Sam can actually go to trial, plead the necessity defense. And that's, plead the necessity defense. And that's, plead the necessity defense. And that's, part of that overall strategy of saying, part of that overall strategy of saying, part of that overall strategy of saying, like guys, we're doing this for a, like guys, we're doing this for a, like guys, we're doing this for a, reason. Like Sam mentioned, uh we had a, reason. Like Sam mentioned, uh we had a, reason. Like Sam mentioned, uh we had a, backup plan uh one week beforehand, backup plan uh one week beforehand, backup plan uh one week beforehand, saying like, okay, this is not a way, saying like, okay, this is not a way, saying like, okay, this is not a way, that we can actually kind of start kind, that we can actually kind of start kind, that we can actually kind of start kind, of raising awareness. All right, we'll, of raising awareness. All right, we'll, of raising awareness. All right, we'll, try the classic civil disobedience, try the classic civil disobedience, try the classic civil disobedience, tactic, which is to to like block a road, tactic, which is to to like block a road, tactic, which is to to like block a road, and knowing that like we're going to be, and knowing that like we're going to be, and knowing that like we're going to be, a nuisance. It's going to be unpopular., a nuisance. It's going to be unpopular., a nuisance. It's going to be unpopular., We we're sorry for the people who we who, We we're sorry for the people who we who, We we're sorry for the people who we who, we annoy with that. Uh but given the, we annoy with that. Uh but given the, we annoy with that. Uh but given the, risks, given the stakes involved, we, risks, given the stakes involved, we, risks, given the stakes involved, we, really do need to take this more, really do need to take this more, really do need to take this more, seriously and we're showing that we're, seriously and we're showing that we're, seriously and we're showing that we're, taking it seriously and we're getting, taking it seriously and we're getting, taking it seriously and we're getting, people to start paying attention to, people to start paying attention to, people to start paying attention to, this., this., this., &gt;&gt; So yeah, that perfectly encapsulates the, &gt;&gt; So yeah, that perfectly encapsulates the, &gt;&gt; So yeah, that perfectly encapsulates the, entire point. I think it makes a lot, entire point. I think it makes a lot, entire point. I think it makes a lot, more sense, of course, hearing that, more sense, of course, hearing that, more sense, of course, hearing that, because, you know, the stakes for AGI, because, you know, the stakes for AGI, because, you know, the stakes for AGI, are certainly high. Now, I also did some, are certainly high. Now, I also did some, are certainly high. Now, I also did some, more digging and I found out that like I, more digging and I found out that like I, more digging and I found out that like I, said before, this wasn't the only time., said before, this wasn't the only time., said before, this wasn't the only time., They also, you know, crashed another, They also, you know, crashed another, They also, you know, crashed another, event. They did the EA Global event in, event. They did the EA Global event in, event. They did the EA Global event in, Oakland in February 2025. And this, Oakland in February 2025. And this, Oakland in February 2025. And this, protest, which I'll I'll add the audio, protest, which I'll I'll add the audio, protest, which I'll I'll add the audio, in just a moment, was part of the, in just a moment, was part of the, in just a moment, was part of the, group's, you know, campaign to once, group's, you know, campaign to once, group's, you know, campaign to once, again permanently ban the development of, again permanently ban the development of, again permanently ban the development of, artificial super intelligence due to the, artificial super intelligence due to the, artificial super intelligence due to the, risk of human extinction and other, risk of human extinction and other, risk of human extinction and other, problems. Now the event in question, problems. Now the event in question, problems. Now the event in question, officially titled the EA global event, officially titled the EA global event, officially titled the EA global event, took place on February the 21st to the, took place on February the 21st to the, took place on February the 21st to the, 23rd and this you know conference was, 23rd and this you know conference was, 23rd and this you know conference was, particularly focused on risks from AI, particularly focused on risks from AI, particularly focused on risks from AI, and other global catastrophic risks. So, and other global catastrophic risks. So, and other global catastrophic risks. So, this is really what they've been doing, this is really what they've been doing, this is really what they've been doing, for a very long time now. Now, it's, for a very long time now. Now, it's, for a very long time now. Now, it's, interesting in this clip, and the reason, interesting in this clip, and the reason, interesting in this clip, and the reason, I say that is because in this clip, they, I say that is because in this clip, they, I say that is because in this clip, they, actually talk about anthropic, another, actually talk about anthropic, another, actually talk about anthropic, another, frontier lab creating artificial, frontier lab creating artificial, frontier lab creating artificial, intelligence at scale. And I'm actually, intelligence at scale. And I'm actually, intelligence at scale. And I'm actually, going to go to the start now, so you, going to go to the start now, so you, going to go to the start now, so you, guys are going to be able to see and, guys are going to be able to see and, guys are going to be able to see and, hear exactly the points they're making., hear exactly the points they're making., hear exactly the points they're making., &gt;&gt; This man, Neil Buddy Shaw, is funding, &gt;&gt; This man, Neil Buddy Shaw, is funding, &gt;&gt; This man, Neil Buddy Shaw, is funding, the death of everyone I love and, the death of everyone I love and, the death of everyone I love and, everyone you love. He is funding, everyone you love. He is funding, everyone you love. He is funding, anthropic. Anthropic is one of the, anthropic. Anthropic is one of the, anthropic. Anthropic is one of the, leading companies trying to build, leading companies trying to build, leading companies trying to build, artificial super intelligence and, artificial super intelligence and, artificial super intelligence and, artificial general intelligence. Many of, artificial general intelligence. Many of, artificial general intelligence. Many of, you know that that could lead to human, you know that that could lead to human, you know that that could lead to human, extinction. He's funding this. He's, extinction. He's funding this. He's, extinction. He's funding this. He's, funding people I the deaths of people I, funding people I the deaths of people I, funding people I the deaths of people I, love. Many of you in this room are part, love. Many of you in this room are part, love. Many of you in this room are part, of the AI safety community. You need to, of the AI safety community. You need to, of the AI safety community. You need to, do something to stop the development of, do something to stop the development of, do something to stop the development of, AGI. That requires getting arrested for, AGI. That requires getting arrested for, AGI. That requires getting arrested for, nonviolent civil disobedience blocking, nonviolent civil disobedience blocking, nonviolent civil disobedience blocking, the entrance to anthropic and open AI, the entrance to anthropic and open AI, the entrance to anthropic and open AI, and whoever is trying to build, and whoever is trying to build, and whoever is trying to build, artificial general intelligence. That is, artificial general intelligence. That is, artificial general intelligence. That is, not okay. Joffrey Hinton says the guy, not okay. Joffrey Hinton says the guy, not okay. Joffrey Hinton says the guy, who just won the Nobel Prize for his, who just won the Nobel Prize for his, who just won the Nobel Prize for his, work in AI says there's a 50% chance, work in AI says there's a 50% chance, work in AI says there's a 50% chance, that building artificial super, that building artificial super, that building artificial super, intelligence could lead to human, intelligence could lead to human, intelligence could lead to human, extinction. That's not okay. You cannot, extinction. That's not okay. You cannot, extinction. That's not okay. You cannot, have proof that something smarter than, have proof that something smarter than, have proof that something smarter than, all of us will stay safe forever. That's, all of us will stay safe forever. That's, all of us will stay safe forever. That's, not possible. trying to build super, not possible. trying to build super, not possible. trying to build super, intelligence is not a legitimate, intelligence is not a legitimate, intelligence is not a legitimate, business practice. Anthropic and OpenAI, business practice. Anthropic and OpenAI, business practice. Anthropic and OpenAI, should not exist. I've locked myself to, should not exist. I've locked myself to, should not exist. I've locked myself to, the front of OpenAI. I have three, the front of OpenAI. I have three, the front of OpenAI. I have three, friends in jail right now who locked, friends in jail right now who locked, friends in jail right now who locked, themselves to the front door to OpenAI, themselves to the front door to OpenAI, themselves to the front door to OpenAI, yesterday. Please, if you think that, yesterday. Please, if you think that, yesterday. Please, if you think that, super intelligence could cause human, super intelligence could cause human, super intelligence could cause human, extinction, do something about it. Don't, extinction, do something about it. Don't, extinction, do something about it. Don't, just chat about it online. Do something., just chat about it online. Do something., just chat about it online. Do something., I'd like to ask people here if you think, I'd like to ask people here if you think, I'd like to ask people here if you think, there's a chance that it could cause, there's a chance that it could cause, there's a chance that it could cause, cause you an extinction, are you willing, cause you an extinction, are you willing, cause you an extinction, are you willing, to get arrested to prevent the deaths of, to get arrested to prevent the deaths of, to get arrested to prevent the deaths of, those you love? Show of hands, please., &gt;&gt; One wonderful, &gt;&gt; One wonderful, stand up. If you are if you want to, stand up. If you are if you want to, stand up. If you are if you want to, prevent the death of those, prevent the death of those, prevent the death of those, &gt;&gt; please do something now., &gt;&gt; please do something now., &gt;&gt; please do something now., &gt;&gt; Otherwise, you're a bunch. Okay, so it, &gt;&gt; Otherwise, you're a bunch. Okay, so it, &gt;&gt; Otherwise, you're a bunch. Okay, so it, started to get a little bit, you know, started to get a little bit, you know, started to get a little bit, you know, there was a little bit of profanity, there was a little bit of profanity, there was a little bit of profanity, there, but I think he was just trying to, there, but I think he was just trying to, there, but I think he was just trying to, drive the point home that this is a, drive the point home that this is a, drive the point home that this is a, serious serious issue. Now, you have to, serious serious issue. Now, you have to, serious serious issue. Now, you have to, understand that for me personally, I was, understand that for me personally, I was, understand that for me personally, I was, rather confused at why they chose to, rather confused at why they chose to, rather confused at why they chose to, mention anthropic. I understand that, mention anthropic. I understand that, mention anthropic. I understand that, yes, they are a big AI lab, but you have, yes, they are a big AI lab, but you have, yes, they are a big AI lab, but you have, to understand that if there is any, to understand that if there is any, to understand that if there is any, company that right now is focusing on AI, company that right now is focusing on AI, company that right now is focusing on AI, safety, you would have to understand, safety, you would have to understand, safety, you would have to understand, that that is what Anthropic does. And in, that that is what Anthropic does. And in, that that is what Anthropic does. And in, this article by Time magazine, they talk, this article by Time magazine, they talk, this article by Time magazine, they talk, about, you know, Anthropic are, about, you know, Anthropic are, about, you know, Anthropic are, essentially really really moving, essentially really really moving, essentially really really moving, forward, you know, the needle in terms, forward, you know, the needle in terms, forward, you know, the needle in terms, of, you know, AI safety. So they talk, of, you know, AI safety. So they talk, of, you know, AI safety. So they talk, about, you know, safety is essentially, about, you know, safety is essentially, about, you know, safety is essentially, their strategy and they have the, their strategy and they have the, their strategy and they have the, responsible scaling policy and they, responsible scaling policy and they, responsible scaling policy and they, they're committing to this to delay, they're committing to this to delay, they're committing to this to delay, releasing more advanced AIs until safety, releasing more advanced AIs until safety, releasing more advanced AIs until safety, measures catch up. And you know, this, measures catch up. And you know, this, measures catch up. And you know, this, was like in 2024. And the crazy thing, was like in 2024. And the crazy thing, was like in 2024. And the crazy thing, about this is that like if you look at, about this is that like if you look at, about this is that like if you look at, Anthropic's mission statement which is, Anthropic's mission statement which is, Anthropic's mission statement which is, on their website, they state that we aim, on their website, they state that we aim, on their website, they state that we aim, to build frontier AI systems that are, to build frontier AI systems that are, to build frontier AI systems that are, reliable, interpretable, steerable. We, reliable, interpretable, steerable. We, reliable, interpretable, steerable. We, conduct frontier research, develop and, conduct frontier research, develop and, conduct frontier research, develop and, apply a variety of safety techniques and, apply a variety of safety techniques and, apply a variety of safety techniques and, you know deploy the resulting systems, you know deploy the resulting systems, you know deploy the resulting systems, via set of partnerships and products., via set of partnerships and products., via set of partnerships and products., And they also say that, you know, they, And they also say that, you know, they, And they also say that, you know, they, see safety as a systematic science, see safety as a systematic science, see safety as a systematic science, conducting research, applying it to, conducting research, applying it to, conducting research, applying it to, their products and feeding those, their products and feeding those, their products and feeding those, insights back into their research and, insights back into their research and, insights back into their research and, regularly sharing what they learn with, regularly sharing what they learn with, regularly sharing what they learn with, the world along the way. And it's true, the world along the way. And it's true, the world along the way. And it's true, okay, they do do this a lot. Like a lot, okay, they do do this a lot. Like a lot, okay, they do do this a lot. Like a lot, of the times you'll see Antropic post, of the times you'll see Antropic post, of the times you'll see Antropic post, their interpretability research, which, their interpretability research, which, their interpretability research, which, is, you know, showing how the models, is, you know, showing how the models, is, you know, showing how the models, work deep down inside. And they are, you, work deep down inside. And they are, you, work deep down inside. And they are, you, know, consistently pushing forward that, know, consistently pushing forward that, know, consistently pushing forward that, frontier. Antropic have always said, frontier. Antropic have always said, frontier. Antropic have always said, that, you know, even if it means that, that, you know, even if it means that, that, you know, even if it means that, they lose the AI race, they're going to, they lose the AI race, they're going to, they lose the AI race, they're going to, focus on AI safety. So, for me to hear, focus on AI safety. So, for me to hear, focus on AI safety. So, for me to hear, them, you know, say that Anthropic, you, them, you know, say that Anthropic, you, them, you know, say that Anthropic, you, know, XY Z, I didn't really understand, know, XY Z, I didn't really understand, know, XY Z, I didn't really understand, that. Now, if you want to talk about, that. Now, if you want to talk about, that. Now, if you want to talk about, OpenAI being unsafe in terms of, OpenAI being unsafe in terms of, OpenAI being unsafe in terms of, releasing products early, that's a, releasing products early, that's a, releasing products early, that's a, conversation I think people are, you, conversation I think people are, you, conversation I think people are, you, know, 100% willing to hear because, know, 100% willing to hear because, know, 100% willing to hear because, OpenAI on several different occasions, OpenAI on several different occasions, OpenAI on several different occasions, have been called out for, you know, not, have been called out for, you know, not, have been called out for, you know, not, focusing enough or not focusing quickly, focusing enough or not focusing quickly, focusing enough or not focusing quickly, enough on AI safety. Meaning that, enough on AI safety. Meaning that, enough on AI safety. Meaning that, despite its stated commitment to safety, despite its stated commitment to safety, despite its stated commitment to safety, you know, many critics have argued that, you know, many critics have argued that, you know, many critics have argued that, the company's actions have not matched, the company's actions have not matched, the company's actions have not matched, that goal. Okay? They they haven't, that goal. Okay? They they haven't, that goal. Okay? They they haven't, matched it. Okay. Now, for the the the, matched it. Okay. Now, for the the the, matched it. Okay. Now, for the the the, one example I'm going to show you guys, one example I'm going to show you guys, one example I'm going to show you guys, here, in fact, I'm going to show you, here, in fact, I'm going to show you, here, in fact, I'm going to show you, guys a couple of examples why, you know, guys a couple of examples why, you know, guys a couple of examples why, you know, his point kind of does stand when it, his point kind of does stand when it, his point kind of does stand when it, comes to OpenAI is that according to, comes to OpenAI is that according to, comes to OpenAI is that according to, multiple people familiar with OpenAI's, multiple people familiar with OpenAI's, multiple people familiar with OpenAI's, processes, OpenAI scaled back their, processes, OpenAI scaled back their, processes, OpenAI scaled back their, safety efforts, dedicating fewer, safety efforts, dedicating fewer, safety efforts, dedicating fewer, resources and less time to risk, resources and less time to risk, resources and less time to risk, assessments while trying to move fast., assessments while trying to move fast., assessments while trying to move fast., Okay, if you take a look at this article, Okay, if you take a look at this article, Okay, if you take a look at this article, here, it says that, you know, OpenAI, here, it says that, you know, OpenAI, here, it says that, you know, OpenAI, said that, you know, we had more, said that, you know, we had more, said that, you know, we had more, thorough safety testing when it was less, thorough safety testing when it was less, thorough safety testing when it was less, important. the FT report said quoting, important. the FT report said quoting, important. the FT report said quoting, one of their sources stating that when, one of their sources stating that when, one of their sources stating that when, OpenAI was testing their 03 model. Okay, OpenAI was testing their 03 model. Okay, OpenAI was testing their 03 model. Okay, so it's crazy. Okay, this is stuff that, so it's crazy. Okay, this is stuff that, so it's crazy. Okay, this is stuff that, OpenAI is saying. In addition to this, OpenAI is saying. In addition to this, OpenAI is saying. In addition to this, okay, OpenAI also said, and this was in, okay, OpenAI also said, and this was in, okay, OpenAI also said, and this was in, April of 2025, that OpenAI updated its, April of 2025, that OpenAI updated its, April of 2025, that OpenAI updated its, safety policy to say that if a rival, safety policy to say that if a rival, safety policy to say that if a rival, ships a high-risisk model without, ships a high-risisk model without, ships a high-risisk model without, comparable safeguards, OpenAI may just, comparable safeguards, OpenAI may just, comparable safeguards, OpenAI may just, adjust or weaken its own safety, adjust or weaken its own safety, adjust or weaken its own safety, requirements so as to not be left, requirements so as to not be left, requirements so as to not be left, behind. This is from Business Insider, behind. This is from Business Insider, behind. This is from Business Insider, and critics have interpreted this as, and critics have interpreted this as, and critics have interpreted this as, open AAI giving itself wiggle room to, open AAI giving itself wiggle room to, open AAI giving itself wiggle room to, relax safety standards if competitive, relax safety standards if competitive, relax safety standards if competitive, pressure is too high. So this is you, pressure is too high. So this is you, pressure is too high. So this is you, know once again another example of, know once again another example of, know once again another example of, OpenAI doing that. Once again most of, OpenAI doing that. Once again most of, OpenAI doing that. Once again most of, you guys you probably won't remember, you guys you probably won't remember, you guys you probably won't remember, this but I remember this cuz I made a, this but I remember this cuz I made a, this but I remember this cuz I made a, video on it but the OpenAI squad, video on it but the OpenAI squad, video on it but the OpenAI squad, literally in charge of mitigating the, literally in charge of mitigating the, literally in charge of mitigating the, risks of super intelligent AI lost, risks of super intelligent AI lost, risks of super intelligent AI lost, nearly half its members and I think the, nearly half its members and I think the, nearly half its members and I think the, team kind of disbanded. So the like it, team kind of disbanded. So the like it, team kind of disbanded. So the like it, was crazy like the people who were, was crazy like the people who were, was crazy like the people who were, primarily focused on AGI safety and, primarily focused on AGI safety and, primarily focused on AGI safety and, preparedness were you know being, preparedness were you know being, preparedness were you know being, marginalized and they departed. They, marginalized and they departed. They, marginalized and they departed. They, actually left and went to anthropic like, actually left and went to anthropic like, actually left and went to anthropic like, most safety AI researchers from open AI, most safety AI researchers from open AI, most safety AI researchers from open AI, actually went to anthropic. Um I think, actually went to anthropic. Um I think, actually went to anthropic. Um I think, Yan Leer was one of them as well and, Yan Leer was one of them as well and, Yan Leer was one of them as well and, then you know he literally had this, then you know he literally had this, then you know he literally had this, whole you know Twitter post about you, whole you know Twitter post about you, whole you know Twitter post about you, know OpenAI not being safe and there was, know OpenAI not being safe and there was, know OpenAI not being safe and there was, an entire Twitter thread. It was pretty, an entire Twitter thread. It was pretty, an entire Twitter thread. It was pretty, crazy. And then there was also a, crazy. And then there was also a, crazy. And then there was also a, whistleblower and they basically did an, whistleblower and they basically did an, whistleblower and they basically did an, open letter. There was a current letter, open letter. There was a current letter, open letter. There was a current letter, from former OPAI employees criticizing, from former OPAI employees criticizing, from former OPAI employees criticizing, you know their habits and you know, you know their habits and you know, you know their habits and you know, stating that you know the company has, stating that you know the company has, stating that you know the company has, prioritized rapid growth over ethical, prioritized rapid growth over ethical, prioritized rapid growth over ethical, considerations and adequate safety, considerations and adequate safety, considerations and adequate safety, measures and they highlight the lack of, measures and they highlight the lack of, measures and they highlight the lack of, transparency in the company's decision-m, transparency in the company's decision-m, transparency in the company's decision-m, processes it's pretty crazy and you know, processes it's pretty crazy and you know, processes it's pretty crazy and you know, of course from the outside it's hard to, of course from the outside it's hard to, of course from the outside it's hard to, see but when you have people leaving the, see but when you have people leaving the, see but when you have people leaving the, company when you've got people you know, company when you've got people you know, company when you've got people you know, stating that look this company is just, stating that look this company is just, stating that look this company is just, know not doing what it needs to do, know not doing what it needs to do, know not doing what it needs to do, safety and then of course the ex policy, safety and then of course the ex policy, safety and then of course the ex policy, lead has criticized the company for, lead has criticized the company for, lead has criticized the company for, rewriting the AI safety history. You, rewriting the AI safety history. You, rewriting the AI safety history. You, have to start to you know notice a, have to start to you know notice a, have to start to you know notice a, pattern here because this has happened, pattern here because this has happened, pattern here because this has happened, again and again and again and the former, again and again and again and the former, again and again and again and the former, open AAI policy researcher Miles, open AAI policy researcher Miles, open AAI policy researcher Miles, Brundage publicly criticized OpenAI for, Brundage publicly criticized OpenAI for, Brundage publicly criticized OpenAI for, rewriting history in a new document, rewriting history in a new document, rewriting history in a new document, about its AI safety philosophy. So you, about its AI safety philosophy. So you, about its AI safety philosophy. So you, have to understand that like his point, have to understand that like his point, have to understand that like his point, about making the fact that you know this, about making the fact that you know this, about making the fact that you know this, you know AI development cycle that we're, you know AI development cycle that we're, you know AI development cycle that we're, going on and you know pushing forward in, going on and you know pushing forward in, going on and you know pushing forward in, frontier Frontier Frontier there is of, frontier Frontier Frontier there is of, frontier Frontier Frontier there is of, course a large concern because it's not, course a large concern because it's not, course a large concern because it's not, just one person that has come out and, just one person that has come out and, just one person that has come out and, said that OpenAI isn't acting safely., said that OpenAI isn't acting safely., said that OpenAI isn't acting safely., It's been multiple different occasions, It's been multiple different occasions, It's been multiple different occasions, and many different OpenAI employees. Now, and many different OpenAI employees. Now, and many different OpenAI employees. Now, uh the company not the company the, uh the company not the company the, uh the company not the company the, organization they did respond to this, organization they did respond to this, organization they did respond to this, you know of course outburst and outrage, you know of course outburst and outrage, you know of course outburst and outrage, and you know going on stage and stuff, and you know going on stage and stuff, and you know going on stage and stuff, and this was an interesting question, and this was an interesting question, and this was an interesting question, because most people don't consider this, because most people don't consider this, because most people don't consider this, when discussing AI safety. So this, when discussing AI safety. So this, when discussing AI safety. So this, question is the prisoner's dilemma, question is the prisoner's dilemma, question is the prisoner's dilemma, option one which is to cooperate. Okay, option one which is to cooperate. Okay, option one which is to cooperate. Okay, because the person basically says, because the person basically says, because the person basically says, you've got China and you know, are you, you've got China and you know, are you, you've got China and you know, are you, going to stop China's AI because if you, going to stop China's AI because if you, going to stop China's AI because if you, stop the United States development of, stop the United States development of, stop the United States development of, AI, you know, we're just going to slow, AI, you know, we're just going to slow, AI, you know, we're just going to slow, down and China's going to rush ahead, down and China's going to rush ahead, down and China's going to rush ahead, anyways. And they said, we're calling, anyways. And they said, we're calling, anyways. And they said, we're calling, for a permanent global ban, keyword, for a permanent global ban, keyword, for a permanent global ban, keyword, global ban, on the development of, global ban, on the development of, global ban, on the development of, artificial super intelligence. Nobody, artificial super intelligence. Nobody, artificial super intelligence. Nobody, should build it and we'd be happy to, should build it and we'd be happy to, should build it and we'd be happy to, work with Chinese citizens and speakers., work with Chinese citizens and speakers., work with Chinese citizens and speakers., But the prisoners dilemma is the fact, But the prisoners dilemma is the fact, But the prisoners dilemma is the fact, that like how do you ensure that both, that like how do you ensure that both, that like how do you ensure that both, companies or both countries are going to, companies or both countries are going to, companies or both countries are going to, slow down because if you decide as a, slow down because if you decide as a, slow down because if you decide as a, country to slow down on AI research and, country to slow down on AI research and, country to slow down on AI research and, the other country doesn't then you're, the other country doesn't then you're, the other country doesn't then you're, going to be in a situation where I don't, going to be in a situation where I don't, going to be in a situation where I don't, want to say you're going to have to bend, want to say you're going to have to bend, want to say you're going to have to bend, the knee to them but they are going to, the knee to them but they are going to, the knee to them but they are going to, have a tremendous advantage against you, have a tremendous advantage against you, have a tremendous advantage against you, in terms of just like raw intelligence, in terms of just like raw intelligence, in terms of just like raw intelligence, which is something that the other, which is something that the other, which is something that the other, country doesn't want them to have. So, country doesn't want them to have. So, country doesn't want them to have. So, the only good good like scenario is if, the only good good like scenario is if, the only good good like scenario is if, they both cooperate. Okay. But right now, they both cooperate. Okay. But right now, they both cooperate. Okay. But right now, we're in the worst scenario which is, we're in the worst scenario which is, we're in the worst scenario which is, where both countries are just racing, where both countries are just racing, where both countries are just racing, ahead because you know they want to be, ahead because you know they want to be, ahead because you know they want to be, first and if they are first they gain a, first and if they are first they gain a, first and if they are first they gain a, massive advantage and that massive, massive advantage and that massive, massive advantage and that massive, advantage is going to probably last, advantage is going to probably last, advantage is going to probably last, forever. And of course you can see, forever. And of course you can see, forever. And of course you can see, someone else asked the question. So then, someone else asked the question. So then, someone else asked the question. So then, you'll let just China develop it first, you'll let just China develop it first, you'll let just China develop it first, and then we're all going to be screwed., and then we're all going to be screwed., and then we're all going to be screwed., The US is where all leading development, The US is where all leading development, The US is where all leading development, is. So we have to stop it first. Once we, is. So we have to stop it first. Once we, is. So we have to stop it first. Once we, stop it here, then we're going to, you, stop it here, then we're going to, you, stop it here, then we're going to, you, know, do everything in our power to help, know, do everything in our power to help, know, do everything in our power to help, the Chinese people stop it. I mean, it's, the Chinese people stop it. I mean, it's, the Chinese people stop it. I mean, it's, it's pretty pretty hard. Like, I'm not, it's pretty pretty hard. Like, I'm not, it's pretty pretty hard. Like, I'm not, going to say it's it's not, you know, going to say it's it's not, you know, going to say it's it's not, you know, possible, but it's pretty pretty hard., possible, but it's pretty pretty hard., possible, but it's pretty pretty hard., Now, you have to understand as well, Now, you have to understand as well, Now, you have to understand as well, something I forgot to add to this is, something I forgot to add to this is, something I forgot to add to this is, that these people aren't the only people, that these people aren't the only people, that these people aren't the only people, calling for uh, you know, AI safety., calling for uh, you know, AI safety., calling for uh, you know, AI safety., It's crazy that like there are actually, It's crazy that like there are actually, It's crazy that like there are actually, billionaires calling for AI safety. Now, billionaires calling for AI safety. Now, billionaires calling for AI safety. Now, I have a video coming on this very soon., I have a video coming on this very soon., I have a video coming on this very soon., It's a video about billionaires and, It's a video about billionaires and, It's a video about billionaires and, millionaires, multi-millionaires calling, millionaires, multi-millionaires calling, millionaires, multi-millionaires calling, for AI safety. I'm going to actually put, for AI safety. I'm going to actually put, for AI safety. I'm going to actually put, up the article right now. I forgot to, up the article right now. I forgot to, up the article right now. I forgot to, add it to this video, so I'm going to, add it to this video, so I'm going to, add it to this video, so I'm going to, quickly do a detour. But there was, quickly do a detour. But there was, quickly do a detour. But there was, another open letter only a few days ago., another open letter only a few days ago., another open letter only a few days ago., Time is running out. A new open letter, Time is running out. A new open letter, Time is running out. A new open letter, calls for a ban on super intelligent AI, calls for a ban on super intelligent AI, calls for a ban on super intelligent AI, development. And it's crazy because, development. And it's crazy because, development. And it's crazy because, you've got, you know, the five noble, you've got, you know, the five noble, you've got, you know, the five noble, laurates, so-called godfathers of AI, laurates, so-called godfathers of AI, laurates, so-called godfathers of AI, Steve Wnjak, Steve Bannon, a close ally, Steve Wnjak, Steve Bannon, a close ally, Steve Wnjak, Steve Bannon, a close ally, of President Trump, Paulo Benati, an, of President Trump, Paulo Benati, an, of President Trump, Paulo Benati, an, adviser to the Pope. I mean, you've got, adviser to the Pope. I mean, you've got, adviser to the Pope. I mean, you've got, a serious list of people that are, a serious list of people that are, a serious list of people that are, causing calling, you know, for this, causing calling, you know, for this, causing calling, you know, for this, development to stop. And the open, development to stop. And the open, development to stop. And the open, consensus basically says that we need a, consensus basically says that we need a, consensus basically says that we need a, broad scientific consensus that it will, broad scientific consensus that it will, broad scientific consensus that it will, be done safely, controllably, and we, be done safely, controllably, and we, be done safely, controllably, and we, also need a strong public buy in. So, also need a strong public buy in. So, also need a strong public buy in. So, the letter was coordinated and published, the letter was coordinated and published, the letter was coordinated and published, by the future of life institute, which, by the future of life institute, which, by the future of life institute, which, is a nonprofit that in 2023 also, is a nonprofit that in 2023 also, is a nonprofit that in 2023 also, published an open letter calling for a, published an open letter calling for a, published an open letter calling for a, six-month pause on the development of, six-month pause on the development of, six-month pause on the development of, powerful AI systems. And remember this, powerful AI systems. And remember this, powerful AI systems. And remember this, letter was widely circulated. The letter, letter was widely circulated. The letter, letter was widely circulated. The letter, did not achieve its goal. So you have to, did not achieve its goal. So you have to, did not achieve its goal. So you have to, remember that like this isn't just, you, remember that like this isn't just, you, remember that like this isn't just, you, know, people that are just AI obsessed, know, people that are just AI obsessed, know, people that are just AI obsessed, calling for the stopping of the, calling for the stopping of the, calling for the stopping of the, development. This is like a global, development. This is like a global, development. This is like a global, movement that is slowly gaining, movement that is slowly gaining, movement that is slowly gaining, traction. You've got billionaires, traction. You've got billionaires, traction. You've got billionaires, multi-millionaires calling for this., multi-millionaires calling for this., multi-millionaires calling for this., They started in 2023. They caused, you, They started in 2023. They caused, you, They started in 2023. They caused, you, know, called for, you know, a pause, a, know, called for, you know, a pause, a, know, called for, you know, a pause, a, six-month pause ages ago. a new open, six-month pause ages ago. a new open, six-month pause ages ago. a new open, letter, you know, around two weeks ago, letter, you know, around two weeks ago, letter, you know, around two weeks ago, a week ago, was also put out and they, a week ago, was also put out and they, a week ago, was also put out and they, called for once again a complete, called for once again a complete, called for once again a complete, slowdown. And now, of course, you've got, slowdown. And now, of course, you've got, slowdown. And now, of course, you've got, this organization pushing forward, this organization pushing forward, this organization pushing forward, calling for a slowdown. So, it's crazy, calling for a slowdown. So, it's crazy, calling for a slowdown. So, it's crazy, because I wonder what the breaking point, because I wonder what the breaking point, because I wonder what the breaking point, is going to be. Now, the crazy thing, is going to be. Now, the crazy thing, is going to be. Now, the crazy thing, about all of this is that I personally, about all of this is that I personally, about all of this is that I personally, believe that they are going to get, believe that they are going to get, believe that they are going to get, increasing amount of support. If you, increasing amount of support. If you, increasing amount of support. If you, have not paid attention to the sentiment, have not paid attention to the sentiment, have not paid attention to the sentiment, on social media surrounding artificial, on social media surrounding artificial, on social media surrounding artificial, intelligence, you might be in a bubble., intelligence, you might be in a bubble., intelligence, you might be in a bubble., Okay? And not an AI stock market bubble, Okay? And not an AI stock market bubble, Okay? And not an AI stock market bubble, but a bubble of what people's opinions, but a bubble of what people's opinions, but a bubble of what people's opinions, of AI actually are. Most people outside, of AI actually are. Most people outside, of AI actually are. Most people outside, of the AI sphere do not like artificial, of the AI sphere do not like artificial, of the AI sphere do not like artificial, intelligence because it doesn't serve, intelligence because it doesn't serve, intelligence because it doesn't serve, their best interest. And I've spoken to, their best interest. And I've spoken to, their best interest. And I've spoken to, people who aren't in this quote unquote, people who aren't in this quote unquote, people who aren't in this quote unquote, AI bubble, the kind of people who watch, AI bubble, the kind of people who watch, AI bubble, the kind of people who watch, these videos, and they really hate AI., these videos, and they really hate AI., these videos, and they really hate AI., And you have to understand that like, And you have to understand that like, And you have to understand that like, organizations like stop AI are only, organizations like stop AI are only, organizations like stop AI are only, going to gain followers over time, going to gain followers over time, going to gain followers over time, because most people just have a really a, because most people just have a really a, because most people just have a really a, bone to pick with AI. Like for example, bone to pick with AI. Like for example, bone to pick with AI. Like for example, this one right here. You can see this, this one right here. You can see this, this one right here. You can see this, user says, "I hate AI with a passion., user says, "I hate AI with a passion., user says, "I hate AI with a passion., It's an unregulated, unconsidered human, It's an unregulated, unconsidered human, It's an unregulated, unconsidered human, ingenuity wrecking resource sucking, ingenuity wrecking resource sucking, ingenuity wrecking resource sucking, climate destroying, theft machine being, climate destroying, theft machine being, climate destroying, theft machine being, pushed by short-sighted, greedy, pushed by short-sighted, greedy, pushed by short-sighted, greedy, individuals putting product and profit, individuals putting product and profit, individuals putting product and profit, over people and planet. But it turns out, over people and planet. But it turns out, over people and planet. But it turns out, I can hate it more. Every time I see, I can hate it more. Every time I see, I can hate it more. Every time I see, posts like this, they have tons and tons, posts like this, they have tons and tons, posts like this, they have tons and tons, of support. People all saying the same, of support. People all saying the same, of support. People all saying the same, thing. Now, it doesn't mean AI is not, thing. Now, it doesn't mean AI is not, thing. Now, it doesn't mean AI is not, going to come because people hate it., going to come because people hate it., going to come because people hate it., I'm just saying that the overwhelming, I'm just saying that the overwhelming, I'm just saying that the overwhelming, public sentiment, if the overwhelming, public sentiment, if the overwhelming, public sentiment, if the overwhelming, public sentiment is one of, you know, public sentiment is one of, you know, public sentiment is one of, you know, one of disgust, then maybe in some areas, one of disgust, then maybe in some areas, one of disgust, then maybe in some areas, AI might not be as, you know, popular as, AI might not be as, you know, popular as, AI might not be as, you know, popular as, we might think. And you have to, we might think. And you have to, we might think. And you have to, understand that at the end of the day, understand that at the end of the day, understand that at the end of the day, you know, many use cases and I think of, you know, many use cases and I think of, you know, many use cases and I think of, course it's important to quickly make a, course it's important to quickly make a, course it's important to quickly make a, distinction because most people that are, distinction because most people that are, distinction because most people that are, saying they hate AI, of course they're, saying they hate AI, of course they're, saying they hate AI, of course they're, not talking about, you know, the, not talking about, you know, the, not talking about, you know, the, algorithms to optimize roots and, algorithms to optimize roots and, algorithms to optimize roots and, optimize the algorithms that give you, optimize the algorithms that give you, optimize the algorithms that give you, your, you know, favorite product or, your, you know, favorite product or, your, you know, favorite product or, whatever. They're talking, of course, whatever. They're talking, of course, whatever. They're talking, of course, about generative AI mainly because it's, about generative AI mainly because it's, about generative AI mainly because it's, replacing humans on many different, replacing humans on many different, replacing humans on many different, levels. And you can see right here, levels. And you can see right here, levels. And you can see right here, someone said that you hate AI because, someone said that you hate AI because, someone said that you hate AI because, it's going to replace you. Actually, I, it's going to replace you. Actually, I, it's going to replace you. Actually, I, hate AI because it's built of stolen, hate AI because it's built of stolen, hate AI because it's built of stolen, data, which is kind of true. It breaks, data, which is kind of true. It breaks, data, which is kind of true. It breaks, copyright laws, kind of true. Poisoning, copyright laws, kind of true. Poisoning, copyright laws, kind of true. Poisoning, the planet and black communities, kind, the planet and black communities, kind, the planet and black communities, kind, of true. Raising our electricity bills, of true. Raising our electricity bills, of true. Raising our electricity bills, spreading information, making people, spreading information, making people, spreading information, making people, sue. I mean, all of these things are, sue. I mean, all of these things are, sue. I mean, all of these things are, kind of true. And I've done research on, kind of true. And I've done research on, kind of true. And I've done research on, all of this stuff. So, I mean, the the, all of this stuff. So, I mean, the the, all of this stuff. So, I mean, the the, gripes that people have with AI is it's, gripes that people have with AI is it's, gripes that people have with AI is it's, it's it's true. Like, it is true. It's, it's it's true. Like, it is true. It's, it's it's true. Like, it is true. It's, not like people just saying, you know, not like people just saying, you know, not like people just saying, you know, oh, AI is bad because this and that., oh, AI is bad because this and that., oh, AI is bad because this and that., I've got to be honest like even as, I've got to be honest like even as, I've got to be honest like even as, someone who's in AI a lot of the points, someone who's in AI a lot of the points, someone who's in AI a lot of the points, that they make if you do extensive, that they make if you do extensive, that they make if you do extensive, research you'll see that you know it's, research you'll see that you know it's, research you'll see that you know it's, fair enough like these points are fair, fair enough like these points are fair, fair enough like these points are fair, enough and it's going to be interesting, enough and it's going to be interesting, enough and it's going to be interesting, to see how AI because it's so, to see how AI because it's so, to see how AI because it's so, proliferate at the moment like it's so, proliferate at the moment like it's so, proliferate at the moment like it's so, like basically in everything at the, like basically in everything at the, like basically in everything at the, moment how that's going to you know how, moment how that's going to you know how, moment how that's going to you know how, companies are going to manage this, companies are going to manage this, companies are going to manage this, moving forward and um one of those you, moving forward and um one of those you, moving forward and um one of those you, know you know things that we keep saying, know you know things that we keep saying, know you know things that we keep saying, we keep seeing is that you know people, we keep seeing is that you know people, we keep seeing is that you know people, are calling for AI safety and people are, are calling for AI safety and people are, are calling for AI safety and people are, now hating AI when they notice that, now hating AI when they notice that, now hating AI when they notice that, there is AI in almost any company like, there is AI in almost any company like, there is AI in almost any company like, is there going to be continued AI, is there going to be continued AI, is there going to be continued AI, adoption because you know look here it, adoption because you know look here it, adoption because you know look here it, was Vogue's August issue has begun to, was Vogue's August issue has begun to, was Vogue's August issue has begun to, use AI models and this person said f you, use AI models and this person said f you, use AI models and this person said f you, AI I hate it AI in any creative field, AI I hate it AI in any creative field, AI I hate it AI in any creative field, yada yada yada f Google you know these, yada yada yada f Google you know these, yada yada yada f Google you know these, people have tons of support and then I'm, people have tons of support and then I'm, people have tons of support and then I'm, also seeing as well that I don't like, also seeing as well that I don't like, also seeing as well that I don't like, either company but this is the potential, either company but this is the potential, either company but this is the potential, biggest middle finger to Coca-Cola they, biggest middle finger to Coca-Cola they, biggest middle finger to Coca-Cola they, could possibly receive for generating AI, could possibly receive for generating AI, could possibly receive for generating AI, ads and if you aren't familiar with what, ads and if you aren't familiar with what, ads and if you aren't familiar with what, that is referring to Coca-Cola basically, that is referring to Coca-Cola basically, that is referring to Coca-Cola basically, released a ad for Christmas and it was, released a ad for Christmas and it was, released a ad for Christmas and it was, largely produced by AI and that ad has, largely produced by AI and that ad has, largely produced by AI and that ad has, received so much backlash it is, received so much backlash it is, received so much backlash it is, absolutely crazy. So I think you guys, absolutely crazy. So I think you guys, absolutely crazy. So I think you guys, can understand the entire picture I'm, can understand the entire picture I'm, can understand the entire picture I'm, trying to paint here. You have these, trying to paint here. You have these, trying to paint here. You have these, people that trying to raise awareness, people that trying to raise awareness, people that trying to raise awareness, about the fact that look AI is pretty, about the fact that look AI is pretty, about the fact that look AI is pretty, pretty dangerous and it could in theory, pretty dangerous and it could in theory, pretty dangerous and it could in theory, you know kill everyone on Earth. That is, you know kill everyone on Earth. That is, you know kill everyone on Earth. That is, a real real scenario. I mean I might, a real real scenario. I mean I might, a real real scenario. I mean I might, have some clips from the godfathers of, have some clips from the godfathers of, have some clips from the godfathers of, AI and they do., AI and they do., AI and they do., &gt;&gt; So open AI was set up with a big, &gt;&gt; So open AI was set up with a big, &gt;&gt; So open AI was set up with a big, emphasis on safety. Um its primary, emphasis on safety. Um its primary, emphasis on safety. Um its primary, objective was to develop artificial, objective was to develop artificial, objective was to develop artificial, general intelligence and ensure that it, general intelligence and ensure that it, general intelligence and ensure that it, was safe., was safe., was safe., Um one of my former students in Yutska, Um one of my former students in Yutska, Um one of my former students in Yutska, was the chief scientist. Um, and over, was the chief scientist. Um, and over, was the chief scientist. Um, and over, time it turned out that Sam Alman was, time it turned out that Sam Alman was, time it turned out that Sam Alman was, much less concerned with safety than, much less concerned with safety than, much less concerned with safety than, with profits. And I think that's um, with profits. And I think that's um, with profits. And I think that's um, unfortunate, unfortunate, unfortunate, [Music], [Music], [Music], &gt;&gt; but you have to understand that like, &gt;&gt; but you have to understand that like, &gt;&gt; but you have to understand that like, this is seeming to be seeming, at least, this is seeming to be seeming, at least, this is seeming to be seeming, at least, to me, to be a movement that's going to, to me, to be a movement that's going to, to me, to be a movement that's going to, gain more and more traction over time., gain more and more traction over time., gain more and more traction over time., As number one, you've got people that, As number one, you've got people that, As number one, you've got people that, hate AI because it's going to replace, hate AI because it's going to replace, hate AI because it's going to replace, them and ruin tons of creative fields, them and ruin tons of creative fields, them and ruin tons of creative fields, and, you know, change the economy in, and, you know, change the economy in, and, you know, change the economy in, ways that most people can't see coming., ways that most people can't see coming., ways that most people can't see coming., And on the other side, you've got people, And on the other side, you've got people, And on the other side, you've got people, that realize that look, if AGI does, that realize that look, if AGI does, that realize that look, if AGI does, happen, there is a real existential, happen, there is a real existential, happen, there is a real existential, risk. And even Samman himself did, risk. And even Samman himself did, risk. And even Samman himself did, actually say that AGI is an extential, actually say that AGI is an extential, actually say that AGI is an extential, existential risk and he still you know, existential risk and he still you know, existential risk and he still you know, stands by this point today. So it's, stands by this point today. So it's, stands by this point today. So it's, crazy. I think it's I think it's really, crazy. I think it's I think it's really, crazy. I think it's I think it's really, crazy. I think it's really interesting, crazy. I think it's really interesting, crazy. I think it's really interesting, and let me know what you guys think, and let me know what you guys think, and let me know what you guys think, about this because I think this is one, about this because I think this is one, about this because I think this is one, of the most interesting conversations. I, of the most interesting conversations. I, of the most interesting conversations. I, think there are going to be many more, think there are going to be many more, think there are going to be many more, scenarios where there's going to be, scenarios where there's going to be, scenarios where there's going to be, cases like this where individuals start, cases like this where individuals start, cases like this where individuals start, rioting, people start saying that look, rioting, people start saying that look, rioting, people start saying that look, we want to ban AI, we want to pause AI., we want to ban AI, we want to pause AI., we want to ban AI, we want to pause AI., I think it's going to be pretty crazy., I think it's going to be pretty crazy., I think it's going to be pretty crazy., But let me know what you guys think.
