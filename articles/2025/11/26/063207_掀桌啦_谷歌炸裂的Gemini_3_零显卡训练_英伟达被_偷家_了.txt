Timestamp: 2025-11-26T06:32:07.338434
Title: 掀桌啦！谷歌炸裂的Gemini 3 零显卡训练，英伟达被“偷家”了？
URL: https://youtube.com/watch?v=qF0Qol7EkAw&si=3Y3J9EqTAqSrtATW
Status: success
Duration: 9:15

Description:
### 核心思想摘要

#### I. 核心架构对比：流水线 vs. 超级厨房 (TPU vs. GPU)
*   **英伟达 GPU (超级厨房):** 一种通用型芯片，拥有数千个“全能厨师”。其传统并行计算架构在处理AI任务时，需要频繁往返于内存（“冰箱”）进行数据存取，导致大量时间与能量浪费在**数据搬运**上，效率低、功耗高、发热大。
*   **谷歌 TPU (流水线):** 一种专为AI矩阵运算设计的ASIC芯片。其核心是**“脉动矩阵”（Systolic Array）**架构，数据像在流水线上传递一样，在一个个计算单元间流动并被处理，无需频繁返回内存。这种“数据复用”机制极大地提升了计算效率和能源效率。

#### II. 谷歌的双重“降维打击”
*   **1. 物理层面 (能效打击):** TPU的流水线架构显著降低了能耗和散热需求。在训练Gemini级别的大模型时，这种能效优势可以节省天文数字般的电费和运营开支。
*   **2. 商业层面 (成本打击):** 谷歌通过自研TPU，成功绕开了英伟达高达74%的巨额毛利（即“技术溢价”或“过路费”）。这意味着谷歌能以接近制造成本的价格运行其AI模型，从而在性价比上对依赖英伟达的对手（如OpenAI）形成巨大优势。

#### III. 谷歌的商业策略：“把肉烂在锅里”
*   **不卖芯片，卖算力:** 谷歌不直接对外销售TPU芯片，而是通过**谷歌云 (Google Cloud)** 将其作为算力服务出租。
*   **旗舰模型做广告:** 利用其性能卓越的**Gemini模型**作为TPU能力的最佳证明，向市场展示其硬件平台的强大实力。
*   **生态深度绑定:** 这一策略成功吸引了Anthropic、Midjourney等顶级AI公司入驻谷歌云，将最强的模型、最高效的算力与云服务深度绑定，以此抢占云市场份额。

#### IV. 英伟达的终极护城河：CUDA
*   **坚不可摧的软件壁垒:** 尽管TPU在硬件和成本上优势巨大，但英伟达依然占据市场绝对主导地位（约80%）。其关键在于经营了超过15年的**CUDA软件生态系统**。
*   **强大的用户锁定:** CUDA是一个成熟、强大且开发者依赖度极高的平台，构成了英伟达最坚固的“护城河”，极大地增加了用户迁移到其他硬件平台的难度和成本。

---

### 核心观点
谷歌TPU凭借其在硬件能效和商业成本上的双重降维打击向英伟达发起挑战，但英伟达依靠其强大且难以替代的CUDA软件生态构筑了最坚固的护城河。

---

### 内容的总体框架
本文采用**对比分析框架**，从**技术架构、商业成本、生态策略**三个维度，深入剖析了谷歌（TPU）与英伟达（GPU）在AI芯片领域的战略博弈和各自的核心优劣势。

---

### 核心概念图

<Mermaid_Diagram>
graph TD
    subgraph "谷歌生态系统 (Google Ecosystem)"
        direction LR
        A["谷歌 Google"] -- "自研" --> B["TPU 芯片"];
        B -- "采用" --> C["脉动矩阵架构 (流水线)"];
        C -- "实现" --> D["高能效 & 数据复用"];
        A -- "通过TPU训练" --> E["Gemini 大模型"];
        E -- "作为顶级广告" --> F["谷歌云 Google Cloud"];
        B -- "通过云提供算力" --> F;
        G["Anthropic & Midjourney <br> (大客户)"] -- "被吸引并使用" --> F;
    end

    subgraph "英伟达生态系统 (Nvidia Ecosystem)"
        direction LR
        H["英伟达 Nvidia"] -- "研发" --> I["GPU 芯片"];
        I -- "采用" --> J["并行计算架构 (超级厨房)"];
        J -- "导致" --> K["高能耗 & 数据搬运瓶颈"];
        H -- "构建核心优势" --> L["CUDA 软件生态"];
        L -- "形成" --> M["强大的护城河 <br> (用户锁定)"];
        I -- "市场主导产品" --> L
    end
    
    subgraph "核心竞争 (The Core Competition)"
        direction TD
        D -- "物理&商业降维打击" --> K;
        M -- "软件生态壁垒" --> B;
    end

    style A fill:#4285F4,stroke:#333,stroke-width:2px,color:#fff
    style B fill:#DB4437,stroke:#333,stroke-width:2px,color:#fff
    style E fill:#0F9D58,stroke:#333,stroke-width:2px,color:#fff
    style F fill:#F4B400,stroke:#333,stroke-width:2px,color:#000
    style G fill:#E0E0E0,stroke:#333,stroke-width:1px
    style C fill:#d6e6ff,stroke:#4285F4,stroke-width:1px
    style D fill:#f8d7da,stroke:#DB4437,stroke-width:1px
    
    style H fill:#76B900,stroke:#333,stroke-width:2px,color:#fff
    style I fill:#343434,stroke:#333,stroke-width:2px,color:#fff
    style L fill:#A4C639,stroke:#333,stroke-width:2px,color:#000
    style M fill:#E0E0E0,stroke:#333,stroke-width:1px
    style J fill:#e0e0e0,stroke:#343434,stroke-width:1px
    style K fill:#f8d7da,stroke:#DB4437,stroke-width:1px

    linkStyle 8 stroke:#DB4437,stroke-width:2px,stroke-dasharray: 5 5;
    linkStyle 9 stroke:#76B900,stroke-width:2px,stroke-dasharray: 5 5;
</Mermaid_Diagram>

Content:
要运用最好的模特性的最重要的模特性不,我们就用TPU谷歌发布了GEM9SREY爸爸13项AI机软测试性能调打Chat GptBasco和Automand都做不住了关键是训练这个史上最强的AI模型谷歌一颗音伪达的GPU都没有用谷歌自己的TPU芯片跟音伪达的GPU核心差异是什么谷歌接下来的TPU策略是什么样子误伪达的互程和还稳功吗以上这个问题这期视频地毫要跟你白扯清楚那么我们马上开始你可以把音伪达的GPU想象成一个塞满了成千上万个厨师的超级大厨房这帮厨师呢,那是相当的权能吗我手能做图形渲染右手能做科学计算而且还能够跑AI训练但是这个厨房的工作流程有一个巨大的霸格简单来说就是五个字类似在路上什么意思呢我来给你解释一下在GPU的这个传统的构架里每次计算这几天个厨师都要整齐化一的走这样一个流程首先听到指令然后几千个人同时冲向兵贵也就是内存对吧,拿出一个冲跑回案板切一刀然后跑回去把冲放回冰箱我手要切第二刀那就再冲向冰箱把冲拿出来切完再跑回去听着是不是特别纯但这其实就是GPU并行工作的原理这枪厨师好像并没有在切菜大部分的时间实际是在厨房里面折返跑就导致这些英伟的GPU厨房里的大厨累的是满头大汗,热量产生巨大电表走得飞快但真正切菜的时间其实只有那么一小会儿这就是为什么数据中心的GPU风扇呼呼转电费层层网上涨因为大部分的能量其实都浪费在了数据颁运上面接下来谷歌的GPU就登场了GPU你可以把它理解成是一个严重的偏科生它继不会炫耍画面也不能打游戏它从诞生的那天起就只为了干一件事情就是做矩阵音算也就是AI训练里面核心的一个单元操作既然只能干一件事情谷歌就给它设计了一种完全不同的构架这个名字听起来非常的玄患叫做卖动矩阵朋友们千万别被这个名字给吓住这其实不是什么高生的词会我说得简单一点它其实就是把因为打GPU的全能大厨变成了一条极度偷懒的流水线我来给你稍微解释一下在TPU的世界里它是这么干活的它是一排大厨排成一条线低约大厨切一刀它不往冰箱里跑它直接顺手低给旁边的第二个大厨第二个大厨再切一刀然后低给旁边的第三个这个数据就像血液在血管里流动一样或者像心跳一样它在卖动流进去之后一步接一步的被处理中间根本不需要再回到内存里面不需要跑腿那叫数据复用这意味着什么意味着同样是算一刀提因为打的大厨跑了10趟冰箱累的是器船需虚但骨骼的流水线大厨站在原地动动手这就给拔了我以说骨骼的TPU相对于因为打的GPU它有一个核心的优势就是结能这个时候你可能会说这省着点力气有啥用反正都能算出来而且因为打可能算得还更快对不对那么在单一芯片的时候省的这点电可能确实是维启足的但是如果你像骨骼那样把极万甚至几十万的芯片连在一起日夜夜的跑几个月去训练GM93的时候这个仗单算起来可能就连下人了脚跑腿就意味着手发热手发热就意味着手用空调手用空调就意味着省下了天价数字的电费这就是骨骼跟英伟达教板的低个底气物理层面的降为打击而且这并不单单是省的电费更要命的是英伟达还省下了那笔本来要交给老黄的巨额保护费接下来咱们算算钱的仗你就知道为什么花儿钱的马上现在看着英伟达的财报心里其实是在打鼓咱们刚才算了一下电费这个是运营开支就是Operational Expanditure我们现在再来看一下硬件成本也就是 Capital Expanditure我们看以伟达的财报最亮眼的是吗就是它的毛利率老黄现在的毛利率是多少今人74%左右而且我看了一下就是从Challenge PT开始爆发AI哲报浪潮起来之后因为达芯片的利润率基本上就没有下过70%这是什么概念意味着微软Mata样化讯职的公司美花100块钱买因为达的卡只有26块钱其实是真正付给了台积电和物料成本剩下74块钱都是交给老黄的技术一架你可以把它理解为AI时代的过路费想上AI这趟车你就带交这笔钱这就是因为达从这个数据上面你确实能看到因为达在市场上的统治里因为只有你的产品足够好你才能卖的起价但是谷歌用自己的TPU这笔账对他们来说就完全变了你看谷歌这个芯片是自演的它只需要炒台积电代工它支付就是研发成本和制造成本那么这74%的巨额利润谷歌一分钱都不用讨它全都留在自己的兜里面你想这已经一出这就是一个巨大的一个插战如果说你是谷歌你要训练JM9 III如果你用因为打的显卡你就要顶着74%的一价在稍前而如果你用自己研发的TPU你就是贴着成本价在跑非常非常地划算这就解释了当时在JM9 Flash 2.0出来的时候谷歌说它的性价比是GPT-SO的24倍不是因为谷歌的算法突然开了挂而是因为它在物理和商业层面同时对Obeni造成了一次降为大级那么聊到这肯定会有朋友会问谷歌的TPU正乡便宜又好用谷歌为什么不直接把它拿出来像因为打的那样子卖显卡岂不是转翻了这个其实就是谷歌最积贼也是最高明的地方谷歌的策略叫做把肉烂在锅里你看因为打它是卖产子的所以说它希望大家封宽的买它的产子所以它就要把这个产子做得特别的通用谁都能用但是谷歌不一样它不卖TPU芯片它只卖TPU的这个算力你想用TPU呢没问题你就要来谷歌云谷歌CLOB来租这个夫妻这招太狠了低它省去了建立庞大销售渠道的这个麻烦也不用去试配千七百怪的客户环境第二也就是最重要的阿仙用自家的GEM9 III给TPU打了个非常想量的广告你想想GEM9 III这次如此的出圈性能调大一重的大模型对吧它背后全都是靠TPU来支撑来训练的这就等于谷歌亲自下场证明了看用我的TPU能训练出这么牛逼的模型谷歌这个模型给自家的TPU背书你想想那些想训练顶尖模型的客户比如说Mid-Journey比如说Athropec对吧它就很有可能都被吸引到谷歌的云品来上去试试也证明了你看最近Athropec不是一口气要了谷歌100万颗TPU吗而Mid-Journey也宣布了要用谷歌的TPU进行训练和推理这种大单子会让谷歌云的试战力撑撑的往上找谷歌说白了就是拿自家最强的模型当广告把客户算力还有云服务全部都绑在一起那么说到这里你是不是感觉因为大家要完蛋了谷歌要统一AI的杜良横了且慢虽然说TPU在硬件和成本上确实是银麻了但是在现实世界里音伟达依然占据着8%的实作用的市场分子了为什么因为因为打的手里还有最后一道也就是最肩部可摧的探息之强到强的存在党主了无数想从音伟达阵营叛逃到谷歌阵营的人到强的名字就叫Kuda他不仅仅是一个软件他是过去15年音伟达的成续一行一行带马对出来的强大护城河只要知道强不到音伟达的帝国就依然稳固但是呢谷歌现在正拿着一把产子想要挖开音伟达的强角那么这把产子是什么他能否替谷歌挖开音伟达的强角连在电源来播我们下期接着聊我是D我们下期每谷驾驶仓再见
