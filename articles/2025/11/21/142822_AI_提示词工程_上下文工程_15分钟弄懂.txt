Timestamp: 2025-11-21T14:28:22.657650
Title: AI 提示词工程 上下文工程 15分钟弄懂！
URL: https://www.youtube.com/watch?v=-8Ygq9AVWZ8
Status: success
Duration: 16:24

Description:
好的，这是根据您提供的文本内容提炼的核心思想摘要。

### **核心思想纲要**

1.  **提示词工程 (Prompt Engineering)：优化单次人机交互**
    *   **核心定义**:
        *   **提示词 (Prompt)**: 用户向AI发出的指令或问题，是人机交互的基础。
        *   **分类**:
            *   **系统提示词 (System Prompt)**: 用于为AI设定角色、背景和行为准则。
            *   **用户提示词 (User Prompt)**: 用户在对话框中输入的具体问题。
    *   **核心目标**: 通过精心设计提问的方式，约束AI的行为，使其返回更精准、稳定且符合预期的回答。
    *   **关键技巧**:
        *   **Zero-Shot**: 只提出要求，不提供具体范例来引导AI。
        *   **Few-Shot**: 在提示词中提供少量范例，指导AI模仿其风格或格式，尤其适用于需要结构化输出的场景。
        *   **思维链 (Chain-of-Thought, COT)**: 引导AI“一步步思考”并展示推理过程，以提高解决复杂问题（如数学运算）的准确率。

2.  **上下文工程 (Context Engineering)：管理AI的长程自主任务**
    *   **核心定义**:
        *   **问题背景**: AI模型本身没有记忆，其“记忆”是通过将完整的对话历史（即**上下文**）重复发送给模型来实现的。
        *   **挑战**: 当AI Agent使用工具（如网页浏览）执行多步自主任务时，上下文会迅速变得冗长、充满中间信息，导致AI容易“迷失”并偏离最初的核心任务。
    *   **核心目标**: 通过一系列程序化规则，自动管理和修改上下文，确保AI在无人实时干预的长程任务中，始终牢记并专注于最初的目标。
    *   **关键技巧**:
        *   **维护焦点 (AI记笔记)**: 提供“记笔记”工具，并用系统提示词指导AI将任务清单等核心目标记录下来，再将笔记置于上下文最显眼（开头/结尾）的位置，以持续引导AI。
        *   **压缩上下文 (Context Compression)**:
            *   **截断**: 直接丢弃过旧的消息。
            *   **总结**: 让AI将旧消息总结成精华，用总结替换原文。
            *   **外部化**: 将网页全文等长内容存入临时数据库（类似RAG），在上下文中仅保留简短的调用指令，大幅缩减长度。
        *   **优化源头**: 在工具返回信息时，预先处理和清理（如去除HTML标签），从源头减少上下文的冗余。

---

### **核心结论**

“提示词工程”通过优化提问来控制AI的单次输出，而“上下文工程”则通过管理对话历史来确保AI在复杂的、多步骤的自主任务中保持专注和方向。

---

### **内容的总览框架**

本文内容构建了一个从**“单次交互优化”**到**“长程任务管理”**的人机协作演进框架，揭示了随着AI能力从简单问答发展到能够自主使用工具完成复杂任务，人类控制和引导AI的策略也必须相应地从“提示词工程”深化到“上下文工程”。

---

### **概念关系图 (Mermaid)**

<Mermaid_Diagram>
graph TD
    subgraph "AI交互控制策略"
        direction LR
        A["提示词工程
(Prompt Engineering)"]
        B["上下文工程
(Context Engineering)"]
    end

    subgraph "优化单次交互 (Optimizing Single Interaction)"
        A -- "关注" --> P["提示词 (Prompt)"]
        P --> P1["系统提示词"]
        P --> P2["用户提示词"]
        A -- "核心目标" --> G1["获得精准、稳定的回复"]
        A -- "关键技巧" --> T1["Zero-Shot"]
        A -- "关键技巧" --> T2["Few-Shot"]
        A -- "关键技巧" --> T3["思维链 (COT)"]
    end

    subgraph "管理长程任务 (Managing Long-term Tasks)"
        B -- "关注" --> C["上下文 (Context)
对话历史"]
        C -- "挑战: AI Agent + 工具" --> Problem["上下文冗长导致任务偏离"]
        B -- "核心目标" --> G2["确保AI不偏离最初目标"]
        B -- "关键技巧" --> S1["维护焦点 (AI记笔记)"]
        B -- "关键技巧" --> S2["压缩上下文"]
        B -- "关键技巧" --> S3["优化工具返回值"]
    end

    style A fill:#F9F7D8,stroke:#333,stroke-width:2px
    style B fill:#F9F7D8,stroke:#333,stroke-width:2px
    style P fill:#E6F3FF,stroke:#333,stroke-width:1px
    style C fill:#E6F3FF,stroke:#333,stroke-width:1px
    style G1 fill:#D5E8D4,stroke:#1E8449,stroke-width:2px
    style G2 fill:#D5E8D4,stroke:#1E8449,stroke-width:2px
    style Problem fill:#F8CECC,stroke:#B85450,stroke-width:2px
    style T1 fill:#DAE8FC,stroke:#6C8EBF,stroke-width:1px
    style T2 fill:#DAE8FC,stroke:#6C8EBF,stroke-width:1px
    style T3 fill:#DAE8FC,stroke:#6C8EBF,stroke-width:1px
    style S1 fill:#DAE8FC,stroke:#6C8EBF,stroke-width:1px
    style S2 fill:#DAE8FC,stroke:#6C8EBF,stroke-width:1px
    style S3 fill:#DAE8FC,stroke:#6C8EBF,stroke-width:1px
</Mermaid_Diagram>

Content:
不知从什么时候开始,很多简单的事情都得换一个高级的说法卖东西叫分销、赚钱、变县、写文章、内容书出、拉人进群叫思欲隐留就连AI写代码也得有个新词叫外部Coding人们总是倾向用高级的词会来演改内容的规法今天我们来聊几个AI时代的流行词提示词、提示词工程、商下文以及那个宣称可以把提示词工程采在脚下摩擦的上下文工程大园模型刚出现的时候主要就是一个聊天机器人用户说你好,大园模型可能会回复,我很好你呢?经过几年的发展,AI的能力已经远远的超过了普通的聊天机器人但聊天依然是AI最核心,也是最实用的功能之一在聊天这个场景下,用户说的你好,就叫做Proud中文翻译过来提示词,所以提示词最基本的定义就是用户发给AI的话对于我很好你呢?这种四平八稳的回答虽然能满足大多数人在多数情况下的期望但这也注定这种回答将会是感巴巴了毫不特色的所以即使只是聊天也可以用上一些聊天机巧比如说我们可以用提示词给AI设定一个角色举个例子,你跟他说,你来扮演一个猫娘,接下来我说你好这个时候AI就可能回复,我很好你呢?名,把这种玩法推向极致的一个软件叫做Clythawan为了保证这期视频不被和解,这里我就不展开多说了有兴趣的朋友可以自己去搜一下但是问题来了,你扮演猫娘这种设定,并不是用户对话内容本身把这种设定和用户真正想说的话混在一起不仅容易出戏,逻辑上也有点乱所以大模型的厂商们就把提示词分成了两部分向你扮演一个猫娘这种设定叫做Sitant prompt也就是系统提示词,而用户说的你好则叫做User prompt也就是用户提示词我们平时在聊天矿里输入的就是用户提示词而系统提示词呢?通常是聊天机器人内置的用户一般不能直接修改不过很多AI应用来提供了一些功能可以间接的影响系统提示词比如在CatGPT里面有一个叫做Customize ChatGPT的功能可以设定一些用户的个人偏好这些信息最终就会成为系统提示词的一部分从而影响CatGPT的输出内容这种通过系统提示词和用户提示词的组合来引导AI返回特定风格回复的做法就叫做提示词工程Prob to Engineering当然了提示词工程可不止是用来玩角色扮演的它最核心的目的是通过一系列技巧来约束AI的行为让它的回复更加稳定减少错误和意外下面我们就来介绍几种常见的技巧比如说AI不太擅长处理数学问题再让它解数学体的时候就比较容易做错这个时候我们就会要求它在回复前仔细的检查确保它的答案是正确的在比如说有时候AI会拒绝回答我们一些问题这个时候就可以在提示词中告诉AI这件事情的严重性于是AI就会偏向于输出更加完整的答案了这些都属于行为的约束像这种只提要求但是不给AI模型具体例子的技巧还有一个专门的叫法叫做ZeroShot与此对应的就是FuelShot这种方法是指用户可以在提示词里面先给AI几个具体的例子当作参考比如说我希望AI帮我把正常的句子转化成猫娘体我就可以在提示词里面先举例比如我们去吃饭吧转化成我们去吃饭好不好压秒我写了一个程序转化成我把程序录好了秒给出范例之后我们再提出真正的需求现在来转化这个句子亲爱的我买了包包送给你这样AI就会根据我们提供的例子给出更贴近预期的答案了比如说回复亲爱的我抓了老数送给你秒FuelShot这个技巧在要求AI返回特径格式的场景下会特别的有用比如说当我们写一个AI应用或者AIAZN的时候通常需要AI稳定的返回带有某种格式的自负串这种场景下用FuelShot就非常的合适如果有朋友想了解AIZN的是什么可以参考这两期视频或者我的知识星球我会分别从原理和编程实现讲明白AIAZN的到底是怎么回事连接我会制定在评论区除了ZeroShot和FuelShot还有一种更加旋学的技巧叫做思维链Chin of Salt 简称COT举个简单的例子我们问AI一到数学体1加2成3等一多少因为大圆模型本质上是一个概率模型它其实并不擅长做精确的数学运算对于这种问题尤其是在早期的模型上精度是比较低的这个时候我们就可以在问题后面多加一句话比如说不要先给出答案请一步一步的拆解问题并且给出每一步的中间结果收到这个指令之后AI的回复就可能变成了根据运算优先级第一步需要先计算二唱一三结果16然后再计算1加6最终结果是7虽然模型本身是没有变的但我们通过提示词引导它一步步思考然后再输出最终算对的概率就会大大的提升这就是所谓的思维链当然了我们觉得这个例子有点过于的简单了即使不用思维链AI基本也不会算错而且如今的网页版聊天机器人大多数都内置了比我们这个例子强大的多的思维链功能不再需要拥护手动输入额外的提示词了但他们背后的原理都是一样的都是通过提示词让AI自己分解问题输出推理过程从而解决更加复杂的问题总结一下所谓的提示词工程本质上就是通过精心设计我们向AI提问的方式来获得更精准更符合我们预期的回答在聊上下文上下文工程之前我们首先要澄清一个事实AI模型本身是没有记忆的这意味著每次我们给AI发送一个消息对它来说都是一次全新的独立的请求但很显然我们在进行连续对话的时候是需要AI寄入我们聊过什么的否则对话就无法成立了那么这个记忆到底是怎么实现的其实在我们和AI聊天的时候并不是直接把消息发送给大语言模型的拥护和AI之间还隔了一个AI agent或者聊天机器人的服务器正确的流程是这样的拥护把消息先发给AI agent或者聊天机器人服务器聊天机器人会把消息发送给AI模型的同时还会保留下完整的历史纪录然后当它收到一条新的用户消息的时候它会把这条消息附加到历史纪录的末尾最后再把这个包含了所有过往信息的完整历史纪录一起发给AI模型这样一来AI模型本身是失异的但它们一次收到了信息都是完整的对话所以看上去就像有了记忆一样这个被一次性发给AI的完整的历史纪录就叫做上下温Context而如何管理和修改这段历史纪录的技巧就被叫做上下温工程Context and Engineering那么这个上下闻到底有什么好管理的呢其实如果AI只是一个简单的一问一答形式的聊天机器人那我们之前聊的提示词工程基本就够用了因为在那种一来一回的对话中用户总有机会通过新的提示词来修正和引导AI的行为确保它的回答不会跑偏但是AI A-ZENTA的出现让情况变得复杂了起来AI A-ZENTA除了传递消息维护历史之外它还拥有一个工具箱里面有一些它自己定义的工具可以供AI模型来调用如果你觉得AI A-ZENTA的概念有点复杂我们还是以往夜版聊天机器人来举例许多往夜版聊天机器人提供了网页流览功能这种聊天机器人本质上就是一个简单的AI A-ZENTA而流览网页就是它提供了一个工具比如说当用户问猫娘的口头产是什么这个时候聊天机器人就会把当前的上下文连同它能使用了所有的工具说明一起都打包发送给AI模型AI模型收到消息之后就会发现工具箱里面有一个用于流览网页的工具可以用于是它可能会决定不直接回答用户的问题而是先用Google搜索一下此时AI模型就会返回一个特殊的指令叫做Torco这个指令大意就是帮我访问这个Google网址搜索猫娘的口头产是什么聊天机器人收到指令之后就会去调用访问网页的工具访问网页的工具就会去访问Google访回网页的内容接下来网页的内容会被打包成一条Torco Response消息和对应的Torco一起放到上下文之中而这个变得更常的上下文会被重新的发给AI模型这个时候AI可能还觉得信息还是不够又想去萌娘摆颗里面再查一下于是就又重复了一次刚才的那个过程上下文里面因此又多出了一对Torco和Torco Response对于比较复杂的问题在AI生成最终答案之前这样的一来一回可能会重复即时甚至上百次上下文就会变得特别特别的长这理请注意一下在这个漫长的探索过程之中用户能实家的影响只有在最最开头的那一句提示词而后续几十次Torco和Torco Response不仅数量多而且像是流兰网页这种Torco Response内容通常也非常的长不然想像当AI模型面对一个越来越长充斥了各种中间信息的上下文而用户又没办法即时的纠正它的行为的时候它的行动方向就很容易跑偏忘记自己到底要干什么所以如何通过一套程序化的规则来自动的管理和修改上下文确保AI在漫长的自主行动中使中符合用户的最初要求这就是上下文工程要解决的核心问题很可惜的是关于上下文到底要怎么管理目前还没有一个公认的完美方案不过这里我可以介绍几种在夜界比较常见比较有效的做法一招上AI学会记比计它的原理类似于我们之前提到的网页流览工具不过这次我们再给AI模型提供一个专门用来记比计的工具当AI在处理任务的时候如果想要记下一些关键信息就可以调用这个工具当然了只提供工具然后让AI自由的发挥记比计效果一般都不会太好所以我们还需要在系统提示词里面明确的给出笔记的使用策略比如说我们可以这样知道模型一在行动前先将任务分解二在笔记中写下你的任务清单三严格根据任务清单来执行任务四美完成一项就在笔记中更新该项的状态这样以来当AI再拿到猫娘的口头产是什么这个问题的时候大模型自己就会先头脑风暴出一个任务清单比如说一用谷歌搜索猫娘二用蒙娘百科搜索猫娘三综合两次的搜索结果总结出口头产然后AI就会通过之前我们介绍的tool code方法调用记比计的工具让Agent把这个清单记录下来现在我们来看一下整个上下文是什么样子里面包含了最开始的系统提示词和用户提示词还有AI调用记比计的tool code和tool response其中的tool response一般不会包含什么有用的信息只是告诉AI笔记更新成功了而这里最关键的一步来了这个被保存的笔记会被Agent插入到整个上下文的开头或者结尾这个插入的位置其实也是有讲究的因为现在的大语言模型普遍采用的是Transformer架构而这种架构天生就对输入信息的开头和结尾部分特别的敏感所以即使上下文变得非常长无论AI中间执行了多少次tool code和tool response开头结尾的信息也基本不会被模型忽略写著核心目标的任务清单和最初的提示词使中都处在最显眼的位置当AI完成一项任务比如用Google搜索猫娘它又会根据系统提示词的指示再次调用记比计的工具把第一项任务标记为一完成然后开始执行第二项通过这种方式就能很大的程度上保证AI在执行复杂的任务的时候不会跑偏当然了比计里面也不仅限于记录任务的清单比如说我们还可以通过系统提示词让AI记录搜索出的关键信息便于后续进行总结等等但无论记录什么这项技术的本质都是人类拥护通过控制最初的提示词来指导AI如何写比计再通过把比计放到上下文中最显眼的位置来间接引导整个AI的处理流程那么既然上下文太长是问题的根源另一个优化的方向就是让它变短最直接的做法就是直接丢掉太老的消息只保留新的消息当然了最开始的系统和用户提示词部分是必须要保留的不然AI就不知道自己要干什么了如果你觉得直接舍弃信息这种方式太暴力了可能会丢失关键的内容那么还有一种更加优雅的做法就是压缩许多Agent会把较老的消息提取出来然后让AI模型去总结其中的关键信息再用这个精链的总结去替换掉原来的上下文从而达到压缩的目的除了这些还有更高级的压缩方法某些Touris Bounce可能会非常的长比如说包含了一篇上万字的文章这个时候Agent就会先把Touris Bounce的内容处理后存到一个脸时的相量数据库里面这个过程就类似我们之前讲过的Rug技术Rug的知识可以回顾我做的这一期视频连接我会指点到评论区文章存入之后Agent就会修改这次的Touris Bounce不再包含原文而是用一句话来代替比如说文章已经存入知识库我为你提供了一个新的工具叫做Corey Document你可以用它来查学文章的片段然后AAM模型就只要查找自己感兴趣的片段就可以了这样以来一个几万字的Touris Bounce就会压缩成了一句几十个字的指令和一些AI主动查出来的片段上下文的长度就得到了很大的控制还有一种方法是直接优化工具的反回值比如说对网页流暖工具Agent可以先去掉网页里面不必要的HTML标签只把最核心的内容反回给AI模型从源头就减少信息的荣誉当然了这里我提到的只是机种比较常见的上下文观力方法这是一个非常热门的AI应用研究方向新的研究和技术也在不断的永限之中总而言之无论是我们前面聊的记忆技还是刚刚所说的减少上下文长度的各种方法所有所有的一切目的都只有一个在人类用户无法实实干预AI行动的时候确保AI模型时中都记得自己最初的任务是什么小学的时候老师问我们长大以后想做什么当时我在作业本上写下的答案是当老师因为我觉得他们是超人什么都懂什么都能讲的明明白白的也不知道老师当时花了多少心思到底用了什么神器的方法过去了几十年我现在依然还记得这里是成全老王我们下期再见
