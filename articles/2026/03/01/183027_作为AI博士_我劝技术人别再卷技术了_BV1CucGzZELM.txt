Timestamp: 2026-03-01T18:30:27.631544
Title: 作为AI博士，我劝技术人别再卷技术了 BV1CucGzZELM
URL: https://b23.tv/yOD519s
Status: success
Duration: 3:15

Description:
**第一部分：文本分析**

1.  **核心论点 (Argument)**
    *   在AI时代，像数据科学家和程序员这样的技术人员，因为其工作模式高度标准化且习惯于确定性地“实现能力”，反而是最容易被AI淘汰的群体。
    *   未来的竞争力将不再是技术能力本身，而是理解资本与系统、对不确定性的容忍度、以及从执行者向设计者、从技术视角向资本视角、从打工逻辑向资产逻辑的认知升级。

2.  **关键证据/例子 (Evidence)**
    *   **作者个人经历：** 在河南大厂七八年数据科学家经验，后在欧洲大厂工作七年，目前为来顿大学AI博士在读，这些背景让他对技术人的职业瓶颈有切身体会。
    *   **AI的优势：** AI作为“更强大的函数”，比人更快、更便宜，且不会抱怨加班，能无限逼近甚至超越技术人员的“实现能力”。
    *   **技术人的局限性：**
        *   习惯被需要，被训练成从输入到输出的“函数”模式。
        *   其价值主要体现在“实现能力”上。
        *   偏爱确定性，如明确的需求、任务、模型、预算和算法。
        *   习惯“向上证明”（GPA、项目成果、论文发表、技术规定、技术深度），而非“向外创造”。
    *   **大厂职业困境：** 在大厂，职位越高级，越像组织模块，仅负责某个算法/模型/系统，却不负责资本分配、产品闭环，本质仍是执行层的高端版本。
    *   **创业试错经验：** 作者自2022年起用AI尝试各种创业，虽未大成功但赚了几万块，从中领悟到真正的核心竞争力是对不确定性的容忍度，而非纯粹的技术能力。

3.  **逻辑推导 (Reasoning)**
    *   **起点：** 技术人（尤其是数据科学家）的核心价值在于其“实现能力”和对标准化、确定性任务的执行。
    *   **AI的冲击：** AI是一个拥有更强实现能力、更低成本且不知疲倦的“函数”，它将无限逼近并最终超越技术人的执行价值。
    *   **后果：** 由于技术人高度标准化、习惯确定性，他们在AI时代将成为“最容易被淘汰的一群人”，其价值将被AI“异化”为可调用的API。
    *   **问题核心：** 技术人偏爱确定性，习惯向上证明而非向外创造，且在大厂中受限于执行层。
    *   **解决方案：** 为了应对这种危机，技术人必须进行认知升级，包括：
        *   从执行者转变为系统设计者。
        *   从技术视角转变为资本视角。
        *   从打工逻辑转变为资产逻辑。
    *   **新能力要求：** 这需要理解资本与系统，培养对不确定性的容忍度，并懂得利用技术作为工具，认知作为杠杆，资本作为放大器来进行“创造”。
    *   **目标：** 通过这种转型，建立底层安全感，实现更自由的职业与生活模式（如半年国内陪父母，半年国外工作用AI做项目）。

4.  **批判性反驳 (Devil's Advocate Audit)**
    *   **AI能力是否被过分高估？** 作者将AI描述为“更强大的函数”，能无限逼近所有实现能力。然而，AI在理解模糊需求、进行跨领域创新、复杂系统集成、伦理决策以及需要人类情感与直觉的领域，仍存在显著局限。技术人的价值并非仅限于代码编写或模型构建，还包括问题定义、系统架构、领域知识整合、人机协作、伦理考量等，这些并非AI短期内能完全替代。
    *   **“最容易被淘汰”的论断是否过于绝对？** “最笨的人”和“最标准化的人”哪个先被淘汰本身有争议。许多低技能、重复性高的体力劳动或初级脑力劳动，可能比高端但标准化的技术工作更容易被自动化。顶尖的AI研究员、架构师、创新者，其独创性和复杂问题解决能力，短期内仍是稀缺资源。
    *   **转型资本视角是否普适且可行？** 作者提出转向理解资本和系统，但这需要完全不同的知识体系、人脉和风险承受能力，并非所有技术人都能或愿意转型。这是否是将技术人推向一个他们不擅长的领域，从而面临新的“不确定性”风险？此外，如果所有人都去搞资本和系统设计，谁来负责底层的技术实现和创新？
    *   **忽略了AI赋能技术人的可能性：** 作者将AI主要视为替代者和竞争者，但AI也可以是技术人的强大工具，帮助他们提高效率、加速创新、处理更复杂的问题，从而提升技术人的价值。将AI视为纯粹的威胁而非协作伙伴，可能过于片面。
    *   **个人目标是否具普遍性？** “半年回中国陪父母，半年在国外工作用AI做自己的项目用投资建立底层安全感”这个愿景，听起来更像是达到财务自由后的理想状态，而非普遍适用于所有技术人的AI时代生存策略。将其作为“躺平”的定义，可能脱离了大部分人的现实。
    *   **“大厂越高级越像组织的一个模块”：** 这更多是对大型组织管理模式的批判，而非AI本身带来的新问题。即使没有AI，大公司的层级结构也可能导致高级职位缺乏全局决策权。

**第二部分：Mermaid 概念图**

<Mermaid_Diagram>
graph TD
    subgraph "技术人现状 (现状与局限)"
        direction LR
        A["技术人 (数据科学家/程序员)"]:::tech_person
        A -- "习惯" --> B["确定性需求/被需要"]:::charact
        A -- "价值基于" --> C["实现能力 (高效执行者)"]:::charact
        A -- "成长路径" --> D["向上证明 (GPA, 论文, 成果)"]:::charact
        A -- "职业天花板" --> E["大厂高级岗 = 组织模块 (执行层高端)"]:::charact
    end
    style "技术人现状 (现状与局限)" fill:#FFF8E1,stroke:#FFD54F,stroke-width:2px;

    subgraph "AI冲击 (外部挑战)"
        direction LR
        F["AI: 更快、更便宜、不抱怨的 '函数'"]:::ai_power
        G["AI让执行成本趋近于零"]:::ai_impact
        H["AI优先淘汰最标准化的人"]:::ai_impact
    end
    style "AI冲击 (外部挑战)" fill:#E3F2FD,stroke:#90CAF9,stroke-width:2px;

    %% Central problem
    B & C & D & E & F & G & H --> I["结论: 技术人是AI时代最易被淘汰的一群人"]:::risk_danger
    I --> J["后果: 不升级认知 -> 被AI变成可调用的API"]:::risk_danger

    subgraph "转型路径 (应对策略)"
        direction TB
        K["策略1: 从执行者 -> 系统设计者"]:::solution
        L["策略2: 从技术视角 -> 资本视角"]:::solution
        M["策略3: 从打工逻辑 -> 资产逻辑"]:::solution
    end
    style "转型路径 (应对策略)" fill:#E8F5E9,stroke:#81C784,stroke-width:2px;

    I --> K
    I --> L
    I --> M

    subgraph "核心理念 (认知升级)"
        direction TB
        N["理解资本和系统"]:::new_skill
        O["对不确定性的容忍度"]:::new_skill
        P["向外创造 (而非向上证明)"]:::new_skill
        Q["技术 = 工具"]:::new_skill
        R["认知 = 杠杆"]:::new_skill
        S["资本 = 放大器"]:::new_skill
    end
    style "核心理念 (认知升级)" fill:#F3E5F5,stroke:#CE93D8,stroke-width:2px;

    K -- "要求" --> N
    L -- "要求" --> N
    M -- "要求" --> N

    N --> O
    O --> P

    K & L & M --> Q
    K & L & M --> R
    K & L & M --> S

    subgraph "作者个人目标 (愿景)"
        direction LR
        T["半年中国陪父母"]:::goal
        U["半年国外工作, AI做项目, 投资建安全感"]:::goal
    end
    style "作者个人目标 (愿景)" fill:#FFFDE7,stroke:#FFEB3B,stroke-width:2px;

    P & N & Q & R & S --> T
    P & N & Q & R & S --> U

    subgraph "😈 批判性反驳 (Devil's Advocate Audit)"
        direction TB
        DA_title["审计质疑点"]:::audit_title
        DA1["AI能力被高估? (缺乏创新/模糊判断)"]:::audit
        DA2["技术人价值仅是'实现能力'? (问题定义/架构/协作)"]:::audit
        DA3["'最易淘汰'论断过于绝对? (低技能劳动 vs. 高端技术)"]:::audit
        DA4["转型资本视角普适且可行? (高门槛/不适合所有人)"]:::audit
        DA5["忽略AI赋能技术人? (AI是工具而非纯竞争者)"]:::audit
        DA6["个人目标普适性不足? (财务自由的特例)"]:::audit
    end
    style "😈 批判性反驳 (Devil's Advocate Audit)" fill:#FDF4F5,stroke:#E91E63,stroke-width:2px;
    style DA_title fill:#FCE4EC,stroke:#E91E63,color:#880E4F,font-weight:bold;

    DA1 --> F
    DA2 --> C
    DA3 --> H
    DA4 --> L
    DA5 --> F
    DA6 --> U

    %% Node Styles
    classDef tech_person fill:#FFCCBC,stroke:#FF8A65,stroke-width:2.5px,color:#BF360C,font-weight:bold;
    classDef charact fill:#FFE0B2,stroke:#FFCC80,stroke-width:1.5px,color:#E65100;
    classDef ai_power fill:#BBDEFB,stroke:#64B5F6,stroke-width:2.5px,color:#1976D2,font-weight:bold;
    classDef ai_impact fill:#90CAF9,stroke:#42A5F5,stroke-width:1.5px,color:#1976D2;
    classDef risk_danger fill:#FFCDD2,stroke:#EF9A9A,stroke-width:3px,color:#C62828,font-weight:bold;
    classDef solution fill:#C8E6C9,stroke:#A5D6A7,stroke-width:2.5px,color:#2E7D32,font-weight:bold;
    classDef new_skill fill:#E1BEE7,stroke:#CE93D8,stroke-width:1.5px,color:#6A1B9A;
    classDef goal fill:#FFFDE7,stroke:#FFEB3B,stroke-width:2px,color:#FBC02D,font-weight:bold;
    classDef audit fill:#FBE9E7,stroke:#FFAB91,stroke-width:1.5px,color:#BF360C,font-weight:italic;
</Mermaid_Diagram>

Content:
我在河南大厂做了七到八年的数据科学家现在也是来顿大学AI博士在读很多人会觉得你这种背景应该是AI时代最安全的人吧但我反而觉得并不是就是我越来越清楚一件事情基础人是AI时代最容易被淘汰的一群人而且不是因为不够聪明恰恰相反是因为太习惯了被需要就是我们这样的比如说程序远啊或者做技术的经常会被训练成一种人就是你给我需求我写代码你给数据我建模型给问题优化算法我们是一个从书路到书出的一个寒树但问题是大模型就是一个更强大的寒树它比你更快 比你更便宜而且不会抱怨加班当你的价值是实现能力AI会无限逼递你那我在欧洲大厂工作了七年走到了一个职业天花板你会发现金树港越高级越像组织的一个模块你负责某个算法 某个模型某个系统但你不负责也无方向资本分配 资本流动 产品庇还你只是执行层的高端的一个版本而AI正在让执行这件事成本驱进为灵我2022年开始用AI做过各种创业转过几万块钱 说实话都不算成功但这些试错让我一试到一件事就是真正靠风险的是不是技术能力而是对不确定性的一种融稳度技术人太喜欢确定性明确的需求 明确的任务明确的模型预算 明确的算法而AI实在没有确定性技术人习惯向上证明而不是向外创造我们一生都在证明 比如说GPA或者是项目成果 若文发表技术规定 技术深度但创业和投资不是证明有喜 是创造有喜我不想再甚至加薪 我更想的是半年回中国陪父母半年在国外工作用AI做自己的项目用投资建立底层安全感林乡躺平就要学会换塞到AI不会先淘汰最笨的人它会先淘汰就是最标准化的人而技术的人是最容易被标准化的那一群人那怎么办呢我们可以做的事情有三件第一就是从一个执行者变成一个系统的设计者然后第二点就是从技术的视角变成一个资本的视角最后要从一个打工的逻辑变成一个资产的逻辑你可以不会写最牛的模型但是你要知道模型解决什么问题谁为这个问题付钱钱又从哪里扭动谁在收割这个认知产我现在也学投资每天赴盘市场我越来越确定未来不是拼谁写得出贷吗而是拼谁理解资本和系统技术它只是工具认知是杠杆资本是放大器技术人如果不升级认知解购AI就会把你变成一个可以被调用的API
